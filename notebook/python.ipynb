{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae82080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Learning\\AI\\rag-intro\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: ML intro new one.pdf\n",
      "  ✓ Loaded 237 pages\n",
      "\n",
      "Processing: ML intro.pdf\n",
      "  ✓ Loaded 20 pages\n",
      "\n",
      "Total documents loaded: 257\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05db6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 257 documents into 703 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: arXiv:1709.02840v3  [cs.LG]  17 May 2018\n",
      "A Brief Introduction to Machine\n",
      "Learning for Engineers\n",
      "(2018), “A Brief Introduction to Machine Learning for Engin eers”, :\n",
      "V ol. XX, No. XX, pp 1– 231. DOI: X...\n",
      "Metadata: {'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 0, 'page_label': 'i', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 0, 'page_label': 'i', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='arXiv:1709.02840v3  [cs.LG]  17 May 2018\\nA Brief Introduction to Machine\\nLearning for Engineers\\n(2018), “A Brief Introduction to Machine Learning for Engin eers”, :\\nV ol. XX, No. XX, pp 1– 231. DOI: XXX.\\nOsvaldo Simeone\\nDepartment of Informatics\\nKing’s College London\\nosvaldo.simeone@kcl.ac.uk'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 1, 'page_label': 'ii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Contents\\nI Basics 5\\n1 Introduction 6\\n1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . 6\\n1.2 When to Use Machine Learning? . . . . . . . . . . . . . . 8\\n1.3 Goals and Outline . . . . . . . . . . . . . . . . . . . . . . 11\\n2 A Gentle Introduction through Linear Regression 15\\n2.1 Supervised Learning . . . . . . . . . . . . . . . . . . . . . 15\\n2.2 Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n2.3 Frequentist Approach . . . . . . . . . . . . . . . . . . . . 19\\n2.4 Bayesian Approach . . . . . . . . . . . . . . . . . . . . . 36\\n2.5 Minimum Description Length (MDL) ∗ . . . . . . . . . . . 42\\n2.6 Information-Theoretic Metrics . . . . . . . . . . . . . . . . 44\\n2.7 Interpretation and Causality ∗ . . . . . . . . . . . . . . . . 47\\n2.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n3 Probabilistic Models for Learning 51\\n3.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . 52'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 1, 'page_label': 'ii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n3 Probabilistic Models for Learning 51\\n3.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . 52\\n3.2 The Exponential Family . . . . . . . . . . . . . . . . . . . 53\\n3.3 Frequentist Learning . . . . . . . . . . . . . . . . . . . . . 59'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 2, 'page_label': 'iii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4 Bayesian Learning . . . . . . . . . . . . . . . . . . . . . . 63\\n3.5 Supervised Learning via Generalized Linear Models (GLM ) 69\\n3.6 Maximum Entropy Property ∗ . . . . . . . . . . . . . . . . 71\\n3.7 Energy-based Models ∗ . . . . . . . . . . . . . . . . . . . . 72\\n3.8 Some Advanced T opics ∗ . . . . . . . . . . . . . . . . . . . 73\\n3.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\nII Supervised Learning 75\\n4 Classiﬁcation 76\\n4.1 Preliminaries: Stochastic Gradient Descent . . . . . . . . . 77\\n4.2 Classiﬁcation as a Supervised Learning Problem . . . . . . 78\\n4.3 Discriminative Deterministic Models . . . . . . . . . . . . 80\\n4.4 Discriminative Probabilistic Models: Generalized Lin ear Mod-\\nels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\n4.5 Discriminative Probabilistic Models: Beyond GLM . . . . . 96\\n4.6 Generative Probabilistic Models . . . . . . . . . . . . . . . 102\\n4.7 Boosting ∗ . . . . . . . . . . . . . . . . . . . . . . . . . . 106'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 2, 'page_label': 'iii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.6 Generative Probabilistic Models . . . . . . . . . . . . . . . 102\\n4.7 Boosting ∗ . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\n4.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\\n5 Statistical Learning Theory ∗ 113\\n5.1 A Formal Framework for Supervised Learning . . . . . . . 114\\n5.2 P AC Learnability and Sample Complexity . . . . . . . . . . 119\\n5.3 P AC Learnability for Finite Hypothesis Classes . . . . . . . 120\\n5.4 VC Dimension and Fundamental Theorem of P AC Learning 124\\n5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nIII Unsupervised Learning 129\\n6 Unsupervised Learning 130\\n6.1 Unsupervised Learning . . . . . . . . . . . . . . . . . . . . 131\\n6.2 K-Means Clustering . . . . . . . . . . . . . . . . . . . . . 134\\n6.3 ML, ELBO and EM . . . . . . . . . . . . . . . . . . . . . 136\\n6.4 Directed Generative Models . . . . . . . . . . . . . . . . 148\\n6.5 Undirected Generative Models . . . . . . . . . . . . . . . 155'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 3, 'page_label': 'iv', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.6 Discriminative Models . . . . . . . . . . . . . . . . . . . . 159\\n6.7 Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . 161\\n6.8 Ranking ∗ . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\n6.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\\nIV Advanced Modelling and Inference 165\\n7 Probabilistic Graphical Models 166\\n7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 167\\n7.2 Bayesian Networks . . . . . . . . . . . . . . . . . . . . . . 170\\n7.3 Markov Random Fields . . . . . . . . . . . . . . . . . . . 178\\n7.4 Bayesian Inference in Probabilistic Graphical Models . . . . 182\\n7.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\\n8 Approximate Inference and Learning 186\\n8.1 Monte Carlo Methods . . . . . . . . . . . . . . . . . . . . 187\\n8.2 Variational Inference . . . . . . . . . . . . . . . . . . . . . 189\\n8.3 Monte Carlo-Based Variational Inference ∗ . . . . . . . . . 197'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 3, 'page_label': 'iv', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2 Variational Inference . . . . . . . . . . . . . . . . . . . . . 189\\n8.3 Monte Carlo-Based Variational Inference ∗ . . . . . . . . . 197\\n8.4 Approximate Learning ∗ . . . . . . . . . . . . . . . . . . . 199\\n8.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nV Conclusions 202\\n9 Concluding Remarks 203\\nAppendices 206\\nA Appendix A: Information Measures 207\\nA.1 Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\\nA.2 Conditional Entropy and Mutual Information . . . . . . . . 210\\nA.3 Divergence Measures . . . . . . . . . . . . . . . . . . . . 212\\nB Appendix B: KL Divergence and Exponential Family 215\\nAcknowledgements 217'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 4, 'page_label': 'v', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 218'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 5, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A Brief Introduction to Machine\\nLearning for Engineers\\nOsvaldo Simeone 1\\n1 Department of Informatics, King’s Col lege London;\\nosvaldo.simeone@kcl.ac.uk\\nABSTRACT\\nThis monograph aims at providing an introduction to key\\nconcepts, algorithms, and theoretical results in machine l earn-\\ning. The treatment concentrates on probabilistic models\\nfor supervised and unsupervised learning problems. It in-\\ntroduces fundamental concepts and algorithms by building\\non ﬁrst principles, while also exposing the reader to more\\nadvanced topics with extensive pointers to the literature,\\nwithin a uniﬁed notation and mathematical framework. The\\nmaterial is organized according to clearly deﬁned categori es,\\nsuch as discriminative and generative models, frequentist\\nand Bayesian approaches, exact and approximate inference,\\nas well as directed and undirected models. This monograph\\nis meant as an entry point for researchers with an engineer-\\ning background in probability and linear algebra.\\nISSN ; DOI XXXXXXXX'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 5, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as well as directed and undirected models. This monograph\\nis meant as an entry point for researchers with an engineer-\\ning background in probability and linear algebra.\\nISSN ; DOI XXXXXXXX\\nc⃝ 2018 XXXXXXXX'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 6, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Notation\\n•Random variables or random vectors – both abbreviated as rvs\\n– are represented using roman typeface, while their values a nd realiza-\\ntions are indicated by the corresponding standard font. F or instance,\\nthe equality x = x indicates that rv x takes value x.\\n•Matrices are indicated using uppercase fonts, with roman ty pe-\\nface used for random matrices.\\n•V ectors will be taken to be in column form.\\n•XT and X† are the transpose and the pseudoinverse of matrix X,\\nrespectively .\\n•The distribution of a rv x, either probability mass function (pmf)\\nfor a discrete rv or probability density function (pdf) for c ontinuous\\nrvs, is denoted as px , px (x), or p(x).\\n•The notation x ∼px indicates that rv x is distributed according\\nto px .\\n•F or jointly distributed rvs (x ,y) ∼pxy, the conditional distribu-\\ntion of x given the observation y = y is indicated as px|y=y , px|y(x|y)\\nor p(x|y).\\n•The notation x |y = y ∼px|y=y indicates that rv x is drawn ac-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 6, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion of x given the observation y = y is indicated as px|y=y , px|y(x|y)\\nor p(x|y).\\n•The notation x |y = y ∼px|y=y indicates that rv x is drawn ac-\\ncording to the conditional distribution px|y=y .\\n•The notation E x∼px [·] indicates the expectation of the argument\\nwith respect to the distribution of the rv x ∼px . Accordingly , we will\\nalso write E x∼px|y [·|y] for the conditional expectation with respect to\\nthe distribution px|y=y . When clear from the context, the distribution\\nover which the expectation is computed may be omitted.\\n•The notation Pr x∼px [·] indicates the probability of the argument\\nevent with respect to the distribution of the rv x ∼px. When clear\\n1'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 7, 'page_label': '2', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2 Notation\\nfrom the context, the subscript is dropped.\\n•The notation log represents the logarithm in base two, while ln\\nrepresents the natural logarithm.\\n•x ∼N(µ,Σ) indicates that random vector x is distributed accord-\\ning to a multivariate Gaussian pdf with mean vector µ and covariance\\nmatrix Σ. The multivariate Gaussian pdf is denoted as N(x|µ,Σ) as a\\nfunction of x.\\n•x ∼U(a,b) indicates that rv x is distributed according to a uni-\\nform distribution in the interval [ a,b]. The corresponding uniform pdf\\nis denoted as U(x|a,b).\\n•δ(x) denotes the Dirac delta function or the Kronecker delta fun c-\\ntion, as clear from the context.\\n•||a||2 = ∑ N\\ni=1 a2\\ni is the quadratic, or l2, norm of a vector a =\\n[a1 ,...,aN ]T . W e similarly deﬁne the l1 norm as ||a||1 = ∑ N\\ni=1 |ai |, and\\nthe l0 pseudo-norm ||a||0 as the number of non-zero entries of vector a.\\n•I denotes the identity matrix, whose dimensions will be clear from\\nthe context. Similarly , 1 represents a vector of all ones.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 7, 'page_label': '2', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•I denotes the identity matrix, whose dimensions will be clear from\\nthe context. Similarly , 1 represents a vector of all ones.\\n•R is the set of real numbers; R+ the set of non-negative real num-\\nbers; R− the set of non-positive real numbers; and RN is the set of all\\nvectors of N real numbers.\\n•1 ( ·) is the indicator function: 1 ( x) = 1 if xis true, and 1 ( x) = 0\\notherwise.\\n•|S| represents the cardinality of a set S.\\n•xS represents a set of rvs xk indexed by the integers k∈S.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 8, 'page_label': '3', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Acronyms\\nAI: Artiﬁcial Intelligence\\nAMP: Approximate Message Passing\\nBN: Bayesian Network\\nDAG: Directed Acyclic Graph\\nELBO: Evidence Lower BOund\\nEM: Expectation Maximization\\nERM: Empirical Risk Minimization\\nGAN: Generative Adversarial Network\\nGLM: Generalized Linear Model\\nHMM: Hidden Markov Model\\ni.i.d.: independent identically distributed\\nKL: Kullback-Leibler\\nLASSO: Least Absolute Shrinkage and Selection Operator\\nLBP: Loopy Belief Propagation\\nLL: Log-Likelihood\\nLLR: Log-Likelihood Ratio\\nLS: Least Squares\\nMC: Monte Carlo\\nMCMC: Markov Chain Monte Carlo\\nMDL: Minimum Description Length\\nMFVI: Mean Field V ariational Inference\\nML: Maximum Likelihood\\nMRF: Markov Random Field\\nNLL: Negative Log-Likelihood\\nP AC: Probably Approximately Correct\\npdf: probability density function\\n3'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 9, 'page_label': '4', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4 Acronyms\\npmf: probability mass function\\nPCA: Principal Component Analysis\\nPPCA: Probabilistic Principal Component Analysis\\nQDA: Quadratic Discriminant Analysis\\nRBM: Restricted Boltzmann Machine\\nSGD: Stochastic Gradient Descent\\nSVM: Support V ector Machine\\nrv: random variable or random vector (depending on the conte xt)\\ns.t.: subject to\\nV AE: V ariational AutoEncoder\\nVC: V apnik–Chervonenkis\\nVI: V ariational Inference'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 10, 'page_label': '5', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part I\\nBasics'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 11, 'page_label': '6', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1\\nIntroduction\\nHaving taught courses on machine learning, I am often asked b y col-\\nleagues and students with a background in engineering to sug gest “the\\nbest place to start” to get into this subject. I typically res pond with a\\nlist of books – for a general, but slightly outdated introduc tion, read\\nthis book; for a detailed survey of methods based on probabil istic mod-\\nels, check this other reference; to learn about statistical learning, I\\nfound this text useful; and so on. This answer strikes me, and most\\nlikely also my interlocutors, as quite unsatisfactory . Thi s is especially\\nso since the size of many of these books may be discouraging fo r busy\\nprofessionals and students working on other projects. This monograph\\nis an attempt to oﬀer a basic and compact reference that descr ibes key\\nideas and principles in simple terms and within a uniﬁed trea tment,\\nencompassing also more recent developments and pointers to the liter-\\nature for further study .\\n1.1 What is Machine Learning?'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 11, 'page_label': '6', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ideas and principles in simple terms and within a uniﬁed trea tment,\\nencompassing also more recent developments and pointers to the liter-\\nature for further study .\\n1.1 What is Machine Learning?\\nA useful way to introduce the machine learning methodology i s by\\nmeans of a comparison with the conventional engineering des ign ﬂow.\\n6'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 12, 'page_label': '7', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.1. What is Machine Learning? 7\\nThis starts with a in-depth analysis of the problem domain, w hich cul-\\nminates with the deﬁnition of a mathematical model. The math emat-\\nical model is meant to capture the key features of the problem under\\nstudy , and is typically the result of the work of a number of ex perts.\\nThe mathematical model is ﬁnally leveraged to derive hand-c rafted so-\\nlutions to the problem.\\nF or instance, consider the problem of deﬁning a chemical pro cess\\nto produce a given molecule. The conventional ﬂow requires c hemists\\nto leverage their knowledge of models that predict the outco me of indi-\\nvidual chemical reactions, in order to craft a sequence of su itable steps\\nthat synthesize the desired molecule. Another example is th e design\\nof speech translation or image/ video compression algorith ms. Both of\\nthese tasks involve the deﬁnition of models and algorithms b y teams\\nof experts, such as linguists, psychologists, and signal pr ocessing prac-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 12, 'page_label': '7', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='these tasks involve the deﬁnition of models and algorithms b y teams\\nof experts, such as linguists, psychologists, and signal pr ocessing prac-\\ntitioners, not infrequently during the course of long stand ardization\\nmeetings.\\nThe engineering design ﬂow outlined above may be too costly a nd\\nineﬃcient for problems in which faster or less expensive sol utions are\\ndesirable. The machine learning alternative is to collect l arge data sets,\\ne.g., of labelled speech, images or videos, and to use this in formation\\nto train general-purpose learning machines to carry out the desired\\ntask. While the standard engineering ﬂow relies on domain kn owledge\\nand on design optimized for the problem at hand, machine lear ning\\nlets large amounts of data dictate algorithms and solutions . T o this\\nend, rather than requiring a precise model of the set-up unde r study ,\\nmachine learning requires the speciﬁcation of an objective , of a model\\nto be trained, and of an optimization technique.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 12, 'page_label': '7', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='end, rather than requiring a precise model of the set-up unde r study ,\\nmachine learning requires the speciﬁcation of an objective , of a model\\nto be trained, and of an optimization technique.\\nReturning to the ﬁrst example above, a machine learning appr oach\\nwould proceed by training a general-purpose machine to pred ict the\\noutcome of known chemical reactions based on a large data set , and\\nby then using the trained algorithm to explore ways to produc e more\\ncomplex molecules. In a similar manner, large data sets of im ages or\\nvideos would be used to train a general-purpose algorithm wi th the aim\\nof obtaining compressed representations from which the ori ginal input\\ncan be recovered with some distortion.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 13, 'page_label': '8', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8 Introduction\\n1.2 When to Use Machine Learning?\\nBased on the discussion above, machine learning can oﬀer an e ﬃcient\\nalternative to the conventional engineering ﬂow when devel opment cost\\nand time are the main concerns, or when the problem appears to be\\ntoo complex to be studied in its full generality . On the ﬂip si de, the\\napproach has the key disadvantages of providing generally s uboptimal\\nperformance, or hindering interpretability of the solutio n, and to apply\\nonly to a limited set of problems.\\nIn order to identify tasks for which machine learning method s may\\nbe useful, reference [\\n31] suggests the following criteria:\\n1. the task involves a function that maps well-deﬁned inputs to well-\\ndeﬁned outputs;\\n2. large data sets exist or can be created containing input-o utput\\npairs;\\n3. the task provides clear feedback with clearly deﬁnable go als and\\nmetrics;\\n4. the task does not involve long chains of logic or reasoning that\\ndepend on diverse background knowledge or common sense;'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 13, 'page_label': '8', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='metrics;\\n4. the task does not involve long chains of logic or reasoning that\\ndepend on diverse background knowledge or common sense;\\n5. the task does not require detailed explanations for how th e deci-\\nsion was made;\\n6. the task has a tolerance for error and no need for provably c orrect\\nor optimal solutions;\\n7. the phenomenon or function being learned should not chang e\\nrapidly over time; and\\n8. no specialized dexterity , physical skills, or mobility i s required.\\nThese criteria are useful guidelines for the decision of whe ther machine\\nlearning methods are suitable for a given task of interest. T hey also oﬀer\\na convenient demarcation line between machine learning as i s intended\\ntoday , with its focus on training and computational statist ics tools, and\\nmore general notions of Artiﬁcial Intelligence (AI) based o n knowledge\\nand common sense [ 87] (see [ 126] for an overview on AI research).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 14, 'page_label': '9', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.2. When to Use Machine Learning? 9\\n1.2.1 Learning T asks\\nW e can distinguish among three diﬀerent main types of machin e learn-\\ning problems, which are brieﬂy introduced below. The discus sion re-\\nﬂects the focus of this monograph on parametric probabilist ic models,\\nas further elaborated on in the next section.\\n1. Supervised learning: W e have N labelled training examples\\nD={(xn ,tn)}N\\nn=1 ,where xn represents a covariate, or explanatory vari-\\nable, while tn is the corresponding label, or response. F or instance,\\nvariable xn may represent the text of an email, while the label tn may\\nbe a binary variable indicating whether the email is spam or n ot. The\\ngoal of supervised learning is to predict the value of the lab el t for\\nan input x that is not in the training set. In other words, supervised\\nlearning aims at generalizing the observations in the data s et Dto new\\ninputs. F or example, an algorithm trained on a set of emails s hould be'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 14, 'page_label': '9', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning aims at generalizing the observations in the data s et Dto new\\ninputs. F or example, an algorithm trained on a set of emails s hould be\\nable to classify a new email not present in the data set D.\\nW e can generally distinguish between classiﬁcation problems, in\\nwhich the label t is discrete, as in the example above, and regression\\nproblems, in which variable tis continuous. An example of a regression\\ntask is the prediction of tomorrow’s temperature t based on today’s\\nmeteorological observations x.\\nAn eﬀective way to learn a predictor is to identify from the da ta\\nset Da predictive distribution p(t|x) from a set of parametrized distri-\\nbutions. The conditional distribution p(t|x) deﬁnes a proﬁle of beliefs\\nover all possible of the label tgiven the input x. F or instance, for tem-\\nperature prediction, one could learn mean and variance of a G aussian\\ndistribution p(t|x) as a function of the input x. As a special case, the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 14, 'page_label': '9', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='perature prediction, one could learn mean and variance of a G aussian\\ndistribution p(t|x) as a function of the input x. As a special case, the\\noutput of a supervised learning algorithm may be in the form o f a\\ndeterministic predictive function t= ˆt(x).\\n2. Unsupervised learning: Suppose now that we have an un-\\nlabelled set of training examples D={xn}N\\nn=1 . Less well deﬁned than\\nsupervised learning, unsupervised learning generally ref ers to the task\\nof learning properties of the mechanism that generates this data set.\\nSpeciﬁc tasks and applications include clustering, which i s the prob-\\nlem of grouping similar examples xn; dimensionality reduction, feature\\nextraction, and representation learning, all related to th e problem of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 15, 'page_label': '10', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='10 Introduction\\nrepresenting the data in a smaller or more convenient space; and gen-\\nerative modelling, which is the problem of learning a genera ting mech-\\nanism to produce artiﬁcial examples that are similar to avai lable data\\nin the data set D.\\nAs a generalization of both supervised and unsupervised lea rning,\\nsemi-supervised learning refers to scenarios in which not all examples\\nare labelled, with the unlabelled examples providing infor mation about\\nthe distribution of the covariates x.\\n3. Reinforcement learning: Reinforcement learning refers to the\\nproblem of inferring optimal sequential decisions based on rewards or\\npunishments received as a result of previous actions. Under supervised\\nlearning, the “label” trefers to an action to be taken when the learner\\nis in an informational state about the environment given by a variable\\nx. Upon taking an action t in a state x, the learner is provided with\\nfeedback on the immediate reward accrued via this decision, and the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 15, 'page_label': '10', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x. Upon taking an action t in a state x, the learner is provided with\\nfeedback on the immediate reward accrued via this decision, and the\\nenvironment moves on to a diﬀerent state. As an example, an ag ent can\\nbe trained to navigate a given environment in the presence of obstacles\\nby penalizing decisions that result in collisions.\\nReinforcement learning is hence neither supervised, since the learner\\nis not provided with the optimal actions tto select in a given state x; nor\\nis it fully unsupervised, given the availability of feedbac k on the quality\\nof the chosen action. Reinforcement learning is also distin guished from\\nsupervised and unsupervised learning due to the inﬂuence of previous\\nactions on future states and rewards.\\nThis monograph focuses on supervised and unsupervised lear ning.\\nThese general tasks can be further classiﬁed along the follo wing dimen-\\nsions.\\n•Passive vs. active learning : A passive learner is given the train-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 15, 'page_label': '10', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='These general tasks can be further classiﬁed along the follo wing dimen-\\nsions.\\n•Passive vs. active learning : A passive learner is given the train-\\ning examples, while an active learner can aﬀect the choice of training\\nexamples on the basis of prior observations.\\n•Oﬄine vs. online learning : Oﬄine learning operates over a batch\\nof training samples, while online learning processes sampl es in a stream-\\ning fashion. Note that reinforcement learning operates inh erently in an\\nonline manner, while supervised and unsupervised learning can be car-\\nried out by following either oﬄine or online formulations.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 16, 'page_label': '11', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.3. Goals and Outline 11\\nThis monograph considers only passive and oﬄine learning.\\n1.3 Goals and Outline\\nThis monograph aims at providing an introduction to key conc epts, al-\\ngorithms, and theoretical results in machine learning. The treatment\\nconcentrates on probabilistic models for supervised and un supervised\\nlearning problems. It introduces fundamental concepts and algorithms\\nby building on ﬁrst principles, while also exposing the read er to more\\nadvanced topics with extensive pointers to the literature, within a uni-\\nﬁed notation and mathematical framework. Unlike other text s that are\\nfocused on one particular aspect of the ﬁeld, an eﬀort has bee n made\\nhere to provide a broad but concise overview in which the main ideas\\nand techniques are systematically presented. Speciﬁcally , the material\\nis organized according to clearly deﬁned categories, such a s discrim-\\ninative and generative models, frequentist and Bayesian ap proaches,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 16, 'page_label': '11', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is organized according to clearly deﬁned categories, such a s discrim-\\ninative and generative models, frequentist and Bayesian ap proaches,\\nexact and approximate inference, as well as directed and und irected\\nmodels. This monograph is meant as an entry point for researc hers\\nwith a background in probability and linear algebra. A prior exposure\\nto information theory is useful but not required.\\nDetailed discussions are provided on basic concepts and ide as, in-\\ncluding overﬁtting and generalization, Maximum Likelihoo d and regu-\\nlarization, and Bayesian inference. The text also endeavor s to provide\\nintuitive explanations and pointers to advanced topics and research di-\\nrections. Sections and subsections containing more advanc ed material\\nthat may be skipped at a ﬁrst reading are marked with a star ( ∗).\\nThe reader will ﬁnd here neither discussions on computing pl atform\\nor programming frameworks, such as map-reduce, nor details on spe-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 16, 'page_label': '11', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The reader will ﬁnd here neither discussions on computing pl atform\\nor programming frameworks, such as map-reduce, nor details on spe-\\nciﬁc applications involving large data sets. These can be ea sily found\\nin a vast and growing body of work. F urthermore, rather than p rovid-\\ning exhaustive details on the existing myriad solutions in e ach speciﬁc\\ncategory , techniques have been selected that are useful to i llustrate the\\nmost salient aspects. Historical notes have also been provi ded only for\\na few selected milestone events.\\nFinally , the monograph attempts to strike a balance between the\\nalgorithmic and theoretical viewpoints. In particular, al l learning al-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 17, 'page_label': '12', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='12 Introduction\\ngorithms are introduced on the basis of theoretical argumen ts, often\\nbased on information-theoretic measures. Moreover, a chap ter is de-\\nvoted to statistical learning theory , demonstrating how to set the ﬁeld\\nof supervised learning on solid theoretical foundations. T his chapter\\nis more theoretically involved than the others, and proofs o f some key\\nresults are included in order to illustrate the theoretical underpinnings\\nof learning. This contrasts with other chapters, in which pr oofs of the\\nfew theoretical results are kept at a minimum in order to focu s on the\\nmain ideas.\\nThe rest of the monograph is organized into ﬁve parts. The ﬁrs t part\\ncovers introductory material. Speciﬁcally , Chapter 2 intr oduces the fre-\\nquentist, Bayesian and Minimum Description Length (MDL) le arning\\nframeworks; the discriminative and generative categories of probabilis-\\ntic models; as well as key concepts such as training loss, gen eralization,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 17, 'page_label': '12', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='frameworks; the discriminative and generative categories of probabilis-\\ntic models; as well as key concepts such as training loss, gen eralization,\\nand overﬁtting – all in the context of a simple linear regress ion problem.\\nInformation-theoretic metrics are also brieﬂy introduced , as well as the\\nadvanced topics of interpretation and causality . Chapter 3 then pro-\\nvides an introduction to the exponential family of probabil istic models,\\nto Generalized Linear Models (GLMs), and to energy-based mo dels,\\nemphasizing main properties that will be invoked in later ch apters.\\nThe second part concerns supervised learning. Chapter 4 cov ers lin-\\near and non-linear classiﬁcation methods via discriminati ve and gen-\\nerative models, including Support V ector Machines (SVMs), kernel\\nmethods, logistic regression, multi-layer neural network s and boosting.\\nChapter 5 is a brief introduction to the statistical learnin g framework\\nof the Probably Approximately Correct (P AC) theory , coveri ng the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 17, 'page_label': '12', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Chapter 5 is a brief introduction to the statistical learnin g framework\\nof the Probably Approximately Correct (P AC) theory , coveri ng the\\nV apnik–Chervonenkis (VC) dimension and the fundamental th eorem\\nof P AC learning.\\nThe third part, consisting of a single chapter, introduced u nsuper-\\nvised learning. In particular, in Chapter 6, unsupervised l earning mod-\\nels are described by distinguishing among directed models, for which\\nExpectation Maximization (EM) is derived as the iterative m aximiza-\\ntion of the Evidence Lower BOund (ELBO); undirected models, for\\nwhich Restricted Boltzmann Machines (RBMs) are discussed a s a rep-\\nresentative example; discriminative models trained using the InfoMax'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 18, 'page_label': '13', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.3. Goals and Outline 13\\nprinciple; and autoencoders. Generative Adversarial Netw orks (GANs)\\nare also introduced.\\nThe fourth part covers more advanced modelling and inferenc e ap-\\nproaches. Chapter 7 provides an introduction to probabilis tic graphical\\nmodels, namely Bayesian Networks (BNs) and Markov Random Fi elds\\n(MRF s), as means to encode more complex probabilistic depen dencies\\nthan the models studied in previous chapters. Approximate i nference\\nand learning methods are introduced in Chapter 8 by focusing on Monte\\nCarlo (MC) and V ariational Inference (VI) techniques. The c hapter\\nbrieﬂy introduces in a uniﬁed way techniques such as variati onal EM,\\nV ariational AutoEncoders (V AE), and black-box inference. Some con-\\ncluding remarks are provided in the last part, consisting of Chapter\\n9.\\nW e conclude this chapter by emphasizing the importance of pr ob-\\nability as a common language for the deﬁnition of learning al gorithms'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 18, 'page_label': '13', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='9.\\nW e conclude this chapter by emphasizing the importance of pr ob-\\nability as a common language for the deﬁnition of learning al gorithms\\n[34]. The centrality of the probabilistic viewpoint was not alw ays rec-\\nognized, but has deep historical roots. This is demonstrate d by the\\nfollowing two quotes, the ﬁrst from the ﬁrst AI textbook publ ished by\\nP . H. Winston in 1977, and the second from an unﬁnished manusc ript\\nby J. von Neumann (see [ 126, 64] for more information).\\n“Many ancient Greeks supported Socrates opinion that deep,\\ninexplicable thoughts came from the gods. T oday’s equiva-\\nlent to those gods is the erratic, even probabilistic neuron .\\nIt is more likely that increased randomness of neural behav-\\nior is the problem of the epileptic and the drunk, not the\\nadvantage of the brilliant. ”\\nfrom Artiﬁcial Intel ligence , 1977.\\n“All of this will lead to theories of computation which are\\nmuch less rigidly of an all-or-none nature than past and'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 18, 'page_label': '13', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='advantage of the brilliant. ”\\nfrom Artiﬁcial Intel ligence , 1977.\\n“All of this will lead to theories of computation which are\\nmuch less rigidly of an all-or-none nature than past and\\npresent formal logic... There are numerous indications to\\nmake us believe that this new system of formal logic will\\nmove closer to another discipline which has been little link ed\\nin the past with logic. This is thermodynamics primarily in\\nthe form it was received from Boltzmann. ”'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 19, 'page_label': '14', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='14 Introduction\\nfrom The Computer and the Brain , 1958.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 20, 'page_label': '15', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2\\nA Gentle Introduction through Linear Regression\\nIn this chapter, we introduce the frequentist, Bayesian and MDL learn-\\ning frameworks, as well as key concepts in supervised learni ng, such as\\ndiscriminative and generative models, training loss, gene ralization, and\\noverﬁtting. This is done by considering a simple linear regr ession prob-\\nlem as a recurring example. W e start by introducing the probl em of su-\\npervised learning and by presenting some background on infe rence. W e\\nthen present the frequentist, Bayesian and MDL learning app roaches in\\nthis order. The treatment of MDL is limited to an introductor y discus-\\nsion, as the rest of monograph concentrates on frequentist a nd Bayesian\\nviewpoints. W e conclude with an introduction to the importa nt topic\\nof information-theoretic metrics, and with a brief introdu ction to the\\nadvanced topics of causal inference and interpretation.\\n2.1 Supervised Learning\\nIn the standard formulation of a supervised learning proble m, we are'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 20, 'page_label': '15', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='advanced topics of causal inference and interpretation.\\n2.1 Supervised Learning\\nIn the standard formulation of a supervised learning proble m, we are\\ngiven a training set Dcontaining N training points ( xn ,tn), n= 1 ,...,N .\\nThe observations xn are considered to be free variables, and known as\\ncovariates, domain points , or explanatory variables ; while the target\\n15'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 21, 'page_label': '16', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='16 A Gentle Introduction through Linear Regression\\nvariables tn are assumed to be dependent on xn and are referred to\\nas dependent variables, labels , or responses. An example is illustrated\\nin Fig. 2.1. W e use the notation xD = ( x1 ,....,xN )T for the covariates\\nand tD = ( t1 ,....,tN )T for the labels in the training set D. Based on\\nthis data, the goal of supervised learning is to identify an a lgorithm\\nto predict the label t for a new, that is, as of yet unobserved, domain\\npoint x.\\n0 0.2 0.4 0.6 0.8 1\\n-1.5\\n-1\\n-0.5\\n0\\n0.5\\n1\\n1.5\\nFigure 2.1: Example of a training set D with N = 10 points ( xn ,tn ), n = 1 , ..., N .\\nThe outlined learning task is clearly impossible in the abse nce of ad-\\nditional information on the mechanism relating variables xand t. With\\nreference to Fig. 2.1, unless we assume, say , that xand tare related by\\na function t= f(x) with some properties, such as smoothness, we have\\nno way of predicting the label tfor an unobserved domain point x. This'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 21, 'page_label': '16', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a function t= f(x) with some properties, such as smoothness, we have\\nno way of predicting the label tfor an unobserved domain point x. This\\nobservation is formalized by the no free lunch theorem to be reviewed\\nin Chapter 5: one cannot learn rules that generalize to unseen examples\\nwithout making assumptions about the mechanism generating the data.\\nThe set of all assumptions made by the learning algorithm is k nown as\\nthe inductive bias .\\nThis discussion points to a key diﬀerence between memorizing and\\nlearning. While the former amounts to mere retrieval of a val ue tn'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 22, 'page_label': '17', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.2. Inference 17\\ncorresponding to an already observed pair ( xn ,tn) ∈D,learning entails\\nthe capability to predict the value t for an unseen domain point x.\\nLearning, in other words, converts experience – in the form o f D– into\\nexpertise or knowledge – in the form of a predictive algorith m. This is\\nwell captured by the following quote by Jorge Luis Borges: “ T o think\\nis to forget details, generalize, make abstractions. ” [ 138].\\nBy and large, the goal of supervised learning is that of ident ifying a\\npredictive algorithm that minimizes the generalization loss , that is, the\\nerror in the prediction of a new label t for an unobserved explanatory\\nvariable x. How exactly to formulate this problem, however, depends\\non one’s viewpoint on the nature of the model that is being lea rned.\\nThis leads to the distinction between the frequentist and th e Bayesian\\napproaches, which is central to this chapter. As it will be al so discussed,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 22, 'page_label': '17', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='This leads to the distinction between the frequentist and th e Bayesian\\napproaches, which is central to this chapter. As it will be al so discussed,\\nthe MDL philosophy deviates from the mentioned focus on pred iction\\nas the goal of learning, by targeting instead a parsimonious description\\nof the data set D.\\n2.2 Inference\\nBefore we start our discussion of learning, it is useful to re view some\\nbasic concepts concerning statistical inference, as they w ill be needed\\nthroughout this chapter and in the rest of this monograph. W e specif-\\nically consider the inference problem of predicting a rv t gi ven the\\nobservation of another rv x under the assumption that their j oint dis-\\ntribution p(x,t) is known. As a matter of terminology , it is noted that\\nhere we will use the term “inference” as it is typically inten ded in the\\nliterature on probabilistic graphical models (see, e.g., [\\n81]), hence di-\\nverging from its use in other branches of the machine learnin g literature\\n(see, e.g., [ 23]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 22, 'page_label': '17', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='literature on probabilistic graphical models (see, e.g., [\\n81]), hence di-\\nverging from its use in other branches of the machine learnin g literature\\n(see, e.g., [ 23]).\\nIn order to deﬁne the problem of optimal inference, one start s by\\ndeﬁning a non-negative loss function ℓ(t,ˆt). This deﬁnes the cost, or\\nloss or risk, incurred when the correct value is twhile the estimate is ˆt.\\nAn important example is the ℓq loss\\nℓq (t,ˆt) = |t−ˆt|q , (2.1)\\nwhich includes as a special case the quadratic loss ℓ2(t,ˆt) = ( t−ˆt)2 ,and'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 23, 'page_label': '18', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='18 A Gentle Introduction through Linear Regression\\nthe 0-1 loss, or detection error , ℓ0(t,ˆt) = |t−ˆt|0,where |a|0 = 1 if a̸= 0\\nand |a|0 = 0 otherwise. Once a loss function is selected, the optimal\\nprediction ˆt(x) for a given value of the observation x is obtained by\\nminimizing the so-called generalization risk or generalization loss 1\\nLp(ˆt) = E (x,t)∼pxt [ℓ(t,ˆt(x))]. (2.2)\\nThe notation Lp emphasizes the dependence of the generalization loss\\non the distribution p(x,t).\\nThe solution of this problem is given by the optimal predicti on or\\ndecision rule 2\\nˆt∗(x) = arg min\\nˆt\\nEt∼pt|x [ℓ(t,ˆt)|x]. (2.3)\\nThis can be seen by using the law of iterated expectations E (x,t)∼pxt [·] =\\nEx∼px [Et∼pt|x [·|x]]. Equation ( 2.3) shows that the optimal estimate, or\\nprediction, ˆt∗ (x) is a function of the posterior distribution p(t|x) of the\\nlabel given the domain point x and of the loss function ℓ. Therefore,\\nonce the posterior p(t|x) is known, one can evaluate the optimal pre-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 23, 'page_label': '18', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='label given the domain point x and of the loss function ℓ. Therefore,\\nonce the posterior p(t|x) is known, one can evaluate the optimal pre-\\ndiction ( 2.3) for any desired loss function, without the need to know\\nthe joint distribution p(x,t).\\nAs a special case of ( 2.3), with the quadratic loss function ℓ2 , the\\noptimal prediction is the conditional mean ˆt∗(x) = E t∼pt|x [t|x]; while\\nfor the 0-1 loss function ℓ0, the optimal decision is the mode of the\\nposterior distribution, i.e., ˆt∗(x) = arg max t p(t|x).\\nF or example, assume that we have\\nt|x = x∼0.8δ(t−x) + 0 .2δ(t+ x), (2.4)\\nso that, conditioned on the event x = x, t equals x with probability\\n0.8 and −x with probability 0.2. The optimal prediction is ˆt∗(x) =\\n0.8x−0.2x= 0 .6x for the quadratic loss, while it is ˆt∗(x) = x for the\\n0-1 loss.\\n1 The term generalization error or population error are also o ften used, but they\\nwill not be adopted in this monograph.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 23, 'page_label': '18', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='0-1 loss.\\n1 The term generalization error or population error are also o ften used, but they\\nwill not be adopted in this monograph.\\n2 The optimal estimate ( 2.3) is also known as Bayes’ prediction or Bayes’ rule, but\\nhere we will not use this terminology in order to avoid confus ion with the Bayesian\\napproach discussed below.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 24, 'page_label': '19', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 19\\nThe goal of supervised learning methods is broadly speaking that of\\nobtaining a predictor ˆt(x) that performs close to the optimal predictor\\nˆt∗(x), based only on the training set D, and hence without knowledge\\nof the joint distribution p(x,t). The closeness in performance is mea-\\nsured by the diﬀerence between the generalization loss Lp(ˆt) achieved\\nby the trained predictor and the minimum generalization loss Lp(ˆt∗ ) of\\nthe optimal predictor, which depends on the true distributi on p(x,t).\\nStrictly speaking, this statement applies only for the freq uentist ap-\\nproach, which is discussed next. As it will be explained late r in the\\nchapter, in fact, while the Bayesian approach still centers around the\\ngoal of prediction, its modelling assumptions are diﬀerent . F urthermore,\\nthe MDL approach concentrates on the task of data compressio n rather\\nthan prediction.\\n2.3 Frequentist Approach'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 24, 'page_label': '19', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='goal of prediction, its modelling assumptions are diﬀerent . F urthermore,\\nthe MDL approach concentrates on the task of data compressio n rather\\nthan prediction.\\n2.3 Frequentist Approach\\nAccording to the frequentist viewpoint, the training data p oints (x n,tn ) ∈\\nDare independent identically distributed (i.i.d.) rvs draw n from a true,\\nand unknown, distribution p(x,t):\\n(xn ,tn) ∼\\ni.i.d.\\np(x,t), i= 1 ,...,N. (2.5)\\nThe new observation (x ,t) is also independently generated from the\\nsame true distribution p(x,t); the domain point x is observed and the\\nlabel t must be predicted. Since the probabilistic model p(x,t) is not\\nknown, one cannot solve directly problem (\\n2.3) to ﬁnd the optimal\\nprediction that minimizes the generalization loss Lp in ( 2.2).\\nBefore discussing the available solutions to this problem, it is worth\\nobserving that the deﬁnition of the “true” distribution p(x,t) depends\\nin practice on the way data is collected. As in the example of t he'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 24, 'page_label': '19', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='observing that the deﬁnition of the “true” distribution p(x,t) depends\\nin practice on the way data is collected. As in the example of t he\\n“beauty AI” context, if the rankings tn assigned to pictures xn of faces\\nare aﬀected by racial biases, the distribution p(x,t) will reﬂect these\\nprejudices and produce skewed results [ 62].\\nT axonomy of solutions. There are two main ways to address the\\nproblem of learning how to perform inference when not knowin g the\\ndistribution p(x,t):'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 25, 'page_label': '20', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='20 A Gentle Introduction through Linear Regression\\n•Separate learning and (plug-in) inference : Learn ﬁrst an approx-\\nimation, say pD (t|x), of the conditional distribution p(t|x) based on\\nthe data D, and then plug this approximation in ( 2.3) to obtain an\\napproximation of the optimal decision as\\nˆtD (x) = arg min\\nˆt\\nEt∼pD (t|x)[ℓ(t,ˆt)|x]. (2.6)\\n•Direct inference via Empirical Risk Minimization (ERM): Learn\\ndirectly an approximation ˆtD (·) of the optimal decision rule by mini-\\nmizing an empirical estimate of the generalization loss ( 2.2) obtained\\nfrom the data set as\\nˆtD (·) = arg min\\nˆt\\nLD (ˆt), (2.7)\\nwhere the empirical risk, or empirical loss , is\\nLD (ˆt) = 1\\nN\\nN∑\\nn=1\\nℓ(tn,ˆt(xn )). (2.8)\\nThe notation LD (ˆt) highlights the dependence of the empirical loss on\\nthe predictor ˆt(·) and on the training set D.\\nIn practice, as we will see, both approaches optimize a set of param-\\neters that deﬁne the probabilistic model or the predictor. F urthermore,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 25, 'page_label': '20', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the predictor ˆt(·) and on the training set D.\\nIn practice, as we will see, both approaches optimize a set of param-\\neters that deﬁne the probabilistic model or the predictor. F urthermore,\\nthe ﬁrst approach is generally more ﬂexible, since having an estimate\\npD (t|x) of the posterior distribution p(t|x) allows the prediction ( 2.6)\\nto be computed for any loss function. In contrast, the ERM sol ution\\n(2.7) is tied to a speciﬁc choice of the loss function ℓ. In the rest of this\\nsection, we will start by taking the ﬁrst approach, and discu ss later\\nhow this relates to the ERM formulation.\\nLinear regression example. F or concreteness, in the following,\\nwe will consider the following running example inspired by [ 23]. In the\\nexample, data is generated according to the true distributi on p(x,t) =\\np(x)p(t|x), where x ∼U(0,1) and\\nt|x = x∼N(sin(2πx),0.1). (2.9)\\nThe training set in Fig. 2.1 was generated from this distribution. If this'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 25, 'page_label': '20', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x)p(t|x), where x ∼U(0,1) and\\nt|x = x∼N(sin(2πx),0.1). (2.9)\\nThe training set in Fig. 2.1 was generated from this distribution. If this\\ntrue distribution were known, the optimal predictor under t he ℓ2 loss'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 26, 'page_label': '21', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 21\\nwould be equal to the conditional mean\\nˆt∗(x) = sin(2 πx). (2.10)\\nHence, the minimum generalization loss is Lp(ˆt∗ ) = 0 .1.\\nIt is emphasized that, while we consider this running exampl e in\\norder to ﬁx the ideas, all the deﬁnitions and ideas reported i n this\\nchapter apply more generally to supervised learning proble ms. This\\nwill be further discussed in Chapter 4 and Chapter 5.\\n2.3.1 Discriminative vs. Generative Probabilistic Models\\nIn order to learn an approximation pD (t|x) of the predictive distribution\\np(t|x) based on the data D, we will proceed by ﬁrst selecting a family\\nof parametric probabilistic models, also known as a hypothesis class ,\\nand by then learning the parameters of the model to ﬁt (in a sen se to\\nbe made precise later) the data D.\\nConsider as an example the linear regression problem introd uced\\nabove. W e start by modelling the label t as a polynomial function\\nof the domain point x added to a Gaussian noise with variance β−1 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 26, 'page_label': '21', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Consider as an example the linear regression problem introd uced\\nabove. W e start by modelling the label t as a polynomial function\\nof the domain point x added to a Gaussian noise with variance β−1 .\\nParameter β is the precision, i.e., the inverse variance of the additive\\nnoise. The polynomial function with degree M can be written as\\nµ(x,w) =\\nM∑\\nj=0\\nwj xj = wT φ(x), (2.11)\\nwhere we have deﬁned the weight vector w= [ w0 w1 ··· wM ]T and the\\nfeature vector φ(x) = [1 x x2 ···xM ]T . The vector wdeﬁnes the relative\\nweight of the powers in the sum (\\n2.11). This assumption corresponds\\nto adopting a parametric probabilistic model p(t|x,θ) deﬁned as\\nt|x = x∼N(µ(x,w),β−1 ), (2.12)\\nwith parameters θ = ( w,β). Having ﬁxed this hypothesis class, the\\nparameter vector θ can be then learned from the data D, as it will be\\ndiscussed.\\nIn the example above, we have parametrized the posterior dis tribu-\\ntion. Alternatively , we can parametrize, and learn, the ful l joint distri-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 26, 'page_label': '21', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='discussed.\\nIn the example above, we have parametrized the posterior dis tribu-\\ntion. Alternatively , we can parametrize, and learn, the ful l joint distri-\\nbution p(x,t). These two alternatives are introduced below.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 27, 'page_label': '22', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='22 A Gentle Introduction through Linear Regression\\n1. Discriminative probabilistic model. With this ﬁrst class of\\nmodels, the posterior, or predictive, distribution p(t|x) is assumed to\\nbelong to a hypothesis class p(t|x,θ) deﬁned by a parameter vector θ.\\nThe parameter vector θ is learned from the data set D. F or a given\\nparameter vector θ, the conditional distribution p(t|x,θ) allows the\\ndiﬀerent values of the label t to be discriminated on the basis of their\\nposterior probability . In particular, once the model is lea rned, one can\\ndirectly compute the predictor ( 2.6) for any loss function.\\nAs an example, for the linear regression problem, once a vect or of\\nparameters θD = ( wD ,βD ) is identiﬁed based on the data Dduring\\nlearning, the optimal prediction under the ℓ2 loss is the conditional\\nmean ˆtD (x) = E t∼p(t|x,θD )[t|x], that is, ˆtD (x) = µ(x,wD ).\\n2. Generative probabilistic model. Instead of learning directly'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 27, 'page_label': '22', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning, the optimal prediction under the ℓ2 loss is the conditional\\nmean ˆtD (x) = E t∼p(t|x,θD )[t|x], that is, ˆtD (x) = µ(x,wD ).\\n2. Generative probabilistic model. Instead of learning directly\\nthe posterior p(t|x), one can model the joint distribution p(x,t) as\\nbeing part of a parametric family p(x,t|θ). Note that, as opposed to\\ndiscriminative models, the joint distribution p(x,t|θ) models also the\\ndistribution of the covariates x. Accordingly , the term “generative” re-\\nﬂects the capacity of this type of models to generate a realiz ation of\\nthe covariates x by using the marginal p(x|θ).\\nOnce the joint distribution p(x,t|θ) is learned from the data, one\\ncan compute the posterior p(t|x,θ) using Bayes’ theorem, and, from\\nit, the optimal predictor ( 2.6) can be evaluated for any loss function.\\nGenerative models make stronger assumptions by modeling al so the\\ndistribution of the explanatory variables. As a result, an i mproper se-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 27, 'page_label': '22', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Generative models make stronger assumptions by modeling al so the\\ndistribution of the explanatory variables. As a result, an i mproper se-\\nlection of the model may lead to more signiﬁcant bias issues. However,\\nthere are potential advantages, such as the ability to deal w ith missing\\ndata or latent variables, such as in semi-supervised learni ng. W e refer\\nto Chapter 6 for further discussion (see also [ 23]).\\nIn the rest of this section, for concreteness, we consider di scrimi-\\nnative probabilistic models p(t|x,θ), although the main deﬁnitions will\\napply also to generative models.\\n2.3.2 Model Order and Model Parameters\\nIn the linear regression example, the selection of the hypot hesis class\\n(\\n2.12) required the deﬁnition of the polynomial degree M, while the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 28, 'page_label': '23', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 23\\ndetermination of a speciﬁc model p(t|x,θ) in the class called for the\\nselection of the parameter vector θ= ( w,β). As we will see, these two\\ntypes of variables play a signiﬁcantly diﬀerent role during learning and\\nshould be clearly distinguished, as discussed next.\\n1. Model order M (and hyperparameters): The model order\\ndeﬁnes the “capacity” of the hypothesis class, that is, the n umber of\\nthe degrees of freedom in the model. The larger M is, the more capable\\na model is to ﬁt the available data. F or instance, in the linea r regression\\nexample, the model order determines the size of the weight ve ctor w.\\nMore generally , variables that deﬁne the class of models to b e learned\\nare known as hyperparameters. As we will see, determining th e model\\norder, and more broadly the hyperparameters, requires a pro cess known\\nas validation.\\n2. Model parameters θ: Assigning speciﬁc values to the model\\nparameters θ identiﬁes a hypothesis within the given hypothesis class.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 28, 'page_label': '23', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as validation.\\n2. Model parameters θ: Assigning speciﬁc values to the model\\nparameters θ identiﬁes a hypothesis within the given hypothesis class.\\nThis can be done by using learning criteria such as Maximum Li keli-\\nhood (ML) and Maximum a Posteriori (MAP).\\nW e postpone a discussion of validation to the next section, a nd we\\nstart by introducing the ML and MAP learning criteria.\\n2.3.3 Maximum Likelihood (ML) Learning\\nAssume now that the model order M is ﬁxed, and that we are interested\\nin learning the model parameters θ.The ML criterion selects a value of\\nθunder which the training set Dhas the maximum probability of being\\nobserved. In other words, the value θ selected by ML is the most likely\\nto have generated the observed training set. Note that there might be\\nmore than one such value.\\nT o proceed, we need to write the probability (density) of the ob-\\nserved labels tD in the training set Dgiven the corresponding domain'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 28, 'page_label': '23', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='more than one such value.\\nT o proceed, we need to write the probability (density) of the ob-\\nserved labels tD in the training set Dgiven the corresponding domain\\npoints x. Under the assumed discriminative model, this is given as\\np(tD |xD ,w,β ) =\\nN∏\\nn=1\\np(tn|xn,w,β ), (2.13)\\n=\\nN∏\\nn=1\\nN(tn|µ(xn,w),β−1 )'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 29, 'page_label': '24', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='24 A Gentle Introduction through Linear Regression\\nwhere we have used the independence of diﬀerent data points. T aking\\nthe logarithm yields the Log-Likelihood (LL) function\\nln p(tD |xD ,w,β ) =\\nN∑\\nn=1\\nln p(tn|xn,w,β )\\n= - β\\n2\\nN∑\\nn=1\\n(µ(xn,w) −tn)2 + N\\n2 ln β\\n2π. (2.14)\\nThe LL function should be considered as a function of the mode l pa-\\nrameters θ = ( w,β), since the data set Dis ﬁxed and given. The ML\\nlearning problem is deﬁned by the minimization of the Negative LL\\n(NLL) function as\\nmin\\nw,β\\n−1\\nN\\nN∑\\nn=1\\nln p(tn|xn,w,β ). (2.15)\\nThis criterion is also referred to as cross-entropy or log-loss, as further\\ndiscussed in Sec. 2.6.\\nIf one is only interested in learning only the posterior mean , as is\\nthe case when the loss function is ℓ2, then one can tackle problem ( 2.14)\\nonly over the weights w, yielding the optimization\\nminw LD (w) = 1\\nN\\nN∑\\nn=1\\n(µ(xn ,w) −tn)2 . (2.16)\\nThe quantity LD (w) is known as the training loss . An interesting ob-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 29, 'page_label': '24', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='only over the weights w, yielding the optimization\\nminw LD (w) = 1\\nN\\nN∑\\nn=1\\n(µ(xn ,w) −tn)2 . (2.16)\\nThe quantity LD (w) is known as the training loss . An interesting ob-\\nservation is that this criterion coincides with the ERM prob lem ( 2.7)\\nfor the ℓ2 loss if one parametrizes the predictor as ˆt(x) = µ(x,w).\\nThe ERM problem ( 2.16) can be solved in closed form. T o this end,\\nwe write the empirical loss as LD (w) = N−1||tD −XD w||2 , with the\\nN ×(M + 1) matrix\\nXD = [ φ(x1 ) φ(x2 ) ··· φ(xN )]T . (2.17)\\nIts minimization hence amounts to a Least Squares (LS) probl em,\\nwhich yields the solution\\nwM L = ( XT\\nD XD )−1XT\\nD tD , (2.18)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 30, 'page_label': '25', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 25\\nNote that, in ( 2.18), we have assumed the typical overdetermined case\\nin which the inequality N >(M + 1) holds. More generally , one has\\nthe ML solution wM L = X†\\nD tD . Finally , diﬀerentiating the NLL with\\nrespect to β yields instead the ML estimate\\n1\\nβM L\\n= LD (wM L ). (2.19)\\n0 0.2 0.4 0.6 0.8 1\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n= 9M\\nM= 1\\nM= 3\\nFigure 2.2: Illustration of underﬁtting and overﬁtting in ML learning: The dashed\\nline is the optimal predictor ( 2.10), which depends on the unknown true distribution,\\nwhile the other lines correspond to the predictor ˆtM L (x) = µ(x, w M L ) learned via\\nML with diﬀerent model orders M .\\nOverﬁtting and Underﬁtting. Adopting the ℓ2 loss, let us now\\ncompare the predictor ˆtM L (x) = µ(x,wM L ) learned via ML with the\\noptimal, but unknown, predictor ˆt∗(x) in ( 2.10). T o this end, Fig. 2.2\\nshows the optimal predictor ˆt∗(x) as a dashed line and the ML-based\\npredictor ˆtM L (x) obtained with diﬀerent values of the model order M'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 30, 'page_label': '25', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='shows the optimal predictor ˆt∗(x) as a dashed line and the ML-based\\npredictor ˆtM L (x) obtained with diﬀerent values of the model order M\\nfor the training set Din Fig. 2.1 (also shown in Fig. 2.2 for reference).\\nW e begin by observing that, with M = 1, the ML predictor under-\\nﬁts the data: the model is not rich enough to capture the variatio ns\\npresent in the data. As a result, the training loss LD (wM L ) in ( 2.16) is\\nlarge.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 31, 'page_label': '26', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='26 A Gentle Introduction through Linear Regression\\nIn contrast, with M = 9, the ML predictor overﬁts the data: the\\nmodel is too rich and, in order to account for the observation s in the\\ntraining set, it yields inaccurate predictions outside it. In this case, the\\ntraining loss LD (w) in ( 2.16) is small, but the generalization loss\\nLp(wM L ) = E (x,t)∼pxt [ℓ(t,µ(x,wM L ))] (2.20)\\nis large. With overﬁtting, the model is memorizing the train ing set,\\nrather than learning how to generalize to unseen examples.\\nThe choice M = 3 appears to be the best by comparison with the\\noptimal predictor. Note that this observation is in practic e precluded\\ngiven the impossibility to determine ˆt∗(x) and hence the generalization\\nloss. W e will discuss below how to estimate the generalizati on loss using\\nvalidation.\\n1 2 3 4 5 6 7 8 9\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\n1.6root average squared loss\\ntraining\\ngeneralization \\n(via validation)\\noverfitting\\nunderfitting'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 31, 'page_label': '26', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='validation.\\n1 2 3 4 5 6 7 8 9\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\n1.6root average squared loss\\ntraining\\ngeneralization \\n(via validation)\\noverfitting\\nunderfitting\\nFigure 2.3: Square root of the generalization loss Lp (wM L ) and of the training loss\\nLD (wM L ) as a function of the model order M for the training data set in Fig. 2.1.\\nThe impact of the model order M on training and generalization\\nlosses is further elaborated on in Fig. 2.3, which shows the squared root\\nof the generalization loss Lp(wM L ) and of the training loss LD (wM L ) as\\na function of M for the same training data set. A ﬁrst remark is that,\\nas expected, the training loss is smaller than the generaliz ation loss,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 32, 'page_label': '27', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 27\\nsince the latter accounts for all pairs (x ,t)∼p(x,t), while the former\\nincludes only the training points used for learning. More im portantly ,\\nthe key observation here is that increasing M allows one to better ﬁt –\\nand possibly overﬁt – the training set, hence reducing LD (wM L ). The\\ngeneralization loss Lp(wM L ) instead tends to decrease at ﬁrst, as we\\nmove away from the underﬁtting regime, but it eventually inc reases\\nfor suﬃciently large M. The widening of the gap between training and\\ngeneralization provides evidence that overﬁtting is occur ring. F rom Fig.\\n2.3, we can hence conclude that, in this example, model orders la rger\\nthan M = 7 should be avoided since they lead to overﬁtting, while\\nmodel order less than M = 3 should also not be considered in order to\\navoid underﬁtting.\\n0 10 20 30 40 50 60 70\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nroot average quadratic loss\\nM\\nM\\n= 1\\n= 7\\ngeneralization (via validation)\\ntraining'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 32, 'page_label': '27', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='avoid underﬁtting.\\n0 10 20 30 40 50 60 70\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nroot average quadratic loss\\nM\\nM\\n= 1\\n= 7\\ngeneralization (via validation)\\ntraining\\nFigure 2.4: Square root of the generalization loss Lp (wM L ) and of the training loss\\nLD (wM L ) as a function of the training set size N . The asymptote of the general-\\nization and training losses is given by the minimum generali zation loss Lp (w∗ ) (cf.\\n(2.21)) achievable for the given model order (see Fig. 2.5).\\nWhat if we had more data? Extrapolating from the behavior ob-\\nserved in Fig. 2.2, we can surmise that, as the number N of data points\\nincreases, overﬁtting is avoided even for large values of M. In fact, when\\nthe training set is big as compared to the number of parameter s in θ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 33, 'page_label': '28', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='28 A Gentle Introduction through Linear Regression\\nwe expect the training loss LD (w) to provide an accurate measure of\\nthe generalization loss Lp(w) for al l possible values of w. Informally ,\\nwe have the approximation LD (w) ≃Lp(w) simultaneously for all val-\\nues of w as long as N is large enough. Therefore, the weight vector\\nwM L that minimizes the training loss LD (w) also (approximately) min-\\nimizes the generalization loss Lp(w). It follows that, for large N, the\\nML parameter vector wM L tends to the the optimal value w∗ (assum-\\ning for simplicity of argument that it is unique) that minimi zes the\\ngeneralization loss among all predictors in the model, i.e. ,\\nw∗ = argminw Lp(w). (2.21)\\nThis discussion will be made precise in Chapter 5.\\nT o oﬀer numerical evidence for the point just made, Fig. 2.4 plots\\nthe (square root of the) generalization and training losses versus N,\\nwhere the training sets were generated at random from the tru e distri-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 33, 'page_label': '28', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the (square root of the) generalization and training losses versus N,\\nwhere the training sets were generated at random from the tru e distri-\\nbution. F rom the ﬁgure, we can make the following important o bserva-\\ntions. First, overﬁtting – as measured by the gap between tra ining and\\ngeneralization losses – vanishes as N increases. This is a consequence of\\nthe discussed approximate equalities LD (w) ≃Lp(w) and wM L ≃w∗ ,\\nwhich are valid as N grows large, which imply the approximate equali-\\nties LD (wM L ) ≃Lp(wM L ) ≃Lp(w∗ ).\\nSecond, it is noted that the training loss LD (wM L ) tends to the\\nminimum generalization loss Lp(w∗ ) for the given M from below, while\\nthe generalization loss Lp(wM L ) tends to it from above. This is be-\\ncause, as N increases, it becomes more diﬃcult to ﬁt the data set D,\\nand hence LD (wM L ) increases. Conversely , as N grows large, the ML\\nestimate becomes more accurate, because of the increasingl y accurate'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 33, 'page_label': '28', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and hence LD (wM L ) increases. Conversely , as N grows large, the ML\\nestimate becomes more accurate, because of the increasingl y accurate\\napproximation wM L ≃w∗ , and thus the generalization loss Lp(wM L )\\ndecreases.\\nThird, selecting a smaller model order M yields an improved gener-\\nalization loss when the training set is small, while a larger value of M is\\ndesirable when the data set is bigger. In fact, as further dis cussed below,\\nwhen N is small, the estimation error caused by overﬁtting dominates\\nthe bias caused by the choice of a small hypothesis class. In contrast ,\\nfor suﬃciently large training sets, the estimation error va nishes and the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 34, 'page_label': '29', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 29\\nperformance is dominated by the bias induced by the selectio n of the\\nmodel.\\n0 10 20 30 40 50 60 70\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nroot average quadratic loss\\nestimation error\\nbias\\nFigure 2.5: Illustration of the bias and training error based on the deco mposition\\n(2.22).\\nBias and generalization gap. The previous paragraph intro-\\nduced the notions of estimation error and bias associated with the\\nselection of a given model order M. While Chapter 5 will provide a\\nmore extensive discussion on these concepts, it is useful to brieﬂy re-\\nview them here in the context of ML learning. Estimation erro r and bias\\nrefer to the following decomposition of the generalization loss achieved\\nby the given solution wM L\\nLp(wM L ) = Lp(ˆt∗ ) + ( Lp(w∗ ) −Lp(ˆt∗)) + ( Lp(wM L ) −Lp(w∗ )). (2.22)\\nThis decomposition is illustrated in Fig. 2.5 for M = 1. In ( 2.22),\\nthe term Lp(ˆt∗ ) = 0 .1 (the ﬁgure shows the square root) is, as seen,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 34, 'page_label': '29', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='This decomposition is illustrated in Fig. 2.5 for M = 1. In ( 2.22),\\nthe term Lp(ˆt∗ ) = 0 .1 (the ﬁgure shows the square root) is, as seen,\\nthe minimum achievable generalization loss without any con straint on\\nthe hypothesis class. The term ( Lp(w∗ ) −Lp(ˆt∗)) represents the bias,\\nor approximation error, caused by the choice of the given hyp othesis\\nclass, and hence also by the choice of M. This is because, by ( 2.21),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 35, 'page_label': '30', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='30 A Gentle Introduction through Linear Regression\\nLp(w∗ ) is the best generalization loss for the given model. Recall that\\nthe loss Lp(w∗ ) can be achieved when N is large enough. Finally , the\\nterm ( Lp(wM L )−Lp(w∗ )) is the estimation error or generalization gap 3\\nthat is incurred due to the fact that N is not large enough and hence\\nwe have wM L ̸= w∗ .\\nF rom the decomposition ( 2.22), a large N allows us to reduce the\\nestimation error, but it has no eﬀect on the bias. This is seen in Fig. 2.4,\\nwhere the asymptote achieved by the generalization loss as N increases\\nequals the minimum generalization loss Lp(w∗ ) for the given model\\norder. Choosing a small value of M in the regime of large data imposes a\\nﬂoor on the achievable generalization loss that no amount of additional\\ndata can overcome.\\nV alidation and testing. In the discussion above, it was assumed\\nthat the generalization loss Lp(w) can somehow be evaluated. Since'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 35, 'page_label': '30', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='data can overcome.\\nV alidation and testing. In the discussion above, it was assumed\\nthat the generalization loss Lp(w) can somehow be evaluated. Since\\nthis depend on the true unknown distribution p(x,t), this evaluation is,\\nstrictly speaking, not possible. How then to estimate the ge neralization\\nloss in order to enable model order selection using a plot as i n Fig. 2.3?\\nThe standard solution is to use validation.\\nThe most basic form of validation prescribes the division of the avail-\\nable data into two sets: a hold-out, or validation, set and the training\\nset. The validation set is used to evaluate an approximation of the\\ngeneralization loss Lp(w) via the empirical average\\nLp(w) ≃ 1\\nNv\\nNv∑\\nn=1\\nℓ(tn,µ(xn ,w)), (2.23)\\nwhere the sum is done over the Nv elements of the validation set.\\nThe just described hold-out approach to validation has a cle ar draw-\\nback, as part of the available data needs to be set aside and no t used\\nfor training. This means that the number of examples that can be'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 35, 'page_label': '30', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='back, as part of the available data needs to be set aside and no t used\\nfor training. This means that the number of examples that can be\\nused for training is smaller than the number of overall avail able data\\npoints. T o partially obviate this problem, a more sophistic ated, and\\ncommonly used, approach to validation is k-fold cross-validation . With\\nthis method, the available data points are partitioned, typ ically at ran-\\ndom, into k equally sized subsets. The generalization loss is then esti -\\n3 This is also deﬁned as generalization error in some referenc es.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 36, 'page_label': '31', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 31\\nmated by averaging k diﬀerent estimates. Each estimate is obtained by\\nretaining one of the k subsets for validation and the remaining k−1\\nsubsets for training. When k = N, this approach is also known as\\nleave-one-out cross-validation.\\nT est set. Once a model order M and model parameters θhave been\\nobtained via learning and validation, one typically needs t o produce\\nan estimate of the generalization loss obtained with this ch oice ( M,θ).\\nThe generalization loss estimated via validation cannot be used for this\\npurpose. In fact, the validation loss tends to be smaller tha n the actual\\nvalue of the generalization loss. After all, we have selecte d the model\\norder so as to yield the smallest possible error on the valida tion set. The\\nupshot is that the ﬁnal estimate of the generalization loss s hould be\\ndone on a separate set of data points, referred to as the test set , that are\\nset aside for this purpose and not used at any stage of learnin g. As an'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 36, 'page_label': '31', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='done on a separate set of data points, referred to as the test set , that are\\nset aside for this purpose and not used at any stage of learnin g. As an\\nexample, in competitions among diﬀerent machine learning a lgorithms,\\nthe test set is kept by a judge to evaluate the submissions and is never\\nshared with the contestants.\\n2.3.4 Maximum A Posteriori (MAP) Criterion\\nW e have seen that the decision regarding the model order M in ML\\nlearning concerns the tension between bias, whose reductio n calls for a\\nlarger M, and estimation error, whose decrease requires a smaller M.\\nML provides a single integer parameter, M, as a gauge to trade oﬀ bias\\nand estimation error. As we will discuss here, the MAP approa ch and,\\nmore generally , regularization, enable a ﬁner control of th ese two terms.\\nThe key idea is to leverage prior information available on th e behavior\\nof the parameters in the absence, or presence, of overﬁtting .\\nT o elaborate, consider the following experiment. Evaluate the ML'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 36, 'page_label': '31', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of the parameters in the absence, or presence, of overﬁtting .\\nT o elaborate, consider the following experiment. Evaluate the ML\\nsolution wM L in (\\n2.18) for diﬀerent values of M and observe how it\\nchanges as we move towards the overﬁtting regime by increasi ng M (see\\nalso [ 23, T able 1.1]). F or the experiment reported in Fig. 2.2, we obtain\\nthe following values: for M = 1, wM L = [0 .93, −1.76]T ; for M = 3,\\nwM L = [ −0.28, 13.32, −35.92, 22.56]T ; and for M = 9, wM L = [13 .86,\\n−780.33, 12.99×103 , −99.27 ×103 , 416.49 ×103 , −1.03 ×106 , 1.56 ×\\n106 , 1.40 ×106 , 0.69 ×106 , −1.44 ×106 ]. These results suggest that a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 37, 'page_label': '32', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='32 A Gentle Introduction through Linear Regression\\nmanifestation of overﬁtting is the large value of norm ∥w∥ of the vector\\nof weights. W e can use this observation as prior information , that is as\\npart of the inductive bias, in designing a learning algorith m.\\nT o this end, we can impose a prior distribution on the vector of\\nweights that gives lower probability to large values. A poss ible, but not\\nthe only , way to do this is to is to assume a Gaussian prior as\\nw∼N(0,α−1 I), (2.24)\\nso that all weights are a priori i.i.d. zero-mean Gaussian va riables with\\nvariance α−1 . Increasing α forces the weights to be smaller as it re-\\nduces the probability associated with large weights. The pr ecision vari-\\nable α is an example of a hyperparameter. In a Bayesian framework,\\nhyperparameters control the distribution of the model para meters. As\\nanticipated, hyperparameters are determined via validati on.\\nRather than maximizing the LL, that is, probability density p(tD |xD ,w,β )'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 37, 'page_label': '32', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='anticipated, hyperparameters are determined via validati on.\\nRather than maximizing the LL, that is, probability density p(tD |xD ,w,β )\\nof the labels in the training set, as for ML, the MAP criterion prescribes\\nthe maximization of the joint probability distribution of w eights and\\nof labels given the prior p(w) = N(w|0,α−1 I), that is,\\np(tD ,w|xD ,β) = p(w)\\nN∏\\nn=1\\np(tn|xn,w,β ). (2.25)\\nNote that a prior probability can also be assumed for the para meter β,\\nbut in this example we leave βas a deterministic parameter. The MAP\\nlearning criterion can hence be formulated as\\nmin\\nw,β\\n−\\nN∑\\nn=1\\nln p(tn|xn ,w,β ) −ln p(w). (2.26)\\nThe name “Maximum a Posteriori” is justiﬁed by the fact that\\nproblem ( 2.26) is equivalent to maximizing the posterior distribution\\nof the parameters w given the available data, as we will further discuss\\nin the next section. This yields the following problem for th e weight\\nvector\\nminw LD (w) + λ\\nN∥w∥2 , (2.27)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 37, 'page_label': '32', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of the parameters w given the available data, as we will further discuss\\nin the next section. This yields the following problem for th e weight\\nvector\\nminw LD (w) + λ\\nN∥w∥2 , (2.27)\\nwhere we have deﬁned λ= α/β and we recall that the training loss is\\nLD (w) = N−1 ∥tD −XD w∥2 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 38, 'page_label': '33', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 33\\nML vs. MAP . Observing ( 2.27), it is important to note the fol-\\nlowing general property of the MAP solution: As the number N of data\\npoints grows large, the MAP estimate tends to the ML estimate , given\\nthat the contribution of the prior information term decreas es as 1 /N.\\nWhen N is large enough, any prior credence is hence superseded by th e\\ninformation obtained from the data.\\nProblem ( 2.27), which is often referred to as ridge regression, mod-\\niﬁes the ML criterion by adding the quadratic (or Tikhonov) regular-\\nization function\\nR(w) = ∥w∥2 (2.28)\\nmultiplied by the term λ/N. The regularization function forces the\\nnorm of the solution to be small, particularly with larger va lues of the\\nhyperparameter λ, or equivalently α. The solution of problem ( 2.27)\\ncan be found by using standard LS analysis, yielding\\nwM AP = ( λI+ XT\\nD XD )−1 XT\\nD tD . (2.29)\\nThis expression conﬁrms that, as N grows large, the term λI becomes'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 38, 'page_label': '33', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='can be found by using standard LS analysis, yielding\\nwM AP = ( λI+ XT\\nD XD )−1 XT\\nD tD . (2.29)\\nThis expression conﬁrms that, as N grows large, the term λI becomes\\nnegligible and the solution tends to the ML estimate ( 2.18) (see [ 86]\\nfor a formal treatment).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 39, 'page_label': '34', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='34 A Gentle Introduction through Linear Regression\\n-40 -30 -20 -10 0\\n0\\n0.5\\n1\\n1.5\\n2\\ngeneralization \\n(via validation)\\ntraining\\nFigure 2.6: Square root of the generalization loss Lp (wM AP ) and of the training\\nloss LD (wM AP ) as a function of the regularization parameter λ for the training data\\nset in Fig. 2.1 with M = 9.\\nFig. 2.6 shows the squared root of the generalization loss Lp(wM AP )\\nand of the training loss LD (wM AP ) as a function of λ (in logarithmic\\nscale) for the training data set in Fig. 2.1 with M = 9. The general-\\nization loss is estimated using validation. W e observe that increasing\\nλ, and hence the relevance of the regularization term, has a si milar im-\\npact as decreasing the model order M. A larger λreduces the eﬀective\\ncapacity of the model. Stated in diﬀerent words, increasing λ reduces\\noverﬁtting but may entail a larger bias.\\nOther standard examples for the prior distribution include the Laplace'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 39, 'page_label': '34', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='capacity of the model. Stated in diﬀerent words, increasing λ reduces\\noverﬁtting but may entail a larger bias.\\nOther standard examples for the prior distribution include the Laplace\\npdf, which yields the l1 norm regularization function R(w) = ∥w∥1 =∑ M\\nj=0 |w|1 . This term promotes the sparsity of the solution, which is\\nuseful in many signal recovery algorithms [\\n14] and in non-parametric\\nfunction estimation [ 146]. The corresponding optimization problem\\nminw LD (w) + λ\\nN∥w∥1 (2.30)\\nis known as LASSO (Least Absolute Shrinkage and Selection Op era-\\ntor).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 40, 'page_label': '35', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 35\\n2.3.5 Regularization\\nW e have seen above that the MAP learning criterion amounts to the\\naddition of a regularization function R(w) to the ML or ERM learning\\nlosses. This function penalizes values of the weight vector w that are\\nlikely to occur in the presence of overﬁtting, or, generally , that are im-\\nprobable on the basis of the available prior information. Th e net eﬀect\\nof this addition is to eﬀectively decrease the capacity of th e model, as\\nthe set of values for the parameter vector wthat the learning algorithm\\nis likely to choose from is reduced. As a result, as seen, regu larization\\ncan control overﬁtting and its optimization requires valid ation.\\nRegularization generally refers to techniques that aim at r educing\\noverﬁtting during training. The discussion in the previous subsection\\nhas focused on a speciﬁc form of regularization that is groun ded in a\\nprobabilistic interpretation in terms of MAP learning. W e n ote that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 40, 'page_label': '35', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='has focused on a speciﬁc form of regularization that is groun ded in a\\nprobabilistic interpretation in terms of MAP learning. W e n ote that\\nthe same techniques, such as ridge regression and LASSO, can also\\nbe introduced independently of a probabilistic framework i n an ERM\\nformulation. F urthermore, apart from the discussed additi on of regu-\\nlarization terms to the empirical risk, there are other ways to perform\\nregularization.\\nOne approach is to modify the optimization scheme by using te ch-\\nniques such as early stopping [56]. Another is to augment the training\\nset by generating artiﬁcial examples and hence eﬀectively i ncreasing\\nthe number N of training examples. Related to this idea is the tech-\\nnique known as bagging. With bagging, we ﬁrst create a number K of\\nbootstrap data sets. Bootstrap data sets are obtained by selecting N\\ndata points uniformly with replacement from D(so that the same data\\npoint generally appears multiple times in the bootstrap dat a set). Then,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 40, 'page_label': '35', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='data points uniformly with replacement from D(so that the same data\\npoint generally appears multiple times in the bootstrap dat a set). Then,\\nwe train the model K times, each time over a diﬀerent bootstrap set.\\nFinally , we average the results obtained from the models usi ng equal\\nweights. If the errors accrued by the diﬀerent models were in dependent,\\nbagging would yield an estimation error that decreases with K. In prac-\\ntice, signiﬁcantly smaller gains are obtained, particular ly for large K,\\ngiven that the bootstrap data sets are all drawn from Dand hence the\\nestimation errors are not independent [ 23].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 41, 'page_label': '36', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='36 A Gentle Introduction through Linear Regression\\n2.4 Bayesian Approach\\nThe frequentist approaches discussed in the previous secti on assume\\nthe existence of a true distribution, and aim at identifying a speciﬁc\\nvalue for the parameters θof a probabilistic model to derive a predictor\\n(cf. ( 2.3)). ML chooses the value θ that maximizes the probability of\\nthe training data, while MAP includes in this calculation al so prior\\ninformation about the parameter vector. With the frequenti st approach,\\nthere are hence two distributions on the data: the true distr ibution,\\napproximated by the empirical distribution of the data and t he model\\n(see further discussion in Sec. 2.8).\\nThe Bayesian viewpoint is conceptually diﬀerent: ( i ) It assumes\\nthat all data points are jointly distributed according to a d istribution\\nthat is known except for some hyperparameters; and ( ii ) the model\\nparameters θ are jointly distributed with the data. As a result, as it'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 41, 'page_label': '36', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='that is known except for some hyperparameters; and ( ii ) the model\\nparameters θ are jointly distributed with the data. As a result, as it\\nwill be discussed, rather than committing to a single value t o explain\\nthe data, the Bayesian approach considers the explanations provided by\\nall possible values of θ, each weighted according to a generally diﬀerent,\\nand data-dependent, “belief” .\\nMore formally , the Bayesian viewpoint sees the vector of par ameters\\nas rvs that are jointly distributed with the labels t D in the training data\\nDand with the new example t. W e hence have the joint distributi on\\np(tD ,w,t |xD ,x). W e recall that the conditioning on the domain points\\nxD and x in the training set and in the new example, respectively , are\\nhallmarks of discriminative probabilistic models. The Bay esian solution\\nsimply takes this modeling choice to its logical end point: i n order to\\npredict the new label t, it directly evaluates the posterior distribution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 41, 'page_label': '36', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='simply takes this modeling choice to its logical end point: i n order to\\npredict the new label t, it directly evaluates the posterior distribution\\np(t|xD ,tD ,x) = p(t|D,x) given the available information ( D,x) by ap-\\nplying the marginalization rules of probability to the join t distribution\\np(tD ,w,t |xD ,x).\\nAs seen, the posterior probability p(t|D,x) can be used as the predic-\\ntive distribution in ( 2.3) to evaluate a predictor ˆt(x). However, a fully\\nBayesian solution returns the entire posterior p(t|D,x), which provides\\nsigniﬁcantly more information about the unobserved label t . As we will\\ndiscuss below, this knowledge, encoded in the posterior p(t|D,x), com-\\nbines both the assumed prior information about the weight ve ctor w'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 42, 'page_label': '37', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.4. Bayesian Approach 37\\nand the information that is obtained from the data D.\\nT o elaborate, in the rest of this section, we assume that the p reci-\\nsion parameter β is ﬁxed and that the only learnable parameters are\\nthe weights in vector w.The joint distribution of the labels in the train-\\ning set, of the weight vector and of the new label, conditione d on the\\ndomain points xD in the training set and on the new point x, is given\\nas\\np(tD ,w,t |xD ,x) = p(w)\\ued19\\ued18\\ued17 \\ued1a\\na priori distribution\\np(tD |xD ,w)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\np(t|x,w)\\ued19 \\ued18\\ued17 \\ued1a\\ndistribution of new data\\n.\\n(2.31)\\nIn the previous equation, we have identiﬁed the a priori dist ribution of\\nthe data; the likelihood term p(tD |xD ,w) = ∏ N\\nn=1 N(tn|µ(xn,w),β−1 )\\nin (\\n2.13)4 ; and the pdf of the new label p(t|w,x) = N(t|µ(x,w),β−1 ).\\nIt is often useful to drop the dependence on the domain points xD and\\nx to write only the joint distribution of the random variables in the\\nmodel as\\np(tD ,w,t ) = p(w)\\ued19\\ued18\\ued17 \\ued1a\\na priori distribution\\np(tD |w)\\ued19 \\ued18\\ued17 \\ued1a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 42, 'page_label': '37', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x to write only the joint distribution of the random variables in the\\nmodel as\\np(tD ,w,t ) = p(w)\\ued19\\ued18\\ued17 \\ued1a\\na priori distribution\\np(tD |w)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\np(t|w)\\ued19 \\ued18\\ued17 \\ued1a\\ndistribution of new data\\n. (2.32)\\nThis factorization can be represented graphically by the Ba yesian Net-\\nwork (BN) in Fig. 2.7. The signiﬁcance of the graph should be clear by\\ninspection, and it will be discussed in detail in Chapter 7.\\nIt is worth pointing out that, by treating all quantities in t he model\\n– except for the hyperparameter α– as rvs, the Bayesian viewpoint does\\naway with the distinction between learning and inference. I n fact, since\\nthe joint distribution is assumed to be known in a Bayesian mo del, the\\nproblem at hand becomes that of inferring the unknown rv t. T o restate\\nthis important point, the Bayesian approach subsumes all pr oblems in\\nthe general inference task of estimating a subset of rvs give n other rvs\\nin a set of jointly distributed rvs with a known joint distrib ution.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 42, 'page_label': '37', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the general inference task of estimating a subset of rvs give n other rvs\\nin a set of jointly distributed rvs with a known joint distrib ution.\\n4 The likelihood is also known as sampling distribution withi n the Bayesian frame-\\nwork [ 92].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 43, 'page_label': '38', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='38 A Gentle Introduction through Linear Regression\\nFigure 2.7: Bayesian Network (BN) describing the joint distribution ( 2.32) of the\\nweight vector w, of the labels t D in the training data D and t in the new example,\\nas used in the Bayesian approach.\\nAs mentioned, we are interested in computing the posterior p roba-\\nbility p(t|D,x) of the new label t given the training data Dand the new\\ndomain point x = x. Dropping again the domain variables to simplify\\nthe notation, we apply standard rules of probability to obta in\\np(t|tD ) = p(tD ,t)\\np(tD ) =\\n∫ p(w)p(tD |w)\\np(tD ) p(t|w)dw\\n=\\n∫\\np(w|tD )p(t|w)dw, (2.33)\\nwhere the second equality follows from the marginalization rule p(tD ,t) =∫\\np(tD ,w,t )dwand the last equality from Bayes’ theorem. Putting back\\nthe dependence on the domain variables, we obtain the predic tive dis-\\ntribution as\\np(t|x,D) =\\n∫\\np(w|D)\\ued19 \\ued18\\ued17 \\ued1a\\nposterior distribution of w\\np(t|x,w)dw. (2.34)\\nThis is the key equation. Accordingly , the Bayesian approac h con-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 43, 'page_label': '38', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tribution as\\np(t|x,D) =\\n∫\\np(w|D)\\ued19 \\ued18\\ued17 \\ued1a\\nposterior distribution of w\\np(t|x,w)dw. (2.34)\\nThis is the key equation. Accordingly , the Bayesian approac h con-\\nsiders the predictive probability p(t|x,w) associated with each value of\\nthe weight vector w weighted by the posterior belief\\np(w|D) = p(w)p(tD |xD ,w)\\np(tD |xD ) . (2.35)\\nThe posterior belief p(w|D), which deﬁnes the weight of the parameter\\nvector w, is hence proportional to the prior belief p(w) multiplied by\\nthe correction p(tD |xD ,w) due to the observed data.\\nComputing the posterior p(w|D), and a fortiori also the predictive\\ndistribution p(t|x,D), is generally a diﬃcult task that requires the adop-\\ntion of approximate inference techniques covered in Chapte r 8. F or this'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 44, 'page_label': '39', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.4. Bayesian Approach 39\\nexample, however, we can directly compute the predictive di stribution\\nas [ 23]\\nt|x,D∼N (µ(x,wM AP ),s2 (x)), (2.36)\\nwhere s2(x) = β−1 (1 + φ(x)T\\n(\\nλI+ XT\\nD XD\\n) −1\\nφ(x)).Therefore, in this\\nparticular example, the optimal predictor under ℓ2 loss is MAP . This is\\nconsequence of the fact that mode and mean of a Gaussian pdf co incide,\\nand is not a general property . Even so, as discussed next, the Bayesian\\nviewpoint can provide signiﬁcantly more information on the label tthan\\nthe ML or MAP .\\nML and MAP vs. Bayesian approach. The Bayesian posterior\\n(2.36) provides a ﬁner prediction of the labels t given the explanatory\\nvariables x as compared to the predictive distribution p(t|x,θM L ) =\\nN(µ(x,wM L ),β−1 ) returned by ML and similarly by MAP . T o see this,\\nnote that the latter has the same variance for all values of x, namely\\nβ−1. Instead, the Bayesian approach reveals that, due to the unev en'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 44, 'page_label': '39', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='note that the latter has the same variance for all values of x, namely\\nβ−1. Instead, the Bayesian approach reveals that, due to the unev en\\ndistribution of the observed values of x, the accuracy of the prediction\\nof labels depends on the value of x: V alues of x closer to the existing\\npoints in the training sets generally exhibit a smaller vari ance.\\nThis is shown in Fig. 2.8, which plots a training set, along with the\\ncorresponding predictor µ(x,wM AP ) and the high-probability interval\\nµ(x,wM AP ) ±s(x) produced by the Bayesian method. W e set M = 9,\\nβ−1 = 0 .1 and α−1 = 0 .2 ×105 .F or reference, we also show the interval\\nµ(x,wM AP ) ±β−1/2 that would result from the MAP analysis. This\\nintervals illustrate the capability of the Bayesian approa ch to provide\\ninformation about the uncertainty associated with the esti mate of t.\\nThis advantage of the Bayesian approach reﬂects its concept ual dif-\\nference with respect to the frequentist approach: The frequ entist pre-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 44, 'page_label': '39', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='This advantage of the Bayesian approach reﬂects its concept ual dif-\\nference with respect to the frequentist approach: The frequ entist pre-\\ndictive distribution refers to a hypothetical new observat ion generated\\nwith the same mechanism as the training data; instead, the Ba yesian\\npredictive distribution quantiﬁes the statistician’s bel ief in the value of\\nt given the assumed prior and the training data.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 45, 'page_label': '40', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='40 A Gentle Introduction through Linear Regression\\n0 0.2 0.4 0.6 0.8 1\\nx\\n-2\\n-1\\n0\\n1\\n2\\n3\\n4\\n5\\n6\\nt\\nµ(x, wM AP)\\nBayesian:\\nµ(x, wM AP) ± s(x)\\nMAP: µ(x, wM AP) ± β− 1\\nFigure 2.8: Illustration of the predictive distribution p(t|x, D) produced by the\\nBayesian method for the training set shown in the ﬁgure as com pared to that ob-\\ntained with the MAP criterion. The larger interval correspo nds to µ(x, w M AP ) ± s(x)\\nfor the Bayesian method, while the smaller interval to µ(x, w M AP ) ± β−1/ 2 for MAP\\n(M = 9, β−1 = 0 .1 and α−1 = 0 .2 × 105 ).\\nF rom ( 2.36), we can make another important general observation\\nabout the relationship with ML and MAP concerning the asympt otic\\nbehavior when N is large. In particular, when N →∞, we have al-\\nready seen that, informally , the limit wM AP →wM L holds. W e now\\nobserve that it is also the case that the variance s2(x) of the Bayesian\\npredictive distribution tends to β−1.As a result, we can conclude that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 45, 'page_label': '40', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='observe that it is also the case that the variance s2(x) of the Bayesian\\npredictive distribution tends to β−1.As a result, we can conclude that\\nthe Bayesian predictive distribution approaches that retu rned by ML\\nwhen N is large. A way to think about this conclusion is that, when\\nN is large, the posterior distribution p(w|D) of the weights tends to\\nconcentrate around the ML estimate, hence limiting the aver age ( 2.34)\\nto the contribution of the ML solution.\\nMarginal likelihood. Another advantage of the Bayesian approach\\nis that, in principle, it allows model selection to be perfor med without\\nvalidation. T oward this end, compute the marginal likelihood\\np(tD |xD ) =\\n∫\\np(w)\\nN∏\\nn=1\\np(tn|xn ,w)dw, (2.37)\\nthat is, the probability density of the training set when mar ginalizing\\nover the weight distribution. With the ML approach, the corr esponding'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 46, 'page_label': '41', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.4. Bayesian Approach 41\\nquantity p(tD |xD ,wM L ) can only increase by choosing a larger model\\norder M. In fact, a larger M entails more degrees of freedom in the\\noptimization ( 2.16) of the LL. A similar discussion applies also to MAP .\\nHowever, this is not the case for ( 2.37): a larger M implies a more\\n“spread-out” prior distribution of the weights, which may r esult in a\\nmore diﬀuse distribution of the labels in ( 2.37). Hence, increasing M\\nmay yield a smaller marginal likelihood.\\n0 2 4 6 8\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1 10-7\\n = 0\\n = 0/8\\n = 0/2\\n = 0/4\\nFigure 2.9: Marginal likelihood versus the model order M for the training set of\\nFig. 2.1 (β = 10, α0 = 10 −3 ).\\nT o illustrate this point, Fig. 2.9 plots the marginal likelihood for\\nthe data set in Fig. 2.1 for β = 10 and three diﬀerent values of α as a\\nfunction of M. The marginal likelihood in this example can be easily\\ncomputed since we have\\ntD |xD = xD ∼N(0,α−1 XD XT\\nD + β−1 I). (2.38)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 46, 'page_label': '41', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function of M. The marginal likelihood in this example can be easily\\ncomputed since we have\\ntD |xD = xD ∼N(0,α−1 XD XT\\nD + β−1 I). (2.38)\\nIt is observed that the marginal likelihood presents a peak a t a given\\nvalue of M, while decreasing when moving away from the optimal value.\\nTherefore, we could take the value of M at which the marginal likeli-\\nhood is maximized as the selected model order.\\nDoes this mean that validation is really unnecessary when ad opting\\na Bayesian viewpoint? Unfortunately , this is not necessari ly the case.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 47, 'page_label': '42', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='42 A Gentle Introduction through Linear Regression\\nIn fact, one still needs to set the hyperparameter α. As seen in Fig.\\n2.9, varying α can lead to diﬀerent conclusions on the optimal value\\nof M. An alternative approach would be to treat α, and even M, as\\nrvs with given priors to be speciﬁed (see, e.g., [ 131]). This would not\\nobviate the problem of selecting hyperparameters – now deﬁn ing the\\nprior distributions of αand M – but it can lead to powerful hierarchical\\nmodels. The necessary tools will be discussed in Chapter 7.\\nAs a ﬁnal note, rather than using often impractical exhausti ve\\nsearch methods, the optimization over the hyperparameters and the\\nmodel order M for all criteria discussed so far, namely ML, MAP and\\nBayesian, can be carried out using so-called Bayesian optim ization tools\\n[132]. A drawback of these techniques is that they have their own h y-\\nperparameters that need to be selected.\\nEmpirical Bayes. Straddling both frequentist and Bayesian view-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 47, 'page_label': '42', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[132]. A drawback of these techniques is that they have their own h y-\\nperparameters that need to be selected.\\nEmpirical Bayes. Straddling both frequentist and Bayesian view-\\npoints is the so-called empirical Bayes method. This approa ch assumes\\nan a priori distribution for the parameters, but then estima tes the pa-\\nrameters of the prior – say mean and variance of a Gaussian pri or –\\nfrom the data [ 48].\\n2.5 Minimum Description Length (MDL) ∗\\nIn this section, we brieﬂy introduce a third, conceptually d istinct, learn-\\ning philosophy – the MDL criterion. The reader is warned that the\\ntreatment here is rather superﬁcial, and that a more formal d eﬁnition\\nof the MDL criterion would would require a more sophisticate d dis-\\ncussion, which can be found in [ 60]. F urthermore, some background\\nin information theory is preferable in order to fully beneﬁt from this\\ndiscussion.\\nT o start, we ﬁrst recall from the treatment above that learni ng'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 47, 'page_label': '42', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in information theory is preferable in order to fully beneﬁt from this\\ndiscussion.\\nT o start, we ﬁrst recall from the treatment above that learni ng\\nrequires the identiﬁcation of a model, or hypothesis class – here the\\nmodel order M – and of a speciﬁc hypothesis, deﬁned by parameters θ\\n– here θ = ( w,β) – within the class. While MDL can be used for both\\ntasks, we will focus here only on the ﬁrst.\\nT o build the necessary background, we now need to review the\\nrelationship between probabilistic models and compressio n. T o this end,\\nconsider a signal x taking values in a ﬁnite alphabet X, e.g., a pixel'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 48, 'page_label': '43', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.5. Minimum Description Length (MDL) ∗ 43\\nin a gray scale image. Fix some probability mass function (pm f) p(x)\\non this alphabet. A key result in information theory states t hat it is\\npossible to design a lossless compression scheme that uses ⌈−log p(x)⌉\\nbits to represent value x5\\nBy virtue of this result, the choice of a probability distrib ution p(x)\\nis akin to the selection of a lossless compression scheme tha t produces a\\ndescription of around −log p(x) bits to represent value x. Note that the\\ndescription length −log p(x) decreases with the probability assigned by\\np(x) to value x: more likely values under p(x) are assigned a smaller\\ndescription. Importantly , a decoder would need to know p(x) in order\\nto recover x from the bit description.\\nAt an informal level, the MDL criterion prescribes the selec tion\\nof a model that compresses the training data to the shortest p ossi-\\nble description. In other words, the model selected by MDL de ﬁnes a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 48, 'page_label': '43', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of a model that compresses the training data to the shortest p ossi-\\nble description. In other words, the model selected by MDL de ﬁnes a\\ncompression scheme that describes the data set Dwith the minimum\\nnumber of bits. As such, the MDL principle can be thought of as a for-\\nmalization of Occam’s razor: choose the model that yields th e simplest\\nexplanation of the data. As we will see below, this criterion naturally\\nleads to a solution that penalizes overﬁtting.\\nWhat is the length of the description of a data set Dthat results\\nfrom the selection of a speciﬁc value of M? The answer is not straight-\\nforward, since, for a given value of M, there are as many probability\\ndistributions as there are values for the corresponding par ameters θ\\nto choose from. A formal calculation of the description leng th would\\nhence require the introduction of the concept of universal c ompression\\nfor a given probabilistic model [ 60]. Here, we will limit ourselves to a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 48, 'page_label': '43', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='hence require the introduction of the concept of universal c ompression\\nfor a given probabilistic model [ 60]. Here, we will limit ourselves to a\\nparticular class of universal codes known as two-part codes .\\nUsing two-part codes, we can compute the description length for\\nthe data Dthat results from the choice of a model order M as fol-\\nlows. First, we obtain the ML solution ( wM L ,βM L ). Then, we describe\\nthe data set by using a compression scheme deﬁned by the proba bil-\\nity p(t|x,wM L ,βM L ) = N(t|µ(x,wM L ),β−1\\nM L ). As discussed, this pro-\\n5 This is known as Kraft’s inequality . More precisely , it stat es that the lossless\\ncompression scheme at hand is preﬁx-free and hence decodabl e, or invertible, without\\ndelay [ 38].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 49, 'page_label': '44', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='44 A Gentle Introduction through Linear Regression\\nduces a description of approximately −∑ N\\nn=1 logp(tn|xn,wM L ,βM L )\\nbits\\n6. This description is, however, not suﬃcient, since the deco der of\\nthe description should also be informed about the parameter s ( wM L ,βM L ).\\nUsing quantization, the parameters can be described by mean s of a\\nnumber C(M) of bits that is proportional to the number of parameters,\\nhere M+ 2.Concatenating these bits with the description produced by\\nthe ML model yields the overall description length\\n−\\nN∑\\nn=1\\nlogp(tn|xn,wM L ,βM L ) + C(M). (2.39)\\nMDL – in the simpliﬁed form discussed here – selects the model order\\nM that minimizes the description length ( 2.39). Accordingly , the term\\nC(M) acts as a regularizer. The optimal value of M for the MDL\\ncriterion is hence the result of the trade-oﬀ between the min imization\\nof the overhead C(M), which calls for a small value of M, and the\\nminimization of the NLL, which decreases with M.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 49, 'page_label': '44', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='criterion is hence the result of the trade-oﬀ between the min imization\\nof the overhead C(M), which calls for a small value of M, and the\\nminimization of the NLL, which decreases with M.\\nUnder some technical assumptions, the overhead term can be o ften\\nevaluated in the form ( K/2) ln N + c, where K is the number of pa-\\nrameters in the model and cis a constant. This expression is not quite\\nuseful in practice, but it provides intuition about the mech anism used\\nby MDL to combat overﬁtting.\\n2.6 Information-Theoretic Metrics\\nW e now provide a brief introduction to information theoreti c metrics\\nby leveraging the example studied in this chapter. As we will see in the\\nfollowing chapters, information-theoretic metrics are us ed extensively\\nin the deﬁnition of learning algorithms. Appendix A provide s a detailed\\nintroduction to information-theoretic measures in terms o f inferential\\ntasks. Here we introduce the key metrics of Kullback-Leible r (KL) di-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 49, 'page_label': '44', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='introduction to information-theoretic measures in terms o f inferential\\ntasks. Here we introduce the key metrics of Kullback-Leible r (KL) di-\\nvergence and entropy by examining the asymptotic behavior o f ML in\\nthe regime of large N. The case with ﬁnite N is covered in Chapter 6\\n(see Sec.\\n6.4.3).\\n6 This neglects the technical issue that the labels are actual ly continuous rvs,\\nwhich could be accounted for by using quantization.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 50, 'page_label': '45', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.6. Information-Theoretic Metrics 45\\nT o start, we revisit the ML problem ( 2.15), which amounts to the\\nminimization of the NLL −N−1 ∑ N\\nn=1 ln p(tn|xn,w,β ), also known as\\nlog-loss. According to the frequentist viewpoint, the trai ning set vari-\\nables are drawn i.i.d. according to the true distribution p(x,t), i.e.,\\n(xn,tn ) ∼pxt i.i.d. over n = 1 ,...,N . By the strong law of large num-\\nbers, we then have the following limit with probability one\\n−1\\nN\\nN∑\\nn=1\\nln p(tn |xn,w,β ) →E(x,t)∼pxt [−ln p(t|x,w,β )] . (2.40)\\nAs we will see next, this limit has a useful interpretation in terms of\\nthe KL divergence.\\nThe KL divergence between two distributions pand q is deﬁned as\\nKL(p∥q) = E x∼px\\n[\\nln p(x)\\nq(x)\\n]\\n. (2.41)\\nThe KL divergence is hence the expectation of the Log-Likeli hood Ratio\\n(LLR) ln( p(x)/q(x)) between the two distributions, where the expecta-\\ntion is taken with respect to the distribution at the numerat or. The'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 50, 'page_label': '45', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='(LLR) ln( p(x)/q(x)) between the two distributions, where the expecta-\\ntion is taken with respect to the distribution at the numerat or. The\\nLLR tends to be larger, on average, if the two distributions d iﬀer more\\nsigniﬁcantly , while being uniformly zero only when the two d istribu-\\ntions are equal. Therefore, the KL divergence measures the “ distance”\\nbetween two distributions. As an example, with p(x) = N(x|µ1,σ2\\n1 )\\nand q(x) = N(x|µ2 ,σ2\\n2 ), we have\\nKL(p∥q) = 1\\n2\\n(\\nσ2\\n1\\nσ2\\n2\\n+ (µ2 −µ1)2\\nσ2\\n2\\n−1 + ln σ2\\n2\\nσ2\\n1\\n)\\n, (2.42)\\nand, in the special case σ2\\n1 = σ2\\n2 = σ2, we can write\\nKL(p∥q) = 1\\n2\\n(µ2 −µ1)2\\nσ2 , (2.43)\\nwhich indeed increase as the two distributions become more d iﬀerent.\\nThe KL divergence is measured in nats when the natural logari thm\\nis used as in ( 2.41), while it is measured in bits if a logarithm in base 2\\nis used. In general, the KL divergence has several desirable properties\\nas a measure of the distance of two distributions [ 23, pp. 55-58]. The'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 50, 'page_label': '45', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is used. In general, the KL divergence has several desirable properties\\nas a measure of the distance of two distributions [ 23, pp. 55-58]. The\\nmost notable is Gibbs’ inequality\\nKL(p∥q) ≥0, (2.44)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 51, 'page_label': '46', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='46 A Gentle Introduction through Linear Regression\\nwhere equality holds if and only if the two distributions p and q are\\nidentical. Nevertheless, the KL divergence has also some se emingly un-\\nfavorable features, such as its non-symmetry , that is, the i nequality\\nKL(p∥q) ̸= KL( q∥p). W e will see in Chapter 8 that the absence of\\nsymmetry can be leveraged to deﬁne diﬀerent types of approxi mate\\ninference and learning techniques.\\nImportantly , the KL divergence can be written as\\nKL(p||q) = E x∼px [−ln q(x)]\\ued19 \\ued18\\ued17 \\ued1a\\nH (p||q)\\n−Ex∼px [−ln p(x)]\\ued19 \\ued18\\ued17 \\ued1a\\nH (p)\\n, (2.45)\\nwhere the ﬁrst term, H(p||q), is known as cross-entropy between p(x)\\nand q(x) and plays an important role as a learning criterion as discu ssed\\nbelow; while the second term, H(p), is the entropy of distribution p(x),\\nwhich is a measure of randomness. W e refer to Appendix A for fu rther\\ndiscussion on the entropy .\\nBased on the decomposition ( 2.45), we observe that the cross-entropy'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 51, 'page_label': '46', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='which is a measure of randomness. W e refer to Appendix A for fu rther\\ndiscussion on the entropy .\\nBased on the decomposition ( 2.45), we observe that the cross-entropy\\nH(p||q) can also be taken as a measure of divergence between two dis-\\ntributions when one is interested in optimizing over the dis tribution\\nq(x), since the latter does not appear in the entropy term. Note t hat\\nthe cross-entropy , unlike the KL divergence, can be negativ e.\\nUsing the deﬁnition ( 2.41), the expected log-loss on the right-hand\\nside of ( 2.40) can be expressed as\\nE(x,t)∼pxt [−ln p(t|x,w,β )] = E x∼px [H(p(t|x)||p(t|x,w,β ))], (2.46)\\nwhich can be easily veriﬁed by using the law of iterated expec tations.\\nTherefore, the average log-loss is the average over the doma in point x\\nof the cross-entropy between the real predictive distribut ion p(t|x) and\\nthe predictive distribution p(t|x,w,β ) dictated by the model. F rom\\n(2.46), the ML problem ( 2.15) can be interpreted as an attempt to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 51, 'page_label': '46', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the predictive distribution p(t|x,w,β ) dictated by the model. F rom\\n(2.46), the ML problem ( 2.15) can be interpreted as an attempt to\\nmake the model-based discriminative distribution p(t|x,w,β ) as close\\nas possible to the actual posterior p(t|x). This is done by minimizing\\nthe KL divergence, or equivalently the cross-entropy , upon averaging\\nover p(x).\\nAs ﬁnal remarks, in machine learning, it is common to use the\\nnotation KL( p∥q) even when q is unnormalized, that is, when q(x) is'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 52, 'page_label': '47', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.7. Interpretation and Causality ∗ 47\\nnon-negative, but we may have the inequality\\n∫\\nq(x)dx ̸= 1. W e also\\nobserve that the entropy H(p) = E x∼px [−ln p(x)] is non-negative for\\ndiscrete rvs, while it may be negative for continuous rvs. Du e to its\\ndiﬀerent properties when evaluated for continuous rvs, the quantity\\nH(p) should be more properly referred to as diﬀerential entropy when\\nthe distribution p is a pdf [ 38]. In the rest of this monograph, we will\\nnot always make this distinction.\\n2.7 Interpretation and Causality ∗\\nHaving learned a predictive model using any of the approache s dis-\\ncussed above, an important, and often overlooked, issue is t he interpre-\\ntation of the results returned by the learned algorithm. Thi s has in fact\\ngrown into a separate ﬁeld within the active research area of deep neu-\\nral networks (see Chapter 4) [\\n102]. Here, we describe a typical pitfall of\\ninterpretation that relates to the assessment of causality relationships'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 52, 'page_label': '47', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ral networks (see Chapter 4) [\\n102]. Here, we describe a typical pitfall of\\ninterpretation that relates to the assessment of causality relationships\\nbetween the variables in the model. W e follow an example in [ 113].\\nFig. 2.10 (top) shows a possible distribution of data points on the\\nplane deﬁned by coordinates x = exercise and t = cholesterol (the\\nnumerical values are arbitrary). Learning a model that rela tes tas the\\ndependent variable to the variable x would clearly identify an upward\\ntrend – an individual that exercises more can be predicted to have a\\nhigher cholesterol level. This prediction is legitimate an d supported by\\nthe available data, but can we also conclude that exercising less would\\nreduce one’s cholesterol? In other words, can we conclude th at there\\nexists a causal relationships between x and t? W e know the answer to\\nbe no, but this cannot be ascertained from the data in the ﬁgur e.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 53, 'page_label': '48', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='48 A Gentle Introduction through Linear Regression\\n-5 0 5 10 15 20 25\\nExercise\\n-20\\n0\\n20\\n40Cholesterol\\n-5 0 5 10 15 20 25\\nExercise\\n-20\\n0\\n20\\n40Cholesterol\\n20 30 40\\n50\\n10\\nFigure 2.10: Illustration of Simpson’s paradox [ 113].\\nThe way out of this conundrum is to leverage prior informatio n\\nwe have about the problem domain. In fact, we can explain away this\\nspurious correlation by including another measurable vari able in the\\nmodel, namely age. T o see this, consider the same data, now re drawn\\nby highlighting the age of the individual corresponding to e ach data\\npoint. The resulting plot, seen in Fig. 2.10 (bottom), reveals that older\\npeople — within the observed bracket — tend to have a higher ch oles-\\nterol as well as to exercise more. Therefore, age is a common c ause of\\nboth exercise and cholesterol levels. In order to capture th e causality\\nrelationship between the latter variables, we hence need to adjust for\\nage. Doing this requires to consider the trend within each ag e sepa-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 53, 'page_label': '48', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='relationship between the latter variables, we hence need to adjust for\\nage. Doing this requires to consider the trend within each ag e sepa-\\nrately , recovering the expected conclusion that exercisin g is useful to\\nlower one’s cholesterol. 7\\nW e conclude that in this example the correlation between x and t,\\nwhile useful for prediction, should not be acted upon for dec ision mak-\\ning. When assessing the causal relationship between xand t, we should\\nﬁrst understand which other variables may explain the obser vations\\nand then discount any spurious correlations.\\nThis discussion reveals an important limitation of most exi sting ma-\\nchine learning algorithms when it comes to identifying caus ality rela-\\ntionships, or, more generally , to answering counterfactua l queries [ 112].\\nThe study of causality can be carried out within the elegant f ramework\\n7 This example is an instance of the so called Simpson’s parado x: patterns visible'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 53, 'page_label': '48', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The study of causality can be carried out within the elegant f ramework\\n7 This example is an instance of the so called Simpson’s parado x: patterns visible\\nin the data disappear, or are even reversed, on the segregate d data.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 54, 'page_label': '49', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.8. Summary 49\\nof interventions on probabilistic graphical models developed by Pearl\\n[113, 81, 118]. Other related approaches are covered in [ 115]. More dis-\\ncussion on probabilistic graphical models can be found in Ch apter 7.\\n2.8 Summary\\nIn this chapter, we have reviewed three key learning framewo rks, namely\\nfrequentist, Bayesian and MDL, within a parametric probabi listic set-\\nup. The frequentist viewpoint postulates the presence of a t rue un-\\nknown distribution for the data, and aims at learning a predi ctor that\\ngeneralizes well on unseen data drawn from this distributio n. This can\\nbe done either by learning a probabilistic model to be plugge d into\\nthe expression of the optimal predictor or by directly solvi ng the ERM\\nproblem over the predictor. The Bayesian approach outputs a predic-\\ntive distribution that combines prior information with the data by solv-\\ning the inference problem of computing the posterior distri bution over'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 54, 'page_label': '49', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tive distribution that combines prior information with the data by solv-\\ning the inference problem of computing the posterior distri bution over\\nthe unseen label. Finally , the MDL method aims at selecting a model\\nthat allows the data to be described with the smallest number of bits,\\nhence doing away with the need to deﬁne the task of generalizi ng over\\nunobserved examples.\\nThe chapter has also focused extensively on the key problem o f\\noverﬁtting, demonstrating how the performance of a learnin g algorithm\\ncan be understood in terms of bias and estimation error. In pa rticular,\\nwhile choosing a hypothesis class is essential in order to en able learning,\\nchoosing the “wrong” class constitutes an irrecoverable bi as that can\\nmake learning impossible. As a real-world example, as repor ted in [\\n109],\\nincluding as independent variables in x the ZIP code of an individual\\nseeking credit at a bank may discriminate against immigrant s or minori-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 54, 'page_label': '49', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='109],\\nincluding as independent variables in x the ZIP code of an individual\\nseeking credit at a bank may discriminate against immigrant s or minori-\\nties. Another example of this phenomenon is the famous exper iment by\\nB. F. Skinner on pigeons [ 133].\\nW e conclude this chapter by emphasizing an important fact ab out\\nthe probabilistic models that are used in modern machine lea rning\\napplications. In frequentist methods, typically at least t wo (possibly\\nconditional) distributions are involved: the empirical da ta distribution\\nand the model distribution. The former amounts to the histog ram of\\nthe data which, by the law of large numbers, tends to the real d istribu-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 55, 'page_label': '50', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='50 A Gentle Introduction through Linear Regression\\ntion when the number of data points goes to inﬁnity; while the latter\\nis parametrized and is subject to optimization. F or this rea son, diver-\\ngence metrics between the two distributions play an importa nt role in\\nthe development of learning algorithms. W e will see in the re st of the\\nmonograph that other frequentist methods may involve a sing le distri-\\nbution rather than two, as discussed in Sec. 6.6, or an additional, so\\ncalled variational, distribution, as covered in Sec. 6.3 and Chapter 8.\\nIn contrast, Bayesian methods posit a single coherent distr ibution\\nover the data and the parameters, and frame the learning prob lem as\\none of inference of unobserved variables. As we will discuss in Chapter 8,\\nvariational Bayesian methods also introduce an additional variational\\ndistribution and are a building block for frequentist learn ing in the\\npresence of unobserved variables.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 55, 'page_label': '50', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='variational Bayesian methods also introduce an additional variational\\ndistribution and are a building block for frequentist learn ing in the\\npresence of unobserved variables.\\nThe running example in this chapter has been one of linear reg res-\\nsion for a Gaussian model. The next chapter provides the nece ssary\\ntools to construct and learn more general probabilistic mod els.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 56, 'page_label': '51', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3\\nProbabilistic Models for Learning\\nIn the previous chapter, we have introduced the frequentist , Bayesian,\\nand MDL learning frameworks. As we have seen, parametric pro babilis-\\ntic models play a key role for all three of them. The linear reg ression\\nexample considered in the previous chapter was limited to a s imple lin-\\near Gaussian model, which is insuﬃcient to capture the range of learn-\\ning problems that are encountered in practice. F or instance , scenarios\\nof interest may encompass discrete variables or non-negati ve quantities.\\nIn this chapter, we introduce a family of probabilistic mode ls, known as\\nthe exponential family , whose members are used as components in many\\nof the most common probabilistic models and learning algori thms. The\\ntreatment here will be leveraged in the rest of the monograph in order\\nto provide the necessary mathematical background. Through out this\\nchapter, we will speciﬁcally emphasize the common properti es of the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 56, 'page_label': '51', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to provide the necessary mathematical background. Through out this\\nchapter, we will speciﬁcally emphasize the common properti es of the\\nmodels in the exponential family , which will prove useful fo r deriving\\nlearning algorithms in the following chapters.\\n51'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 57, 'page_label': '52', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='52 Probabilistic Models for Learning\\n3.1 Preliminaries\\nW e start with a brief review of some deﬁnitions that will be us ed\\nthroughout the chapter and elsewhere in the monograph (see [ 28] for\\nmore details). Readers with a background in convex analysis and cal-\\nculus may just review the concept of suﬃcient statistic in th e last para-\\ngraph.\\nFirst, we deﬁne a convex set as a subset of RD , for some D, that\\ncontains all segments between any two points in the set. Geom etrically ,\\nconvex sets hence cannot have “indentations” . F unction f(x) is convex\\nif its domain is a convex set and if it satisﬁes the inequality f(λx+ (1 −\\nλ)y) ≤λf(x) + (1 −λ)f(y) for all x and y in its domain and for all\\n0 ≤λ≤1. Geometrically , this condition says that the function is “ ∪”-\\nshaped: the curve deﬁning the function cannot lie above the s egment\\nobtained by connecting any two points on the curve. A functio n is\\nstrictly convex if the inequality above is strict except for λ = 0 or'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 57, 'page_label': '52', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='obtained by connecting any two points on the curve. A functio n is\\nstrictly convex if the inequality above is strict except for λ = 0 or\\nλ = 1 when x ̸= y. A concave, or strictly concave, function is deﬁned\\nby reversing the inequality above – it is hence “ ∩”-shaped.\\nThe minimization of a convex (“ ∪”) function over a convex con-\\nstraint set or the maximization of a concave (“ ∩”) function over a\\nconvex constraint set are known as convex optimization problems . F or\\nthese problems, there exist powerful analytical and algori thmic tools\\nto obtain globally optimal solutions [ 28].\\nW e also introduce two useful concepts from calculus. The gradient\\nof a diﬀerentiable function f(x) with x= [ x1 ···xD ]T ∈RD is deﬁned\\nas the D×1 vector ∇f(x) = [ ∂f(x)/∂x1 ···∂f(x)/∂xD ]T containing\\nall partial derivatives. At any point x in the domain of the function,\\nthe gradient is a vector that points to the direction of local ly maximal\\nincrease of the function. The Hessian ∇2f(x) is the D×Dmatrix with'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 57, 'page_label': '52', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the gradient is a vector that points to the direction of local ly maximal\\nincrease of the function. The Hessian ∇2f(x) is the D×Dmatrix with\\n(i,j) element given by the second-order derivative ∂2 f(x)/∂xi ∂xj . It\\ncaptures the local curvature of the function.\\nFinally , we deﬁne the concept of suﬃcient statistic . Consider a rv\\nx ∼p(x|θ), whose distribution depends on some parameter θ. A func-\\ntion f(x) is a suﬃcient statistic 1 for the estimate of θ if the likelihood\\n1 A statistic is a function of the data.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 58, 'page_label': '53', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.2. The Exponential Family 53\\np(x|θ) of the parameters θdepends on xonly through the function f(x).\\nAs an example, for a rv x ∼N(0,σ2 ), the function f(x) = x2 can be\\neasily seen to be suﬃcient for the estimate of the variance σ2.\\n3.2 The Exponential Family\\nIn this section, we introduce the exponential family of para metric prob-\\nabilistic models. As it will be discussed, this family inclu des as special\\ncases most of the distributions typically assumed when solv ing machine\\nlearning problems. F or example, it includes Gaussian, Lapl ace, Gamma,\\nBeta and Dirichlet pdfs, as well as Bernoulli, Categorical, multinomial,\\nand Poisson pmfs. An extensive list can be found in [\\n156].\\n3.2.1 Basic Deﬁnitions\\nThe exponential family contains probabilistic models of th e form\\np(x|η) = 1\\nZ(η) exp\\n( K∑\\nk=1\\nηk uk (x)\\n)\\nm(x)\\n= 1\\nZ(η) exp\\n(\\nηT u(x)\\n)\\nm(x), (3.1)\\nwhere xis a discrete or continuous-valued vector; η= [ η1 ···ηK ]T is the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 58, 'page_label': '53', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x|η) = 1\\nZ(η) exp\\n( K∑\\nk=1\\nηk uk (x)\\n)\\nm(x)\\n= 1\\nZ(η) exp\\n(\\nηT u(x)\\n)\\nm(x), (3.1)\\nwhere xis a discrete or continuous-valued vector; η= [ η1 ···ηK ]T is the\\nvector of natural parameters ; u(x) = [ u1 (x) ··· uK (x)]T is the vector of\\nsuﬃcient statistics , with each suﬃcient statistic uk (x) being a function\\nof x; m(x) ≥0 is the base measure , which is a function of x that is\\nindependent of the natural parameter vector η; and Z(η) is the partition\\nfunction\\nZ(η) =\\n∫\\nexp\\n(\\nηT u(x)\\n)\\nm(x) d x (3.2)\\nfor continuous rvs and Z(η) = ∑\\nx exp\\n(\\nηT u(x)\\n)\\nm(x) for discrete rvs.\\nThe suﬃcient statistic vector u(x) can be seen to be a suﬃcient statistic\\nfor the estimation of the natural parameter vector η given x.\\nThe partition function normalizes the distribution so that it inte-\\ngrates, or sums, to one. It is also often useful to use the unnormalized\\ndistribution\\n˜p(x|η) = exp\\n(\\nηT u(x)\\n)\\nm(x), (3.3)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 59, 'page_label': '54', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='54 Probabilistic Models for Learning\\nsince the latter is generally easier to evaluate.\\nIn short, distributions belonging to the exponential famil y are such\\nthat the logarithm of the unnormalized distribution ˜ p(x|η), which is\\nalso known as the energy function , is linear 2 in the natural parameters,\\ni.e.,\\nln ˜p(x|η) = ηT u(x) + ln m(x) . (3.4)\\nF or this reason, models of the form ( 3.1) are also referred to as log-\\nlinear.3 Including the partition function, the LL of the natural para m-\\neters can be written as\\nln p(x|η) = ηT u(x) −A(η) + ln m(x), (3.5)\\nwhere\\nA(η) = ln Z(η) (3.6)\\nis the log-partition function.\\nAs per ( 3.1), a probabilistic model belonging to the exponential\\nfamily is identiﬁed by the set of suﬃcient statistics {uk (x)}K\\nk=1 , whose\\norder is irrelevant, and by the measure m(x). A speciﬁc hypothesis\\nwithin the model is selected by determining the natural para meter vec-\\ntor η. The set of feasible values for the natural parameters conta ins all,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 59, 'page_label': '54', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='within the model is selected by determining the natural para meter vec-\\ntor η. The set of feasible values for the natural parameters conta ins all,\\nand only , the vectors η for which the unnormalized distribution ˜ p(x|η)\\ncan be normalized, that is, for which the inequality A(η) < ∞holds.\\nW e will see below that this set is convex.\\nExample 3.1. (Gaussian pdf) As a ﬁrst example, consider the Gaus-\\nsian pdf\\nN(x|ν,σ2 ) = 1\\n(2πσ2 )1/2 exp\\n(\\n−x2\\n2σ2 + ν\\nσ2 x− ν2\\n2σ\\n2\\n)\\n.\\nThis can be written in the form ( 3.1) upon identiﬁcation of the base\\nmeasure m(x) = 1 and of the suﬃcient statistics u(x) = [ x x2]. Note\\nthat, in order to do this, we need to map the parameters ( ν,σ2 ) to the\\n2 Or, more precisely , aﬃne given the presence of an additive co nstant.\\n3 There exists a more general version of the exponential famil y in which the\\nnatural parameters are non-linear functions of the paramet ers that identify the dis-\\ntribution.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 60, 'page_label': '55', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.2. The Exponential Family 55\\nnatural parameters via the relationship η = [ ν/σ2 −1/(2σ2 ) ]. As a\\nresult, while the parameters ( ν,σ2 ) take all possible allowed values\\nin R ×R+, the natural parameter vector η takes values in the set\\nR ×R−. Every value η in this set corresponds to a valid pdf within\\nthe hypothesis class of N(x|ν,σ2 ) models. Finally , we can compute the\\nlog-partition function as\\nA(η) = ν2\\n2σ2 + 1\\n2 ln(2πσ2 ) = −η2\\n1\\n4η2\\n−1\\n2 ln\\n(\\n−\\n( 2η2\\n2π\\n))\\n. (3.7)\\nIn order to ensure identiﬁability of the natural parameters , the suﬃ-\\ncient statistics {uk (x)}K\\nk=1 need to be linearly independent. This means\\nthat no suﬃcient statistic uk (x) should be computable, for all x, as\\na linear combination of other suﬃcient statistics uk′ (x) with k′ ̸= k.\\nF or example, this is the case for the vector u(x) = [ x x2 ] of suﬃcient\\nstatistics for the Gaussian distribution. This condition i s referred to as\\nminimal representation [\\n151]. Unless stated otherwise, we will assume'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 60, 'page_label': '55', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='statistics for the Gaussian distribution. This condition i s referred to as\\nminimal representation [\\n151]. Unless stated otherwise, we will assume\\nin the following that the exponential family under study is m inimal.\\nF urthermore, we will assume the technical condition that th e set of fea-\\nsible values for η is also open (that is, it excludes its boundary), which\\nyields a regular exponential family .\\n3.2.2 Natural Parameters, Mean Parameters and Convexity\\nAs suggested by the example above, once the suﬃcient statist ics and\\nthe base measure are ﬁxed, a speciﬁc hypothesis – pdf or pmf – c an be\\nidentiﬁed by either specifying the vector ηof natural parameters or the\\nvector µ of mean parameters. The latter is deﬁned as the expectation\\nof the vector of suﬃcient statistics\\nµ= E x∼p(x|η)[u(x)]. (3.8)\\nF or the preceding example, we have the mean parameter vector µ =\\n[E[x] = ν, E[x2 ] = σ2 + ν2]T . W e can therefore use the notation p(x|µ)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 60, 'page_label': '55', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='µ= E x∼p(x|η)[u(x)]. (3.8)\\nF or the preceding example, we have the mean parameter vector µ =\\n[E[x] = ν, E[x2 ] = σ2 + ν2]T . W e can therefore use the notation p(x|µ)\\nas well as p(x|η) to describe a model in the exponential family . As we\\nwill see below, the availability of these two parametrizati ons implies\\nthat learning can be done on either sets of variables.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 61, 'page_label': '56', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='56 Probabilistic Models for Learning\\nA key property of the exponential family is that the mapping b e-\\ntween natural parameters and mean parameters is given by the gradi-\\nent of the log-partition function. Speciﬁcally , it can be ve riﬁed that the\\npartial derivative of the log-partition function equals th e mean of the\\ncorresponding suﬃcient statistic\\n∂A(η)\\n∂ηk\\n= E x∼p(x|η) [uk (x)] = µk , (3.9)\\nor, in vector form,\\n∇η A(η) = E x∼p(x|η) [u(x)] = µ. (3.10)\\nAlthough we will not be making use of this result here, the Hes sian\\n∇2\\nη A(η) of the log-partition function can be similarly seen to equa l the\\ncovariance matrix of the suﬃcient statistics\\n4 . It is also equal to the\\nFisher information matrix for the natural parameters [ 45].\\nThe log-partition function A(η) in ( 3.6) is strictly convex in η, as\\nit follows from the fact that it is a log-sum-exp function com posed\\nwith an aﬃne function [ 28]. This property has the following important'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 61, 'page_label': '56', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='it follows from the fact that it is a log-sum-exp function com posed\\nwith an aﬃne function [ 28]. This property has the following important\\nconsequences. First, the set of feasible values for the natu ral parameters\\nis a convex set [ 28]. Note that this is generally not the case for the\\ncorresponding set of feasible values for the mean parameter s. Second,\\nthe mapping ( 3.10) between natural parameters ηand mean parameters\\nµ is invertible (see, e.g., [ 10])5 .\\nThird, the LL function ln p(x|η) in ( 3.5) is a concave function of η.\\nAs further discussed below, the ML problem hence amounts to m axi-\\nmization of a convex optimization problem.\\n3.2.3 Bernoulli Model\\nDue to its importance for binary classiﬁcation problems, we detail here\\nthe Bernoulli model. W e also introduce the important logist ic sigmoid\\nfunction.\\n4 More generally , the log-partition function A(η) is the cumulant function for rv\\nx.\\n5 The inverse mapping between mean parameters and natural par ameters is given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 61, 'page_label': '56', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function.\\n4 More generally , the log-partition function A(η) is the cumulant function for rv\\nx.\\n5 The inverse mapping between mean parameters and natural par ameters is given\\nby the gradient ∇µ A∗ (µ) of the convex conjugate function A∗(µ) = sup η ηT µ − A(η),\\nwhere the maximization is over the feasible set of natural pa rameters.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 62, 'page_label': '57', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.2. The Exponential Family 57\\nThe Bernoulli distribution for a binary rv x ∈{0,1}is given as\\nBern(x|µ) = µx (1 −µ)1−x , (3.11)\\nwith µ = E x∼Bern(x|µ) [x] = Pr[x = 1]. Since we can write the LL\\nfunction as\\nln (Bern( x|µ)) = ln\\n( µ\\n1 −µ\\n)\\nx+ ln (1 −µ) , (3.12)\\nthe suﬃcient statistic deﬁning the Bernoulli model is u(x) = x and\\nthe measure function is m(x) = 1. The mapping between the natural\\nparameter η and the mean parameter µ is given as\\nη= ln\\n( µ\\n1 −µ\\n)\\n, (3.13)\\nthat is, the natural parameter is the LLR η= ln(Bern(1 |µ)/Bern(0|µ)).\\nF unction ( 3.13) is also known as the logit function . The corresponding\\nset of feasible values is hence R.\\nThe inverse mapping is instead given by the logistic sigmoid func-\\ntion\\nµ= σ(η) = 1\\n1 + e−η . (3.14)\\nThe sigmoid function converts a real number into the interva l [0 ,1]\\nvia an S-shape that associates values less than 0.5 to negati ve values\\nof the argument and larger values to positive numbers. Final ly , the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 62, 'page_label': '57', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='via an S-shape that associates values less than 0.5 to negati ve values\\nof the argument and larger values to positive numbers. Final ly , the\\nlog-partition function is given by the convex function of th e natural\\nparameters\\nA(η) = −ln(1 −µ) = ln(1 + eη ). (3.15)\\nNote that the relationship ( 3.10) is easily veriﬁed.\\n3.2.4 Categorical or Multinoulli Model\\nF or its role in multi-class classiﬁcation, we introduce her e in some de-\\ntail the Categorical or Multinoulli distribution, along wi th the one-hot\\nencoding of categorical variables and the soft-max functio n.\\nThe Categorical model applies to discrete variables taking C values,\\nhere labeled without loss of generality as {0,1,...,C −1}. Note that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 63, 'page_label': '58', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='58 Probabilistic Models for Learning\\nsetting C = 2 recovers the Bernoulli distribution. Pmfs in this model\\nare given as\\nCat(x|µ) =\\nC −1∏\\nk=1\\nµ1(x=k)\\nk ×µ\\n1−\\n∑ C−1\\nk=1 1(x=k)\\n0 , (3.16)\\nwhere we have deﬁned µk = Pr [x = k] for k = 1 ,...,C −1 and µ0 =\\n1 −∑ C −1\\nk=1 µk = Pr [x = 0]. The LL function is given as\\nln (Cat( x|µ)) =\\nC −1∑\\nk=1\\n1 ( x= k) ln µk\\nµ0\\n+lnµ0. (3.17)\\nThis demonstrates that the categorical model is in the expon ential fam-\\nily , with suﬃcient statistics vector u(x) = [1( x= 1) ··· 1(x= C−1)]T\\nand measure function m(x) = 1. F urthermore, the mean parameters\\nµ = [ µ1 ···µC −1]T are related to the natural parameter vector η =\\n[η1 ···ηC −1 ]T by the mapping\\nηk = ln\\n(\\nµk\\n1 −∑ C −1\\nj=1 µj\\n)\\n, (3.18)\\nwhich again takes the form of an LLR. The inverse mapping is gi ven\\nby\\nµ=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 1\\n1+\\n∑ C−1\\nk=1 eη k\\n.\\n.\\n.\\neη C−1\\n1+\\n∑ C−1\\nk=1 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n. (3.19)\\nThe parametrization given here is minimal, since the suﬃcie nt statis-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 63, 'page_label': '58', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='by\\nµ=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 1\\n1+\\n∑ C−1\\nk=1 eη k\\n.\\n.\\n.\\neη C−1\\n1+\\n∑ C−1\\nk=1 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n. (3.19)\\nThe parametrization given here is minimal, since the suﬃcie nt statis-\\ntics u(x) are linearly independent. An overcomplete representatio n would\\ninstead include in the vector of suﬃcient statistics also th e function\\n1(x= 0). In this case, the resulting vector of suﬃcient statisti cs\\nu(x) =\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\n1(x= 0)\\n.\\n.\\n.\\n1(x= C−1)\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb (3.20)\\nis known as one-hot encoding of the categorical variable, since only\\none entry equals 1 while the others are zero. F urthermore, wi th this'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 64, 'page_label': '59', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.3. Frequentist Learning 59\\nencoding, the mapping between the natural parameters and th e mean\\nparameters µ= [ µ0 ···µC −1]T can be expressed in terms of the softmax\\nfunction\\nµ= softmax( η)=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 0\\n∑ C−1\\nk=0 eη k\\n.\\n.\\n.\\neη C−1\\n∑ C−1\\nk=0 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n. (3.21)\\nThe softmax function softmax( η) converts a vector of “scores” η into\\na probability vector. F urthermore, the function has the pro perty that,\\nas c grows to inﬁnity , softmax( cη) tends to a vector with all zero en-\\ntries except for the position corresponding to the maximum v alue ηk\\n(assuming that it is unique). This justiﬁes its name.\\n3.3 Frequentist Learning\\nIn this section, we provide general results concerning ML an d MAP\\nlearning when the probabilistic model belongs to the expone ntial family .\\nAs seen in the previous chapter, with ML and MAP , one postulat es that\\nthe N available data points xD = {x1 ,...,x N }are i.i.d. realizations\\nfrom the probabilistic model p(x|η) as\\nxn ∼\\ni.i.d.\\np(x|η), n= 1 ,...,N. (3.22)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 64, 'page_label': '59', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the N available data points xD = {x1 ,...,x N }are i.i.d. realizations\\nfrom the probabilistic model p(x|η) as\\nxn ∼\\ni.i.d.\\np(x|η), n= 1 ,...,N. (3.22)\\nThis data is used to estimate the natural parameters η, or the corre-\\nsponding mean parameters µ.\\nUsing (\\n3.5), the LL of the natural parameter vector given the ob-\\nservation xD can be written as\\nlnp(xD |η) =\\nN∑\\nn=1\\nlnp(xn|η)\\n= −NA(η) + ηT\\nN∑\\nn=1\\nu(xn) +\\nN∑\\nn=1\\nlnm(xn ). (3.23)\\nTherefore, neglecting terms independent of η, we can write\\nlnp(xD |η) = −NA(η) + ηT u(xD ), (3.24)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 65, 'page_label': '60', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='60 Probabilistic Models for Learning\\nwhere we have deﬁned the cumulative suﬃcient statistics\\nuk (xD ) =\\nN∑\\nn=1\\nuk (xn), k= 1 ,...,K, (3.25)\\nand the vector u(xD ) = [ u1 (xD ) ··· uK (xD )]T .\\nA ﬁrst important observation is that the LL function only dep ends\\non the K statistics uk (xD ), k = 1 ,...,K . Therefore, the vector u(xD )\\nis a suﬃcient statistic for the estimate of η given the observation xD .\\nImportantly , vector u(xD ) is of size K, and hence it does not grow with\\nthe size N of the data set. In fact, the exponential family turns out to\\nbe unique in this respect: Informally , among all distributi ons whose\\nsupport does not depend on the parameters, only distributio ns in the\\nexponential family have suﬃcient statistics whose number d oes not\\ngrow with the number N of observations (Koopman-Pitman-Darmois\\ntheorem) [ 7].\\nGradient of the LL function. A key result that proves very\\nuseful in deriving learning algorithms is the expression of the gradient'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 65, 'page_label': '60', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='theorem) [ 7].\\nGradient of the LL function. A key result that proves very\\nuseful in deriving learning algorithms is the expression of the gradient\\nof the LL ( 3.24) with respect to the natural parameters. T o start, the\\npartial derivative with respect to ηk can be written as\\n∂lnp(xD |η)\\n∂ηk\\n= uk (xD ) −N∂A(η)\\n∂ηk\\n. (3.26)\\nUsing ( 3.9) and ( 3.10), this implies that we have\\n1\\nN\\n∂lnp(xD |η)\\n∂ηk\\n= 1\\nNuk (xD ) −µk , (3.27)\\nand for the gradient\\n1\\nN∇η lnp(xD |η) = 1\\nNu(xD ) −µ\\n= 1\\nN\\nN∑\\nn=1\\nu(xn ) −µ. (3.28)\\nThe gradient ( 3.28) is hence given by the diﬀerence between the empir-\\nical average N−1 ∑ N\\nn=1 u(xn) of the suﬃcient statistics given the data\\nxD and the ensemble average µ.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 66, 'page_label': '61', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.3. Frequentist Learning 61\\nThe following observation is instrumental in interpreting algorithms\\nbased on gradient ascent or descent for exponential familie s. The nor-\\nmalized gradient of the LL ( 3.28) has two components: ( i ) the “posi-\\ntive” component u(xD )/N points in a direction of the natural param-\\neter space that maximizes the unnormalized distribution ln ˜p(xD |η) =\\nηT u(xD ) + ∑ N\\nn=1 ln m(xn), hence maximizing the “ﬁtness” of the model\\nto the observed data xD ; while ( ii ) the “negative” component −µ =\\n−∇η A(η) points in a direction that minimizes the partition functio n,\\nthus minimizing the “ﬁtness” of the model to the unobserved d ata. The\\ntension between these two components is resolved when the em pirical\\nexpectation of the suﬃcient statistics equals that under th e model, as\\ndiscussed below.\\nML Learning. Due to concavity of the LL function, or equivalently\\nconvexity of the NLL, and assuming the regularity of the dist ribution,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 66, 'page_label': '61', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='discussed below.\\nML Learning. Due to concavity of the LL function, or equivalently\\nconvexity of the NLL, and assuming the regularity of the dist ribution,\\nthe ML estimate ηM L is obtained by imposing the optimality condition\\n∇η lnp(xD |η) = 0 , (3.29)\\nwhich gives\\nµM L = 1\\nN\\nN∑\\nn=1\\nu(xn). (3.30)\\nIn words, the ML estimate of the mean parameters is obtained b y\\nmatching the ensemble averages obtained under the model to t he em-\\npirical averages observed from the data. This procedure is k nown as\\nmoment matching. Note that, from ( 3.30), if needed, we can also com-\\npute the ML estimate ηM L using the mapping between the two sets of\\nparameters.\\nF rom ( 3.30), we can infer that the ML estimate is consistent: if\\nthe data is generated from a distribution p(x|η∗ ) within the assumed\\nfamily , the ML estimate will tend to it with probability one a s N grows\\nto inﬁnity by the strong law of large numbers [ 86]. However, for ﬁnite\\nN, ML may suﬀer from overﬁtting, as we will see next.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 66, 'page_label': '61', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='family , the ML estimate will tend to it with probability one a s N grows\\nto inﬁnity by the strong law of large numbers [ 86]. However, for ﬁnite\\nN, ML may suﬀer from overﬁtting, as we will see next.\\nExample 3.2. (Gaussian pdf). The ML estimates of the parameters'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 67, 'page_label': '62', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='62 Probabilistic Models for Learning\\n(µ, σ2 ) for the Gaussian model are given as\\nµM L = 1\\nN\\nN∑\\nn=1\\nxn (3.31)\\nσ2\\nM L = 1\\nN\\nN∑\\nn=1\\nx2\\nn −µ2\\nM L . (3.32)\\nF or the Bernoulli model, we have the ML estimate of the mean pa ram-\\neter µ= Pr [x = 1]\\nµM L = 1\\nN\\nN∑\\nn=1\\nxn = N[1]\\nN , (3.33)\\nwhere N[k] measures the number of observations equal to k, i.e.,\\nN[k] = |{n: xn = k}|.\\nNote that N[1] has a binomial distribution. F or the Categorical model,\\nwe can similarly write the ML estimate of the mean parameters µk =\\nPr [x = k] as\\nµk,M L = 1\\nN\\nN∑\\nn=1\\n1(xn = k) = N[k]\\nN . (3.34)\\nThe vector [ N[0],...,N [C −1]]T has a multinomial distribution.\\nT o illustrate the problem of overﬁtting, consider the categ orical\\nmodel. As per ( 3.34), if no instance of the data equal to some value\\nk is observed, i.e., if N[k] = 0, ML assigns a zero probability to the\\nevent x = k. In mathematical terms, if N[k] = 0 , the ML estimate of\\nthe probability of the event x = k is zero, that is, µk,M L = 0. So, ML'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 67, 'page_label': '62', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='event x = k. In mathematical terms, if N[k] = 0 , the ML estimate of\\nthe probability of the event x = k is zero, that is, µk,M L = 0. So, ML\\ngives zero probability to any previously unobserved event. The problem,\\nwhich is an instance of overﬁtting, is known as the black swan paradox\\nor zero-count problem : F or the European explorers of the 17th century\\n– or at least for those of them adhering to the ML principle – th e black\\nswans in the Americas could not exist! [ 104]\\nMAP Learning. A MAP solution can be in principle derived by\\nincluding in the optimality condition ( 3.29) the gradient of the prior\\ndistribution. W e will instead solve the MAP problem in the ne xt section\\nby computing the mode of the posterior distribution of the pa rameters.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 68, 'page_label': '63', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4. Bayesian Learning 63\\n3.4 Bayesian Learning\\nAs we discussed in the previous chapter, the Bayesian viewpo int is to\\ntreat all variables as jointly distributed, including the m odel parameters\\nµ and the new, unobserved value x . The joint distribution is given as\\np(xD ,µ,x |α) = p(µ|α)\\ued19 \\ued18\\ued17 \\ued1a\\na priori distribution\\np(xD |µ)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\np(x|µ)\\ued19 \\ued18\\ued17 \\ued1a\\ndistribution of new data\\n, (3.35)\\nwhere α represents the vector of hyperparameters deﬁning the prior\\ndistribution. The problem of inferring the unobserved valu e x is solved\\nby evaluating the predictive distribution\\np(x|xD ,α) =\\n∫\\np(µ|xD ,α)p(x|µ)dµ. (3.36)\\nThis distribution accounts for the weighted average of the c ontributions\\nfrom all values of the parameter vector µaccording to the posterior dis-\\ntribution p(µ|xD ,α).Note that, for clarity , we left indicated the depen-\\ndence on the hyperparameters α. Using Bayes’ theorem, the posterior\\nof the parameter vector can be written as\\np(µ|xD ,α) = p(µ|α)p(xD |µ)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 68, 'page_label': '63', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='dence on the hyperparameters α. Using Bayes’ theorem, the posterior\\nof the parameter vector can be written as\\np(µ|xD ,α) = p(µ|α)p(xD |µ)\\np(xD |α) ∝p(µ|α)p(xD |µ). (3.37)\\nAs discussed in Chapter 2, this relationship highlights the dependence\\nof the posterior on both the prior distribution and the likel ihood p(xD |µ).\\nW e also note the the denominator in ( 3.37) is the marginal likelihood.\\nPrior distribution. The ﬁrst issue we should address is the choice\\nof the prior distribution. There are two main approaches: 1) Conjugate\\nprior : choose the prior p(µ|α), so that posterior p(µ|xD ,α) has the same\\ndistribution as the prior p(µ|α) but with generally diﬀerent parameters;\\n2) Non-informative prior : choose the prior that is the least informative\\ngiven the observed data [ 23, pp. 117-120]. Here, we will work with\\nconjugate priors, which are more commonly adopted in applic ations. In\\nfact, a key advantage of models in the exponential family is t hat they'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 68, 'page_label': '63', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='conjugate priors, which are more commonly adopted in applic ations. In\\nfact, a key advantage of models in the exponential family is t hat they\\nall admit conjugate priors, and the conjugate priors are als o members\\nof the exponential family .\\nRather than providing a general discussion, which may be of l imited\\npractical use, we proceed by means of representative exampl es. A table\\nof models with corresponding prior distributions can be fou nd in [ 155].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 69, 'page_label': '64', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='64 Probabilistic Models for Learning\\n3.4.1 Beta-Bernoulli Model\\nThe Beta-Bernoulli model is suitable to study binary data. C onditioned\\non the parameter µ = Pr [x = 1], the pmf of the N i.i.d. available\\nobservations xD with xn ∈{0,1}is given as\\np(xD |µ) =\\nN∏\\nn=1\\nBern(xn|µ) = µN [1](1 −µ)N [0]. (3.38)\\nAs seen, a conjugate prior should be such that the posterior ( 3.37) has\\nthe same distribution of the prior but with diﬀerent paramet ers. F or\\nthe likelihood ( 3.38), the conjugate prior is the Beta distribution , which\\nis deﬁned as\\np(µ|a,b) = Beta( µ|a,b) ∝µa−1 (1 −µ)b−1 , (3.39)\\nwhere a and b are hyperparameters and the normalization constant is\\nnot made explicit in order to simplify the notation. It is wor th empha-\\nsizing that ( 3.39) is a probability distribution on a probability µ. Plots\\nof the beta pdf for diﬀerent values of a,b ≥1 can be found in Fig. 3.1.\\n0 0.2 0.4 0.6 0.8 1\\n0\\n1\\n2\\n3\\n4\\n5\\nFigure 3.1: Beta distribution with diﬀerent values of the hyperparamet ers a, b ≥ 1.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 70, 'page_label': '65', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4. Bayesian Learning 65\\nA verage and mode of the Beta pdf can be evaluated as\\nEµ∼Beta(µ|a,b)[µ] = a\\na+ b (3.40)\\nmodeµ ∼Beta(µ|a,b) [µ] = a−1\\na+ b−2 , (3.41)\\nwhere the mode expression is only valid when a,b> 1 (when this condi-\\ntion is not met, the distribution is multi-modal, see Fig. 3.1). The mean\\n(3.39) suggests that the hyperparameters aand bcan be interpreted as\\nthe number of observations that are expected to equal “1” and “0”, re-\\nspectively , out of a total number of a+ bmeasurements, based on prior\\ninformation alone. More ﬁttingly , as we shall see next, we ca n think of\\nthese a priori observations as “virtual” measurements, als o known as\\npseudo-counts, that should be used alongside the actual measurements\\nxD during learning.\\nW e can now compute the posterior distribution of the paramet er\\nvector using ( 3.37) as\\np(µ|xD ,a,b) ∝Beta ( µ|a+ N[1],b + N[0] )\\n= µN [1]+a−1(1 −µ)N [0]+b−1 . (3.42)\\nThis conﬁrms that the posterior distribution is indeed a Bet a pdf, as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 70, 'page_label': '65', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='vector using ( 3.37) as\\np(µ|xD ,a,b) ∝Beta ( µ|a+ N[1],b + N[0] )\\n= µN [1]+a−1(1 −µ)N [0]+b−1 . (3.42)\\nThis conﬁrms that the posterior distribution is indeed a Bet a pdf, as\\ndictated by the choice of a Beta conjugate prior. F urthermor e, the\\nposterior Beta distribution has parameters a+ N[1] and b+ N[0]. This\\nis consistent with the interpretation given above: the tota l number of\\neﬀective observations equal to “1” and “0” are a+ N[1] and b+ N[0],\\nrespectively . As anticipated, the MAP estimate of µ can be obtained\\nby taking the mode of the posterior ( 3.37), yielding\\nµM AP = a+ N[1] −1\\na+ b+ N −2 . (3.43)\\nAs we discussed in the previous chapter, we have the limit µM AP →\\nµM L for N →∞.\\nBack to the Bayesian viewpoint, the predictive distributio n ( 3.36)\\nis given as\\np(x= 1 |xD ,a,b) =\\n∫\\np(µ|xD ,a,b)p(x= 1 |µ)dµ\\n= E µ∼p(µ|xD ,a,b)[µ] = N[1] + a\\nN + a+ b (3.44)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 71, 'page_label': '66', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='66 Probabilistic Models for Learning\\nwhere we have used the expression ( 3.40) for the mean of a Beta rv. W e\\nobserve that, if N is small, the predictive probability is approximately\\nequal to the mean of the prior, i.e., p(x= 1 |xD ,a,b) ≈a/(a+ b); while,\\nif N is large, as we have seen in the previous chapter, the predict ive\\nprobability tends to the ML solution, i.e., p(x= 1 |xD ,a,b) ≈N[1]/N.\\nAs an example of a non-conjugate prior, one could choose the d istri-\\nbution of the natural parameter η, or equivalently of the logit function\\n(3.13) of µ, as Gaussian [ 92].\\nThe following example illustrates the potential advantage s, already\\ndiscussed in Chapter 2, of the Bayesian approach in avoiding overﬁtting.\\nNote that MAP would also yield similar results in this exampl e.\\nExample 3.3. (Predicting online reviews) On an online shopping\\nplatform, there are two sellers oﬀering a product at the same price. The\\nﬁrst has 30 positive reviews and 0 negative reviews, while th e second'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 71, 'page_label': '66', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='platform, there are two sellers oﬀering a product at the same price. The\\nﬁrst has 30 positive reviews and 0 negative reviews, while th e second\\nhas 90 positive reviews and 10 negative reviews. Which one to choose?\\nT o tackle this problem, we can learn a Beta-Bernoulli model t o predict\\nwhether the next review will be positive or not. W e can comput e the\\nprobability that the next review is positive via the predict ive distribu-\\ntion ( 3.44). The result is shown in Fig. 3.2: While the ﬁrst seller has\\na 100% positive rate, as opposed to the 90% rate of the ﬁrst sel ler, we\\nprefer to choose the ﬁrst seller unless the prior distributi on is weak,\\nwhich translates here into the condition a= b≲ 3.\\n3.4.2 Dirichlet-Categorical Model\\nThe Dirichlet-Categorical model generalizes the Beta-Ber noulli model\\nto the case of discrete observations that can take any number C of\\nvalues. The treatment follows along the same lines as for the Beta-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 71, 'page_label': '66', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to the case of discrete observations that can take any number C of\\nvalues. The treatment follows along the same lines as for the Beta-\\nBernoulli model, and hence we provide only a brief discussio n. The\\nlikelihood function can be written as\\np(xD |µ) =\\nC −1∏\\nk=0\\nµN [k]\\nk . (3.45)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 72, 'page_label': '67', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4. Bayesian Learning 67\\n2 4 6 8 10\\n0.75\\n0.8\\n0.85\\n0.9\\n0.95\\n1\\nfirst seller\\nsecond seller\\nFigure 3.2: Probability that the next review is positive using the predi ctive distri-\\nbution ( 3.44) for Example 3.3.\\nThe conjugate prior is the Dirichlet distribution, a genera lization of the\\nBeta distribution:\\np(µ|α) = Dir( µ|α) ∝\\nC −1∏\\nk=0\\nµαk −1\\nk , (3.46)\\nwhere αk is the hyperparameter representing the number of “prior”\\nobservations equal to k. Note that the Dirichlet distribution is a joint\\npdf for the entries of the mean vector µ. Mean and mode vectors for\\nthe Dirichlet distribution are given as\\nEµ∼Dir(µ|α) [µ] = α\\n∑ C −1\\nj=0 αj\\n(3.47)\\nmodeµ ∼Dir(µ|α)[µ] = α−1\\n∑ C −1\\nj=0 αj −C. (3.48)\\nThe posterior of the parameters is the Dirichlet distributi on\\np(µ|xD ,α) ∝\\nC −1∏\\nk=0\\nµN [k]+αk −1\\nk = Dir( µ|α+ N), (3.49)\\nin which we can again interpret αk + N[k] as the eﬀective number of\\nobservations equal to k. F rom this distribution, we can obtain the MAP'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 73, 'page_label': '68', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='68 Probabilistic Models for Learning\\nestimate as the mode. Finally , the Bayesian predictive dist ribution is\\np(x= k|xD ,α) = N[k] + αk\\nN + ∑ C −1\\nj=0 αj\\n. (3.50)\\nOne can check that the behavior in the two regimes of small and large\\nN is consistent with the discussion on the Beta-Bernoulli mod el.\\n3.4.3 Gaussian-Gaussian Model\\nAs a last example, we consider continuous observations that are as-\\nsumed to have a Gaussian distribution N(µ,σ2 ) with unknown mean\\nµ but known variance σ2. The likelihood function is hence p(xD |µ) =∏ N\\nn=1 N(xn|µ,σ2 ). The conjugate prior is also Gaussian, namely p(µ|µ0 ,σ2\\n0 ) =\\nN(µ|µ0,σ2\\n0 ),with hyperparameters ( µ0,σ2\\n0 ). The posterior p(µ|xD ,µ0,σ2\\n0 ) =\\nN(µ|µN ,σ2\\nN ) is hence Gaussian, with mean and variance satisfying\\nµN = σ2 /N\\nσ2\\n0 + σ2 /Nµ0 + σ2\\n0\\nσ2\\n0 + σ2 /NµM L (3.51)\\n1\\nσ2\\nN\\n= 1\\nσ2\\n0\\n+ N\\nσ2 , (3.52)\\nwhere we recall that the ML estimate is µM L = ∑ N\\nn=1 xn/N.Note that,\\nsince mean and mode are equal for the Gaussian distribution, the mean'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 73, 'page_label': '68', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='0\\nσ2\\n0 + σ2 /NµM L (3.51)\\n1\\nσ2\\nN\\n= 1\\nσ2\\n0\\n+ N\\nσ2 , (3.52)\\nwhere we recall that the ML estimate is µM L = ∑ N\\nn=1 xn/N.Note that,\\nsince mean and mode are equal for the Gaussian distribution, the mean\\nµN is also the MAP estimate µM AP of µ. Finally , the predictive distribu-\\ntion is also Gaussian and given as p(x|xD ,µ0 ,σ2\\n0 ) = N(x|µN ,σ2 + σ2\\nN ).\\nOnce again, as N grows large, the predictive distribution tends to that\\nreturned by the ML approach, namely N(x|µM L ,σ2 ).\\nFig.\\n3.3 illustrates the relationship among ML, MAP and Bayesian\\nsolutions for the Gaussian-Gaussian model. In all the panel s, the dotted\\nline represents the prior distribution, which is character ized by the pa-\\nrameters ( µ0 = 1, σ2\\n0 = 3), and the dashed line is the true distribution\\nof the data, which is assumed to be Gaussian with parameters ( µ= 0 ,\\nσ2 = 1), hence belonging to the assumed model. Each subﬁgure plo ts\\na realization of N observations (circles), along with the ML solution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 73, 'page_label': '68', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='σ2 = 1), hence belonging to the assumed model. Each subﬁgure plo ts\\na realization of N observations (circles), along with the ML solution\\n(diamond) and the MAP estimate (star). The solid lines repre sent the\\nBayesian predictive distribution.\\nAs N increases, we observe the following, already discussed, ph e-\\nnomena: ( i ) the ML estimate µM L consistently estimates the true value'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 74, 'page_label': '69', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.5. Supervised Learning via Generalized Linear Models (GL M) 69\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\nN =\\nN =\\nN =\\nN =\\n1\\n10\\n100\\n5\\nFigure 3.3: Gaussian-Gaussian model: prior distribution N (x|µ0 = 1, σ2\\n0 = 3) (dot-\\nted), true distribution N (x|µ = 0 ,σ2 = 1) (dashed), N observations (circles), ML\\nsolution (diamond), the MAP estimate (star), and Bayesian p redictive distribution\\n(solid line).\\nµ = 0; ( ii ) the MAP estimate µM AP tends to the ML estimate µM L ;\\nand ( iii ) the Bayesian predictive distribution tends to the ML predi c-\\ntive distribution, which in turn coincides with the true dis tribution due\\nto ( i ).\\n3.5 Supervised Learning via Generalized Linear Models (GLM)\\nDistributions in the exponential family are not directly su itable to serve\\nas discriminative probabilistic models to be used in superv ised learning\\ntasks. In this section, we introduce Generalized Linear Mod els (GLMs),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 74, 'page_label': '69', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as discriminative probabilistic models to be used in superv ised learning\\ntasks. In this section, we introduce Generalized Linear Mod els (GLMs),\\nwhich are popular probabilistic discriminative models tha t build on\\nmembers of the exponential family .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 75, 'page_label': '70', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='70 Probabilistic Models for Learning\\nT o elaborate, let us denote as exponential( ·|η) a probabilistic model\\nin the exponential family , that is, a model of the form ( 3.1) with natural\\nparameters η. W e also write exponential( ·|µ) for a probabilistic model\\nin the exponential family with mean parameters µ.\\nUsing the notation adopted in the previous chapter, in its mo st\\ncommon form, a GLM deﬁnes the probability of a target variabl e t as\\np(t|x,W) = exponential( t|η= Wx), (3.53)\\nwhere we recall that xis the vector of explanatory variables, and W here\\ndenotes a matrix of learnable weights of suitable dimension s. According\\nto ( 3.53), GLMs posit that the response variable t has a conditional\\ndistribution from the exponential family , with natural par ameter vector\\nη = Wx given by a linear function of the given explanatory variable s\\nx with weights W. More generally , we may have the parametrization\\np(t|x,W) = exponential( t|η= Wφ(x)) (3.54)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 75, 'page_label': '70', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='η = Wx given by a linear function of the given explanatory variable s\\nx with weights W. More generally , we may have the parametrization\\np(t|x,W) = exponential( t|η= Wφ(x)) (3.54)\\nfor some feature vector φ(·) obtained as a function of the input variables\\nx (see next chapter).\\nWhile being the most common, the deﬁnition ( 3.54) is still not the\\nmost general for GLMs. More broadly , GLMs can be interpreted as a\\ngeneralization of the linear model considered in the previo us chapter,\\nwhereby the mean parameters are deﬁned as a linear function o f a\\nfeature vector. This viewpoint, described next, may also pr ovide a more\\nintuitive understanding of the modelling assumptions made by GLMs.\\nRecall that, in the recurring example of Chapter 2, the targe t vari-\\nable was modelled as Gaussian distributed with mean given by a linear\\nfunction of the covariates x. Extending the example, GLMs posit the\\nconditional distribution\\np(t|x,W) = exponential( t|µ= g(Wφ(x))), (3.55)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 75, 'page_label': '70', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function of the covariates x. Extending the example, GLMs posit the\\nconditional distribution\\np(t|x,W) = exponential( t|µ= g(Wφ(x))), (3.55)\\nwhere the mean parameter vector is parametrized as a functio n of the\\nfeature vector φ(x) through a generally non-linear vector function g(·)\\nof suitable dimensions. In words, GLM assume that the target variable\\nis a “noisy” measure of the mean µ= g(Wφ(x)).\\nWhen the function g(·) is selected as the gradient of the partition\\nfunction of the selected model, e.g., g(·) = ∇η A(·), then, by ( 3.10), we'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 76, 'page_label': '71', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.6. Maximum Entropy Property ∗ 71\\nobtain the GLM ( 3.54). This choice for g(·) is typical, and is referred\\nto as the (inverse of the) canonical link function. F or insta nce, the\\nlinear regression model p(t|x,w) = N(t|wT φ(x),σ2 ) used in Chapter 2\\ncorresponds to a GLM with canonical link function. Througho ut this\\nmonograph, when referring to GLMs, we will consider models o f the\\nform ( 3.54), or, equivalently ( 3.55), with canonical link function. F or\\nfurther generalizations, we refer to [ 104, 15].\\nGLMs, especially in the form ( 3.54), are widely used. As we will\\nalso discuss in the next chapter, learning the parameters of GLMs can\\nbe done by means of gradient ascent on the LL using the identit y ( 3.28)\\nand the chain rule of diﬀerentiation.\\n3.6 Maximum Entropy Property ∗\\nIn this more technical section, we review the maximum entropy prop-\\nerty of the exponential family . Beside providing a compelli ng motiva-\\ntion for adopting models in this class, this property also il luminates'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 76, 'page_label': '71', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='erty of the exponential family . Beside providing a compelli ng motiva-\\ntion for adopting models in this class, this property also il luminates\\nthe relationship between natural and mean parameters.\\nThe key result is the following: The distribution p(x|η) in (\\n3.1) ob-\\ntains the maximum entropy over all distributions p(x) that satisfy the\\nconstraints E x∼p(x)[uk (x)] = µk for all k= 1 ,...,K . Recall that, as men-\\ntioned in Chapter 2 and discussed in more details in Appendix A, the\\nentropy is a measure of randomness of a random variable. Math emati-\\ncally , the distribution p(x|η) solves the optimization problem\\nmax\\np(x)\\nH(p) s.t. E x∼p(x) [uk (x)]=µk for k= 1 ,...,K. (3.56)\\nEach natural parameter ηk turns out to be the optimal Lagrange mul-\\ntiplier associated with the kth constraint (see [ 45, Ch. 6-7]).\\nT o see the practical relevance of this result, suppose that t he only\\ninformation available about some data xis given by the means of given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 76, 'page_label': '71', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='T o see the practical relevance of this result, suppose that t he only\\ninformation available about some data xis given by the means of given\\nfunctions uk (x), k= 1 ,...,K . The probabilistic model ( 3.1) can then\\nbe interpreted as encoding the least additional informatio n about the\\ndata, in the sense that it is the “most random” distribution u nder the\\ngiven constraints. This observation justiﬁes the adoption of this model\\nby the maximum entropy principle.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 77, 'page_label': '72', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='72 Probabilistic Models for Learning\\nF urthermore, the fact that the exponential distribution so lves the\\nmaximum entropy problem ( 3.56) illuminates the relationship between\\nmean parameters {µk }and natural parameters {ηk }, as the natural\\nparameter ηk is the optimal Lagrange multiplier associated with the\\nconstraint Ex∼p(x) [uk (x)] = µk .\\nAs another note on the exponential family and information-t heoretic\\nmetrics, in Appendix B we provide discussion about the compu tation\\nof the KL divergence between two distributions in the same ex ponential\\nfamily but with diﬀerent parameters.\\n3.7 Energy-based Models ∗\\nA generalization of the exponential family is given by proba bilistic mod-\\nels of the form\\np(x|η) = 1\\nZ(η) exp\\n(\\n−\\n∑\\nc\\nEc(xc|η)\\n)\\n, (3.57)\\nwhere functions Ec(xc|η) are referred to as energy functions and Z(η)\\nis the partition function. Each energy function Ec(xc|η) generally de-\\npends on a subset xc of the variables in vector x. If each energy function'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 77, 'page_label': '72', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is the partition function. Each energy function Ec(xc|η) generally de-\\npends on a subset xc of the variables in vector x. If each energy function\\ndepends linearly on the parameter vector η, we recover the exponen-\\ntial family discussed above. However, the energy functions may have a\\nmore general non-linear form. An example is the function Ec(xc|η) =\\nln\\n(\\n1 + ( ηT\\nc xc)2\\n)\\ncorresponding to a Student’s t-distribution model 6\\n[83].\\nModels in the form ( 3.57) encode information about the plausibil-\\nity of diﬀerent conﬁgurations of subsets of rvs x c using the associated\\nenergy value: a large energy entails an implausible conﬁgur ation, while\\na small energy identiﬁes likely conﬁgurations. F or example , a subset\\nof rvs x c may tend to be equal with high probability , implying that\\nconﬁgurations in which this condition is not satisﬁed shoul d have high\\nenergy . Energy-based models are typically represented via the graphi-\\ncal formalism of Markov networks, as it will be discussed in C hapter'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 77, 'page_label': '72', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='energy . Energy-based models are typically represented via the graphi-\\ncal formalism of Markov networks, as it will be discussed in C hapter\\n7.\\n6 A Student’s t-distribution can be interpreted as an inﬁnite mixture of Gaussians.\\nAs a result, it has longer tails than a Gaussian pdf [ 23, Chapter 2].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 78, 'page_label': '73', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.8. Some Advanced T opics ∗ 73\\nWith energy-based models, the key formula ( 3.28) of the gradient\\nof the LL with respect to the model’s parameters generalizes as\\n1\\nN∇η lnp(xD |η) = −1\\nN\\nN∑\\nn=1\\n∑\\nc\\n∇η Ec(xn|η) +\\n∑\\nc\\nEx∼p(x|η)[∇η Ec(x|η)].\\n(3.58)\\nGeneralizing the discussion around ( 3.28), the ﬁrst term in ( 3.58) is\\nthe “positive” component that points in a direction that min imizes the\\nenergy of the observations xD ; while the second term is the “negative”\\ncomponent that pushes up the energy of the unobserved conﬁgu rations.\\nIn gradient-ascent methods, the application of the ﬁrst ter m is typically\\nreferred to as the positive phase, while the second is referr ed to as the\\nnegative phase. (The negative phase is even taken by some aut hors\\nto model the working of the brain while dreaming! [ 56]) While for\\nthe exponential family the expectation in the negative phas e readily\\nyields the mean parameters, for more general models, the eva luation of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 78, 'page_label': '73', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the exponential family the expectation in the negative phas e readily\\nyields the mean parameters, for more general models, the eva luation of\\nthis term is generally prohibitive and typically requires M onte Carlo\\napproximations, which are discussed in Chapter 8.\\n3.8 Some Advanced T opics ∗\\nThe previous sections have focused on the important class of parametric\\nprobabilistic models in the exponential family . Here we bri eﬂy put the\\ncontent of this chapter in the broader context of probabilis tic models\\nfor machine learning. First, it is often useful to encode add itional infor-\\nmation about the relationships among the model variables by means of\\na graphical formalism that will be discussed in Chapter 7. Se cond, the\\nproblem of learning the distribution of given observations , which has\\nbeen studied here using parametric models, can also be tackl ed using\\na non-parametric approach. Accordingly , the distribution is inferred'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 78, 'page_label': '73', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='been studied here using parametric models, can also be tackl ed using\\na non-parametric approach. Accordingly , the distribution is inferred\\nmaking only assumptions regarding its local smoothness. Ty pical tech-\\nniques in this family include Kernel Density Estimation and Nearest\\nNeighbor Density Estimation (see, e.g., [\\n140]).\\nF urthermore, rather than learning individual probability densities,\\nin some applications, it is more useful to directly estimate ratios of\\ndensities. This is the case, for instance, when one wishes to estimate the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 79, 'page_label': '74', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='74 Probabilistic Models for Learning\\nmutual information between two observed variables, or in tw o-sample\\ntests, whereby one needs to decide whether two sets of observ ations\\nhave the same distribution or not. W e refer to [ 140] for details. Finally ,\\nthere exist important scenarios in which it is not possible t o assign an\\nexplicit probabilistic model to given observations, but on ly to specify a\\ngenerative mechanism. The resulting likelihood-free infe rence problems\\nare covered in [ 100], and will be further discussed in Chapter 6.\\n3.9 Summary\\nIn this chapter, we have reviewed an important class of proba bilistic\\nmodels that are widely used as components in learning algori thms for\\nboth supervised and unsupervised learning tasks. Among the key prop-\\nerties of members of this class, known as the exponential fam ily , are\\nthe simple form taken by the gradient of the LL, as well as the a vailabil-\\nity of conjugate priors in the same family for Bayesian infer ence. An'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 79, 'page_label': '74', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the simple form taken by the gradient of the LL, as well as the a vailabil-\\nity of conjugate priors in the same family for Bayesian infer ence. An\\nextensive list of distributions in the exponential family a long with corre-\\nsponding suﬃcient statistics, measure functions, log-par tition functions\\nand mappings between natural and mean parameters can be foun d in\\n[\\n156]. More complex examples include the Restricted Boltzmann M a-\\nchines (RBMs) to be discussed in Chapter 6 and Chapter 8. It is worth\\nmentioning that there are also distribution not in the expon ential fam-\\nily , such as the uniform distribution parametrized by its su pport. The\\nchapter also covered the important idea of applying exponen tial mod-\\nels to supervised learning via GLMs. Energy-based models we re ﬁnally\\ndiscussed as an advanced topic.\\nThe next chapter will present various applications of model s in the\\nexponential family to classiﬁcation problems.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 80, 'page_label': '75', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part II\\nSupervised Learning'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 81, 'page_label': '76', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4\\nClassiﬁcation\\nThe previous chapters have covered important background ma terial on\\nlearning and probabilistic models. In this chapter, we use t he princi-\\nples and ideas covered so far to study the supervised learnin g problem\\nof classiﬁcation. Classiﬁcation is arguably the quintesse ntial machine\\nlearning problem, with the most advanced state of the art and the most\\nextensive application to problems as varied as email spam de tection\\nand medical diagnosis. Due to space limitations, this chapt er cannot\\nprovide an exhaustive review of all existing techniques and latest devel-\\nopments, particularly in the active ﬁeld of neural network r esearch. F or\\ninstance, we do not cover decision trees here (see, e.g., [ 158]). Rather,\\nwe will provide a principled taxonomy of approaches, and oﬀe r a few\\nrepresentative techniques for each category within a uniﬁe d framework.\\nW e will speciﬁcally proceed by ﬁrst introducing as prelimin ary mate-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 81, 'page_label': '76', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='representative techniques for each category within a uniﬁe d framework.\\nW e will speciﬁcally proceed by ﬁrst introducing as prelimin ary mate-\\nrial the Stochastic Gradient Descent optimization method. Then, we\\nwill discuss deterministic and probabilistic discriminat ive models, and\\nﬁnally we will cover probabilistic generative models.\\n76'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 82, 'page_label': '77', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.1. Preliminaries: Stochastic Gradient Descent 77\\n4.1 Preliminaries: Stochastic Gradient Descent\\nIn this section, we review a technique that is extensively us ed in the\\nsolution of optimization problems that deﬁne learning prob lems such\\nas ML and MAP (see Chapter 2). The technique is known as Stocha stic\\nGradient Descent (SGD). SGD is introduced here and applied t hrough-\\nout this monograph to other learning problems, including un super-\\nvised learning and reinforcement learning. Discussions ab out conver-\\ngence and about more advanced optimization techniques, whi ch may\\nbe skipped at a ﬁrst reading, can be found in the Appendix A of t his\\nchapter.\\nSGD addresses optimization problems of the form\\nmin\\nθ\\nN∑\\nn=1\\nfn(θ), (4.1)\\nwhere θ is the vector of variables to be optimized. The cost function\\nfn(θ) typically depends on the nth example in the training set D. F ol-\\nlowing the notation set in Chapter 2, for example, in the case of dis-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 82, 'page_label': '77', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='fn(θ) typically depends on the nth example in the training set D. F ol-\\nlowing the notation set in Chapter 2, for example, in the case of dis-\\ncriminative deterministic models, the conventional form f or the cost\\nfunctions is\\nfn(θ) = ℓ(tn,ˆt(xn,θ)), (4.2)\\nwhere ℓ is a loss function; ( xn,tn) is the nth training example; and\\nˆt(x,θ) is a predictor parametrized by vector θ.\\nSGD requires the diﬀerentiability of cost functions fn(·). The idea\\nis to move at each iteration in the direction of maximum desce nt for\\nthe cost function in (\\n4.1), when the latter is evaluated as ∑\\nn∈S fn(θ)\\nover a subset, or mini-batch, Sof samples from the training set. 1 Given\\na learning rate schedule γ(i) and an initialization θ(0) of the parameters,\\nSGD repeats in each iteration until convergence the followi ng two steps:\\n•Pick a mini-batch Sof S indices from the set {1,...,N }according\\nto some predetermined order or randomly;\\n1 Strictly speaking, when the functions fn (θ) are ﬁxed and they are processed'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 82, 'page_label': '77', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•Pick a mini-batch Sof S indices from the set {1,...,N }according\\nto some predetermined order or randomly;\\n1 Strictly speaking, when the functions fn (θ) are ﬁxed and they are processed\\nfollowing a deterministic order, the approach should be ref erred to as incremental\\ngradient method [ 22]. However, the term SGD is used in machine learning, capturi ng\\nthe fact that the choice of the mini-batches may be randomize d, and that the sum\\n(4.1) is considered to be an empirical average of a target ensembl e mean (see also\\n[101]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 83, 'page_label': '78', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='78 Classiﬁcation\\n•Update the weights in the direction of steepest local descen t as\\nθ(i) ←θ(i−1) −γ(i)\\nS\\n∑\\nn∈S\\n∇θ fn(θ)|θ=θ(i−1) . (4.3)\\nThe learning rate γ(i) as a function of the iteration iis generally consid-\\nered to be part of the hyperparameters to be optimized via val idation.\\nMore discussion on this can be found in Appendix A of this chap ter.\\n4.2 Classiﬁcation as a Supervised Learning Problem\\nClassiﬁcation is a supervised learning problem in which the label tcan\\ntake a discrete ﬁnite number of values. W e refer to Sec.\\n2.1 for an in-\\ntroduction to supervised learning. In binary classiﬁcatio n, each domain\\npoint x is assigned to either one of two classes, which are denoted as\\nC0 and C1 and identiﬁed by the value of the label t as follows\\nx∈C0 if t= 0 or t= −1 (4.4a)\\nx∈C1 if t= 1 . (4.4b)\\nNote that we will ﬁnd it convenient to use either the label t = 0 or\\nt = −1 to identify class C0 . In the more general case of K classes'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 83, 'page_label': '78', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x∈C0 if t= 0 or t= −1 (4.4a)\\nx∈C1 if t= 1 . (4.4b)\\nNote that we will ﬁnd it convenient to use either the label t = 0 or\\nt = −1 to identify class C0 . In the more general case of K classes\\nC0, C1,..., CK −1, we will instead prefer to use one-hot encoding (Sec.\\n3.2) by labelling a point x∈Ck with a K×1 label t that contains all\\nzeros except for a “1” entry at position k+ 1.\\nExample 4.1. Examples of binary classiﬁcation include email spam\\ndetection and creditworthiness assessment 2 . In the former case, the\\ndomain point xmay be encoded using the bag-of-words model, so that\\neach entry represents the count of the number of times that ea ch term\\nin a given set appears in the email. In the latter application , the domain\\nvector xgenerally includes valuable information to decide on wheth er a\\ncustomer should be granted credit, such as credit score and s alary (see,\\ne.g., [ 2]). Examples of multi-class classiﬁcation include classiﬁ cation of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 83, 'page_label': '78', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='customer should be granted credit, such as credit score and s alary (see,\\ne.g., [ 2]). Examples of multi-class classiﬁcation include classiﬁ cation of\\ntext documents into categories such as sports, politics or t echnology ,\\nand labelling of images depending on the type of depicted ite m.\\n2 While less useful, the “hot dog/ not hot dog” classiﬁer desig ned in the “Silicon\\nV alley” HBO show (Season 4) is also a valid example.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 84, 'page_label': '79', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.2. Classiﬁcation as a Supervised Learning Problem 79\\nThe binary classiﬁcation problem is illustrated in Fig. 4.1. Given\\na training set Dof labeled examples xn, n = 1 ,...,N , the problem is\\nto assign a new example x to either class C0 or C1. In this particular\\nstandard data set, the two variables in each vector xn measure the\\nsepal length and sepal width of an iris ﬂower. The latter may b elong\\nto either the setosa or virginica family , as encoded by the la bel tn and\\nrepresented in the ﬁgure with diﬀerent markers. Throughout , we denote\\nas D the dimension of the domain point x (D= 2 in Fig. 4.1).\\n4 5 6 7 8 9\\n0.5\\n1\\n1.5\\n2\\n2.5\\n3\\n3.5\\n4\\n4.5\\n?\\nFigure 4.1: Illustration of the binary ( K = 2 classes) classiﬁcation problem with\\na domain space of dimension D = 2: to which class should the new example x be\\nassigned?\\nF ollowing the taxonomy introduced in Chapter 2, we can disti nguish\\nthe following modeling approaches, which will be reviewed i n the given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 84, 'page_label': '79', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='assigned?\\nF ollowing the taxonomy introduced in Chapter 2, we can disti nguish\\nthe following modeling approaches, which will be reviewed i n the given\\norder throughout the rest of this chapter.\\n• Discriminative deterministic models : Model directly the deter-\\nministic mapping between domain point and label via a parame trized\\nfunction t= ˆt(x).\\n•Discriminative probabilistic models : Model the probability of a\\npoint xbelonging to class Ck via a parametrized conditional pmf p(t|x),\\nwith the relationship between t and Ck deﬁned in ( 4.4). W e will also'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 85, 'page_label': '80', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='80 Classiﬁcation\\nwrite p(Ck |x) for the discriminative probability when more convenient.\\n•Generative probabilistic model : Model the joint distribution of\\ndomain point and class label by specifying the prior distrib ution p(t),\\nor p(Ck ), and the class-dependent probability distribution p(x|t), or\\np(x|Ck ), of the domain points within each class.\\nDiscriminative models are arguably to be considered as sett ing the\\ncurrent state of the art on classiﬁcation, including popula r methods\\nsuch as Support V ector Machine (SVM) and deep neural network s. Gen-\\nerative models are potentially more ﬂexible and powerful as they allow\\nto capture distinct class-dependent properties of the cova riates x.\\n4.3 Discriminative Deterministic Models\\nIn this section, we discuss binary classiﬁcation using disc riminative de-\\nterministic models. Owing to their practical importance an d to their\\nintuitive geometric properties, we focus on linear models, whereby the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 85, 'page_label': '80', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='terministic models. Owing to their practical importance an d to their\\nintuitive geometric properties, we focus on linear models, whereby the\\nbinary prediction ˆt(x) is obtained by applying a threshold rule on a\\ndecision variable a(x, ˜w) obtained as a linear function of the learnable\\nweights ˜w (the notation will be introduced below). Note that the deci-\\nsion variable a(x, ˜w) may not be a linear function of the covariates x.\\nAs we will discuss, this class of models underlie important a lgorithms\\nthat are extensively used in practical applications such as SVM. A\\nbrief discussion on multi-class classiﬁcation using deter ministic models\\nis provided at the end of this section. In the next two section s, we cover\\ndiscriminative probabilistic models, including GLMs and m ore general\\nmodels.\\n4.3.1 Model\\nIn their simplest form, linear discriminative determinist ic classiﬁcation\\nmodels are of the form\\nˆt(x, ˜w) = sign ( a(x, ˜w)) , (4.5)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 86, 'page_label': '81', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 81\\nwhere the activation, or decision variable, is given as\\na(x, ˜w) =\\nD∑\\nd=1\\nwdxd + w0\\n= wT x+ w0 = ˜wT ˜x, (4.6)\\nand we have deﬁned the weight vectors w = [ w1 ···wD ]T and ˜ w =\\n[w0 w1 ···wD ]T , as well as the extended domain point ˜ x = [1 xT ]T ,\\nwith x= [ x1 ···xD ]T . The sign function in decision rule ( 4.5) outputs\\n1 if its argument is positive, and 0 or −1 if the argument is negative\\ndepending on the assumed association rule in ( 4.4).\\nGeometric interpretation: classiﬁcation, geometric and f unc-\\ntional margins. The decision rule ( 4.5) deﬁnes a hyperplane that sep-\\narates the domain points classiﬁed as belonging to either of the two\\nclasses. A hyperplane is a line when D= 2; a plane when D = 3; and,\\nmore generally , a D−1-dimensional aﬃne subspace [ 28] in the domain\\nspace. The hyperplane is deﬁned by the equation a(x, ˜w) = 0, with\\npoints on either side characterized by either positive or ne gative values'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 86, 'page_label': '81', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='space. The hyperplane is deﬁned by the equation a(x, ˜w) = 0, with\\npoints on either side characterized by either positive or ne gative values\\nof the activation a(x, ˜w). The decision hyperplane can be identiﬁed as\\ndescribed in Fig. 4.2: the vector w deﬁnes the direction perpendicular\\nto the hyperplane and −w0/||w||is the bias of the decision surface in\\nthe direction w.//\\nFigure 4.2: Key deﬁnitions for a binary linear classiﬁer.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 87, 'page_label': '82', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='82 Classiﬁcation\\nGiven a point x, it is useful to measure the conﬁdence level at which\\nthe classiﬁer assigns x to the class identiﬁed through rule ( 4.5). This\\ncan be done by quantifying the Euclidean distance between x and the\\ndecision hyperplane. As illustrated in Fig. 4.2, this distance, also known\\nas classiﬁcation margin , can be computed as |a(x, ˜w) |/∥w∥.\\nA point x has a true label t, which may or may not coincide with\\nthe one assigned by rule ( 4.5). T o account for this, we augment the\\ndeﬁnition of margin by giving a positive sign to correctly cl assiﬁed\\npoints and a negative sign to incorrectly classiﬁed points. Assuming\\nthat t takes values in {−1,1}, this yields the deﬁnition of geometric\\nmargin as\\nt·a(x, ˜w)\\n∥w∥ , (4.7)\\nwhose absolute value equals the classiﬁcation margin. F or f uture refer-\\nence, we also deﬁne the functional margin as t·a(x, ˜w).\\nF eature-based model. The model described above, in which the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 87, 'page_label': '82', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='whose absolute value equals the classiﬁcation margin. F or f uture refer-\\nence, we also deﬁne the functional margin as t·a(x, ˜w).\\nF eature-based model. The model described above, in which the\\nactivation is a linear function of the input variables x, has the following\\ndrawbacks.\\n-4 -2 0 2 4\\n-4\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\nFigure 4.3: A non-linearly separable training set.\\n1) Bias: As suggested by the example in Fig. 4.3, dividing the do-\\nmain of the covariates xby means of a hyperplane may fail to capture'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 88, 'page_label': '83', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 83\\nthe geometric structure of the data. In particular, in the ex ample, the\\ntwo classes are not linearly separable in the space of the covariates – no\\nhyperplane separates exactly the domain points in the two cl asses. In\\nsuch cases, classiﬁers of the form ( 4.5) may yield large average losses\\ndue to the bias induced by the choice of the model (see Sec. 2.3.3).\\n2) Overﬁtting : When D is large and the data points N are insuﬃ-\\ncient, learning the D+ 1 weights of the classiﬁer may cause overﬁtting.\\n3) Data-dependent domain size : In some applications, the dimension\\nD may even change from data point to data point, that is, it may v ary\\nwith the index n. F or example, a text xn, e.g., represented in ASCII\\nformat, will have a diﬀerent dimension Dn depending on the number\\nof words in the text.\\nT o address these problems, a powerful approach is that of wor king\\nwith feature vectors φk (x), k = 1 ,...,D ′, rather than directly with'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 88, 'page_label': '83', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of words in the text.\\nT o address these problems, a powerful approach is that of wor king\\nwith feature vectors φk (x), k = 1 ,...,D ′, rather than directly with\\nthe covariates x, as the input to the classiﬁer. A feature φk (x) is a, gen-\\nerally non-linear, function of the vector x. It is important to emphasize\\nthat these functions are ﬁxed and not learned.\\nChoosing a number of features D′ > D, which yields an overcom-\\nplete representation of the data point x, may help against bias; while\\nopting for an undercomplete representation with D′ < D may help\\nsolve the problem of overﬁtting. F urthermore, the same numb er of fea-\\ntures D′, e.g., word counts in a bag-of-words model, may be selected\\nirrespective of the size of the data point, addressing also t he last prob-\\nlem listed above.\\nThe feature-based model can be expressed as ( 4.5) with activation\\na(x, ˜w) =\\nD′\\n∑\\nk=1\\nwk φk (x) = ˜ wT φ(x), (4.8)\\nwhere we have deﬁned the feature vector φ(x) = [ φ1 (x) ··· φD′ (x)]T .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 88, 'page_label': '83', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The feature-based model can be expressed as ( 4.5) with activation\\na(x, ˜w) =\\nD′\\n∑\\nk=1\\nwk φk (x) = ˜ wT φ(x), (4.8)\\nwhere we have deﬁned the feature vector φ(x) = [ φ1 (x) ··· φD′ (x)]T .\\nNote that model ( 4.5) is a special case of ( 4.8) with the choice φ(x) =\\n[1 xT ]T .\\n4.3.2 Learning\\nAs seen in Sec. 2.3.3, learning of deterministic discriminative models\\ncan be carried out by means of ERM for a given loss function ℓ. F ur-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 89, 'page_label': '84', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='84 Classiﬁcation\\nthermore, as discussed in Sec. 2.3.5, overﬁtting can be controlled by\\nintroducing a regularization function R( ˜w) on the weight vector ˜ w. Ac-\\ncordingly , a deterministic predictor ˆt(x, ˜w) as deﬁned in ( 4.5) can be\\nlearned by solving the regularized ERM problem\\nmin\\n˜w\\nLD ( ˜w) + λ\\nNR( ˜w), (4.9)\\nwith the empirical risk\\nLD ( ˜w) = 1\\nN\\nN∑\\nn=1\\nℓ\\n(\\ntn,ˆt(xn, ˜w)\\n)\\n. (4.10)\\nIn ( 4.9), the hyperparameter λ should be selected via validation as\\nexplained in Sec. 2.3.5.\\nExtending the examples discussed in Sec. 2.3.5, the regularization\\nterm is typically convex but possibly not diﬀerentiable, e. g., R( ˜w) =\\n∥˜w∥1 . F urthermore, a natural choice for the loss function is the 0 -1 loss,\\nwhich implies that the generalization loss Lp in ( 2.2) is the probability\\nof classiﬁcation error.\\nIn the special case of linearly separable data sets, the resu lting\\nERM problem can be converted to a Linear Program (LP) [ 133]. Since'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 89, 'page_label': '84', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of classiﬁcation error.\\nIn the special case of linearly separable data sets, the resu lting\\nERM problem can be converted to a Linear Program (LP) [ 133]. Since\\nit is in practice impossible to guarantee the separability c ondition a\\npriori, one needs generally to solve directly the ERM proble m ( 4.9).\\nThe function sign( ·) has zero derivative almost everywhere, and is not\\ndiﬀerentiable when the argument is zero. F or this reason, it is diﬃcult\\nto tackle problem ( 4.9) via standard gradient-based optimization algo-\\nrithms such as SGD. It is instead often useful to consider surrogate\\nloss functions ℓ(t,a) that depend directly on the diﬀerentiable (aﬃne)\\nactivation a(x, ˜w). The surrogate loss function should preferably be\\nconvex in a, and hence in ˜ w, ensuring that the resulting regularized\\nERM problem\\nmin\\n˜w\\nN∑\\nn=1\\nℓ(tn,a(xn , ˜w)) + λ\\nNR( ˜w) (4.11)\\nis convex. This facilitates optimization [ 28], and, under suitable addi-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 89, 'page_label': '84', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ERM problem\\nmin\\n˜w\\nN∑\\nn=1\\nℓ(tn,a(xn , ˜w)) + λ\\nNR( ˜w) (4.11)\\nis convex. This facilitates optimization [ 28], and, under suitable addi-\\ntional conditions, guarantees generalization [ 133] (see also next chap-\\nter). The surrogate loss function should also ideally be an u pper bound'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 90, 'page_label': '85', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 85\\non the original loss function. In this way , the actual averag e loss is\\nguaranteed to be smaller than the value attained under the su rrogate\\nloss function. Examples of surrogate functions that will be considered\\nin the following can be found in Fig. 4.4.\\n-2 -1 0 1 2\\n0\\n0.5\\n1\\n1.5\\n2\\n2.5\\n3\\n0-1\\nhinge\\nexponential\\nperceptron\\nlogistic\\nFigure 4.4: Some notable surrogate loss functions for binary classiﬁca tion along\\nwith the 0-1 loss.\\nPerceptron Algorithm\\nThe perceptron algorithm is one of the very ﬁrst machine lear ning and\\nAI algorithms. It was introduced by F rank Rosenblatt at the C ornell\\nAeronautical Laboratory in 1957 to much fanfare in the popul ar press –\\nit is “the embryo of an electronic computer that [the Navy] ex pects will\\nbe able to walk, talk, see, write, reproduce itself and be con scious of\\nits existence. ” reported The New Y ork Times [ 144]. The algorithm was\\nimplemented using analog electronics and demonstrated imp ressive –'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 90, 'page_label': '85', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='its existence. ” reported The New Y ork Times [ 144]. The algorithm was\\nimplemented using analog electronics and demonstrated imp ressive –\\nfor the time – classiﬁcation performance on images [ 23].\\nUsing the feature-based model for generality , the perceptr on algo-\\nrithm attempts to solve problem ( 4.11) with the surrogate perceptron'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 91, 'page_label': '86', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='86 Classiﬁcation\\nloss function deﬁned as\\nℓ(t,a(x, ˜w)) = max (0 ,−t·a(x, ˜w)) . (4.12)\\nThe perceptron loss assigns zero cost to a correctly classiﬁ ed example\\nx, whose functional margin t·a(x, ˜w) is positive, and a cost equal to\\nthe absolute value of the functional margin for a misclassiﬁ ed example,\\nwhose functional margin is negative. A comparison with the 0 -1 loss\\nis shown in Fig. 4.4. The perceptron algorithm tackles problem ( 4.11)\\nwith λ = 0 via SGD with mini-batch size S = 1. The resulting algo-\\nrithm works as follows. First, the weights ˜ w(0) are initialized. Then, for\\neach iteration i= 1 ,2,...\\n•Pick a training example ( xn,tn) uniformly with replacement from\\nD;\\n•If the example is correctly classiﬁed, i.e., if tna(xn , ˜w) ≥0, do not\\nupdate the weights: ˜ w(i) ←˜w(i−1) ;\\n•If the example is not correctly classiﬁed, i.e., if tna(xn , ˜w) < 0,\\nupdate the weights as:\\n˜w(i) ←˜w(i−1) −∇˜w ℓ(tn,a(xn, ˜w))|˜w= ˜w(i−1) = ˜w(i−1) + φ(xn)tn.\\n(4.13)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 91, 'page_label': '86', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•If the example is not correctly classiﬁed, i.e., if tna(xn , ˜w) < 0,\\nupdate the weights as:\\n˜w(i) ←˜w(i−1) −∇˜w ℓ(tn,a(xn, ˜w))|˜w= ˜w(i−1) = ˜w(i−1) + φ(xn)tn.\\n(4.13)\\nIt can be proved that, at each step, the algorithm reduces the term\\nℓ(tn,a(xn , ˜w)) in the perceptron loss related to the selected training\\nexample n if the latter is misclassiﬁed. It can also be shown that, if\\nthe training set is linearly separable, the perceptron algo rithm ﬁnds a\\nweight vector ˜wthat separates the two classes exactly in a ﬁnite number\\nof steps [ 23]. However, convergence can be slow. More importantly , the\\nperceptron fails on training sets that are not linearly sepa rable, such as\\nthe “XOR” training set D={([0,0]T ,0),([0,1]T ,1),([1,0]T ,1),([1,1]T ,0)}\\n[97]. This realization came as a disappointment and contribute d to the\\nﬁrst so-called AI winter period characterized by a reduced f unding for\\nAI and machine learning research [ 154].\\nSupport Vector Machine (SVM)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 91, 'page_label': '86', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ﬁrst so-called AI winter period characterized by a reduced f unding for\\nAI and machine learning research [ 154].\\nSupport Vector Machine (SVM)\\nSVM, introduced in its modern form by Cortes and V apnik [\\n37] in\\n1995, was among the main causes for a renewal of interest in ma chine'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 92, 'page_label': '87', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 87\\nlearning and AI. F or this section, we will write explicitly ( and with a\\nslight abuse of notation) the activation as\\na(x, ˜w) = w0 + wT φ(x), (4.14)\\nin order to emphasize the oﬀset w0 . SVM solves the regularized ERM\\nproblem ( 4.11) with the surrogate hinge loss function\\nℓ(t,a(x, ˜w)) = max(0 ,1 −t·a(x, ˜w)), (4.15)\\nand with the regularization function R( ˜w) = ∥w∥2. Note that the latter\\ninvolves only the vector wand not the bias weight w0 – we will see below\\nwhy this is a sensible choice. The hinge loss function is also shown in\\nFig. 4.4.\\nTherefore, unlike the perceptron algorithm, SVM includes a regular-\\nization term, which was shown to ensure strong theoretical g uarantees\\nin terms of generalization error [ 39]. F urthermore, rather than relying\\non SGD, SVM attempts to directly solve the regularized ERM pr oblem\\nusing powerful convex optimization techniques [ 28].\\nT o start, we need to deal with the non-diﬀerentiability of th e hinge'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 92, 'page_label': '87', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='on SGD, SVM attempts to directly solve the regularized ERM pr oblem\\nusing powerful convex optimization techniques [ 28].\\nT o start, we need to deal with the non-diﬀerentiability of th e hinge\\nloss ( 4.15). This can be done by introducing auxiliary variables zn , one\\nfor each training example n. In fact, imposing the inequality zn ≥\\nℓ(tn,a(xn , ˜w)) yields the following equivalent problem\\nmin\\n˜w,z\\nN∑\\nn=1\\nzn + λ\\nN ∥w∥2 (4.16a)\\ns.t. tn ·a(xn, ˜w) ≥1 −zn (4.16b)\\nzn ≥0 for n=1,...,N, (4.16c)\\nwhere z= [ z1 ···zN ]T . The equivalence between the original regularized\\nERM problem and problem ( 4.16) follows from the fact that any opti-\\nmal value of the variables ( ˜ w,z) must satisfy either constraint ( 4.16b) or\\n(4.16c) with equality . This can be seen by contradiction: a solutio n for\\nwhich both constraints are loose for some n could always be improved\\nby decreasing the value of the corresponding variables zn until the most'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 92, 'page_label': '87', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='which both constraints are loose for some n could always be improved\\nby decreasing the value of the corresponding variables zn until the most\\nstringent of the two constraints in ( 4.16) is met. As a consequence, at\\nan optimal solution, we have the equality zn = ℓ(tn,a(xn , ˜w)).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 93, 'page_label': '88', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='88 Classiﬁcation\\nThe advantage of formulation ( 4.16) is that the problem is convex,\\nand can hence be solved using powerful convex optimization t echniques\\n[28]. In fact, the cost function is strictly convex, and thus the optimal\\nsolution is unique [ 28]. F urthermore, the optimal solution has an in-\\nteresting interpretation in the special case in which the tr aining data\\nset is linearly separable. As we will see, this interpretati on justiﬁes the\\nname of this technique.\\nLinearly separable sets and support vectors. When the data\\nset is linearly separable, it is possible to ﬁnd a vector ˜ w such that all\\npoints are correctly classiﬁed, and hence all the functiona l margins are\\npositive, i.e., tn ·a(xn, ˜w) >0 for n= 1 ,...,N . Moreover, by scaling the\\nvector ˜w, it is always possible to ensure that the minimum functional\\nmargin equals 1 (or any other positive value). This means tha t we can\\nimpose without loss of optimality the inequalities tn ·a(xn , ˜w) ≥1 for'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 93, 'page_label': '88', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='margin equals 1 (or any other positive value). This means tha t we can\\nimpose without loss of optimality the inequalities tn ·a(xn , ˜w) ≥1 for\\nn = 1 ,...,N and hence set z = 0 in problem ( 4.16). This yields the\\noptimization problem\\nmin\\n˜w\\n∥w∥2 (4.17a)\\ns.t. tn ·a(xn, ˜w) ≥1 for n=1,...,N. (4.17b)\\nThe problem above can be interpreted as the maximization of the\\nminimum geometric margin across all training points . T o see this, note\\nthat, under the constraint ( 4.17b), the minimum geometric margin can\\nbe computed as\\nmin\\nn=1,...,N\\ntna(xn , ˜w)\\n∥w∥ = 1\\n∥w∥. (4.18)\\nF urthermore, we call the vectors that satisfy the constrain ts ( 4.17b)\\nwith equality , i.e., tn ·a(xn , ˜w) = 1, as support vectors, since they sup-\\nport the hyperplanes parallel to the decision hyperplane at the mini-\\nmum geometric margin. At an optimum value ˜ w, there are at least two\\nsupport vectors, one on either side of the separating hyperp lane (see\\n[23, Fig. 7.1]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 93, 'page_label': '88', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='mum geometric margin. At an optimum value ˜ w, there are at least two\\nsupport vectors, one on either side of the separating hyperp lane (see\\n[23, Fig. 7.1]).\\nUsing Lagrange duality , the support vectors can be easily id entiﬁed\\nby observing the optimal values {αn }of the multipliers associated with\\nthe constraints ( 4.16b). Support vectors xn correspond to positive La-\\ngrange multipliers αn > 0 (see, e.g., [ 23]), while all other points have'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 94, 'page_label': '89', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 89\\nzero Lagrange multipliers. Note that the Lagrange multipli ers are re-\\nturned by standard solvers such as the ones implemented by th e CVX\\ntoolbox in MA TLAB [ 58].\\n-1 -0.5 0 0.5 1\\n-1\\n-0.5\\n0\\n0.5\\n1\\nFigure 4.5: Example of binary classiﬁcation with SVM using polynomial f eatures\\nup to degree M (λ/N = 0 .2).\\nExample 4.2. In the example in Fig. 4.5, the illustrated N = 80\\ntraining samples are fed to a SVM using the monomial feature v ec-\\ntor φ(x) = [1 x1 x2 ···xM\\n1 xM\\n2 ] and λ/N = 0 .2 for given model orders\\nM. The decision boundary is shown using dashed and solid lines . It is\\nseen that, using a suﬃciently large order (here M = 3), SVM is able to\\neﬀectively partition the two samples in the two classes. F ur thermore,\\neven with larger values of M (here M = 8), SVM appears not to suﬀer\\nfrom signiﬁcant overﬁtting thanks to the quadratic regular ization term.\\nThe optimization problem (\\n4.16) may be conveniently tackled by'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 94, 'page_label': '89', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='from signiﬁcant overﬁtting thanks to the quadratic regular ization term.\\nThe optimization problem (\\n4.16) may be conveniently tackled by\\nusing Lagrange duality techniques. This approach also allo ws one to\\nnaturally introduce the powerful tool of kernel methods. Th e interested\\nreader can ﬁnd this discussion in Appendix B of this chapter.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 95, 'page_label': '90', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='90 Classiﬁcation\\n4.3.3 Multi-Class Classiﬁcation ∗\\nHere we brieﬂy describe classiﬁcation scenarios with K >2 classes. As\\na ﬁrst observation, it is possible to build multi-class clas siﬁers based\\nsolely on multiple binary classiﬁers, such as SVM. This can b e done\\nby following one of two general strategies, namely one-versus-the-rest\\nand one-versus-one [23, Chapter 7]. The one-versus-the-rest approach\\ntrains K separate binary classiﬁers, say k = 1 ,...,K , with the kth\\nclassiﬁer operating on the examples relative to class Ck against the\\nexamples from all other classes. The one-versus-one method , instead,\\ntrains K(K−1)/2 binary classiﬁers, one for each pair of classes. Both\\napproaches can yield ambiguities in classiﬁcation [ 23, Chapter 7].\\n4.4 Discriminative Probabilistic Models: Generalized Linea r Mod-\\nels\\nDiscriminative probabilistic models are potentially more powerful than\\ndeterministic ones since they allow to model sources of unce rtainty'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 95, 'page_label': '90', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='els\\nDiscriminative probabilistic models are potentially more powerful than\\ndeterministic ones since they allow to model sources of unce rtainty\\nin the label assignment to the input variables. This randomn ess may\\nmodel noise, labelling errors, e.g., for crowdsourced labe ls, and/or the\\nresidual uncertainty in the classiﬁcation rule due to the av ailability of\\nlimited data. Probabilistic models can also more naturally accommo-\\ndate the presence of more than two classes by producing a prob ability\\ndistribution over the possible label values.\\nIn this section, we study GLMs, which were introduced in Sec. 3.5.\\nW e recall that a GLM ( 3.54) posits that the conditional pmf p(t|x),\\nor p(Ck |x), is a member of the exponential family in which the natural\\nparameter vector η is given as a linear function of a feature vector\\nφ(x), i.e., η= Wφ(x) for weight matrix W.3 It is noted that GLMs are\\nnot linear: only the unnormalized log-likelihood is linear in the weight'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 95, 'page_label': '90', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='φ(x), i.e., η= Wφ(x) for weight matrix W.3 It is noted that GLMs are\\nnot linear: only the unnormalized log-likelihood is linear in the weight\\nmatrix W (see Sec. 3.2). W e start by discussing binary classiﬁcation\\nand then cover the multi-class case in Sec. 4.4.3.\\n3 See Sec. 3.5 for a more general deﬁnition.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 96, 'page_label': '91', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.4. Discriminative Probabilistic Models: Generalized Li near Models 91\\n4.4.1 Model\\nF or classiﬁcation, the label t can take a ﬁnite number of values, and\\nit can hence be described by a Bernoulli variable in the binar y case\\nor, more generally , by a Categorial variable (see Chapter 3) . The GLM\\n(\\n3.54) for binary classiﬁcation is known as logistic regression, and it\\nassumes the predictive distribution\\np(t= 1 |x) = σ( ˜wT φ(x)). (4.19)\\nW e recall that σ(a) = (1 + exp( −a))−1 is the sigmoid function (see\\nChapter 2). W e also observe that\\nσ(−a) = 1 −σ(a), (4.20)\\nwhich implies that we can write p(t= 0 |x) = 1 −σ( ˜wT φ(x)) = σ(−˜wT φ(x)).\\nIntuitively , the sigmoid function in ( 4.19) can be thought of as a “soft”\\nversion of the threshold function sign( a) used by the deterministic mod-\\nels studied in the previous section.\\nW e emphasize that the logistic regression model ( 4.19) is a GLM\\nsince it amounts to a Bernoulli distribution, which is in the exponential'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 96, 'page_label': '91', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='els studied in the previous section.\\nW e emphasize that the logistic regression model ( 4.19) is a GLM\\nsince it amounts to a Bernoulli distribution, which is in the exponential\\nfamily , with natural parameter vector η= ˜wT φ(x) as in\\nt|x,w ∼Bern(t|η= ˜wT φ(x)). (4.21)\\nInference. Before discussing learning, we observe that inference is\\nstraightforward. In fact, once the discriminative model ( 4.19) is known,\\nthe average 0-1 loss, that is, the probability of error, is mi nimized by\\nchoosing the label according to the following rule\\np(C1 |x) = p(t= 1 |x)\\nC1\\n≷\\nC0\\n1\\n2 , (4.22)\\nor equivalently ˜ wT φ(x)\\nC1\\n≷\\nC0\\n0.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 97, 'page_label': '92', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='92 Classiﬁcation\\n4.4.2 Learning\\nConsider ﬁrst ML. The NLL function can be written as\\n−ln p(tD |xD , ˜w) = −\\nN∑\\nn=1\\nln p(tn|xn , ˜w) (4.23)\\n= −\\nN∑\\nn=1\\n{tn ln(yn) + (1 −tn) ln(1 −yn)}, (4.24)\\nwhere we have deﬁned yn = σ( ˜wT φ(xn )). The NLL (\\n4.23) is also re-\\nferred to as the cross entropy loss criterion, since the term −tln(y) −\\n(1 −t) ln(1 −y) is the cross-entropy H((t,1 −t)||(y,1 −y)) (see Sec. 2.6).\\nW e note that the cross-entropy can be used to obtain upper bou nds on\\nthe probability of error (see, e.g., [ 50]). The ML problem of minimizing\\nthe NLL is convex (see Sec. 3.1), and hence it can be solved either\\ndirectly using convex optimization tools, or by using itera tive methods\\nsuch as SGD or Newton (the latter yields the iterative reweig hed least\\nsquare algorithm [ 23, p. 207]).\\nThe development of these methods leverages the expression o f the\\ngradient of the LL function ( 3.28) (used with N = 1) for the exponential'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 97, 'page_label': '92', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='square algorithm [ 23, p. 207]).\\nThe development of these methods leverages the expression o f the\\ngradient of the LL function ( 3.28) (used with N = 1) for the exponential\\nfamily . T o elaborate, using the chain rule for diﬀerentiati on, we can\\nwrite the gradient\\n∇˜w ln p(t|x, ˜w) = ∇η ln Bern( t|η)|η= ˜wφ(x) ×∇˜w ( ˜wT φ(x)), (4.25)\\nwhich, recalling that ∇η ln(Bern(t|η)) = ( t−σ(η)) (cf. ( 3.28)), yields\\n∇˜w ln p(t|x, ˜w) = ( t−y)φ(x). (4.26)\\nEvaluating the exact posterior distribution for the Bayesi an ap-\\nproach turns out to be generally intractable due to the diﬃcu lty in\\nnormalizing the posterior\\np(w|D) ∝p(w)\\nN∏\\nn=1\\np(tn|xn, ˜w). (4.27)\\nW e refer to [ 23, p. 217-220] for an approximate solution based on\\nLaplace approximation. Other useful approximate methods w ill be dis-\\ncussed in Chapter 8.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 98, 'page_label': '93', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.4. Discriminative Probabilistic Models: Generalized Li near Models 93\\nAs a ﬁnal remark, with bipolar labels, i.e., t∈{−1,+1}, the cross-\\nentropy loss function can be written as\\n−ln p(tD |xD , ˜w) =\\nN∑\\nn=1\\nln(1 + exp( −tna(xn, ˜w)). (4.28)\\nThis formulation shows that logistic regression can be thou ght of as an\\nERM method with loss function ℓ(t,a(x, ˜w)) = ln(1 + exp( −ta(x, ˜w)),\\nwhich is seen in Fig. 4.4 to be a convex surrogate loss of the 0-1 loss.\\nMixture models. ∗ As seen, the Bayesian approach obtains the pre-\\ndictive distribution by averaging over multiple models p(t|x,w) with\\nrespect to the parameters’ posterior p(w|D) (cf. ( 2.34)). The result-\\ning model hence mixes the predictions returned by multiple discrimi-\\nnative models p(t|x,w) to obtain the predictive distribution p(t|x) =∫\\np(w|D)p(t|x,w)dw. As we brieﬂy discuss below, it is also possible to\\nlearn mixture models within a frequentist framework.\\nConsider Kprobabilistic discriminative models p(t|x,wk ), k= 1 ,...,K ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 98, 'page_label': '93', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(w|D)p(t|x,w)dw. As we brieﬂy discuss below, it is also possible to\\nlearn mixture models within a frequentist framework.\\nConsider Kprobabilistic discriminative models p(t|x,wk ), k= 1 ,...,K ,\\nsuch as logistic regression. The mixture model is deﬁned as\\np(t|x,θ) =\\nK∑\\nk=1\\nπk p(t|x,wk ). (4.29)\\nIn this model, the vector θ of learnable parameters includes the prob-\\nability vector π, which deﬁnes the relative weight of the K models,\\nand the vectors w1 ,...,wK for the K constituent models. As discussed,\\nin the Bayesian approach, the weights πk are directly obtained by us-\\ning the rules of probability , as done in ( 4.27). Within a frequentist\\napproach, instead, ML training is typically performed via a specialized\\nalgorithm, which will be described in Chapter 6, known as Exp ectation\\nMaximization (EM).\\nMixture models increase the capacity of discriminative mod els and\\nhence allow to learn more complex relationships between cov ariates'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 98, 'page_label': '93', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Maximization (EM).\\nMixture models increase the capacity of discriminative mod els and\\nhence allow to learn more complex relationships between cov ariates\\nand labels. In particular, a mixture model, such as ( 4.29), has a num-\\nber of parameters that increases proportionally with the nu mber K of\\nconstituent models. Therefore, the capacity of a mixture mo del grows\\nlarger with K. As an example, this increased capacity may be leveraged\\nby specializing each constituent model p(t|x,wk ) to a diﬀerent area of\\nthe covariate domain.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 99, 'page_label': '94', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='94 Classiﬁcation\\nGiven their larger capacity , mixture models may be prone to o ver-\\nﬁtting. A way to control overﬁtting will be discussed in Sec. 4.7.\\n4.4.3 Multi-Class Classiﬁcation\\nIn the case of K classes, the relevant exponential family distribution is\\nCategorical with natural parameters depending linearly on the feature\\nvector. This yields the following discriminative model as a generaliza-\\ntion of logistic regression\\nt|x,W ∼Cat(t|η= Wφ(x)), (4.30)\\nwhere the label vector t is deﬁned using one-hot encoding (Ch apter 3)\\nand W is a matrix of weights. W e can also equivalently write the vec tor\\nof probabilities for the K classes as\\ny= softmax( Wφ(x))=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 0\\n∑ K−1\\nk=0 eη k\\n.\\n.\\n.\\neη K−1\\n∑ K−1\\nk=0 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n, (4.31)\\nwhere y = [ y1 ···yK ]T with yk = p(Ck |x); and ηk = wT\\nk+1φ(x) with wT\\nk\\nbeing the kth row of the weight matrix W.\\nLearning follows as for logistic regression. T o brieﬂy elab orate on\\nthis point, the NLL can be written as the cross-entropy funct ion'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 99, 'page_label': '94', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='k+1φ(x) with wT\\nk\\nbeing the kth row of the weight matrix W.\\nLearning follows as for logistic regression. T o brieﬂy elab orate on\\nthis point, the NLL can be written as the cross-entropy funct ion\\n−ln p(tD |xD ,W) = −\\nN∑\\nn=1\\nln p(tn|xn,W)\\n= −\\nN∑\\nn=1\\ntT\\nn ln(yn), (4.32)\\nwhere the logarithm is applied element by element, and we hav e yn =\\nsoftmax(Wφ(xn )). Note that each term in (\\n4.32) can be expressed as\\nthe cross-entropy −tT\\nn ln(yn) = H(tn||yn). The ML problem is again\\nconvex and hence eﬃciently solvable. The gradient of the NLL can be\\nagain found using the general formula (\\n3.28) for exponential models\\nand the chain rule for derivatives. W e can write\\n∇W ln p(t|x,W)=∇η ln Cat( t|η)|η=W φ (x) ×∇W (Wφ(x)), (4.33)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 100, 'page_label': '95', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.4. Discriminative Probabilistic Models: Generalized Li near Models 95\\nwhich yields\\n∇W ln p(t|x,W) = ( t−y)φ(x)T . (4.34)\\n4.4.4 Relation to Neural Networks\\nGLM models of the form (\\n4.30), or ( 4.19) in the special case of binary\\nclassiﬁcation, can be interpreted in terms of the neural net work shown\\nin Fig. 4.6. A neural network consists of a directed graph of computing\\nelements, known as neurons. Each neuron applies a determini stic trans-\\nformation of its inputs, as deﬁned by the incoming edges, to p roduce a\\nscalar output on its outgoing edge.\\nIn Fig. 4.6, the input vector xis ﬁrst processed by a hidden layer of\\nneurons, in which each kth neuron computes the feature φk (x). Then,\\neach kth neuron in the output layer applies the kth element of the\\nsoftmax non-linearity ( 4.31) to the numbers produced by the hidden\\nneurons in order to compute the probability yk = p(Ck |x). Note that,\\nin the case of binary classiﬁcation, only one output neuron i s suﬃcient'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 100, 'page_label': '95', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='neurons in order to compute the probability yk = p(Ck |x). Note that,\\nin the case of binary classiﬁcation, only one output neuron i s suﬃcient\\nin order to compute the probability ( 4.19). It is also important to em-\\nphasize that only the weights between hidden and output laye rs are\\nlearned, while the operation of the neurons in the hidden lay er is ﬁxed.\\nFigure 4.6: GLM as a three-layer neural network with learnable weights o nly be-\\ntween hidden and output layers.\\nW e remark that one should not confuse a graph such as the one in\\nFig. 4.6 with the BN representation previously seen in Fig. 2.7, which\\nwill be further discussed in Chapter 7. In fact, while BNs rep resent\\nprobability distributions, diagrams of neural networks su ch as in Fig.\\n4.6 describe deterministic functional relations among variab les. This'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 101, 'page_label': '96', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='96 Classiﬁcation\\nis despite the fact that the output layer of the network in Fig . 4.6\\ncomputes a vector of probabilities. In other words, while th e nodes of a\\nBN are rvs, those in the graph of a neural network are computat ional\\nnodes.\\n“Extreme machine learning” . ∗ An architecture in which the\\nfeatures φ(x) are selected via random linear combinations of the input\\nvector x is sometimes studied under the rubric of “extreme machine\\nlearning” [ 67]. The advantage of this architecture as compared to deep\\nneural networks with more hidden layers and full learning of the weights\\n(Sec. 4.5) is its low complexity .\\n4.5 Discriminative Probabilistic Models: Beyond GLM\\nFigure 4.7: A multi-layer neural network.\\nAs depicted in Fig. 4.6, GLMs can be interpreted as three-layer neural\\nnetworks in which the only hidden layer computes ﬁxed featur es. The\\nﬁxed features are then processed by the output classiﬁcatio n layer. In\\nvarious applications, determining suitable features is a c omplex and'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 101, 'page_label': '96', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ﬁxed features are then processed by the output classiﬁcatio n layer. In\\nvarious applications, determining suitable features is a c omplex and\\ntime-consuming task that requires signiﬁcant domain knowl edge. Mov-\\ning beyond GLMs allows us to work with models that learn not on ly\\nthe weights used by the output layer for classiﬁcation, but a lso the vec-\\ntor of features φ(x) on which the output layer operates. This approach\\nyields a much richer set of models, which, along with suitabl e learning\\nalgorithms, has led to widely publicized breakthroughs in a pplications\\nranging from speech translation to medical diagnosis.\\nAs a prominent example of beyond-GLM classiﬁcation models, we\\ndescribe here feed-forward multi-layer neural networks, o r deep neural'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 102, 'page_label': '97', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.5. Discriminative Probabilistic Models: Beyond GLM 97\\nnetworks when the hidden layers are in large number. W e note t hat, be-\\nside yielding state-of-the-art classiﬁcation algorithms , multi-layer feed-\\nforward networks are also key components of the computation al theory\\nof mind [ 116].\\n4.5.1 Model\\nAs illustrated in Fig. 4.7, feed-forward multi-layer networks consist of\\nmultiple layers with learnable weights. F ocusing on multi- class classiﬁ-\\ncation, we have the chain of vectors x →h1 →···→ hL →y, where\\nx is the D×1 input (observed) vector; y is the K×1 vector of output\\nprobabilities for the K classes; and hl represents the vector of outputs\\nat the lth hidden layer. The number of neurons in each hidden layer\\nis a hyperparameter to be optimized via validation or Bayesi an meth-\\nods (Chapter 2). Note that the adopted numbering of the layer s is not\\nuniversally accepted, and the reverse ordering is also used .\\nReferring to Fig. 4.7, we can write the operation of the neural net-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 102, 'page_label': '97', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='universally accepted, and the reverse ordering is also used .\\nReferring to Fig. 4.7, we can write the operation of the neural net-\\nwork through the functional relations\\nh1 = h(a1 ) with a1 = W1x (4.35a)\\nhl = h(al ) with al = Wlhl−1 (4.35b)\\nfor l= 2 ,...,L (4.35c)\\ny= softmax( aL+1 ) with aL+1=WL+1hL. (4.35d)\\nThe non-linear function h(·) is applied element-wise and is typically\\nselected as a sigmoid, such as the logistic sigmoid or the hyp erbolic\\ntangent, or else, as has become increasingly common, the Rec tiﬁed\\nLinear Unit (ReLU) h(a) = max(0 ,a). In ( 4.35), we have deﬁned the\\nactivation vectors al for the hidden layers l= 1 ,...,L, and the matrices\\nof weights Wl, l= 1 ,...,L + 1, whose dimensions depend on the size of\\nthe hidden layers. W e denote the tensor 4 of all weights as W.\\nThe learnable weights of the hidden layers encode the featur e vector\\nφ(x) = hL used by the last layer for classiﬁcation. With multi-layer n et-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 102, 'page_label': '97', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The learnable weights of the hidden layers encode the featur e vector\\nφ(x) = hL used by the last layer for classiﬁcation. With multi-layer n et-\\nworks, we have then moved from having ﬁxed features deﬁned a p riori\\n4 A tensor is a generalization of a matrix in that it can have mor e than two\\ndimensions, see, e.g., [ 35].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 103, 'page_label': '98', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='98 Classiﬁcation\\nby vector φ(x) in linear models to designing optimal features that max-\\nimize the classiﬁer’s performance in non-linear models. F u rthermore,\\nin multi-layer networks, the learned features h1,...,hL tend to progress\\nfrom low-level features in the lower layers, such as edges in an image,\\nto higher-level concepts and categories, such as “cats” or “ dogs”, in the\\nhigher layers [ 56].\\n4.5.2 Learning\\nT raining deep neural networks is an art [ 56]. The basic underlying al-\\ngorithm is backpropagation, ﬁrst proposed in 1969 and then reinvented\\nin the mid-1980s [ 126, 125]. However, in practice, a number of tricks\\nare required in order to obtain state-of-the-art performan ce, including\\nmethods to combat overﬁtting, such as dropout. Covering the se solu-\\ntions would require a separate treatise, and here we refer to [64, 56] for\\nan extensive discussion.\\nBackpropagation – or backprop for short – extends the derivation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 103, 'page_label': '98', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tions would require a separate treatise, and here we refer to [64, 56] for\\nan extensive discussion.\\nBackpropagation – or backprop for short – extends the derivation\\ndone in ( 4.34) to evaluate the gradient of the LL to be used within\\nan SGD-based algorithm. Again, the main ingredients are the general\\nformula ( 3.28) for exponential models and the chain rule for derivatives.\\nT o elaborate, select a given training example ( xn ,tn) = ( x,t) to be used\\nin an iteration of SGD. Backprop computes the derivative of t he NLL,\\nor cross-entropy loss function, L(W) = −ln p(t|x,W) = −tT ln y (cf.\\n(4.32)), where the output y is obtained via the relations ( 4.35). It is\\nimportant to note that, unlike the linear models studied abo ve, the\\ncross-entropy for multi-layer is generally a non-convex fu nction of the\\nweights.\\nBackprop computes the gradients with respect to the weight m atri-\\nces by carrying out the following phases.\\n•F orward pass: Given x, apply formulas ( 4.35) to evaluate a1,h1 ,a2 ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 103, 'page_label': '98', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='weights.\\nBackprop computes the gradients with respect to the weight m atri-\\nces by carrying out the following phases.\\n•F orward pass: Given x, apply formulas ( 4.35) to evaluate a1,h1 ,a2 ,\\nh2 ,...,aL ,hL , and y.\\n•Backward pass : Given a1 ,h1 ,a2 ,h2 ,...,aL ,hL ,aL+1,y and t, com-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 104, 'page_label': '99', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.5. Discriminative Probabilistic Models: Beyond GLM 99\\npute\\nδL+1 = ( y−t) (4.36a)\\nδl = ( Wl+1)T δl+1 ·h′ (al ) for l= L,L −1,...,1 (4.36b)\\n∇W l L(W) = δl (hl−1 )T for l= 1 ,2,...,L + 1 , (4.36c)\\nwhere h′ (·) denotes the ﬁrst derivative of the function h(·); the product\\n·is taken element-wise; and we set h0 = x.\\nBackprop requires a forward pass and a backward pass for ever y con-\\nsidered training example. The forward pass uses the neural n etwork as\\ndeﬁned by equations ( 4.35). This entails multiplications by the weight\\nmatrices Wl in order to compute the activation vectors, as well as ap-\\nplications of the non-linear function h(·). In contrast, the backward\\npass requires only linear operations, which, by ( 4.36b), are based on\\nthe transpose ( Wl )T of the weight matrix Wl used in the forward pass.\\nThe derivatives ( 4.36c) computed during the backward pass are of\\nthe general form\\n∇wl\\nij\\nL(W) = hl−1\\ni ×δl\\nj , (4.37)\\nwhere wl\\nij is the ( i,j)th element of matrix Wl corresponding to the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 104, 'page_label': '99', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The derivatives ( 4.36c) computed during the backward pass are of\\nthe general form\\n∇wl\\nij\\nL(W) = hl−1\\ni ×δl\\nj , (4.37)\\nwhere wl\\nij is the ( i,j)th element of matrix Wl corresponding to the\\nweight between the pre-synaptic neuron j in layer l−1 and the post-\\nsynaptic neuron i in layer l; hl−1\\ni is the output of the pre-synaptic\\nneuron i; and δl\\nj is the back-propagated error. The back-propagated\\nerror assigns “responsibility” for the error y−t measured at the last\\nlayer (layer L+ 1) to each synaptic weight wl\\nij between neuron jin layer\\nl−1 and neuron iin layer l. The back-propagated error is obtained via\\nthe linear operations in ( 4.36b).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 105, 'page_label': '100', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='100 Classiﬁcation\\n-4 -3 -2 -1 0 1 2 3 4\\n-4\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n4\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\nFigure 4.8: Probability that the class label is the same as for the exampl es marked\\nwith circles according to the output of a feed-forward multi -layer network with one\\nhidden layer ( L = 1) and six hidden neurons (with sigmoid non-linearity). Th e\\nprobability is represented by the color map illustrated by t he bar on the right of the\\nﬁgure. F or reference, the solid line represent the decision line for logistic regression.\\nExample 4.3. In the example in Fig. 4.8, the illustrated N = 300\\ntraining examples are used to train a logistic regression, i .e., GLM,\\nmodel and a feed-forward multi-layer network with one hidde n layer\\n(L= 1) and six hidden neurons with sigmoid non-linearity h(x) = σ(x).\\nThe logistic model uses linear features φ(x) = [1 x]T . Both networks are\\ntrained using SGD. F or logistic regression, the decision li ne is illustrated'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 105, 'page_label': '100', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The logistic model uses linear features φ(x) = [1 x]T . Both networks are\\ntrained using SGD. F or logistic regression, the decision li ne is illustrated\\nas a solid line, while for the multi-layer network we plot the probability\\nthat the class label is the same as for the examples marked wit h circles\\nas color map. The GLM model with linear features is seen to be u nable\\nto capture the structure of the data, while the multi-layer n etwork can\\nlearn suitable features that improve the eﬀectiveness of cl assiﬁcation.\\n4.5.3 Some Advanced T opics ∗\\nW e conclude this section by noting a few important aspects of the\\nongoing research on deep neural networks.\\nA ﬁrst issue concerns the theoretical understanding of the g eneral-\\nization properties of deep neural networks. On the face of it , the success'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 106, 'page_label': '101', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.5. Discriminative Probabilistic Models: Beyond GLM 101\\nof deep neural networks appears to defy one of the the princip les laid\\nout in Chapter 2, which will be formalized in the next chapter : Highly\\nover-parametrized models trained via ML suﬀer from overﬁtt ing and\\nhence do not generalize well. Recent results suggest that th e use of\\nSGD, based on the gradient ( 4.37), may act a regularizer following an\\nMDL perspective. In fact, SGD favors the attainment of ﬂat lo cal max-\\nima of the likelihood function. Flat maxima require a smalle r number\\nof bits to be speciﬁed with respect to sharp maxima, since, in ﬂat max-\\nima, the parameter vector can be described with limited prec ision as\\nlong as it remain within the ﬂat region of the likelihood func tion [ 66,\\n79, 71] (see also [ 78] for a diﬀerent perspective).\\nAnother important aspect concerns the hardware implementa tion\\nof backprop. This is becoming extremely relevant given the p ractical'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 106, 'page_label': '101', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='79, 71] (see also [ 78] for a diﬀerent perspective).\\nAnother important aspect concerns the hardware implementa tion\\nof backprop. This is becoming extremely relevant given the p ractical\\napplications of deep neural networks for consumer’s device s. In fact,\\na key aspect of backprop is the need to propagate the error, wh ich\\nis measured at the last layer, to each synapse via the backwar d pass.\\nThis is needed in order to evaluate the gradient ( 4.37). While a software\\nimplementation of this rule does not present any conceptual diﬃculty ,\\nrealizing the computations in ( 4.36) in hardware, or even on a biological\\nneural system, is faced with a number of issues.\\nA ﬁrst problem is the non-locality of the update ( 4.37). An update\\nrule is local if it only uses information available at each ne uron. In\\ncontrast, as seen, rule ( 4.37) requires back-propagation through the\\nneural network. Another issue is the need for the backward pa ss to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 106, 'page_label': '101', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='contrast, as seen, rule ( 4.37) requires back-propagation through the\\nneural network. Another issue is the need for the backward pa ss to\\nuse a diﬀerent neural path with respect to the forward pass, g iven that,\\nunlike the backward pass, the forward pass includes also non -linearities.\\nA useful discussion of hardware implementation aspects can be found\\nin [ 12] (see also references therein).\\nT o obviate at least some of these practical issues, a number o f vari-\\nations of the rule ( 4.37) have been proposed [ 12]. F or instance, the\\nfeedback alignment rule modiﬁes ( 4.36b) by using ﬁxed random ma-\\ntrices in lieu of the current weight matrices Wl; while the broadcast\\nalignment rule writes the vectors δl as a linear function with ﬁxed\\nrandom coeﬃcients of the error ( y−t), hence removing the need for\\nback-propagation [ 129].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 107, 'page_label': '102', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='102 Classiﬁcation\\nF urthermore, beside ML, there exist Bayesian learning algo rithms\\n[53], including simpliﬁed approaches such as dropout [ 56, 64]. Signiﬁ-\\ncant progress has also been made on applications such as imag e recog-\\nnition by leveraging the underlying structure, or geometry , of the data\\n[30]. As an important case in point, convolutional neural networks lever-\\nage the stationarity , locality and spatial invariance of im age features\\nby limiting the receptive ﬁeld of the neurons (i.e., by setti ng to zero\\nweights that connect to “distant” pixels) and by tying the we ights of\\nneurons in the same layer.\\nAnother recent development is the design of event-driven spiking\\nneural networks that can be implemented on neuromorphic com puting\\nplatforms with extremely low energy consumption (see, e.g. , [ 84, 11]).\\n4.6 Generative Probabilistic Models\\nAs discussed in Chapter 2, discriminative models do not atte mpt to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 107, 'page_label': '102', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='platforms with extremely low energy consumption (see, e.g. , [ 84, 11]).\\n4.6 Generative Probabilistic Models\\nAs discussed in Chapter 2, discriminative models do not atte mpt to\\nmodel the distribution of the domain points x, learning only the predic-\\ntive distribution p(t|x). In contrast, generative models aim at modelling\\nthe joint distribution by specifying parametrized version s of the prior\\ndistribution p(t), or p(Ck ), and of the class-conditional probability dis-\\ntribution p(x|t), or p(x|Ck ). As a result, generative models make more\\nassumptions about the data by considering also the distribu tion of the\\ncovariates x. As such, generative models may suﬀer from bias when\\nthe model is incorrectly selected. However, the capability to capture\\nthe properties of the distribution of the explanatory varia bles x can im-\\nprove learning if the class-conditional distribution p(x|t) has signiﬁcant\\nstructure.\\n4.6.1 Model\\nGenerative models for binary classiﬁcation are typically d eﬁned as fol-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 107, 'page_label': '102', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='prove learning if the class-conditional distribution p(x|t) has signiﬁcant\\nstructure.\\n4.6.1 Model\\nGenerative models for binary classiﬁcation are typically d eﬁned as fol-\\nlows\\nt ∼Bern(π) (4.38a)\\nx|t = t∼exponential(ηt), (4.38b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 108, 'page_label': '103', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.6. Generative Probabilistic Models 103\\nwhere exponential( η) represents a distribution from the exponential\\nfamily with natural parameter vector η (see previous chapter). Accord-\\ningly , the parameters of the model are θ = ( π,η0 ,η1 ), where vectors\\nηt represent the natural parameters of the class-dependent di stribu-\\ntions. As we have seen in Chapter 2, we can also equivalently u se\\nmean parameters to deﬁne the exponential family distributi ons. As\\na result of this choice, the joint distribution for rv (x ,t) is given as\\np(x,t|π,η0 ,η1 ) = p(t|π)p(x|ηt).\\nInference. Given a new point x, in order to minimize the proba-\\nbility of error, the optimal prediction of the class under 0- 1 loss can be\\nseen to satisfy the maximum a posteriori rule\\np(C1 |x) = πp(x|η1 )\\nπp(x|η1 ) + (1 −π)p(x|η0 )\\nC1\\n≷\\nC0\\n1\\n2 . (4.39)\\n4.6.2 Learning\\nW e now focus on ML learning. The LL function can be written as\\nln p(D|π,η0 ,η1 ) =\\nN∑\\nn=1\\nln p(tn|π) +\\nN∑\\nn=1:\\ntn =0\\nln p(xn|η0) +\\nN∑\\nn=1:\\ntn =1\\nln p(xn|η1 ).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 108, 'page_label': '103', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='C1\\n≷\\nC0\\n1\\n2 . (4.39)\\n4.6.2 Learning\\nW e now focus on ML learning. The LL function can be written as\\nln p(D|π,η0 ,η1 ) =\\nN∑\\nn=1\\nln p(tn|π) +\\nN∑\\nn=1:\\ntn =0\\nln p(xn|η0) +\\nN∑\\nn=1:\\ntn =1\\nln p(xn|η1 ).\\n(4.40)\\nGiven the decomposition of the LL in ( 4.40), we can optimize over π, η0\\nand η1 separately , obtaining the respective ML estimates. Note, h ow-\\never, that, while for π we can use the entire data set, the optimization\\nover parameters η0 and η1 can leverage smaller data sets that include\\nonly the samples xn with labels tn = 0 or tn = 1, respectively . As we\\ndiscussed in Chapter 2, ML estimates of exponential familie s merely\\nrequire moment matching, making these estimates generally easy to\\nobtain. W e illustrate this point below with two important ex amples.\\nQuadratic Discriminant Analysis (QDA) . In QDA, the class-\\ndependent distributions are Gaussian with class-dependen t mean and\\ncovariance:\\nt ∼Bern(π) (4.41a)\\nx|t = k∼N(µk ,Σ k ). (4.41b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 109, 'page_label': '104', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='104 Classiﬁcation\\nBy the general rules derived in Chapter 2 for the exponential family ,\\nML selects the moment matching estimates\\nπM L = N[1]\\nN (4.42a)\\nµk,M L = 1\\nN[k]\\nN∑\\nn=1:\\ntn =k\\nxn (4.42b)\\nΣ k,M L = 1\\nN[k]\\nN∑\\nn=1:\\ntn =k\\n(xn −µk )(xn −µk )T . (4.42c)\\nThe resulting predictive distribution for the label of a new sample is\\nthen given by ( 4.39) by plugging in the estimates above as\\np(C1 |x) = πM L N(x|µ1,M L ,Σ 1,M L )\\nπM L N(x|µ1,M L ,Σ 1,M L ) + (1 −πM L )N(x|µ0,M L ,Σ 0,M L ) .\\n(4.43)\\nLinear Discriminant Analysis (LDA) . Setting Σ k = Σ for both\\nclasses k = 1 ,2 yields the Linear Discriminant Analysis (LDA) model\\n[104]. Imposing that two generally distinct parameters, such as Σ 1 and\\nΣ 2 are equal is an example of parameter tying or sharing . By reducing\\nthe number of parameters to be learned, parameter sharing ca n reduce\\noverﬁtting at the potential cost of introducing bias (see Ch apter 2).\\nUnder the assumption of conjugate priors, and of a priori ind epen-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 109, 'page_label': '104', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='overﬁtting at the potential cost of introducing bias (see Ch apter 2).\\nUnder the assumption of conjugate priors, and of a priori ind epen-\\ndence of the parameters, MAP and Bayesian approaches can be d irectly\\nobtained by following the derivations discussed in Chapter 2. W e refer\\nto [ 23, 15, 104] for details.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 110, 'page_label': '105', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.6. Generative Probabilistic Models 105\\n-4 -3 -2 -1 0 1 2 3 4\\n-4\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n4\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\nFigure 4.9: Probability that the class label is the same as for the exampl es marked\\nwith circles according to the output of the generative model QDA. The probability\\nis represented by the color map illustrated by the bar on the r ight of the ﬁgure. F or\\nthis example, it can be seen that LDA fails to separate the two classes (not shown).\\nExample 4.4. W e continue the example in Sec. 4.5 by showing in Fig.\\n4.9 the probability ( 4.43) that the class label is the same as for the\\nexamples marked with circles according to the output of QDA. Given\\nthat the covariates have a structure that is well modelled by a mixture\\nof Gaussians with diﬀerent covariance matrices, QDA is seen to perform\\nwell, arguably better than the discriminative models studi ed in Sec. 4.5.\\nIt is important to note, however, that LDA would fail in this e xample.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 110, 'page_label': '105', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='well, arguably better than the discriminative models studi ed in Sec. 4.5.\\nIt is important to note, however, that LDA would fail in this e xample.\\nThis is because a model with equal class-dependent covarian ce matrices,\\nas assumed by LDA, would entail a signiﬁcant bias for this exa mple.\\n4.6.3 Multi-Class Classiﬁcation ∗\\nAs an example of a generative probabilistic model with multi ple classes,\\nwe brieﬂy consider the generalization of QDA to K ≥2 classes. Extend-\\ning ( 4.41) to multiple classes, the model is described as\\nt ∼Cat(π) (4.44a)\\nx|t = k∼N(µk ,Σ k ), (4.44b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 111, 'page_label': '106', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='106 Classiﬁcation\\nwhere t is encoded using one-hot encoding, so that the label o f each\\nexample is given by the vector tn = [ t0n ,...,t(K −1)n ]T . F ollowing the\\ndiscussion above, moment matching yields the ML estimates\\nπk,M L = N[k]\\nN =\\n∑ N\\nn=1 tkn\\nN (4.45a)\\nµk,M L = 1\\nN[k]\\nN∑\\nn=1\\ntkn xn (4.45b)\\nΣ k,M L = 1\\nN[k]\\nN∑\\nn=1\\ntkn (xn −µk )(xn −µk )T . (4.45c)\\n4.7 Boosting ∗\\nIn this last section, we return to the mixture models of the fo rm ( 4.29)\\nand discuss a popular training approach to reduce overﬁttin g. W e focus\\non deterministic discriminative models with activations ak (x, ˜wk ), k=\\n1,...,K, in which the mixture predictor is given as\\na(x, ˜w) =\\nK∑\\nk=1\\nπk ak (x, ˜wk ) (4.46)\\nwith learnable parameters {πk }and {˜wk }. The technique, known as\\nboosting, trains one model ak (x, ˜wk ) at a time in a sequential fashion,\\nfrom k = 1 to k = K, hence adding one predictor at each training\\nstep k. As a result, boosting increases the capacity of the model in a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 111, 'page_label': '106', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='from k = 1 to k = K, hence adding one predictor at each training\\nstep k. As a result, boosting increases the capacity of the model in a\\nsequential manner, extending the sum in ( 4.46) over a growing number\\nof predictors. In this way , one starts by training a model wit h a large\\nbias, or approximation error; and progressively decreases the bias at\\nthe cost of a potentially larger estimation error (see Chapt er 2 and the\\nnext chapter for further discussion on bias and estimation e rror). As we\\nwill discuss below, each model is trained by solving an ERM pr oblem\\nin which the contribution of a training example is weighted b y the error\\nrate of the previously trained models.\\nT o elaborate, boosting – more speciﬁcally the AdaBoost sche me –\\ncan be described as solving an ERM problem with the exponenti al loss\\nfunction ℓ(t,a(x, ˜w)) = exp( −t·a(x, ˜w)), which is plotted in Fig. 4.4.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 112, 'page_label': '107', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.8. Summary 107\\nWhen training the kth model, the outputs a1 (x, ˜w1 ),...,ak−1 (x, ˜wk−1 )\\nof the previously trained models, as well as their weights π1,...,πk−1 ,\\nare kept ﬁxed. Excluding the models k+ 1 ,...,K , the training loss can\\nbe written as\\nN∑\\nn=1\\nα(k)\\nn exp(−πk tn ·ak (xn, ˜wk )), (4.47)\\nwith the weights\\nα(k)\\nn = exp\\n\\uf8eb\\n\\uf8ed−tn ·\\nk−1∑\\nj=1\\nπj aj (xn, ˜wj )\\n\\uf8f6\\n\\uf8f8. (4.48)\\nAn important point is that the weights (\\n4.48) are larger for training\\nsamples n with smaller functional margin under the mixture model∑ k−1\\nj=1 πj aj (xn , ˜wj ). Therefore, when training the kth model, we give\\nmore importance to examples that fare worse in terms of class iﬁcation\\nmargins under the current mixture model. Note that, at each t raining\\nstep k, one trains a simple model, which has the added advantage\\nof reducing the computational complexity as compared to the direct\\nlearning of the full training model. W e refer to [ 23, Ch. 14][ 133, Ch. 10]\\nfor further details.\\n4.8 Summary'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 112, 'page_label': '107', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of reducing the computational complexity as compared to the direct\\nlearning of the full training model. W e refer to [ 23, Ch. 14][ 133, Ch. 10]\\nfor further details.\\n4.8 Summary\\nThis chapter has provided a brief review of the key supervise d learning\\nproblem of classiﬁcation. F ollowing the taxonomy put forth in Chapter\\n2, we have divided learning algorithms according to the type of models\\nused to relate explanatory variables and labels. Speciﬁcal ly , we have de-\\nscribed deterministic discriminative models, both linear and non-linear,\\ncovering the perceptron algorithm, SVM, and backprop for mu lti-layer\\nneural networks; probabilistic discriminative models, co ncentrating on\\nGLM; and probabilistic generative models, including QDA an d LDA.\\nW e have also introduced the more advanced topics of mixture m odels\\nand boosting. W e ﬁnally mention that supervised learning, i n the form\\nof classiﬁcation and regression, can also be used as a buildi ng block for'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 112, 'page_label': '107', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and boosting. W e ﬁnally mention that supervised learning, i n the form\\nof classiﬁcation and regression, can also be used as a buildi ng block for\\nthe task of sequential decision processing via imitation le arning (see,\\ne.g., [\\n88]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 113, 'page_label': '108', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='108 Classiﬁcation\\nWhile this chapter has focused on algorithmic aspects, the n ext\\nchapter discusses a well-established theoretical framewo rk in which to\\nstudy the performance of learning for classiﬁcation.\\nAppendix A: More on SGD ∗\\nIn this appendix, we provide some discussion on the converge nce of\\nSGD and on more advanced optimization techniques.\\nConvergence\\nT o brieﬂy discuss the convergence properties of SGD, consid er ﬁrst for\\nreference the conventional gradient descent algorithms, w hich corre-\\nsponds to choosing the entire training set, i.e., S= {1,...,N }, at each\\niteration. If the function to be optimized is strictly conve x\\n5 , as for the\\nquadratic loss, the algorithm is guaranteed to converge to t he (unique)\\nminimum even with a ﬁxed learning rate γ(i) = γ, as long as the lat-\\nter is no larger than the inverse of the maximum curvature of t he loss\\nfunction L, i.e., γ ≤1/L. F or twice-diﬀerentiable loss functions, the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 113, 'page_label': '108', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ter is no larger than the inverse of the maximum curvature of t he loss\\nfunction L, i.e., γ ≤1/L. F or twice-diﬀerentiable loss functions, the\\nmaximum curvature L can be evaluated as the maximum eigenvalue\\nof the Hessian matrix. F unctions with ﬁnite curvature L are known\\nas Lipschitz smooth. F or these functions, the convergence i s geometric,\\nand hence the number of iterations needed to obtain an error o n the\\noptimal solution equal to ǫ scales as ln(1 /ǫ) (see, e.g., [ 152, Chapter\\n8][33, 72]).\\nW e turn now to the proper SGD algorithm operating with a small er\\nmini-batch size S. If the learning rate schedule is selected so as to satisfy\\nthe Robbins–Monro conditions\\n∞∑\\ni=1\\nγ(i) = ∞and\\n∞∑\\ni=1\\n(γ(i) )2 <∞, (4.49)\\nthe SGD algorithm is known to converge to the optimal solutio n of\\nproblem ( 4.9) in the case of strictly convex functions and to station-\\nary points for non-convex functions with bounded curvature (see [ 152,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 113, 'page_label': '108', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='problem ( 4.9) in the case of strictly convex functions and to station-\\nary points for non-convex functions with bounded curvature (see [ 152,\\n5 If the function is twice diﬀerentiable, strict convexity is equivalent to the re-\\nquirement that all the eigenvalues of the Hessian matrix are strictly positive.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 114, 'page_label': '109', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.8. Summary 109\\nChapter 8] for details). Learning rate schedules that satis fy ( 4.49) in-\\nclude γ(i) = 1 /i. The intuitive reason for the use of diminishing learning\\nrates is the need to limit the impact of the “noise” associate d with the\\nﬁnite-sample estimate of the gradient [ 22]. The proof of convergence\\nleverages the unbiasedness of the estimate of the gradient o btained by\\nSGD.\\nIn practice, a larger mini-batch size S decreases the variance of the\\nestimate of the gradient, hence improving the accuracy when close to a\\nstationary point. However, choosing a smaller S can improve the speed\\nof convergence when the current solution is far from the opti mum [ 152,\\nChapter 8][ 22]. A smaller mini-batch size S is also known to improve\\nthe generalization performance of learning algorithms by a voiding sharp\\nextremal points of the training loss function [ 66, 79, 71] (see also Sec.\\n4.5). F urthermore, as an alternative to decreasing the step siz e, one can'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 114, 'page_label': '109', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='extremal points of the training loss function [ 66, 79, 71] (see also Sec.\\n4.5). F urthermore, as an alternative to decreasing the step siz e, one can\\nalso increase the size of the mini-batch along the iteration s of the SGD\\nalgorithm [ 136].\\nVariations and Generalizations\\nMany variations of the discussed basic SGD algorithm have be en pro-\\nposed and are routinely used. General principles motivatin g these sched-\\nule variants include [\\n56, Chapter 8]: ( i ) momentum, or heavy-bal l, mem-\\nory: correct the direction suggested by the stochastic gradien t by consid-\\nering the “momentum” acquired during the last update; ( ii ) adaptivity:\\nuse a diﬀerent learning rate for diﬀerent parameters depend ing on an\\nestimate of the curvature of the loss function with respect t o each pa-\\nrameter; ( iii ) control variates : in order to reduce the variance of the\\nSGD updates, add control variates that do not aﬀect the unbia sed-\\nness of the stochastic gradient and are negatively correlat ed with the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 114, 'page_label': '109', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='SGD updates, add control variates that do not aﬀect the unbia sed-\\nness of the stochastic gradient and are negatively correlat ed with the\\nstochastic gradient; and ( iv) second-order updates: include information\\nabout the curvature of the cost or objective function in the p arameter\\nupdate.\\nAs detailed in [ 56, Chapter 8][ 76, 43], to which we refer for further\\ndiscussions, schemes in the ﬁrst category include Nesterov momentum;\\nin the second category , we ﬁnd AdaGrad, RMSprop and Adam; and the\\nthird encompasses SVRG and SAGA. Finally , the fourth featur es New-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 115, 'page_label': '110', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='110 Classiﬁcation\\nton methods, which require calculation of the Hessian to eva luate the\\nlocal curvature of the objective, and approximated Newton m ethods,\\nwhich leverage an estimate of the Hessian. The practical and theoret-\\nical implications of the use of these methods is still under d iscussion\\n[157].\\nRelated to second-order methods is the natural gradient approach,\\nwhich applies most naturally to probabilistic models in whi ch the func-\\ntion to be optimized is a LL [ 5]. The conventional gradient method\\nupdates the parameters by moving in the direction that minim izes the\\ncost function under a constraint on the norm of the update vec tor in\\nthe parameter space. A potentially problematic aspect of th is method is\\nthat the Euclidean distance ||θ′ −θ′′||2 between two parameter vectors\\nθ′ and θ′′,e.g., two mean parameters in a model within the exponential\\nfamily , does not provide a direct measure of the distance of t he two'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 115, 'page_label': '110', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='θ′ and θ′′,e.g., two mean parameters in a model within the exponential\\nfamily , does not provide a direct measure of the distance of t he two\\ncorresponding distributions in terms of relevant metrics s uch as the\\nKL divergence. The natural gradient method addresses this i ssue by\\nmeasuring the size of the update directly in terms of the KL di vergence\\nbetween distributions. This modiﬁes the update by pre-mult iplying the\\ngradient with the inverse of the Fisher information matrix [ 5].\\nThe discussion above focuses on the common case of diﬀerenti able\\ncost functions. ERM problems typically include possibly no n-diﬀerentiable\\nregularization terms. T o tackle these problems, technique s such as the\\nsubgradient method and proximal gradient can be used in lieu of SGD\\n[22]. Other important aspects of optimization schemes include paral-\\nlelism and non-convexity (see, e.g., [ 130, 141, 44, 161]). Alternatives\\nto gradient methods that do not require diﬀerentiability in clude evolu-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 115, 'page_label': '110', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='lelism and non-convexity (see, e.g., [ 130, 141, 44, 161]). Alternatives\\nto gradient methods that do not require diﬀerentiability in clude evolu-\\ntionary schemes [ 128].\\nAppendix B: Kernel Methods ∗\\nIn this section, we provide a brief introduction to kernel me thods. This\\nsection requires some background in Lagrange duality .\\nW e start by revisiting the problem ( 4.16) solved by SVM. Using\\nLagrange duality , the optimization ( 4.16) can be solved in the dual do-\\nmain, that is, by optimizing over the dual variables or the La grange\\nmultipliers. Referring for details to [ 23, Chapter 7], the resulting prob-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 116, 'page_label': '111', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.8. Summary 111\\nlem turns out to be quadratic and convex. Importantly , the re sulting\\noptimal activation can be expressed as\\na(x, ˜w) =\\nN∑\\nn=1\\nαntnk(x,xn ), (4.50)\\nwhere αn are the optimal dual variables, and we have deﬁned the kernel\\nfunction\\nk(x,y) = φ(x)T φ(y), (4.51)\\nwhere xand yare two argument vectors. The kernel function measures\\nthe correlation – informally , the similarity – between the t wo input vec-\\ntors xand y. The activation ( 4.50) has hence an intuitive interpretation:\\nThe decision about the label of an example x depends on the support\\nvectors xn, which have αn >0, that are the most similar to x. W e note\\nthat equation ( 4.50) can also be justiﬁed using the representer theorem\\nin [ 133, Chapter 16], which shows that the optimal weight vector mus t\\nbe a linear combination of the feature vectors {φ(xn)}N\\nn=1 .\\nW orking in the dual domain can have computational advantage s\\nwhen the number of the primal variables, here the size D′ of the weight'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 116, 'page_label': '111', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='be a linear combination of the feature vectors {φ(xn)}N\\nn=1 .\\nW orking in the dual domain can have computational advantage s\\nwhen the number of the primal variables, here the size D′ of the weight\\nvector ˜w, is larger than the number N of dual variables. While this\\nseems a prior unlikely to happen in practice, it turns out tha t this is\\nnot the case. The key idea is that one can use (\\n4.50) with any other\\nkernel function, not necessarily one explicitly deﬁned by a feature func-\\ntion φ(·). A kernel function is any symmetric function measuring the\\ncorrelation of two data points, possibly in an inﬁnite-dime nsional space.\\nThis is known as the kernel trick .\\nAs a ﬁrst example, the polynomial kernel\\nk(x,y) = ( γxT y+ r)L, (4.52)\\nwhere r> 0, corresponds to a correlation φ(x)T φ(y) in a high-dimensional\\nspace D′. F or instance, with L = 2 and D = 1, we have D′ = 6 and\\nthe feature vector φ(x) =\\n[\\n1,\\n√\\n2x1,\\n√\\n2x2 , x2\\n1 x2\\n2,\\n√\\n2x1x2\\n] T\\n[104]. As'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 116, 'page_label': '111', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='space D′. F or instance, with L = 2 and D = 1, we have D′ = 6 and\\nthe feature vector φ(x) =\\n[\\n1,\\n√\\n2x1,\\n√\\n2x2 , x2\\n1 x2\\n2,\\n√\\n2x1x2\\n] T\\n[104]. As\\nanother, more extreme, example, the conventional Gaussian kernel\\nk(x,y) = e−r∥ x−y∥ 2\\n(4.53)\\ncorresponds to an inner product in an inﬁnite dimensional sp ace [ 104].\\nAn extensive discussion on kernel methods can be found in [ 104].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 117, 'page_label': '112', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='112 Classiﬁcation\\nBefore leaving the subject of kernel methods, it is worth not ing that\\nan important class of methods including k−Nearest Neighbor ( k-NN),\\nuses kernels that are data-dependent. k-NN is also an example of non-\\nparametric learning rules. In contrast to the other schemes studied here,\\nit does not rely on a parametric model of the (probabilistic) relationship\\nbetween input and output. Instead, k-NN leverages the assumption that\\nthe labels of nearby points x should be similar [ 81].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 118, 'page_label': '113', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5\\nStatistical Learning Theory ∗\\nStatistical learning theory provides a well-established t heoretical frame-\\nwork in which to study the trade-oﬀ between the number N of available\\ndata points and the generalization performance of a trained machine.\\nThe approach formalizes the notions of model capacity , esti mation er-\\nror (or generalization gap), and bias that underlie many of t he design\\nchoices required by supervised learning, as we have seen in t he previous\\nchapters. This chapter is of mathematical nature, and it dep arts from\\nthe algorithmic focus of the text so far. While it may be skipp ed at a\\nﬁrst reading, the chapter sheds light on the key empirical ob servations\\nmade in the previous chapters relative to learning in a frequ entist set-\\nup. It does so by covering the theoretical underpinnings of s upervised\\nlearning within the classical framework of statistical lea rning theory .\\nT o this end, the chapter contains a number of formal statemen ts with'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 118, 'page_label': '113', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning within the classical framework of statistical lea rning theory .\\nT o this end, the chapter contains a number of formal statemen ts with\\nproofs. The proofs have been carefully selected in order to h ighlight\\nand clarify the key theoretical ideas. This chapter follows mostly the\\ntreatment in [ 133].\\n113'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 119, 'page_label': '114', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='114 Statistical Learning Theory ∗\\n5.1 A Formal Framework for Supervised Learning\\nIn this chapter, we concentrate on discriminative determin istic models\\nfor binary classiﬁcation, as it is typically done in statist ical learning\\ntheory . W e also focus on the standard 0-1 loss ℓ(t,ˆt) = 1( ˆt ̸= t), for\\nwhich the generalization loss is the probability of error. T he labels tfor\\nthe two classes take values in the set {0,1}(cf. (\\n4.4)).\\nThe learning problem is formalized as follows. Assume that a model,\\nor hypothesis class, Hhas been selected. This set contains a, possibly\\nuncountable, number of predictors ˆt that map each point x in the do-\\nmain space to a label ˆt(x) in {0,1}. W e would like to choose a speciﬁc\\nhypothesis, or predictor, ˆt∈H that minimize the generalization error\\n(cf. ( 2.2))\\nLp(ˆt) = E(x,t)∼pxt [ℓ(t,ˆt(x))]. (5.1)\\nSolving this inference problem would yield an optimal model within\\nclass Has\\nˆt∗\\nH ∈argmin\\nˆt∈H\\nLp(ˆt). (5.2)\\nThe notation in ('),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 119, 'page_label': '114', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='(cf. ( 2.2))\\nLp(ˆt) = E(x,t)∼pxt [ℓ(t,ˆt(x))]. (5.1)\\nSolving this inference problem would yield an optimal model within\\nclass Has\\nˆt∗\\nH ∈argmin\\nˆt∈H\\nLp(ˆt). (5.2)\\nThe notation in (\\n5.2) emphasizes that there may be multiple optimal\\nhypotheses returned by the minimization of the generalizat ion error\\nLp(ˆt). Nevertheless, to ﬁx the ideas, it is useful to think of the c ase in\\nwhich there is a unique optimal hypothesis. This is, for inst ance, the\\ncase when the loss function is strictly convex. Obtaining th e optimal\\npredictor ( 5.2) requires knowledge of the true distribution p(x,t), which\\nis not available.\\nExample 5.1. F or the linear (deterministic) methods studied in Chap-\\nter 4, the model is deﬁned as\\nH= {t˜w (x) = sign( wT x+ w0)} (5.3)\\nwith ˜w= [ wT w0]T , and similarly for the feature-based version. Identi-\\nfying a hypothesis within this class requires the selection of the weight\\nvector ˜w∈RD+1.\\nIn lieu of the true distribution p(x,t), what is available is an i.i.d.\\ntraining set'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 119, 'page_label': '114', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='fying a hypothesis within this class requires the selection of the weight\\nvector ˜w∈RD+1.\\nIn lieu of the true distribution p(x,t), what is available is an i.i.d.\\ntraining set\\nD= {(xn,tn )}N\\nn=1 ∼\\ni.i.d.\\np(x,t) (5.4)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 120, 'page_label': '115', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.1. A Formal Framework for Supervised Learning 115\\ndistributed according to p(x,t). A learning algorithm, such as ERM,\\ntakes the training set Das input and returns a predictor ˆtD ∈H as\\noutput. W e would like the predictive model ˆtD ∈ Hto yield a gen-\\neralization error Lp(ˆtD ) that is as close as possible to the minimum\\ngeneralization loss Lp(ˆt∗\\nH). Note that the selected model ˆtD is random\\ndue to randomness of the data set D.\\nIn this regard, we recall that the ERM learning rule chooses a hy-\\npothesis ˆtERM\\nD ∈H by following the criterion ˆtERM\\nD = argmin ˆt∈H LD (ˆt),\\nwhere the empirical risk is\\nLD (ˆt) = 1\\nN\\nN∑\\nn=1\\nℓ(tn ,ˆt(xn))). (5.5)\\nThe notation in ( 5.5) emphasizes the randomness of the training set\\nD= {(xn,tn )}N\\nn=1 .\\nSince the distribution p(x,t) is unknown, a learning rule ˆtD , such\\nas ERM, can only minimize the generalization loss Lp(ˆt) approximately\\nbased on the observation of the data D. F urthermore, this approxi-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 120, 'page_label': '115', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as ERM, can only minimize the generalization loss Lp(ˆt) approximately\\nbased on the observation of the data D. F urthermore, this approxi-\\nmation can only be guaranteed at some probability level due to the\\nrandomness of the data set D. This is illustrated in Fig.\\n5.1, in which\\nwe have represented a high-probability interval for rv Lp(ˆtD ) on the\\nhorizontal axis. W e would like the approximation to be accur ate for all\\nvalues of Lp(ˆtD ) within this interval.\\nBut there is more: the probabilistic guarantee in terms of ac curacy\\ncannot depend on the speciﬁc distribution p(x,t), but it should instead\\nbe universal with respect to all distributions p(x,t). In summary , the\\nbest one can hope for is to have a learning rule ˆtD that is Probably\\nApproximately Correct (P AC).\\nIn order to formalize this notion, we introduce the followin g deﬁni-\\ntion.\\nDeﬁnition 5.1. A learning rule ˆtD is ( N,ǫ,δ ) P AC if, when working\\non data sets Dof N examples, it satisﬁes the inequality\\nLp(ˆtD ) ≤Lp(ˆt∗'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 120, 'page_label': '115', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion.\\nDeﬁnition 5.1. A learning rule ˆtD is ( N,ǫ,δ ) P AC if, when working\\non data sets Dof N examples, it satisﬁes the inequality\\nLp(ˆtD ) ≤Lp(ˆt∗\\nH) + ǫ (5.6)\\nwith probability no smaller than 1 −δ,that is,\\nPrD ∼\\ni.i.d.\\npxt [Lp(ˆtD ) ≤Lp(ˆt∗\\nH) + ǫ] ≥1 −δ, (5.7)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 121, 'page_label': '116', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='116 Statistical Learning Theory ∗\\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n0 2 4 6 8 10\\nFigure 5.1: A learning algorithm ˆtD outputs a hypothesis that depends on the\\nrandom training set D. It hence takes values in a given interval (the box on the\\nhorizontal axis) with some large probability 1 − δ. The accuracy level ǫ is measured\\nby the diﬀerence with respect to optimal generalization los s Lp (ˆt∗\\nH) for the worst-\\ncase ˆtD in the high-probability interval.\\nfor any true distribution p(x,t).\\nIn (\\n5.6), we have deﬁned ǫ as the accuracy parameter and δ as the\\nconﬁdence parameter. The accuracy is also known as estimation error\\nor generalization gap according to the deﬁnition given in Sec. 2.3.3. In\\nwords, the ( N,ǫ,δ ) P AC condition ( 5.6) requires that the learning rule\\nˆtD operating over N data points is ǫ−accurate with probability 1 −δ\\nfor any distribution p(x,t).\\nThe key question is: Given a model H, how large should N be in\\norder to ensure the existence of an ( N,ǫ,δ) P AC learning scheme ˆtD'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 121, 'page_label': '116', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for any distribution p(x,t).\\nThe key question is: Given a model H, how large should N be in\\norder to ensure the existence of an ( N,ǫ,δ) P AC learning scheme ˆtD\\nfor given accuracy and conﬁdence levels (ǫ,δ)? At a high level, we know\\nthat a large model order implies the need for a larger N in order to\\navoid overﬁtting. More precisely , we expect to observe the b ehavior\\nillustrated in Fig. 5.2: As N increases, ( i ) the interval of values taken\\nby the generalization loss Lp(ˆtD ) with probability no smaller than 1 −δ\\nshrinks; and ( ii ) the generalization loss Lp(ˆtD ) tends to the minimum\\ngeneralization loss Lp(ˆt∗\\nH ),and hence the estimation error vanishes. As'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 122, 'page_label': '117', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.1. A Formal Framework for Supervised Learning 117\\nillustrated in the next example, this expected behavior is a consequence\\nof the law of large numbers, since a larger N allows an increasingly\\naccurate estimation of the true general loss.\\n5 10 15 20 25 30 35 40 45 50\\n0.8\\n1\\n1.2\\n1.4\\n1.6\\n1.8\\n2\\n2.2\\nFigure 5.2: High-probability interval (dashed arrow) for the generali zation error\\nLp (ˆtD ) versus the number N of data points for a model H.\\nExample 5.2. Consider the problem of binary classiﬁcation using the\\nmodel of threshold functions, namely\\nH=\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nˆtθ (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if x<θ\\n1, if x≥θ\\n= 1( x≥θ)\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe, (5.8)\\nwhere xis a real number ( D= 1). Note that the model is parametrized\\nby the threshold θ. Make the realizability assumption that the true dis-\\ntribution is within the hypothesis allowed by the model, i.e ., p(x,t) =\\np(x)1(t= ˆt0(x)) and hence the optimal hypothesis is ˆt∗\\nH = ˆt0, or, equiva-\\nlently , the optimal threshold is θ∗ = 0. Assuming a uniform distribution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 122, 'page_label': '117', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x)1(t= ˆt0(x)) and hence the optimal hypothesis is ˆt∗\\nH = ˆt0, or, equiva-\\nlently , the optimal threshold is θ∗ = 0. Assuming a uniform distribution\\np(x) = U(x|−0.5,0.5) in the interval [ −0.5,0.5] for the domain points,\\nFig.\\n5.3 shows the generalization error Pr[ ˆtθ (x) ̸= t0(x)] = |θ|, as well\\nas the training loss LD (ˆtθ ) for the training set shown on the horizontal\\naxis, for two values of N. Note that the training loss LD (ˆtθ ) is simply'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 123, 'page_label': '118', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='118 Statistical Learning Theory ∗\\nthe fraction of training examples that are correctly classi ﬁed. It is ob-\\nserved that, as N increases, the training loss, or empirical risk, becomes\\nan increasingly reliable estimate of the generalization lo ss uniformly for\\nall hypotheses, parameterized by θ, in the model.\\n-0.5 0 0.5\\n0\\n0.2\\n0.4\\n0.6\\n-0.5 0 0.5\\n0\\n0.2\\n0.4\\n0.6\\nFigure 5.3: Generalization and training losses for a scalar threshold c lassiﬁer model.\\nAs suggested by the example, if N is large enough, the empirical\\nrisk, or training loss, LD (ˆt) approximates increasingly well (with high\\nprobability) the generalization loss Lp(ˆt) for any ﬁxed hypothesis in\\nˆt∈H by the law of large numbers. It would then seem that the proble m\\nis solved: Since LD (ˆt) ≃ Lp(ˆt) for any ˆt, the ERM solution ˆtERM\\nD ,\\nwhich minimizes the training loss LD (ˆt), should also approximately\\nminimize the generalization loss Lp(ˆt), and hence we have ˆtERM\\nD ≃ˆt∗\\nH .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 123, 'page_label': '118', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='D ,\\nwhich minimizes the training loss LD (ˆt), should also approximately\\nminimize the generalization loss Lp(ˆt), and hence we have ˆtERM\\nD ≃ˆt∗\\nH .\\nHowever, this argument is incorrect. In fact, we need the tra ining loss\\nLD (ˆt) to be an accurate approximation of the generalization loss Lp(ˆt)\\nuniformly for al l hypotheses in ˆt∈H in order to ensure the condition\\nˆtERM\\nD ≃ˆt∗\\nH. As we will see in the rest of this chapter, guaranteeing\\nthis condition requires to observe a number of samples N that grows\\nwith the “capacity” of the model H, that is, roughly , with the number\\nof parameters deﬁning the hypotheses in H. Moreover, some models'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 124, 'page_label': '119', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.2. P AC Learnability and Sample Complexity 119\\nturn out to be impossible to learn – in the sense of P AC learnab ility\\nformalized below – no matter how large N is.\\n5.2 P AC Learnability and Sample Complexity\\nIn order to formally address the key question posed above reg arding\\nthe learnability of a model H, we make the following deﬁnitions. As\\nmentioned, for simplicity , we consider binary classiﬁcati on under the 0-1\\nloss, although the analysis can be generalized under suitab le conditions\\n[\\n133].\\nDeﬁnition 5.2. A hypothesis class His P AC learnable if, for any ǫ,δ ∈\\n(0,1), there exist an ( N,ǫ,δ ) P AC learning rule as long as the inequality\\nN ≥NH(ǫ,δ) is satisﬁed for some function NH (ǫ,δ) <∞.\\nIn words, a hypothesis class is P AC learnable if, as long as en ough\\ndata is collected, a learning algorithm can be found that obt ains any\\ndesired level of accuracy and conﬁdence. An illustration of the threshold\\nNH(ǫ,δ) can be found in Fig. 5.2. A less strong deﬁnition of P AC'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 124, 'page_label': '119', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='desired level of accuracy and conﬁdence. An illustration of the threshold\\nNH(ǫ,δ) can be found in Fig. 5.2. A less strong deﬁnition of P AC\\nlearnability requires ( 5.7) to hold only for all true distributions p(x,t)\\nthat can be written as\\np(x,t) = p(x)1(t= ˆt(x)) (5.9)\\nfor some marginal distribution p(x) and for some hypothesis ˆt(x) ∈H.\\nThe condition ( 5.9) is known as the realizability assumption, which im-\\nplies that the data is generated from some mechanism that is i ncluded\\nin the hypothesis class. Note that realizability implies th e linear sepa-\\nrability of any data set drawn from the true distribution for the class\\nof linear predictors (see Chapter 4).\\nA ﬁrst important, and perhaps surprising, observation is th at not all\\nmodels are P AC learnable. As an extreme example of this pheno menon,\\nconsider the class Hof all functions from RD to {0,1}. By the no\\nfree lunch theorem , this class is not P AC learnable. In fact, given any'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 124, 'page_label': '119', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='consider the class Hof all functions from RD to {0,1}. By the no\\nfree lunch theorem , this class is not P AC learnable. In fact, given any\\namount of data, we can always ﬁnd a distribution p(x,t) under which\\nthe P AC condition is not satisﬁed. Intuitively , even in the r ealizable\\ncase, knowing the correct predictor ˆt(x) in ( 5.9) for any number of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 125, 'page_label': '120', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='120 Statistical Learning Theory ∗\\nx∈RD yields no information on the value of ˆt(x) for other values of x.\\nAs another, less obvious, example the class\\nH= {hw (x) = 1(sin( wx) >0)} (5.10)\\nis not P AC learnable despite being parameterized by a single scalar\\n[133].\\nDeﬁnition 5.3. The sample complexity N∗\\nH(ǫ,δ) of model His the min-\\nimal value of NH (ǫ,δ) that satisﬁes the requirements of P AC learning\\nfor H.\\nW e will see next that the sample complexity depends on the ca-\\npacity of the model H. Note that the sample complexity of the two\\nexamples above is inﬁnite since they are not P AC learnable. W e also\\nremark that P AC learnability may be alternatively deﬁned un der the\\nadditional conditions on the scaling of N∗\\nH(ǫ,δ) as a function of ǫ and\\nδ, as well as on the computational complexity of the learning r ule. W e\\nwill not consider these more reﬁned deﬁnitions here, and we r efer the\\nreader to [ 51, 133] for discussion.\\n5.3 P AC Learnability for Finite Hypothesis Classes'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 125, 'page_label': '120', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='will not consider these more reﬁned deﬁnitions here, and we r efer the\\nreader to [ 51, 133] for discussion.\\n5.3 P AC Learnability for Finite Hypothesis Classes\\nIn this section, we consider models with a ﬁnite number of hyp othe-\\nses. The main result is summarized in the following theorem, which is\\nproved below in Sec.\\n5.3.1.\\nTheorem 5.1. A ﬁnite hypothesis class His P AC learnable with sample\\ncomplexity satisfying the inequality\\nN∗\\nH(ǫ,δ) ≤\\n⌈\\n2 ln |H|+ 2 ln(2 /δ)\\nǫ2\\n⌉\\n≜ NERM\\nH (ǫ,δ). (5.11)\\nMoreover, the ERM algorithm achieves the upper bound NERM\\nH (ǫ,δ).\\nThe previous theorem shows that all ﬁnite classes are P AC lea rnable.\\nF urthermore, for all ﬁnite classes, ERM is a P AC learning rul e for any\\ndesired levels of accuracy and conﬁdence ( ǫ,δ), as long as N is larger\\nthan the threshold NERM\\nH (ǫ,δ). This threshold, which we will refer to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 126, 'page_label': '121', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.3. P AC Learnability for Finite Hypothesis Classes 121\\nas the ERM sample complexity for class H, depends on the capacity\\nof the hypothesis class, deﬁned as ln |H|(nats) or log 2 |H|(bits). This\\nis the number of bits required to index the hypotheses in H. It is also\\ninteresting to note that increasing the accuracy , i.e., dec reasing ǫ is\\nmore demanding than increasing the conﬁdence, that is, decr easing δ,\\nin terms of sample complexity .\\nAnother way to understand the result ( 5.11) is that, with N data\\npoints, we can achieve the estimation error\\nǫ=\\n√\\n2 ln(2 |H|/δ)\\nN , (5.12)\\nwith probability 1 −δ, by using ERM. As a result, with N data points,\\nwe can upper bound the generalization loss of ERM as\\nLp(ˆtERM\\nD ) ≤Lp(ˆt∗\\nH) +\\n√\\n2 ln |H|/δ\\nN (5.13)\\nwith probability 1 −δ. In words, ERM achieves the optimal generaliza-\\ntion loss with an estimation error that scales with square ro ot of the\\nmodel capacity and with the inverse square root of N.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 126, 'page_label': '121', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='with probability 1 −δ. In words, ERM achieves the optimal generaliza-\\ntion loss with an estimation error that scales with square ro ot of the\\nmodel capacity and with the inverse square root of N.\\nAs another important note, under the realizability assumpt ion, the\\ntheorem can be modiﬁed to yield the smaller upper bound [ 133]\\nN∗\\nH(ǫ,δ) ≤\\n⌈\\nln |H|+ ln(1/ δ)\\nǫ\\n⌉\\n≜ NERM\\nH (ǫ,δ), (5.14)\\nwhich is also achievable by ERM.\\nWhat does the theorem say about inﬁnite models such as the lin ear\\nclassiﬁer ( 5.3)? One approach is to learn a “quantized” version of H,\\nsay Hb , in which each weight is represented by bbits or, equivalently , as\\none of 2 b pre-determined quantization levels. As a result, the numbe r\\nof hypotheses in the hypothesis class His |H| = (2 b )D+1 , and the\\ncapacity of the hypothesis class is log |H|= ( D+ 1) b (bits) or ln |H|=\\nb(D+ 1) ln 2 (nats). It follows that, using ( 5.3), we obtain the ERM\\nsample complexity\\nNERM\\nH (ǫ,δ) =\\n⌈\\n2b(D+ 1) ln 2 + 2 ln(2 /δ)\\nǫ2\\n⌉\\n. (5.15)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 127, 'page_label': '122', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='122 Statistical Learning Theory ∗\\nIt is observed that the ERM sample complexity scales proport ionally\\nto the number of parameters D+ 1 and to the resolution b. Therefore,\\nobtaining an arbitrary precision by selecting larger value s of b yields\\na sample complexity that grows unbounded. W e will see below h ow to\\ncorrect this result by introducing a more advanced theory of general-\\nization through the concept of V apnik–Chervonenkis (VC) di mension.\\n5.3.1 Proof of Theorem 5.1\\nThe proof of Theorem 5.1 reveals the role played by the training loss\\nLD (ˆt) in approximating the generalization loss Lp(ˆt) uniformly for all\\nhypotheses ˆt∈H. W e start with the following key lemma.\\nLemma 5.2. F or any N ≥NERM\\nH (ǫ,δ), we have\\nPrD ∼\\ni.i.d.\\np(x,t)\\n[\\n|Lp(ˆt) −LD (ˆt)|≤ ǫ\\n2 for all ˆt∈H\\n]\\n≥1 −δ. (5.16)\\nReﬂecting the observation made above around Fig. 5.3, the lemma\\nsays that the training loss LD (ˆt) is a uniformly accurate approximation,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 127, 'page_label': '122', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x,t)\\n[\\n|Lp(ˆt) −LD (ˆt)|≤ ǫ\\n2 for all ˆt∈H\\n]\\n≥1 −δ. (5.16)\\nReﬂecting the observation made above around Fig. 5.3, the lemma\\nsays that the training loss LD (ˆt) is a uniformly accurate approximation,\\nwith accuracy level ǫ/2, of the generalization loss, as long as N ≥\\nNERM\\nH (ǫ,δ).\\nAssume now that the lemma is true – a proof will be given below.\\nUsing the lemma, Theorem 5.1 follows immediately from the inequali-\\nties\\nLp(ˆtERM\\nD ) ≤LD (ˆtERM\\nD ) + ǫ\\n2 ≤LD (ˆt∗ ) + ǫ\\n2 (5.17)\\n≤Lp(ˆt∗ ) + ǫ\\n2 + ǫ\\n2 = Lp(ˆt∗ ) + ǫ, (5.18)\\nwhere the ﬁrst inequality follows from the lemma; the second from the\\ndeﬁnition of ERM; and the third by another application of the lemma.\\nW e hence only need to prove the Lemma in order to conclude the\\nproof. T o proceed, we will use Hoeﬀding’s inequality , which says the\\nfollowing (see, e.g., [ 133]). F or i.i.d. rvs u 1,u2,··· ,uM ∼p(u) such\\nthat E [u i] = µ and Pr[ a ≤ui ≤b] = 1, we have the large deviation\\ninequality\\nPr\\n[⏐\\n⏐\\n⏐\\n⏐\\n⏐\\n1\\nM\\nM∑\\nm=1\\num −µ\\n⏐\\n⏐\\n⏐\\n⏐\\n⏐>ǫ\\n]'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 127, 'page_label': '122', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='following (see, e.g., [ 133]). F or i.i.d. rvs u 1,u2,··· ,uM ∼p(u) such\\nthat E [u i] = µ and Pr[ a ≤ui ≤b] = 1, we have the large deviation\\ninequality\\nPr\\n[⏐\\n⏐\\n⏐\\n⏐\\n⏐\\n1\\nM\\nM∑\\nm=1\\num −µ\\n⏐\\n⏐\\n⏐\\n⏐\\n⏐>ǫ\\n]\\n≤2 exp\\n(\\n− 2Mǫ2\\n(b−a)2\\n)\\n. (5.19)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 128, 'page_label': '123', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.3. P AC Learnability for Finite Hypothesis Classes 123\\nW e can now write the following sequence of equalities and ine qualities,\\nwhich prove the lemma and hence conclude the proof:\\nPrD ∼\\ni.i.d.\\np(x,t)\\n[\\n∃ˆt∈H : |Lp(ˆt) −LD (ˆt)|> ǫ\\n2\\n]\\n=PrD ∼\\ni.i.d.\\np(x,t)\\n\\uf8ee\\n\\uf8f0⋃\\nˆt∈H\\n{\\n|Lp(ˆt) −LD (ˆt)|> ǫ\\n2\\n}\\uf8f9\\n\\uf8fb\\n≤\\n∑\\nˆt∈H\\nPrD ∼\\ni.i.d.\\np(x,t)\\n[\\n|Lp(ˆt) −LD (ˆt)|> ǫ\\n2\\n]\\n≤2\\n∑\\nˆt∈H\\nexp\\n(\\n−Nǫ2\\n2\\n)\\n=2|H|exp\\n(\\n−Nǫ2\\n2\\n)\\n≤δ,\\nwhere the ﬁrst inequality follows by the union bound; the sec ond by\\nHoeﬀding’s inequality; and the third can be veriﬁed to be tru e as long\\nas the inequality N ≥NERM\\nH (ǫ,δ) is satisﬁed.\\n5.3.2 Structural Risk Minimization ∗\\nThe result proved above is useful also to introduce the Struc tural Risk\\nMinimization (SRM) learning approach. SRM is a method for jo int\\nmodel selection and hypothesis learning that is based on the minimiza-\\ntion of an upper bound on the generalization loss. In princip le, the ap-\\nproach avoids the use of validation, and has deep theoretica l properties'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 128, 'page_label': '123', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion of an upper bound on the generalization loss. In princip le, the ap-\\nproach avoids the use of validation, and has deep theoretica l properties\\nin terms of generalization [ 133]. In practical applications, the approach\\nis rarely used, and validation is often preferable. It is nev ertheless con-\\nceptually and theoretically a cornerstone of statistical l earning theory .\\nT o elaborate, assume that we have a nested set of hypothesis c lasses\\nH1 ⊆H2 ⊆... ⊆HMmax . F or instance, the nested model may corre-\\nspond to linear classiﬁers with increasing orders M ∈{1,2,...,Mmax }.\\nF rom Lemma 5.2, we can obtain the following bound\\nLp(ˆt) ≤LD (ˆt) +\\n√\\nln(2|HM |/δ)\\n2N (5.20)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 129, 'page_label': '124', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='124 Statistical Learning Theory ∗\\nfor all ˆt ∈ HM , with probability 1 −δ. SRM minimizes this upper\\nbound, which is a pessimistic estimate of the generalizatio n loss, over\\nboth the choice of the model M and the hypothesis ˆt∈HM . W e note\\nthe similarity of this approach with the simpliﬁed MDL crite rion based\\non two-part codes covered in Chapter 2.\\n5.4 VC Dimension and Fundamental Theorem of P AC Learning\\nW e have seen that ﬁnite classes are P AC learnable with sample com-\\nplexity proportional to the model capacity ln |H|by using ERM. In this\\nsection, we address the following questions: Is NERM\\nH (ǫ,δ) the smallest\\nsample complexity? How can we deﬁne the capacity of inﬁnite h ypoth-\\nesis classes? W e have discussed at the end of Sec.\\n5.3 that the answer\\nto the latter question cannot be found by extrapolating from results\\nobtained when considering ﬁnite hypothesis classes. In con trast, will\\nsee here that the answers to both of these questions rely on th e con-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 129, 'page_label': '124', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='obtained when considering ﬁnite hypothesis classes. In con trast, will\\nsee here that the answers to both of these questions rely on th e con-\\ncept of VC dimension, which serves as a more fundamental deﬁn ition\\nof capacity of a model. The VC dimension is deﬁned next.\\nDeﬁnition 5.4. A hypothesis class His said to shatter a set of domain\\npoints X= {xn}V\\nn=1 if, no matter how the corresponding labels {tn ∈\\n{0,1}}V\\nn=1 are selected, there exists a hypothesis ˆt ∈H that ensures\\nˆt(xn) = tn for all n= 1 ,...,V .\\nDeﬁnition 5.5. The VC dimension VCdim( H) of the model His the\\nsize of the largest set Xthat is shattered by H.\\nBased on the deﬁnitions above, to prove that a model has VCdim (H) =\\nV, we need to carry out the following two steps:\\nStep 1 ) Demonstrate the existence of a set X with |X|= V that\\nis shattered by H; and\\nStep 2 ) Prove that no set X of dimension V + 1 exists that is\\nshattered by H.\\nThe second step is typically seen to be more diﬃcult, as illus trated'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 129, 'page_label': '124', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is shattered by H; and\\nStep 2 ) Prove that no set X of dimension V + 1 exists that is\\nshattered by H.\\nThe second step is typically seen to be more diﬃcult, as illus trated\\nby the following examples.\\nExample 5.3. The threshold function model (\\n5.8) has VCdim( H)= 1,\\nsince there is clearly a set Xof one sample ( V = 1) that can be shat-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 130, 'page_label': '125', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.4. VC Dimension and Fundamental Theorem of P AC Learning 125\\ntered (Step 1); but there are no sets of V = 2 that can be shattered\\n(Step 2). In fact, for any set X= ( x1 ,x2 ) of two points with x1 ≤x2 ,\\nthe label assignment ( t1 ,t2) = (1 ,0) cannot be realized by any choice\\nof the threshold θ, which is the only parameter in the model.\\nExample 5.4. The model H= {ˆta,b(x) = 1 ( a≤x≤b)}, which assigns\\nthe label t = 1 within an interval [ a,b] and the label t = 0 outside it,\\nhas VCdim( H)= 2. In fact, any set of V = 2 points can be shattered\\n– and hence there also exists one such set (Step 1); while ther e are no\\nsets Xof V = 3 points that can be shattered (Step 2). F or Step 2, note\\nthat, for any set X= ( x1 ,x2 ,x3) of three points with x1 ≤x2 ≤x3, the\\nlabel assignment ( t1 ,t2 ,t3) = (1 ,0,1) cannot be realized by any choice\\nof the two free parameters ( a,b).\\nExample 5.5. The model H= {ˆta1 ,a2 ,b1 ,b2 (x) = 1( a1 ≤x1 ≤a2 and b1 ≤'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 130, 'page_label': '125', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='label assignment ( t1 ,t2 ,t3) = (1 ,0,1) cannot be realized by any choice\\nof the two free parameters ( a,b).\\nExample 5.5. The model H= {ˆta1 ,a2 ,b1 ,b2 (x) = 1( a1 ≤x1 ≤a2 and b1 ≤\\nx2 ≤b2)}, which assigns the label t= 1 within an axis-aligned rectan-\\ngle deﬁned by parameters a1,a2 ,b1 and b2 has VCdim( H)= 4, as it can\\nbe proved by using arguments similar to the previous example s.\\nExample 5.6. The linear classiﬁer ( 5.3) has VCdim( H)= D+ 1 [ 133].\\nThe example above suggests that the VC dimension of a set ofte n\\ncoincides with the number of degrees of freedom, or free para meters, in\\nthe model. However, this is not necessarily the case.\\nExample 5.7. Model (\\n5.10), while having a single parameter, has an\\ninﬁnite VC dimension [ 133].\\nW e also note that, for ﬁnite classes, we have the inequality V Cdim(H) ≤\\nlog |H|, since |H|hypotheses can create at most |H|diﬀerent label con-\\nﬁgurations. The next theorem, whose importance is attested by its title'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 130, 'page_label': '125', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='log |H|, since |H|hypotheses can create at most |H|diﬀerent label con-\\nﬁgurations. The next theorem, whose importance is attested by its title\\nof fundamental theorem of P AC learning, provides an answer to the two\\nquestions posed at the beginning of this section.\\nTheorem 5.3. A model Hwith ﬁnite VCdim( H)= d < ∞is P AC\\nlearnable with sample complexity\\nC1\\nd+ ln(1 /δ)\\nǫ2 ≤N∗\\nH(ǫ,δ) ≤C2\\nd+ ln(1 /δ)\\nǫ2 (5.21)\\nfor some constants C1 and C2 . Moreover, the ERM learning rule achieves\\nthe upper bound.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 131, 'page_label': '126', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='126 Statistical Learning Theory ∗\\nThe theorem shows that the sample complexity is proportiona l to\\n(VCdim(H) + ln(1 /δ))/ǫ2 . This reveals that VCdim( H) can be consid-\\nered as the correct deﬁnition of capacity for a hypothesis cl ass H, irre-\\nspective of whether the class is ﬁnite or not: As VCdim( H) increases,\\nthe number of required data points for P AC learning increase s propor-\\ntionally to it. F urthermore, the theorem demonstrates that , if learning\\nis possible for a given model H, then ERM allows us to learn with\\nclose-to-optimal sample complexity .\\nF or a proof of this result and for extensions, we refer to the e xtensive\\ntreatment in [ 133]. W e mention here the important extension of the\\ntheory of generalization to convex learning problems – i.e. , to problems\\nwith convex parameter set and a convex loss function. Rather than\\ndepending on the model complexity as the theory developed so far,\\ngeneralization in this class of problems hinges on the stabi lity of the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 131, 'page_label': '126', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='depending on the model complexity as the theory developed so far,\\ngeneralization in this class of problems hinges on the stabi lity of the\\nlearning algorithms. Stability is the property that small c hanges in the\\ninput do not aﬀect much the output of the learning algorithm – a notion\\nrelated to that of diﬀerential privacy [ 119]. W e also point to the related\\nnotion of capacity of a perceptron introduced in [ 94].\\n5.5 Summary\\nThis chapter has described the classical P AC framework for t he anal-\\nysis of the generalization performance of supervised learn ing for clas-\\nsiﬁcation. W e have seen that the concept of VC dimension deﬁn es the\\ncapacity of the model, and, through it, the number of samples needed\\nto learn the model with a given accuracy and conﬁdence, or sam ple\\ncomplexity . In the next chapter, we move from supervised lea rning to\\nunsupervised learning problems.\\nAppendix: Minimax Redundancy and Model Capacity ∗'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 131, 'page_label': '126', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='complexity . In the next chapter, we move from supervised lea rning to\\nunsupervised learning problems.\\nAppendix: Minimax Redundancy and Model Capacity ∗\\nIn this appendix, we describe an alternative deﬁnition of mo del capacity\\nthat is directly related to the conventional notion of Shann on’s capacity\\nof a noisy channel [\\n38]. As for Sec. 2.5, some background in information\\ntheory may be needed to fully appreciate the content of this a ppendix.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 132, 'page_label': '127', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.5. Summary 127\\nT o elaborate, consider a probabilistic model Hdeﬁned as the set\\nof all pmfs p(x|θ) parametrized by θ in a given set. With some abuse\\nof notation, we take Hto be also the domain of parameter θ. T o ﬁx\\nthe ideas, assume that x takes values over a ﬁnite alphabet. W e know\\nfrom Sec. 2.5, that a distribution q(x) is associated with a lossless\\ncompression scheme that requires around −log q(x) bits to describe a\\nvalue x. F urthermore, if we were informed about the true parameter θ,\\nthe minimum average coding length would be the entropy H(p(x|θ)),\\nwhich requires setting q(x) = p(x|θ) (see Appendix A).\\nAssume now that we only know that the parameter θ lies in set\\nH, and hence the true distribution p(x|θ) is not known. In this case,\\nwe cannot select the true parameter distribution, and we nee d instead\\nto choose a generally diﬀerent distribution q(x) to deﬁne a compres-\\nsion scheme. With a given distribution q(x), the average coding length\\nis given by −∑'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 132, 'page_label': '127', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to choose a generally diﬀerent distribution q(x) to deﬁne a compres-\\nsion scheme. With a given distribution q(x), the average coding length\\nis given by −∑\\nx p(x|θ) log q(x). Therefore, the choice of a generally\\nincorrect distribution q(x) entails a redundancy of\\n∆ R(q(x),θ) = −\\n∑\\nx\\np(x|θ) log q(x) −H(p(x|θ)) ≥0 (5.22)\\nbits.\\nThe redundancy ∆ R(q(x),θ) in ( 5.22) depends on the true value of\\nθ. Since the latter is not known, this quantity cannot be compu ted. W e\\ncan instead obtain a computable metric by maximizing over al l values\\nof θ∈H, which yields the worst-case redundancy\\n∆ R(q(x),H) = max\\nθ∈H\\n∆ R(q(x),θ). (5.23)\\nThis quantity can be minimized over q(x) yielding the so-called mini-\\nmax redundancy:\\n∆ R(H) = min\\nq(x)\\n∆ R(q(x),H) (5.24)\\n= min\\nq(x)\\nmax\\nθ\\n−\\n∑\\nx\\np(x|θ) log q(x) −H(p(x|θ)) (5.25)\\n= min\\nq(x)\\nmax\\nθ\\n∑\\nx\\np(x|θ) log p(x|θ)\\nq(x) . (5.26)\\nThe minimax redundancy can be taken as a measure of the capaci ty\\nof model H,since a richer model tends to yield a larger ∆ R(H).In fact,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 133, 'page_label': '128', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='128 Statistical Learning Theory ∗\\nfor a richer model, it is more diﬃcult to ﬁnd a representative distribu-\\ntion q(x) that yields an average coding length close to the minimum\\nH(p(x|θ)) for all values of θ.\\nIt turns out that the minimax redundancy equals the capacity\\nC(p(x|θ)) of the channel p(x|θ), which is deﬁned as C(p(x|θ)) = max p(θ) I(x; θ)\\n[38]. This is shown by the following sequence of equalities:\\n∆ R(H) =min\\nq(x)\\nmax\\np(θ)\\n∑\\nx\\n∑\\nθ\\np(θ)p(x|θ) log p(x|θ)\\nq(x) (5.27a)\\n=max\\np(θ)\\nmin\\nq(x)\\n∑\\nx\\n∑\\nθ\\np(θ)p(x|θ) log p(x|θ)\\nq(x) (5.27b)\\n=max\\np(θ)\\n∑\\nx\\n∑\\nθ\\np(θ)p(x|θ) log p(x|θ)\\np(x) (5.27c)\\n=C(p(x|θ)), (5.27d)\\nwhere the ﬁrst equality follows since the average of a set of n umbers is\\nno larger than any of the numbers; the second is a consequence of the\\nminimax theorem since the term ∑\\nx\\n∑\\nθ p(θ)p(x|θ) log( p(x|θ)/q(x)) is\\nconvex in q(x) and concave in p(θ); and the third equality follows by\\nGibbs’ inequality (see Sec. 2.6 and ( A.5) in Appendix A). As a ﬁnal'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 133, 'page_label': '128', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x\\n∑\\nθ p(θ)p(x|θ) log( p(x|θ)/q(x)) is\\nconvex in q(x) and concave in p(θ); and the third equality follows by\\nGibbs’ inequality (see Sec. 2.6 and ( A.5) in Appendix A). As a ﬁnal\\nnote, the mutual information I(x; θ) between model parameter and\\ndata also plays a central role in obtaining bounds on the perf ormance\\nof estimation [ 91].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 134, 'page_label': '129', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part III\\nUnsupervised Learning'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 135, 'page_label': '130', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6\\nUnsupervised Learning\\nUnlike supervised learning, unsupervised learning tasks o perate over\\nunlabelled data sets. Apart from this general statement, un supervised\\nlearning is more loosely deﬁned than supervised learning, a nd it also\\nlacks a strong theoretical framework to mirror the P AC learn ing the-\\nory covered in the previous chapter. Nevertheless, it is wid ely expected\\nthat future breakthroughs in machine learning will come mai nly from\\nadvances in the theory and design of unsupervised learning a lgorithms.\\nThis is due to the availability of huge repositories of unlab elled data,\\nas well as to the broader applicability of learning tasks whe reby the\\nmachine learns, as it were, without supervision or feedback . Unsuper-\\nvised learning is also considered by some as the key to the dev elopment\\nof general, as opposed to task, speciﬁc AI [ 137] (see also [ 142, 87] for\\nmore on general AI).\\nGenerally speaking, unsupervised learning algorithms aim at learn-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 135, 'page_label': '130', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of general, as opposed to task, speciﬁc AI [ 137] (see also [ 142, 87] for\\nmore on general AI).\\nGenerally speaking, unsupervised learning algorithms aim at learn-\\ning some properties of interest of the mechanism underlying the gen-\\neration of the data. In this sense, unsupervised learning co ncerns the\\nstudy of generative models, although, as we will see, this st atement\\ncomes with some caveats. A common aspect of many models used f or\\nunsupervised learning is the presence of hidden, or latent, variables\\n130'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 136, 'page_label': '131', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.1. Unsupervised Learning 131\\nthat help explain the structure of the data.\\nThis chapter starts by discussing applications of unsuperv ised learn-\\ning, and by providing a description of the well-known K-means algo-\\nrithm. It then covers directed and undirected generative pr obabilistic\\nmodels for unsupervised learning. As we will detail, these m odels posit\\ndiﬀerent types of statistical dependence relations betwee n hidden and\\nmeasured variables. Discriminative models, which capture the depen-\\ndence of hidden variables on observed variables, as well as a utoencoders,\\nwhich combine discriminative and generative models, are al so intro-\\nduced. The chapter is concluded with a discussion of a diﬀere nt type\\nof learning algorithm that may be considered as unsupervise d, namely\\nPageRank, which is included due to its practical relevance.\\n6.1 Unsupervised Learning\\nDeﬁning unsupervised learning. A general, and rather imprecise,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 136, 'page_label': '131', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='PageRank, which is included due to its practical relevance.\\n6.1 Unsupervised Learning\\nDeﬁning unsupervised learning. A general, and rather imprecise,\\ndeﬁnition of unsupervised learning tasks is the following. T aking a fre-\\nquentist viewpoint, we are given a data set D consisting of N i.i.d.\\nunlabelled observations x n ∈RD . These are assumed to be drawn i.i.d.\\nfrom an unknown true distribution as\\nD= {xn }N\\nn=1 ∼\\ni.i.d.\\np(x). (6.1)\\nThe goal is to learn some useful properties of the distributi on p(x),\\nwhere the properties of interest depend on the speciﬁc appli cation.\\nWhile this deﬁnition is general enough to include also the es timation\\nproblems studied in Chapter 3, as mentioned, unsupervised l earning\\nproblems are typically characterized by the presence of hidden or la-\\ntent variables. Notable examples include the following.\\n•Density estimation : Density estimation aims at learning directly\\na good approximation of the distribution p(x), e.g., for use in plug-in\\nestimators ['),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 136, 'page_label': '131', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•Density estimation : Density estimation aims at learning directly\\na good approximation of the distribution p(x), e.g., for use in plug-in\\nestimators [\\n86], to design compression algorithms (see Sec. 2.5), or to\\ndetect outliers [ 139].\\n• Clustering: Clustering assumes the presence of an unobserved\\nlabel zn associated to each data point xn, and the goal is that of recov-\\nering the labels zn for all points in the data set D. F or example, one'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 137, 'page_label': '132', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='132 Unsupervised Learning\\nmay wish to cluster a set Dof text documents according to their topics,\\nby modelling the latter as an unobserved label zn. Broadly speaking,\\nthis requires to group together documents that are similar a ccording\\nto some metric. It is important at this point to emphasize the distinc-\\ntion between classiﬁcation and clustering: While the forme r assumes\\nthe availability of a labelled set of training examples and e valuates its\\n(generalization) performance on a separate set of unlabell ed examples,\\nthe latter works with a single, unlabelled, set of examples. The diﬀerent\\nnotation used for the labels – zn in lieu of tn – is meant to provide a\\nreminder of this key diﬀerence.\\n•Dimensionality reduction and representation : Given the set D, we\\nwould like to represent the data points xn ∈D in a space of lower dimen-\\nsionality . This makes it possible to highlight independent explanatory\\nfactors, and/or to ease visualization and interpretation [ 93], e.g., for'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 137, 'page_label': '132', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='sionality . This makes it possible to highlight independent explanatory\\nfactors, and/or to ease visualization and interpretation [ 93], e.g., for\\ntext analysis via vector embedding (see, e.g., [ 124]).\\n•F eature extraction: F eature extraction is the task of deriving func-\\ntions of the data points xn that provide useful lower-dimensional inputs\\nfor tasks such as supervised learning. The extracted featur es are unob-\\nserved, and hence latent, variables. As an example, the hidd en layer of\\na deep neural network extract features from the data for use b y the\\noutput layer (see Sec. 4.5).\\n•Generation of new samples : The goal here is to learn a machine\\nthat is able to produce samples that are approximately distr ibuted ac-\\ncording to the true distribution p(x). F or example, in computer graphics\\nfor ﬁlmmaking or gaming, one may want to train a software that is able\\nto produce artiﬁcial scenes based on a given description.\\nThe variety of tasks and the diﬃculty in providing formal deﬁ ni-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 137, 'page_label': '132', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for ﬁlmmaking or gaming, one may want to train a software that is able\\nto produce artiﬁcial scenes based on a given description.\\nThe variety of tasks and the diﬃculty in providing formal deﬁ ni-\\ntions, e.g., on the realism of an artiﬁcially generated imag e, make unsu-\\npervised learning, at least in its current state, a less form al ﬁeld than\\nsupervised learning. Often, loss criteria in unsupervised learning mea-\\nsure the divergence between the learned model and the empiri cal data\\ndistribution, but there are important exceptions, as we wil l see.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 138, 'page_label': '133', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.1. Unsupervised Learning 133\\nFigure 6.1: (a) Directed generative models; (b) Undirected generative models; (c)\\nDiscriminative models; (d) Autoencoders.\\nModels. W e now review the type of models that can be used to\\ntackle unsupervised learning problems. The models will be f urther dis-\\ncussed in the subsequent sections of this chapter.\\n•Directed generative models: Directed generative models are mix-\\nture models in which the distribution p(x|θ) of the data is deﬁned by a\\nparametrized prior p(z|θ) of the latent variables z and by a parametrized\\nconditional distribution p(x|z,θ) that deﬁnes the relationship between\\nlatent and observed variables. Accordingly , the distribut ion can be ex-\\npressed, for discrete latent variables z, as\\np(x|θ) =\\n∑\\nz\\np(z|θ)p(x|z,θ). (6.2)\\nA similar expression applies to continuous hidden variable s with an in-\\ntegral in lieu of the sum. Directed models are suitable to cap ture the\\ncause-eﬀect relationships between z and x. A BN describing d irected'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 138, 'page_label': '133', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tegral in lieu of the sum. Directed models are suitable to cap ture the\\ncause-eﬀect relationships between z and x. A BN describing d irected\\ngenerative models is shown in Fig. 6.1(a). Graphical models, including\\nBNs, will be covered in detail in the next chapter. Examples o f di-\\nrected generative models include the mixture of Gaussians m odel, and\\nthe so-called likelihood-free models , in which the conditional distribu-\\ntion p(x|z,θ) is implemented by a deterministic transformation, most\\ntypically a multi-layer network.\\n•Undirected generative models: Undirected models parametrize di-\\nrectly the joint distribution of the observed variables x an d the hidden\\nvariables z as p(x,z|θ), and accordingly write the distribution of the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 139, 'page_label': '134', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='134 Unsupervised Learning\\ndata as\\np(x|θ) =\\n∑\\nz\\np(x,z|θ). (6.3)\\nUnlike directed models, undirected models capture the aﬃni ty , or com-\\npatibility , of given conﬁgurations of values for z and x. An M arkov Ran-\\ndom Field (MRF) describing undirected generative models is shown in\\nFig. 6.1(b) (see next chapter). A prominent example is given by RBMs.\\n•Discriminative models : Discriminative models attempt to directly\\nlearn an encoding probabilistic mapping p(z|x,θ) between the data\\npoint x and a representation z . This is represented by the BN in Fig.\\n6.1(c).\\n•Autoencoders: As seen in Fig. 6.1(d), autoencoders compose a\\nparametrized discriminative model p(z|x,θ), which produces the hid-\\nden variables z from the data x, with a parametrized generati ve model\\np(x|z,θ). The former is known as encoder, while the latter as decoder.\\nAccordingly , the latent variables are also referred to as th e code. The\\nmost typical implementations use parameterized determini stic func-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 139, 'page_label': '134', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Accordingly , the latent variables are also referred to as th e code. The\\nmost typical implementations use parameterized determini stic func-\\ntions z= Fθ (x) and x= Gθ (z) in lieu of the more general probabilistic\\nmodels p(z|x,θ) and p(x|z,θ), respectively . As we will see, autoencoders\\nare trained to reproduce the data x at the output, turning the unsu-\\npervised problem into a supervised one with “labels” given b y the data\\npoint x itself.\\n6.2 K-Means Clustering\\nW e start by reviewing the well-known K-means clustering algorithm.\\nThe purpose here is to emphasize an algorithmic structure, n amely the\\nExpectation Maximization (EM) algorithm, that is conceptu ally at the\\ncore of many unsupervised learning algorithms.\\nThe problem is one of multi-cluster clustering: Given a data set\\nD= {xn}N\\nn=1 , we would like to assign every vector xn ∈RD to one\\nof K clusters. Cluster indices are encoded by categorical varia bles zn\\nvia one-hot encoding (see Chapter 3). Accordingly , we write the kth'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 139, 'page_label': '134', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='n=1 , we would like to assign every vector xn ∈RD to one\\nof K clusters. Cluster indices are encoded by categorical varia bles zn\\nvia one-hot encoding (see Chapter 3). Accordingly , we write the kth\\ncomponent of vector zn as zkn = 1 if xn is assigned to cluster k, while\\nwe write zkn = 0 otherwise. It is emphasized that the labels are not\\ngiven for any of the examples in D. Therefore, the algorithm should'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 140, 'page_label': '135', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.2. K-Means Clustering 135\\ndiscern some regularity in the data in order to divide the dat a set into\\nK classes.\\nK-means is a heuristic method that attempts to cluster togeth er\\npoints that are mutually close in Euclidean distance. T o thi s end, K-\\nmeans assigns all points in the same cluster a given “prototy pe” repre-\\nsentative vector µk . This vector can be thought of in terms of quantiza-\\ntion: all points within a given cluster can be quantized to th e prototype\\nµk with minimal quadratic loss. This is formalized by the follo wing op-\\ntimization problem over the cluster assignment variables zn and the\\ncluster representatives µk :\\nmin\\n{zn },{µk }\\nN∑\\nn=1\\nK∑\\nk=1\\nzkn d(xn,µk ), (6.4)\\nwhere d(x,µ) = ∥x−µ∥2 is the squared Euclidean distance. When us-\\ning a general distance metric, the approach to be described i s instead\\nknown as the K-medoids algorithm. In this regard, we note, for in-\\nstance, that it is possible to apply clustering also to discr ete data as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 140, 'page_label': '135', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='known as the K-medoids algorithm. In this regard, we note, for in-\\nstance, that it is possible to apply clustering also to discr ete data as\\nlong as the distance d is properly deﬁned – typically by a matrix of\\npairwise dissimilarities.\\nThe K-means algorithm performs alternatively optimization of t he\\ncluster assignment variables zn and of the cluster representatives µk as\\nfollows:\\n•Initialize cluster representatives {µold\\nk }.\\n•Expectation step, or E step : F or ﬁxed vectors {µold\\nk },solve problem\\n(\\n6.4) over the cluster assignment {zn }:\\nznew\\nkn =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 for k= argmin j d(xn,µold\\nj )\\n0 otherwise\\n. (6.5)\\nAccordingly , each training point is assigned to the cluster with the clos-\\nest prototype. Note that this step generally requires the co mputation\\nof K distances for each data point xn.\\n•Maximization step, or M step : F or ﬁxed vectors {zn }, solve prob-\\nlem (\\n6.4) over the cluster representatives {µk }. Imposing the optimality'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 140, 'page_label': '135', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of K distances for each data point xn.\\n•Maximization step, or M step : F or ﬁxed vectors {zn }, solve prob-\\nlem (\\n6.4) over the cluster representatives {µk }. Imposing the optimality\\ncondition that the gradient of the objective function in ( 6.4) be zero,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 141, 'page_label': '136', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='136 Unsupervised Learning\\nwe obtain\\nµnew\\nk =\\n∑ N\\nn=1 znew\\nkn xn\\n∑ N\\nn=1 znew\\nkn\\n. (6.6)\\nThe new cluster representative µnew\\nk for each cluster k is the mean of\\nthe data points assigned to cluster k.\\n•If a convergence criterion is not satisﬁed, set { µold\\nk }←{ µnew\\nk }\\nand return to the E step.\\nSince both E step and M step minimize the objective function i n\\n(\\n6.4), respectively over the cluster assignment variables zn and the\\ncluster representatives µk , the value of the objective function is non-\\ndecreasing across the iterations. This ensures convergenc e. Illustrations\\nof convergence and examples can be found in [ 23, Chapter 9]. As a note,\\nthe algorithm is also known as Lloyd-Max quantization [ 54].\\nAt a high level, K-means alternates between: ( i ) making inferences\\nabout the hidden variables { zn} based on the current model deﬁned\\nby the representatives { µk } in the E step; and ( ii ) updating the model\\n{µk } to match the data { xn } and the inferred variables { zn } in the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 141, 'page_label': '136', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='by the representatives { µk } in the E step; and ( ii ) updating the model\\n{µk } to match the data { xn } and the inferred variables { zn } in the\\nM step. W e will see that a similar algorithmic structure is ap plied by\\nmany unsupervised learning algorithms.\\nBefore we move on to discussing more general solutions, it is worth\\nspending a few words on the problem of selecting the number K of\\nclusters. A ﬁrst possibility is to add or remove clusters unt il certain\\nheuristic criteria are satisﬁed, such as the “purity” of clu sters. A second\\napproach is hierarchical clustering, whereby one builds a t ree, known\\nas dendrogram, that includes clustering solutions with an i ncreasing\\nnumber of clusters as one moves away from the root (see, e.g., [51]).\\nY et another solution is to let K be selected automatically by adopting\\na non-parametric Bayesian approach via a Dirichlet process prior [ 104].\\n6.3 ML, ELBO and EM\\nIn this section, we discuss two key technical tools that are e xtensively'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 141, 'page_label': '136', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a non-parametric Bayesian approach via a Dirichlet process prior [ 104].\\n6.3 ML, ELBO and EM\\nIn this section, we discuss two key technical tools that are e xtensively\\nused in tackling unsupervised learning problems, namely th e Evidence\\nLower BOund (ELBO) and the EM algorithm. The starting point i s the\\nfundamental problem of learning a probabilistic, directed or undirected,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 142, 'page_label': '137', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 137\\nmodel p(x|θ) from the data using ML. W e will discuss later how to learn\\ndiscriminative models and autoencoders.\\n6.3.1 ML Learning\\nF rom Sec.\\n2.6, we know that ML, asymptotically in N, tends to min-\\nimize a KL divergence between the true distribution p(x) and the se-\\nlected hypothesis in the model. This is a criterion that is we ll suited\\nfor many of the unsupervised learning tasks mentioned above , such as\\ndensity estimation or generation of new samples, and it is he nce useful\\nto start the discussion with ML learning.\\nBefore we do that, a few remarks are in order. First, it is ofte n useful\\nto choose divergences other than KL, which are tailored to th e speciﬁc\\napplication of interest [ 8]. W e will further discuss this aspect in Sec.\\n6.4.3. Second, when the goal is representation learning, the mach ine\\naims at obtaining useful features z. Hence, minimizing the KL diver-\\ngence to match the true distribution p(x) does not directly address the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 142, 'page_label': '137', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='aims at obtaining useful features z. Hence, minimizing the KL diver-\\ngence to match the true distribution p(x) does not directly address the\\nobjective of representation learning, unless appropriate restrictions are\\nimposed on the model p(x|z,θ).In fact, if the generative model p(x|z,θ)\\nis too powerful, then it can disregard the features z and stil l obtain a\\nhigh likelihood for the data (see, e.g., [ 69]). W e will get back to this\\npoint in Sec. 6.6. Finally , obtaining ML solutions is often impractical,\\nparticularly in large models. Nevertheless, understandin g the ML prob-\\nlem allows one to better gauge the impact of the approximatio ns and\\nsimpliﬁcations made to obtain eﬃcient algorithms.\\nT o proceed, we consider probabilistic, directed or undirec ted, model,\\nand focus, for the purpose of simplifying the notation, on a d ata set\\nwith a single data point ( N = 1). The extension to a data set with an\\narbitrary number N of points only requires adding an outer sum over'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 142, 'page_label': '137', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='with a single data point ( N = 1). The extension to a data set with an\\narbitrary number N of points only requires adding an outer sum over\\nthe sample index to the LL function. W e also concentrate on di screte\\nhidden rvs, and the generalization to continuous rvs is obta ined by sub-\\nstituting sums with suitable integrals. The ML problem can b e written\\nas the maximization of the LL function as\\nmax\\nθ\\nln p(x|θ) = ln\\n( ∑\\nz\\np(x,z|θ)\\n)\\n, (6.7)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 143, 'page_label': '138', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='138 Unsupervised Learning\\nwhere x denotes the data and z the hidden or latent variables. Note\\nthe marginalization with respect to the hidden variables in (6.7). This\\nproblem should be contrasted with the supervised learning M L problem\\nobtained when both x and z are observed, namely\\nmax\\nθ\\nln p(x,z|θ). (6.8)\\nExample 6.1. Consider a directed generative Bernoulli-Gaussian model\\ncharacterized as\\nz ∼Bern(0.5) (6.9a)\\nx|z = 0 ∼N(2,1) (6.9b)\\nx|z = 1 ∼N(θ,1). (6.9c)\\nThis corresponds to a mixture of Gaussians model, in which th e only\\nparameter θ is the mean of one of the two Gaussian components. As-\\nsume that we observe x = 0. Consider ﬁrst the supervised learning\\ncase, where we assume that we also measure z = 1. In this case, the\\nLL function in ( 6.8) is ln p(x = 0 ,z = 1 |θ) = ln N(x|θ,1) + ln(0 .5).\\nIn contrast, with unsupervised learning, the LL function in (6.7) is\\nln p(x= 0 |θ) = ln(0 .5N(0|2,1) + 0 .5N(0|θ,1)).\\nThe LL functions are shown in Fig. 6.2. Unlike supervised learning,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 143, 'page_label': '138', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='In contrast, with unsupervised learning, the LL function in (6.7) is\\nln p(x= 0 |θ) = ln(0 .5N(0|2,1) + 0 .5N(0|θ,1)).\\nThe LL functions are shown in Fig. 6.2. Unlike supervised learning,\\nthe LL for unsupervised learning is seen to be non-concave. In this\\nexample, this is a consequence of the fact that, when θ is suﬃciently\\nlarge in absolute value, the probability of the data xresulting from the\\nﬁxed Gaussian distribution centered at x = 2 makes the contribution\\nof the Gaussian centered θ increasingly irrelevant.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 144, 'page_label': '139', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 139\\n-4 -3 -2 -1 0 1 2 3 4\\n-5\\n-4.5\\n-4\\n-3.5\\n-3\\n-2.5\\n-2\\n-1.5\\n-1\\n-0.5Log-likelihood\\nsupervised\\nunsupervised\\nFigure 6.2: Illustration of LL functions for supervised and unsupervis ed learning\\nin a mixture of Gaussians model (Example 6.1).\\nSolving problem ( 6.7) has two additional complications as compared\\nto the supervised learning counterpart ( 6.8). The ﬁrst issue was high-\\nlighted in the previous example: Even for models in which the ML\\nsupervised learning problem is convex, the LL is generally n on-concave\\nwhen the variables z are hidden, which precludes the use of co nvex\\noptimization algorithms. Barring the use of often impracti cal global\\noptimization algorithms, in general, non-convex problems cannot be\\nsolved exactly . Rather, the best one can hope for with standa rd local\\noptimization schemes, such as SGD, is obtaining stationary points or\\nlocally optimal points [ 28]. In practice, this problem may not be critical'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 144, 'page_label': '139', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='optimization schemes, such as SGD, is obtaining stationary points or\\nlocally optimal points [ 28]. In practice, this problem may not be critical\\nsince non-convexity is not by itself a cause of poor learning performance.\\nF or instance, as seen in Chapter 4, beyond-GLM supervised le arning\\nmethods, including deep neural networks, solve non-convex problems.\\nThe second complication is the need to sum – or integrate – ove r the\\nhidden variables in order to evaluate the LL. This step is com plicated\\nby the fact that the distribution of the hidden variables nee ds to be\\nlearned and is hence unknown. This is a signiﬁcant obstacle t o the\\ndevelopment of eﬃcient learning algorithms, and it general ly needs to\\nbe addressed in order to make learning feasible. In the rest o f this\\nsection, we describe two technical tools that are useful to t ackle these'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 145, 'page_label': '140', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='140 Unsupervised Learning\\nproblems. Chapter 8 will develop more complex solutions for issues\\narising in the presence of large latent spaces in which margi nalization\\nis not viable.\\n6.3.2 ELBO\\nMany methods to tackle the ML problem (\\n6.7) are based on the maxi-\\nmization of the ELBO. These techniques include the EM algori thm and\\nsome of the variational inference algorithms to be discusse d in Chapter\\n8. The key element in the development of the ELBO is the introd uction\\nof an auxiliary distribution q(z) on the latent variables. This is referred\\nto as the variational distribution or the variational posterior for rea-\\nsons that will be made clear later. As we will see, computatio n of the\\nELBO requires an average over distribution q(z), which can be ﬁxed\\nindependently of the model parameters. This solves the key p roblem\\nidentiﬁed above of averaging over the parameter-dependent marginal\\nof the hidden variables.\\nDeﬁnition 6.1. F or any ﬁxed value x and any distribution q(z) on'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 145, 'page_label': '140', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='identiﬁed above of averaging over the parameter-dependent marginal\\nof the hidden variables.\\nDeﬁnition 6.1. F or any ﬁxed value x and any distribution q(z) on\\nthe latent variables z (possibly dependent on x), the ELBO L(q,θ) is\\ndeﬁned in one of the following equivalent forms\\nL(q,θ) =E z∼q(z)[ln p(x,z|θ) −ln q(z)\\ued19\\n\\ued18\\ued17 \\ued1a\\nlearning signal\\n] (6.10)\\n= E z∼q(z)[ln p(x,z|θ)]\\n\\ued19 \\ued18\\ued17 \\ued1a\\nnegative energy\\n+ H(q)\\ued19 \\ued18\\ued17 \\ued1a\\nentropy\\n(6.11)\\n= E z∼q(z)[ln p(x|z,θ)]\\n\\ued19 \\ued18\\ued17 \\ued1a\\ncross-entropy\\n− KL ( q(z)||p(z|θ))\\ued19 \\ued18\\ued17 \\ued1a\\nvariational regularization\\n(6.12)\\n= −KL ( q(z)||p(x,z|θ)) (6.13)\\n= ln p(x|θ) −KL ( q(z)||p(z|x,θ)) , (6.14)\\nwhere we have identiﬁed some terms using common terminology that\\nwill be clariﬁed in the following, and, in ( 6.13), we have used the con-\\nvention of deﬁning KL( p||q) even when q is not normalized (see Sec.\\n2.6).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 146, 'page_label': '141', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 141\\nThe equivalence between the three forms of the ELBO can be eas -\\nily checked. The form ( 6.11) justiﬁes the deﬁnition of the negative of\\nthe ELBO as variational free energy or Gibbs free energy , which is the\\ndiﬀerence of energy and entropy . This form is particularly u seful for\\nundirected models in which one speciﬁes directly the joint d istribution\\np(x,z|θ), such as energy-based models, while the form ( 6.12) is espe-\\ncially well suited for directed models that account for the d iscriminative\\ndistribution p(x|z,θ), such as for deep neural networks [ 27]. F or both\\nforms the ﬁrst term can be interpreted as a cross-entropy los s. The\\nform ( 6.13) is more compact, and suggests that, as we will formalize\\nbelow, the ELBO is maximized when q(z) is selected to match the\\nmodel distribution. The last form yields terms that are gene rally not\\neasily computable, but it illuminates the relationship bet ween the LL\\nfunction and the ELBO, as we discuss next.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 146, 'page_label': '141', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='model distribution. The last form yields terms that are gene rally not\\neasily computable, but it illuminates the relationship bet ween the LL\\nfunction and the ELBO, as we discuss next.\\nThe following theorem describes the deﬁning property of the ELBO\\nas well as another important property . T aken together, thes e features\\nmake the ELBO uniquely suited for the development of algorit hmic\\nsolutions for problem ( 6.7).\\nTheorem 6.1. The ELBO is a global lower bound on the LL function,\\nthat is,\\nln p(x|θ) ≥L(q,θ), (6.15)\\nwhere equality holds at a value θ0 if and only if the distribution q(z)\\nsatisﬁes q(z) = p(z|x,θ0 ). F urthermore, the ELBO is concave in q(z)\\nfor a ﬁxed θ; and, if ln p(x,z|θ) is concave in θ, it is also concave in θ\\nfor a ﬁxed q(z).\\nProof. The ﬁrst part of the theorem follows immediately from the for m\\n(6.14), which we can rewrite as\\nln p(x|θ) = L(q,θ)+KL ( q(z)||p(z|x,θ)) , (6.16)\\nand from Gibbs’ inequality . In fact, the latter implies that the KL di-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 146, 'page_label': '141', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='(6.14), which we can rewrite as\\nln p(x|θ) = L(q,θ)+KL ( q(z)||p(z|x,θ)) , (6.16)\\nand from Gibbs’ inequality . In fact, the latter implies that the KL di-\\nvergence KL ( q(z)||p(z|x,θ)) is non-negative and equal to zero if and\\nonly if the two distributions in the argument are equal. The c oncavity\\nof the ELBO can be easily checked using standard properties o f con-\\nvex functions [ 28]. As a note, an alternative proof of the ﬁrst part of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 147, 'page_label': '142', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='142 Unsupervised Learning\\nthe theorem can be provided via the importance sampling tric k and\\nJensen’s inequality . In fact, we can write\\nln p(x|θ) = ln\\n( ∑\\nz\\np(x,z|θ)\\n)\\n(6.17a)\\n= ln\\n( ∑\\nz\\nq(z) p(x,z|θ)\\nq(z)\\n)\\n(6.17b)\\n≥\\n∑\\nz\\nq(z) ln\\n( p(x,z|θ)\\nq(z)\\n)\\n= L(q,θ), (6.17c)\\nwhere the ﬁrst equality is just obtained by multiplying and d ividing\\nby q(z) – the importance sampling trick – and the last step is a conse -\\nquence of Jensen’s inequality . W e recall that Jensen’s ineq uality says\\nthat for any concave function f(x) – here f(x) = ln( x) – we have the\\ninequality E[ f(x)] ≤f(E[x]).\\nW e illustrate the just described properties of the ELBO via t he\\nfollowing example.\\nExample 6.2. Consider again the directed generative Bernoulli-Gaussia n\\nmodel (\\n6.9). The posterior distribution of the latent variable given a n\\nobservation x is given as\\np(z= 1 |x= 0 ,θ) = N(0|θ,1)\\nN(0|2,1) + N(0|θ,1) . (6.18)\\nFix a parametrized variational distribution q(z|ϕ) = Bern( z|ϕ). Using'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 147, 'page_label': '142', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='observation x is given as\\np(z= 1 |x= 0 ,θ) = N(0|θ,1)\\nN(0|2,1) + N(0|θ,1) . (6.18)\\nFix a parametrized variational distribution q(z|ϕ) = Bern( z|ϕ). Using\\n(6.11), the ELBO is then given as\\nL(q,θ) = ϕ(ln(N(0|θ,1)+ln(0.5))+(1−ϕ)(ln(N(0|2,1)+ln(0.5))+H(q).\\n(6.19)\\nThe theorem above says that, given any value of ϕ, the ELBO is a lower\\nbound on the LL function, uniformly for all values of θ. F urthermore,\\nthis bound is tight. i.e., it equals the LL function, at all va lues θ0 for\\nwhich the selected variational distribution q(z|ϕ) equals the posterior of\\nthe hidden variables, that is, for which we have ϕ= p(z= 1 |x= 0 ,θ0 ).\\nThis is shown in Fig. 6.3, where we plot the LL and the ELBO. W e see\\nthat indeed the ELBO is a uniform lower bound on the LL, which i s'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 148, 'page_label': '143', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 143\\ntight for speciﬁc values θ0 of the parameter θ. Reﬂecting the concavity\\nproperty of the ELBO in the theorem, the ELBO is also seen to be a\\nconcave function of the parameter θ.\\n-4 -3 -2 -1 0 1 2 3 4\\n-5\\n-4.5\\n-4\\n-3.5\\n-3\\n-2.5\\n-2\\n-1.5Log-likelihood\\nNLL\\nELBO ( 0=  3)\\nELBO ( 0 =  2)\\nFigure 6.3: Illustration of the ELBO for two diﬀerent choices of the vari ational\\ndistribution that are tight at diﬀerent values θ0 of the parameter.\\nThe lower bound property of the ELBO makes it useful not only\\nfor the purpose of ML optimization but also as an estimate of L L, and\\nhence of how well the model ﬁts the data, for the goal of model s election.\\nF urthermore, the ELBO can be computed analytically in speci al cases\\nfor exponential models [ 151, 159].\\nThe ELBO can be generalized as the multi-sample ELBO [32]:\\nln p(x|θ) ≥Ez1 ,...,zK ∼\\ni.i.d.\\nq(z)\\n[\\nln\\n(\\n1\\nK\\nK∑\\nk=1\\np(x,zk |θ)\\nq(zk )\\n)]\\n. (6.20)\\nThe proof of this inequality follows in the same way as for the ELBO.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 148, 'page_label': '143', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ln p(x|θ) ≥Ez1 ,...,zK ∼\\ni.i.d.\\nq(z)\\n[\\nln\\n(\\n1\\nK\\nK∑\\nk=1\\np(x,zk |θ)\\nq(zk )\\n)]\\n. (6.20)\\nThe proof of this inequality follows in the same way as for the ELBO.\\nThis bound has the advantage that, as K grows large, it tends to be-\\ncome increasingly accurate. In fact, as K →∞, by the law of large\\nnumbers, we have the limit K−1 ∑ K\\nk=1 p(x,zk |θ)/q(zk ) →∑\\nz p(x,z|θ)\\nwith probability one.\\nELBO and Bayesian inference. In summary , for a given vari-\\national distribution q(z), the ELBO provides an upper bound on the\\nLL function, or equivalently a lower bound on the NLL functio n. This'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 149, 'page_label': '144', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='144 Unsupervised Learning\\nbound is tight for values of the parameter vectors θ at which we have\\nthe equality q(z) = p(z|x,θ). As such, given a certain value θ of the\\nparameter vector, the variational distribution q(z) that provides the\\ntightest bound is the posterior distribution q(z) = p(z|x,θ), at which\\nthe KL divergence in ( 6.16) vanishes. That is, in order to obtain the\\ntightest ELBO, one needs to solve the Bayesian inference pro blem of\\ncomputing the posterior p(z|x,θ) of the hidden variables for the given\\nvalue θ. This property can be stated for reference as follows\\nargmax\\nq(z)\\nL(q,θ) = p(z|x,θ). (6.21)\\nGradients of the LL and of the ELBO over the model\\nparameters.∗ Under suitable diﬀerentiability assumptions, the gradi-\\nent of the ELBO at the value θ0 in which the ELBO is tight coincides\\nwith the gradient of the LL, i.e.,\\n∇θ ln p(x|θ)|θ=θ0 = ∇θ L(p(z|x,θ0 ),θ) |θ=θ0\\n= E z∼p(z|x,θ0) [∇θ ln p(x,z|θ)|θ=θ0 ] . (6.22)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 149, 'page_label': '144', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ent of the ELBO at the value θ0 in which the ELBO is tight coincides\\nwith the gradient of the LL, i.e.,\\n∇θ ln p(x|θ)|θ=θ0 = ∇θ L(p(z|x,θ0 ),θ) |θ=θ0\\n= E z∼p(z|x,θ0) [∇θ ln p(x,z|θ)|θ=θ0 ] . (6.22)\\nThis is also suggested by the curves in Fig. 6.3. W e will see with an\\nexample in Sec. 6.5.1 that this formula is extremely useful when the\\ngradient for the complete log-likelihood ∇θ ln p(x,z|θ)|θ=θ0 can be easily\\ncomputed, such as for exponential family models.\\nOther global lower bounds on the likelihood. ∗ Revisiting the\\nproof of Theorem 6.1, it can be concluded that the following general\\nfamily of lower bounds\\nf(p(x|θ)) ≥Ez∼q(z)\\n[\\nf\\n( p(x,z|θ)\\nq(z)\\n)]\\n, (6.23)\\nfor any concave function f. While the ELBO equals the negative of a KL\\ndivergence between variational distribution and the true d istribution,\\nas seen in ( 6.13), this representation yields more general divergence\\nmeasures, such as the α-divergence to be discussed in Chapter 8 [ 90,\\n13, 159].\\n6.3.3 EM Algorithm'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 149, 'page_label': '144', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as seen in ( 6.13), this representation yields more general divergence\\nmeasures, such as the α-divergence to be discussed in Chapter 8 [ 90,\\n13, 159].\\n6.3.3 EM Algorithm\\nAs mentioned, a large number of practical schemes for unsupe rvised\\nlearning using directed and undirected generative models a re based on'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 150, 'page_label': '145', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 145\\n•Initialize parameter vector θold.\\n•E step: F or ﬁxed parameter vector θold, maximize the ELBO over\\nthe variational distribution q, i.e., solve problem maxq L(q,θold), which,\\nby ( 6.21), yields the new distribution\\nqnew(z) = p(z|x,θold). (6.24)\\n•M step: F or ﬁxed variational distribution qnew(z), maximize the\\nELBO over the parameter vector θ, i.e., solve problem max\\nθ\\nL(qnew,θ).\\nThis convex problem can be equivalently written as the maxim ization\\nof the negative energy\\nmax\\nθ\\nQ(θ,θold) =E z∼p(z|x,θold) [ln p(x,z|θ)] . (6.25)\\n•If a convergence criterion is not satisﬁed, set θnew ←θoldand return\\nto the E step.\\nT able 6.1: EM algorithm.\\nthe maximization of ELBO L(q,θ) in lieu of the LL function. As seen,\\nthis maximization has the key advantage that the ELBO is a con cave\\nfunction of the parameters θ. F urthermore, the lower bound property\\n(6.15) ensures that, if the ELBO is tight at a value θ0, the result of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 150, 'page_label': '145', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function of the parameters θ. F urthermore, the lower bound property\\n(6.15) ensures that, if the ELBO is tight at a value θ0, the result of\\nthe optimization of the ELBO must necessarily yield a LL valu e that\\nis no smaller than ln p(x|θ0 ). This observation is leveraged by the EM\\nalgorithm to obtain a procedure that is guaranteed to conver ge to a\\nstationary point of the original ML problem ( 6.7).\\nThe EM algorithm is described in T able 6.1.\\nIn many problems of interest, the model p(x,z|θ) can be taken to be\\neither the product of a prior and a likelihood from the expone ntial fam-\\nily for directed models, or directly a member of the exponent ial family\\nfor undirected models. In these cases, the problem (\\n6.25) solved in the\\nM step will be seen below via an example to reduce to the corres pond-\\ning supervised learning problem, with the caveat that the su ﬃcient\\nstatistics are averaged over the posterior distribution p(z|x,θold).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 150, 'page_label': '145', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ing supervised learning problem, with the caveat that the su ﬃcient\\nstatistics are averaged over the posterior distribution p(z|x,θold).\\nThe EM algorithm is an instance of the more general Majorizat ion'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 151, 'page_label': '146', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='146 Unsupervised Learning\\nMinimization (MM) algorithm [ 141]. In this class of algorithms, at each\\niteration, one constructs a tight lower bound of the objecti ve function\\nat the current iterate θold. This bound, which should be easy to max-\\nimize, is then optimized, yielding the new iterate θnew. The process is\\nillustrated in Fig. 6.4. As it can be seen, at each iteration one is guar-\\nanteed that the objective function is not decreased, which e nsures con-\\nvergence to a local optimum of the original problem. In EM, th e tight\\nlower bound is the ELBO L(qnew,θ), which is obtained by computing\\nthe posterior distribution of the latent variables qnew(z) = p(z|x,θold )\\nat the current iterate θold.\\n...\\nLL\\nnewold\\nFigure 6.4: Illustration of the EM algorithm. The dashed line is the LL fu nction.\\nThe solid lines represent the ELBOs corresponding to the ﬁrs t two steps of the\\nalgorithm, while the dashed-dotted line is the ELBO after a n umber of iterations.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 151, 'page_label': '146', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The solid lines represent the ELBOs corresponding to the ﬁrs t two steps of the\\nalgorithm, while the dashed-dotted line is the ELBO after a n umber of iterations.\\nAt each step, EM maximizes the ELBO, which is a lower bound on t he LL function.\\nEM is an instance of the more general MM approach [ 141].\\nGeneralizing the K-means algorithm, the EM algorithm alternates\\nbetween: ( i ) making inferences about the hidden variables z based on\\nthe model deﬁned by the current iterate of the model paramete r θ\\nin the E step; and ( ii ) updating the model θ to match the data x\\nand the inferred variables z in the M step. It is useful to emph asize'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 152, 'page_label': '147', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 147\\nthat unsupervised learning, even in the assumed frequentis t approach,\\nentails the Bayesian inference problem of evaluating the po sterior of\\nthe hidden variables.\\nGeneralization to N observ ations. W e conclude this section by\\nmaking explicit the generalization of the EM algorithm to th e case in\\nwhich we have N i.i.d. observations. T o elaborate, assume that we have\\npairs of observed/ unobserved i.i.d. variables (x n ,zn), whose assumed\\njoint distribution can be written as p(xN ,zN |θ) = ∏ N\\nn=1 p(xn,zn |θ).\\nE step : The E step requires the computation of the posterior p(zN |xN ,θ).\\nThis can be seen to factorize across the examples, since we ha ve\\np(zN |xN ,θ) = p(xN ,zN |θ)\\np(xN |θ) =\\nn∏\\nn=1\\np(xn,zn |θ)\\np(xn|θ)\\n=\\nn∏\\nn=1\\np(zn |xn,θ). (6.26)\\nTherefore, in order to compute the posterior, we can operate separately\\nfor each example in the data set by evaluating p(zn|xn ,θ) for all n =\\n1,...,N .\\nM step : In a similar manner, the negative energy function Q(θ,θold)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 152, 'page_label': '147', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for each example in the data set by evaluating p(zn|xn ,θ) for all n =\\n1,...,N .\\nM step : In a similar manner, the negative energy function Q(θ,θold)\\nto be used in the M step can be computed separately for each example\\nas\\nQ(θ,θold) = E zN ∼p(zN |xN ,θold)\\n[\\nln p(xN ,zN |θ)\\n]\\n=\\nN∑\\nn=1\\nEzn ∼p(zn |xn ,θold) [ln p(xn,zn |θ)] , (6.27)\\nand hence separately for each example. Note that the optimiz ation in\\nthe M step should instead be done jointly on ( 6.27).\\nExtensions.∗ The EM algorithm solves the non-convexity prob-\\nlem identiﬁed at the beginning of this section by optimizing ELBOs\\niteratively according to the outlined MM mechanism. Nevert heless, im-\\nplementing the EM algorithm may be too computationally dema nding\\nin practice. In fact, the E step requires to compute the poste rior dis-\\ntribution of the latent variables, which may be intractable when the\\nlatent space is large; and the M step entails an average over t he poste-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 152, 'page_label': '147', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tribution of the latent variables, which may be intractable when the\\nlatent space is large; and the M step entails an average over t he poste-\\nrior distribution, which can also be intractable. In Chapte r 8, we will'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 153, 'page_label': '148', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='148 Unsupervised Learning\\nsee approaches to overcome these problems via approximate i nference\\nand learning techniques. F or extensions of EM algorithm, we refer to\\n[15, pp. 247-248]. In this regard, it is observed here that the EM al-\\ngorithm applies also to scenarios in which diﬀerent data poi nts have\\ngenerally diﬀerent subsets of unobserved variables.\\n6.4 Directed Generative Models\\nIn this section, we discuss directed generative models, in w hich, as seen\\nin Fig.\\n6.1(a), one posits a parametrized prior p(z|θ) of the latent vari-\\nables z and a parametrized conditional decoding distributi on p(x|z,θ).\\nAs discussed, the goal can be that of learning the distributi on p(x) of\\nthe true data or to extract useful features z. In the latter ca se, the use\\nof directed generative model is referred to as performing analysis by\\nsynthesis. W e ﬁrst discuss two prototypical applications of EM to per-\\nform ML learning. W e then outline an alternative approach, k nown as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 153, 'page_label': '148', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='synthesis. W e ﬁrst discuss two prototypical applications of EM to per-\\nform ML learning. W e then outline an alternative approach, k nown as\\nGAN, which can be thought of as a generalization of ML. Accord ingly ,\\nrather than selecting a priori the KL divergence as a perform ance met-\\nric, as done implicitly by ML, GANs learn at the same time dive rgence\\nand generative model.\\nMulti-layer extensions of generative directed models disc ussed here\\nfall in the category of Helmholtz machines. W e refer to, e.g. , [ 42], for a\\ndiscussion about the task of training these networks via an a pproxima-\\ntion of the EM algorithm, which uses tools covered in Chapter 8.\\n6.4.1 Mixture of Gaussians Model\\nThe mixture of Gaussians model can be described by the follow ing\\ndirected generative model\\nzn ∼Cat(π) (6.28a)\\nxn|zn = k∼N(µk ,Σ k ), (6.28b)\\nwith parameter vector θ = [ π,µ0 ,...,µK −1,Σ 0,...,Σ K −1 ]. W e use one-\\nhot encoding for the categorical variables zn = [ z0n ,...,z(K −1)n ]T .Note'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 153, 'page_label': '148', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='xn|zn = k∼N(µk ,Σ k ), (6.28b)\\nwith parameter vector θ = [ π,µ0 ,...,µK −1,Σ 0,...,Σ K −1 ]. W e use one-\\nhot encoding for the categorical variables zn = [ z0n ,...,z(K −1)n ]T .Note\\nthat this model can be thought as an unsupervised version of t he QDA\\nmodel for the fully observed, or supervised, case studied in Sec. 4.6'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 154, 'page_label': '149', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.4. Directed Generative Models 149\\n(cf. ( 4.44)). W e will see below that the EM algorithm leverages this\\nobservation in the M step. F urthermore, it will be observed t hat EM\\nfor mixture of Gaussians generalizes the K-means algorithm.\\nE step . In the E step, as per ( 6.26), we need to solve the inference\\nproblem of computing the posterior p(zkn |xn,θold) for every example n\\nand cluster index k= 0 ,...,K −1. In this case, this can be done directly\\nvia Bayes’ theorem since the normalization requires to sum o nly over\\nthe K possible values taken by z n, yielding\\np(zkn = 1 |xn ,θold) = πold\\nk N(xn |µold\\nk ,Σ old\\nk )\\n∑ K −1\\nj=0 πold\\nj N(xn|µold\\nj ,Σ old\\nj )\\n. (6.29)\\nM step . In the M step, we need to maximize the negative energy\\nfunction Q(θ,θold) in (\\n6.27). Each term in the sum can be computed\\ndirectly as\\nEzn ∼p(zn |xn ,θold) [ln p(xn,zn |θ)] =\\nK −1∑\\nk=0\\n¯zkn {ln πk + ln N(xn|µk ,Σ k )}\\n(6.30)\\nwith\\n¯zkn = Ezn ∼p(zn |xn ,θold) [zkn ] = p(zkn = 1 |xn,θold). (6.31)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 154, 'page_label': '149', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='directly as\\nEzn ∼p(zn |xn ,θold) [ln p(xn,zn |θ)] =\\nK −1∑\\nk=0\\n¯zkn {ln πk + ln N(xn|µk ,Σ k )}\\n(6.30)\\nwith\\n¯zkn = Ezn ∼p(zn |xn ,θold) [zkn ] = p(zkn = 1 |xn,θold). (6.31)\\nAs it can be easily checked, the function Q(θ,θold) equals the LL func-\\ntion of the QDA supervised problem, in which the variables zn are\\nobserved, with the following caveat: the suﬃcient statisti cs zkn are\\nreplaced by their posterior averages ¯zkn . As a result, as opposed to su-\\npervised learning, EM describes each example xn as being part of all\\nclusters, with the “responsibility” of cluster k being given by ¯zkn . Hav-\\ning made this observation, we can now easily optimize the Q(θ,θold)\\nfunction by using the ML solutions ( 4.45) for QDA by substituting ¯zkn\\nfor the observed variable tkn .\\nSetting Σ k = ǫI as a known parameter and letting ǫ →0 recovers\\nthe K-means algorithm [ 23, p. 443].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 155, 'page_label': '150', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='150 Unsupervised Learning\\n-5 0 5\\n0\\n0.05\\n0.1\\n0.15\\n0.2\\n0.25\\n0.3\\n0.35\\nFigure 6.5: T rue distribution (dashed line) and mixture of Gaussians mo del learned\\nvia EM (solid line).\\nExample 6.3. Consider data generated from the multi-modal distribu-\\ntion shown in Fig. 6.5 as a dashed line, which obtained as a mixture\\nof two Gaussians and an exponential distribution. When M = 1 , the\\nmixture of Gaussians distribution learned via EM correspon ds to the\\nconventional ML estimate, and is hence obtained via moment m atching\\n(see Chapter 3). This is plotted in the ﬁgure for a given data r ealiza-\\ntion with N = 100 . Running EM with the larger values M = 2 and\\nM = 3 also returns the same distribution. This distribution is se en to\\nbe inclusive of the entire support of the true distribution a nd to smooth\\nout the edges of the original distribution. As we will furthe r discuss in\\nSec. 6.4.3, this is a consequence of the fact that ML minimizes the KL\\ndivergence over the second argument.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 155, 'page_label': '150', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='out the edges of the original distribution. As we will furthe r discuss in\\nSec. 6.4.3, this is a consequence of the fact that ML minimizes the KL\\ndivergence over the second argument.\\nA similar model that applies to binary data, rather than cont inu-\\nous data, such as black-and-white images, is the mixture of B ernoullis\\nmodel. The EM algorithm can be derived by following the same s teps\\ndetailed here [ 23].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 156, 'page_label': '151', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.4. Directed Generative Models 151\\n6.4.2 Probabilistic Principal Component Analysis\\nProbabilistic Principal Component Analysis (PPCA) is a pop ular gen-\\nerative model that describes the data in terms of M <D features that\\nare linearly related to the data vector. Speciﬁcally , PPCA u ses a linear\\nfactor generative model with M <D features described as\\nzn ∼N(0,I) (6.32a)\\nxn|zn = z∼N(Wz + µ,σ2I), (6.32b)\\nwith parameter vector θ= ( W µ σ). Equivalently , according to PPCA,\\nthe data vector can be written as\\nxn = Wzn + µ+ q n, (6.33)\\nwith the latent variables zn ∼ N(0,I) and the additive noise qn ∼\\nN(0,σ2 I). According to (\\n6.33), the columns {wk }of the matrix W =\\n[w1 w2 ···wM ] can be interpreted as linear features of the data. This is\\nin the sense that each data point is written as a linear combin ation of\\nthe feature vectors as\\nxn =\\nM∑\\nm=1\\nwmzmn + µ+ q n, (6.34)\\nwhere zmn is the mth component of the latent vector zn .\\nIn the models studied above, the latent variable was a catego rical'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 156, 'page_label': '151', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the feature vectors as\\nxn =\\nM∑\\nm=1\\nwmzmn + µ+ q n, (6.34)\\nwhere zmn is the mth component of the latent vector zn .\\nIn the models studied above, the latent variable was a catego rical\\nidentiﬁer of the class of the observation. As such, In PPCA, i nstead,\\nthe representation of an observation xn in the hidden variable space\\nis distributed across all the variables in vector zn. This yields a more\\neﬃcient encoding of the hidden representation. This is part icularly clear\\nin the case discrete hidden rv, which will be further discuss ed in Sec.\\n6.5.1 (see also [ 20]).\\nAn EM algorithm can be devised to learn the parameter vector a s\\ndescribed in [ 23, p. 577]. The E step leverages the known result that\\nthe posterior of the latent variables can be written as\\nzn|xn = xn,θ ∼N(zn |J−1 WT (xn −µ),J−1 ), (6.35)\\nwith matrix J = σ−2WT W + I.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 157, 'page_label': '152', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='152 Unsupervised Learning\\nW e note that, if we model the latent variables zkn , k = 1 ,...,M ,\\nare independent but not Gaussian, we obtain a type of Indepen dent\\nComponent Analysis (ICA) (see [ 23, p. 591]). It is also possible to\\nimpose structure on the latent vector by selecting suitable marginal\\ndistributions p(z). F or instance, choosing Student’s t-distribution or a\\nLaplace distribution tends to impose sparsity on the learne d model. A\\ngeneral discussion on linear factor models can be found in [ 104] (see\\nalso [ 36] for a generalization of PPCA to any model in the exponential\\nfamily).\\n6.4.3 GAN\\nIn Sec.\\n2.6, we have seen that ML can be interpreted, in the asymptotic\\nregime of a large data set N, as minimizing the KL divergence between\\nthe true distribution of the data and the model. W e start this section by\\nrevisiting this argument for unsupervised learning in orde r to highlight\\na similar interpretation that holds for ﬁnite values of N. This viewpoint'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 157, 'page_label': '152', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='revisiting this argument for unsupervised learning in orde r to highlight\\na similar interpretation that holds for ﬁnite values of N. This viewpoint\\nwill lead us to generalize the ML learning approach to techni ques in\\nwhich the choice of the divergence measure is adapted to the d ata. As an\\nimportant by-product, the resulting technique, known as GA N, will be\\nseen to accommodate easily likelihood-free models. GANs ar e currently\\nconsidered to yield state-of-the-art results for image gen eration [ 57].\\nT o simplify the discussion, assume that variables xn are categorical\\nand take a ﬁnite number of values. T o start, let us observe tha t the\\nNLL function ( 6.1) for i.i.d. data can be written as\\n−1\\nN\\nN∑\\nn=1\\nlnp(xn|θ) = −\\n∑\\nx\\nN[x]\\nN lnp(x|θ), (6.36)\\nwhere we recall that N[x] = |{n : xn = x}|. W e now note that the\\nML problem of minimizing the NLL ( 6.36) over θ is equivalent to the\\nminimization of the KL divergence\\nmin\\nθ\\n−\\n∑\\nx\\npD (x)lnp(x|θ) +\\n∑\\nx\\npD (x)lnpD (x)\\n=min\\nθ'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 157, 'page_label': '152', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ML problem of minimizing the NLL ( 6.36) over θ is equivalent to the\\nminimization of the KL divergence\\nmin\\nθ\\n−\\n∑\\nx\\npD (x)lnp(x|θ) +\\n∑\\nx\\npD (x)lnpD (x)\\n=min\\nθ\\nKL(pD (x)||p(x|θ)), (6.37)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 158, 'page_label': '153', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.4. Directed Generative Models 153\\nwhere we have deﬁned the empirical distribution\\npD (x) = N[x]\\nN . (6.38)\\nW e hence conclude the ML attempts to minimize the KL divergen ce\\nbetween the empirical distribution pD (x) of the data and the model\\ndistribution p(x|θ). The ML problem min θ KL(pD (x)||p(x|θ)) is also\\nknown as the M-projection of the data distribution pD (x) into the\\nmodel {p(x|θ)}[40] (see Chapter 8 for further discussion).\\nThe KL divergence ( 6.37) is a measure of the diﬀerence between\\ntwo distribution with speciﬁc properties that may not be tai lored to\\nthe particular application of interest. F or instance, dist ributions ob-\\ntained by minimizing ( 6.37) tend to provide “blurry” estimates of the\\ndistribution of the data distribution, as we have seen in Fig . 6.5. As\\na result, learning image distributions using M-projection s is known to\\ncause the learned model to produce unfocused images [ 57].\\nThe KL divergence is not, however, the only measure of the diﬀ er-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 158, 'page_label': '153', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a result, learning image distributions using M-projection s is known to\\ncause the learned model to produce unfocused images [ 57].\\nThe KL divergence is not, however, the only measure of the diﬀ er-\\nence between two distributions. As discussed in more detail in Appendix\\nA, the KL divergence is in fact part of the larger class of f-divergences\\nbetween two distributions p(x) and q(x). This class includes divergence\\nmeasures deﬁned by the variational expression 1\\nDf (p||q) = max\\nT (x)\\nEx∼p[T(x)] −Ex∼q [g(T(x))], (6.39)\\nfor some concave increasing function g(·) (the meaning of the f sub-\\nscript is discussed in Appendix A). The key new element in ( 6.39) is\\nthe decision rule T(x), which is also known as discriminator or critic.\\nThis function takes as input a sample x and ideally outputs a large\\nvalue when xis generated from distribution p, and a small value when\\nit is instead generated from q. Optimizing over T(x) hence ensures that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 158, 'page_label': '153', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='value when xis generated from distribution p, and a small value when\\nit is instead generated from q. Optimizing over T(x) hence ensures that\\nthe right-hand side of ( 6.39) is large when the two distributions are dif-\\nferent and hence can be distinguished based on the observati on of x.\\nWhen the domain over which the discriminator T(x) is optimized is left\\nunconstrained, solving problem ( 6.39) recovers the KL divergence and\\n1 The term variational refers to the fact that the deﬁnition in volves an optimiza-\\ntion.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 159, 'page_label': '154', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='154 Unsupervised Learning\\nthe Jensen-Shannon divergence, among others, with speciﬁc choices of\\nfunction g (see Appendix A). 2\\nGeneralizing the ML problem ( 6.37), GANs attempt to solve the\\nproblem\\nmin\\nθ\\nDf (pD (x)||p(x|θ)). (6.40)\\nMore precisely , GANs parametrize the discriminator T(x) by choosing a\\ndiﬀerentiable function Tϕ(x) of the parameter vector ϕ. This eﬀectively\\nreduces the search space for the discriminator, and deﬁnes a diﬀerent\\ntype of divergence for each value of ϕ. A typical choice for Tϕ (x) is the\\noutput of a multi-layer neural network with weights ϕ or a function\\nthereof (see Sec. 4.5). With this in mind, using ( 6.39) in ( 6.40), we\\nobtain the minimax problem solved by GANs 3\\nmin\\nθ\\nmaxϕ Ex∼pD [Tϕ (x)] −Ex∼p(x|θ)[g(Tϕ (x))]. (6.41)\\nAccording to ( 6.41), GANs select the divergence measure adaptively\\nthrough the optimization of the discriminator Tϕ(x). Problem ( 6.41)\\ncan also be interpreted in terms of a strategic game played by generator\\nand discriminator [ 57].4'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 159, 'page_label': '154', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='through the optimization of the discriminator Tϕ(x). Problem ( 6.41)\\ncan also be interpreted in terms of a strategic game played by generator\\nand discriminator [ 57].4\\nThe original GAN method [ 57] operates by setting Tϕ(x) = ln Dϕ (x),\\nwhere Dϕ(x) is the output of a multi-layer perceptron, and g(t) =\\n−log(1 −exp(t)). A variation that is shown to be more useful in prac-\\ntice is also discussed in the ﬁrst GAN paper (see [ 49]). As another\\npopular example, W asserstein GAN simply sets Tϕ(x) to be the output\\nof a multi-layer perceptron and chooses g(t) = −(1 −t).\\nApplication to likelihood-free models. ∗ GANs are typically\\nused with likelihood-free models. Accordingly , the model d istribution\\np(x|θ) is written as\\np(x|θ) =\\n∫\\nδ(x−Gθ (z))N(z|0,I)dz. (6.42)\\n2 F or a given function T (x), the right-hand side of ( 6.39), excluding the maxi-\\nmization, provides a lower bound on the divergence Df (p||q). Another useful related'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 159, 'page_label': '154', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='∫\\nδ(x−Gθ (z))N(z|0,I)dz. (6.42)\\n2 F or a given function T (x), the right-hand side of ( 6.39), excluding the maxi-\\nmization, provides a lower bound on the divergence Df (p||q). Another useful related\\nbound for the KL divergence is the so-called Donsker-V aradh an representation (see,\\ne.g., [ 18]).\\n3 The version of GAN given here is known as f -GANs [ 107], which is a general-\\nization of the original GAN.\\n4 It is noted that the GAN set-up is reminiscent of the adversar ial model used\\nto deﬁne semantic security in cryptography .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 160, 'page_label': '155', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.5. Undirected Generative Models 155\\nThe samples x are hence modelled as the output of a generator function\\nGθ (z), whose input z is given by i.i.d. Gaussian variables. This gener-\\native model can hence be interpreted as a generalization of P PCA to\\nnon-linear encoders Gθ (z). The latter is conventionally modelled again\\nas a multi-layer neural network.\\nProblem ( 6.41) is typically tackled using SGD (Chapter 4) by iterat-\\ning between the optimization of the generator parameters θ and of the\\ndiscriminator parameters ϕ (see [ 8, Algorithm 1]). Learning requires\\nempirical approximations for the evaluation of the gradien ts that will\\nbe discussed in Chapter 8.\\nLikelihood ratio estimation viewpoint. ∗ When no constraints\\nare imposed over the discriminator T(x) in ( 6.39) and the function g\\nis selected as g(t) = exp( t−1), the optimal solution is given as T(x) =\\n1 + ln( pD (x)/p(x|θ)) and the corresponding divergence measure ( 6.39)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 160, 'page_label': '155', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is selected as g(t) = exp( t−1), the optimal solution is given as T(x) =\\n1 + ln( pD (x)/p(x|θ)) and the corresponding divergence measure ( 6.39)\\nis the KL divergence KL (pD (x)||p(x|θ)). Therefore, solving problem\\n(6.39) over a suﬃciently general family of functions Tϕ(x) allows one\\nto obtain an estimate of the log-likelihood ratio ln(pD (x)/p(x|θ)). As\\na result, GANs can be interpreted as carrying out the estimat ion of\\nlikelihood ratios between the data and the model distributi ons as a\\nstep in the learning process. The idea of estimating likelih ood ratios in\\norder to estimate KL divergences is useful in other learning problems\\nbased on variational inference, to be discussed in Chapter 8 (see [ 70]).\\nSome research topics. ∗ Among topics of current research, we\\nmention here the problem of regularization of GANs [ 123]. W e also note\\nthat GANs can also be extended to supervised learning proble ms [ 108].\\nThe GAN approach of formulating the divergence as an optimiz ation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 160, 'page_label': '155', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='that GANs can also be extended to supervised learning proble ms [ 108].\\nThe GAN approach of formulating the divergence as an optimiz ation\\nover a discriminator function was also recently found to be u seful for\\nICA [ 29].\\n6.5 Undirected Generative Models\\nUnlike directed generative models, undirected generative models posit\\na joint distribution for the hidden and the observed variabl es that cap-\\ntures aﬃnity , rather than causality , relationships betwee n the two sets\\nof variables, as seen in Fig.\\n6.1(b). In this section, we discuss a repre-\\nsentative example of undirected generative models that is c onsidered'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 161, 'page_label': '156', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='156 Unsupervised Learning\\nto be a powerful tool for a number of applications, including feature se-\\nlection, generation of new samples, and even recommendatio n systems\\n[127]. The model, known as RBM, also ﬁnds application as a compo-\\nnents of larger multi-layer structures, also for supervise d learning [ 64].\\n6.5.1 Restricted Boltzmann Machines (RBM)\\nRBMs are typically characterized by an M-dimensional binary hidden\\nvector z ∈{0,1}M , while the observed variables may be discrete or\\ncontinuous. Here we consider the case of binary observed var iables,\\nwhich is suitable to model, e.g., black-and-white images or positive/\\nnegative recommendations. The RBM model is deﬁned as (\\n6.3), where\\nthe joint distribution of visible and latent variables is a l og-linear model,\\nand hence part of the exponential family . Mathematically , w e have\\np(x,z|θ) = 1\\nZ(θ) exp(−E(x,z|θ)), (6.43)\\nwith the energy function given as\\nE(x,z|θ) = −aT z−bT x−xT Wz, (6.44)\\nand the partition function as Z(θ) = ∑'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 161, 'page_label': '156', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x,z|θ) = 1\\nZ(θ) exp(−E(x,z|θ)), (6.43)\\nwith the energy function given as\\nE(x,z|θ) = −aT z−bT x−xT Wz, (6.44)\\nand the partition function as Z(θ) = ∑\\nx,z exp(−E(x,z|θ)).The param-\\neter vector θ includes the M ×1 vector a, the D×1 vector b and the\\nD×M matrix W.\\nThe qualiﬁer “restricted” captures the fact that the energy func-\\ntion ( 6.44) only features cross-terms that include one variable from x\\nand one from z, and not two variables from x or two from z. In other\\nwords, the model accounts for the aﬃnities between variable s in x and\\nz, but not directly between variables in either x or z [20]. F or instance,\\nif ( i,j)th entry wij of matrix W is a large positive number, variables\\nxi and zj will tend to have equal signs in order to minimize the energy\\nand hence maximize the probability; and the opposite is true when wij\\nis negative. As we will seen in the next chapter, this type of p robabilis-\\ntic relationship can be represented by the undirected graph ical model'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 161, 'page_label': '156', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is negative. As we will seen in the next chapter, this type of p robabilis-\\ntic relationship can be represented by the undirected graph ical model\\nknown as MRF shown in Fig. 6.6.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 162, 'page_label': '157', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.5. Undirected Generative Models 157\\nFigure 6.6: An undirected graph (MRF) describing the joint distributio n prescribed\\nby the RBM model ( 6.43)-(6.44).\\nF rom the model, it is easy to compute the distribution of each\\nhidden or observed variable when conditioning on all the obs erved or\\nhidden variables, respectively . In particular, we have tha t the variables\\nin z are mutually independent when conditioned on x, and, similarly ,\\nthe variables in x are independent given z. F urthermore, the conditional\\ndistributions are given as:\\np(zj = 1 |x,θ) = σ(wT\\nj x+ aj ) (6.45a)\\np(xi = 1 |z,θ) = σ( ˜wT\\ni z+ bi), (6.45b)\\nwhere wj is the jth column of W and ˜wi is the ith row of matrix W re-\\narranged into a column vector via transposition. These rela tionships\\nreveal the signiﬁcance of the binary hidden variables z in terms of fea-\\ntures.\\nIn fact, as for PPCA, we can consider each column of matrix W\\nas a feature vector that contributes in explaining the obser vations. T o'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 162, 'page_label': '157', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tures.\\nIn fact, as for PPCA, we can consider each column of matrix W\\nas a feature vector that contributes in explaining the obser vations. T o\\nsee this, note that ( 6.45a) suggests that the jth hidden variable zj\\nequals 1 when the feature wj is well correlated with the data point x.\\nProbability ( 6.45b) also conﬁrms this interpretation, as each variable zj\\nmultiplies the ith element of the feature vector wj in deﬁning the LLR\\n˜wT\\ni z+ bi (see Sec. 3.2). F urthermore, the distributed representation of\\nthe data in terms of the binary hidden vector z is more eﬃcient than\\nthat provided by models with categorical variables such as t he mixture\\nof Gaussian model. This is in the following sense. While cate gorical\\nmodels require to learn a number of parameters that increase s linearly\\nwith the number of classes, the distributed representation with a binary\\nvector z can distinguish 2D combinations of features with a number of\\nparameters that increases only linearly with D [20].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 163, 'page_label': '158', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='158 Unsupervised Learning\\nLearning is typically done by means of an approximate SGD met hod\\nthat leverages MC techniques. Recalling the general formul a ( 3.28) for\\nthe exponential family , the gradient at the current iterati on θ = θold\\ncan be computed using ( 6.22) as\\n∇wij ln p(x|θ)|θ=θold = Ezj ∼p(zj |x,θold)[xi zj ] −Exi , zj ∼p(x, z j |θold)[xi zj ],\\n(6.46)\\nwhich can be further simpliﬁed using ( 6.45). The gradient presents the\\nstructure, noted in Chapter 3, given by the diﬀerence betwee n a positive\\ncomponent, which depends on the data x, and a negative component,\\nwhich instead requires an ensemble average over all other po ssible sam-\\nples x ∼p(x|θold). Similar relations can be written for the gradients\\nwith respect to a and b, namely\\n∇aj ln p(x|θ)|θ=θold = Ezj ∼p(zj |x,θold)[zj ] −Ezj ∼p(zj |θold)[zj ] (6.47)\\nand\\n∇bi ln p(x|θ)|θ=θold = xi −Exi ∼p(xi |θold )[xi ]. (6.48)\\nIn order to evaluate the expectations in the negative compon ents of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 163, 'page_label': '158', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and\\n∇bi ln p(x|θ)|θ=θold = xi −Exi ∼p(xi |θold )[xi ]. (6.48)\\nIn order to evaluate the expectations in the negative compon ents of\\nthe gradients, one typically uses a an MC technique known as M arkov\\nChain MC (MCMC) to be discussed in Chapter 8. More speciﬁcall y , a\\nsimpliﬁed approach known as Contrastive Divergence (CD) ha s been\\nfound to be an eﬀective approximation. Accordingly , one “cl amps” the\\nvisible variables to the observed variables x = x, and generates the\\nsequence x →z(0) →x(1) →z(1) , using the conditional probability\\n(6.45a) to generate z from x and ( 6.45b) to generate x from z. The\\nresulting samples are used to approximate the expectations as\\n∇wij ln p(x|θ)|θ=θold ≃xi z(0)\\nj −x(1)\\ni z(1)\\nj , (6.49)\\nand similar expressions apply for the other gradients. The C D scheme\\ncan also be generalized to CD- k by increasing the Markov chain se-\\nquence to k steps, and the using the resulting samples x(k) and z(k) in\\nlieu of x(1) and z(1) .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 163, 'page_label': '158', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='can also be generalized to CD- k by increasing the Markov chain se-\\nquence to k steps, and the using the resulting samples x(k) and z(k) in\\nlieu of x(1) and z(1) .\\nExtensions and application of the RBM are discussed in [\\n20, 153].\\nGeneralizations of RBMs with multiple layers of hidden vari ables are\\nreferred to as Deep Boltzmann Machines. W e refer to [ 64] for discussion\\nabout training and applications.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 164, 'page_label': '159', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.6. Discriminative Models 159\\n6.6 Discriminative Models\\nWhen the goal is learning a representation z of data x, one can try to di-\\nrectly learn a parametrized encoder, or discriminative mod el, p(z|x,θ),\\nas illustrated in Fig. 6.1(c). With an encoder p(z|x,θ), we can deﬁne\\nthe joint distribution as p(x,z|θ) = p(x)p(z|x,θ), where p(x) is the\\ntrue distribution of the data. The latter is in practice appr oximated\\nusing the empirical distribution pD (x) of the data. This yields the joint\\ndistribution\\np(x,z|θ) = pD (x)p(z|x,θ). (6.50)\\nF rom (6.50), it is observed that, unlike the frequentist methods con-\\nsidered up to now, discriminative models for unsupervised l earning are\\nbased on the deﬁnition of a single distribution over observe d and un-\\nobserved variables. As such, divergence measures, which in volve two\\ndistributions, are not relevant performance metrics. In co ntrast, a suit-\\nable metric is the mutual information between the jointly di stributed'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 164, 'page_label': '159', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='distributions, are not relevant performance metrics. In co ntrast, a suit-\\nable metric is the mutual information between the jointly di stributed\\nvariables ( x,z). The mutual information is a measure of the statistical\\ndependence between the two rvs and is introduced in Appendix A.\\nT o elaborate, a typical learning criterion is the maximizat ion of the\\nmutual information Ip(x,z|θ)(x; z) between the representation z and the\\ndata x under the joint distribution p(x,z|θ). Note that, for clarity , we\\nexplicitly indicated the joint distribution used to evalua te the mutual\\ninformation as a subscript. It can be related to the KL diverg ence as\\nIp(x,z|θ)(x; z) = KL(p(x,z|θ)||p(x)p(z)). This relationship indicates that\\nthe mutual information quantiﬁes the degree of statistical dependence,\\nor the distance from independence, for the two rvs.\\nThe resulting Information Maximization problem is given as\\nmax\\nθ\\nIpD (x)p(z|x,θ)(x; z) . (6.51)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 164, 'page_label': '159', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='or the distance from independence, for the two rvs.\\nThe resulting Information Maximization problem is given as\\nmax\\nθ\\nIpD (x)p(z|x,θ)(x; z) . (6.51)\\nAs seen, in order to avoid learning the trivial identity mapp ing, one\\nneeds to impose suitable constraints on the encoder p(z|x,θ) in order to\\nrestrict its capacity . In order to tackle problem ( 6.51), a typical solution\\nis to resort to an MM approach that is akin to the EM algorithm f or\\nML learning described above (see Fig. 6.4).\\nT o this end, as for EM, we introduce a variational distributi on\\nq(x|z), and observe that we have the following lower bound on the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 165, 'page_label': '160', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='160 Unsupervised Learning\\nmutual information 5\\nIpD (x)p(z|x,θ)(x; z) ≥H(pD (x)) + Ex,z∼pD (x)p(z|x,θ)[ln q(x|z)]. (6.52)\\nThis result follows using the same steps as for the ELBO. The b ound is\\ntight when the variational distribution q(x|z) equals the exact posterior\\np(x|z,θ) = pD (x)p(z|x,θ)/(∑\\nx pD (x)p(z|x,θ)). Based on this inequal-\\nity , one can design an iterative optimization algorithm ove r the model\\nparameters and the variational distribution q(x|z) (see, e.g., [ 3, 150]).\\nWhen the latter is constrained to lie in a parametrized famil y , the opti-\\nmization over the decoder q(x|z) is an example of variational inference,\\nwhich will be discussed in Chapter 8. The optimization over t he model\\nparameters can be simpliﬁed when the model has additional st ructure,\\nsuch as in the InfoMax ICA method [ 85].\\nInference-based interpretation. ∗ The mutual information can\\nbe related to the error probability of inferring x given the representa-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 165, 'page_label': '160', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='such as in the InfoMax ICA method [ 85].\\nInference-based interpretation. ∗ The mutual information can\\nbe related to the error probability of inferring x given the representa-\\ntion z. This can be seen, e.g., by using F ano’s inequality [ 38, 3]. More\\nconcretely , criterion ( 6.52) can be interpreted in terms of inference of x\\ngiven z by noting that its right-hand side can be written as the diﬀer -\\nence H(pD (x))−(Ex,z∼pD (x)p(z|x,θ)[−ln q(x|z)]).In fact, the second term\\nis the cross-entropy measure for the prediction of x given z by means\\nof the variational distribution q(x|z). Therefore, by maximizing ( 6.52)\\nover θ, the model p(z|x,θ) obtains a representation z such that the\\npredictor q(x|z) ensures, on average, a good reconstruction of x given\\nz. This point is further elaborated on in [ 4]. W e speciﬁcally point to [ 4,\\nFig. 2], where a comparison with methods based on ML is provid ed.\\nInformation bottleneck method. ∗ An important variation of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 165, 'page_label': '160', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Fig. 2], where a comparison with methods based on ML is provid ed.\\nInformation bottleneck method. ∗ An important variation of\\nthe InfoMax principle yields the information bottleneck method. In the\\nlatter, one assumes the presence of an additional variable y, jointly\\ndistributed with x, which represents the desired information, but is\\nunobserved. The goal is, as above, to learn an encoder p(z|x,θ) be-\\ntween the observed x and the representation z. However, here, this is\\ndone by maximizing the mutual information I(y; z) between the tar-\\nget unobserved variable y and the representation z, in the presence of\\na regularization term that aims at minimizing the complexit y of the\\n5 The bound is also used by the Blahut-Arimoto algorithm [ 38].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 166, 'page_label': '161', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.7. Autoencoders 161\\nrepresentation. This penalty term is given by the mutual inf ormation\\nI(x; z) , which ﬁnds justiﬁcation in rate-distortion arguments [ 145].\\n6.7 Autoencoders\\nAs seen in Fig. 6.1, autoencoders include parametric models for both\\nencoder and decoder. W e focus here for brevity on determinis tic autoen-\\ncoders, in which the encoder is deﬁned by a function z = Fθ (x) and the\\ndecoder by a function x = Gθ (z). Note that the parameters deﬁning\\nthe two functions may be tied or may instead be distinct, and t hat\\nthe notation is general enough to capture both cases. W e will mention\\nat the end of this section probabilistic autoencoders, in wh ich encoder\\nand decoder are deﬁned by conditional probability distribu tions.\\nAutoencoders transform the unsupervised learning problem of ob-\\ntaining a representation z = Fθ (x) of the input xbased solely on unla-\\nbelled examples {xn }N\\nn=1 into an instance of supervised learning. They'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 166, 'page_label': '161', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='taining a representation z = Fθ (x) of the input xbased solely on unla-\\nbelled examples {xn }N\\nn=1 into an instance of supervised learning. They\\ndo so by concatenating the encoder z = Fθ (x) with a decoder x= Gθ (z),\\nso as to obtain the input-output relationship t = Gθ (Fθ (x)). The key\\nidea is to train this function by setting the target t to be equal to\\nthe input x. As such, the machine learns to obtain an intermediate\\nrepresentation z = Fθ (x) that makes it possible to recover a suitable\\nestimate t= Gθ (z) ≃x of x.\\nT o formalize the approach, learning is typically formulate d in terms\\nof the ERM problem\\nmin\\nθ\\nN∑\\nn=1\\nℓ(xn,Gθ (Fθ (xn))), (6.53)\\nin which, as explained, the encoder-decoder mapping Gθ (Fθ (·)) is trained\\nto reproduce the input at its output.\\nIn the absence of constraints on encoder and decoder, the pro blem\\nabove trivially returns an identify mapping, i.e., Gθ (Fθ (x)) = x. In\\norder to potentially learn a useful model, one should hence i mpose'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 166, 'page_label': '161', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='above trivially returns an identify mapping, i.e., Gθ (Fθ (x)) = x. In\\norder to potentially learn a useful model, one should hence i mpose\\nconstraints, such as dimensionality or sparsity , on the lat ent vector z.\\nSome notable examples are discussed next.\\nPCA. PCA assumes linear encoder and decoder, and ties their\\nweight matrices via a transposition. Speciﬁcally , PCA sets the encoder'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 167, 'page_label': '162', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='162 Unsupervised Learning\\nas Fθ (x) = WT x and the decoder as Gθ (z) = Wz. The parameters θ\\nare hence given by the D×M matrix W. By these deﬁnitions, the M\\ncolumns of W have the interpretation of linear features as for PPCA.\\nWith a quadratic loss function, the learning problem ( 6.53) is given\\nas\\nmin\\nW\\nN∑\\nn=1\\n∥xn −WWT xn∥2 . (6.54)\\nThis problem can be solved in closed form. The solution is in f act\\ngiven by the M principal eigenvectors of the sample covariance matrix\\nN−1 ∑ N\\nn=1 xnxT\\nn .Extensions of PCA that use the kernel trick (Chapter\\n4) can be also devised (see, e.g., [\\n104]). F urthermore, PCA can be seen\\nto be a special case of PPCA by setting in the latter µ = 0 and by\\ntaking the limit σ2 →0.\\nDictionary learning. In dictionary learning, the decoder is linear,\\ni.e., Gθ (z) = Wz, as for PCA. However, the encoder is limited only\\nby constraints on the set of feasible latent variables z. A typical such\\nconstraint is sparsity: the latent vector should have a smal l number of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 167, 'page_label': '162', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='by constraints on the set of feasible latent variables z. A typical such\\nconstraint is sparsity: the latent vector should have a smal l number of\\nnon-zero elements. Deﬁning as Cthe set of feasible values for z, the\\ndictionary learning problem can be formulated as\\nmin\\nW,{zn }∈C\\n1\\nN\\nN∑\\nn=1\\n∥xn −Wzn∥2 . (6.55)\\nThe name of the method accounts for the fact that matrix W can be\\nthought of as the dictionary of M features – its columns – that are\\nused to describe the data. The problem above is typically sol ved using\\nalternate optimization. Accordingly , one optimizes over W for a ﬁxed\\nset of latent vectors {zn }, which is a standard least squares problem;\\nand the optimizes over each latent vector zn for a ﬁxed W. The second\\nproblem can be tackled by using standard sparsity-based met hods, such\\nas LASSO (Chapter 2).\\nMulti-layer autoencoders. ∗ One can also represent both encoder\\nand decoder as multi-layer neural networks. In this case, th e weights'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 167, 'page_label': '162', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as LASSO (Chapter 2).\\nMulti-layer autoencoders. ∗ One can also represent both encoder\\nand decoder as multi-layer neural networks. In this case, th e weights\\nof encoder and decoders are typically tied to be the transpos e of one\\nanother, in a manner similar to PCA. T raining is often done ﬁr st layer-\\nby-layer, e.g., using RBM training, and then via backpropag ation across\\nthe entire network [ 64].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 168, 'page_label': '163', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.8. Ranking ∗ 163\\nDenoising autoencoders. ∗ An alternative approach to facilitate\\nthe learning of useful features is that taken by denoising autoencoders\\n[150]. Denoising autoencoders add noise to each input xn, obtaining\\na noisy version ˜xn, and to then train the machine with the aim of\\nrecovering the input xn from its noisy version ˜xn. F ormally , this can be\\ndone by minimizing the empirical risk ∑ N\\nn=1 ℓ(xn,Gθ (Fθ (˜xn))).\\nProbabilistic autoencoders. ∗ Instead of using deterministic en-\\ncoder and decoder, it is possible to work with probabilistic encoders\\nand decoders, namely p(z|x,θ) and p(x|z,θ), respectively . T reating the\\ndecoder as a variational distribution, learning can then be done by a\\nvariant of the EM algorithm. The resulting algorithm, known as V ari-\\national AutoEncoder (V AE), will be mentioned in Chapter 8.\\n6.8 Ranking ∗\\nW e conclude this chapter by brieﬂy discussing the problem of ranking.\\nWhen one has available ranked examples, ranking can be formu lated'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 168, 'page_label': '163', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.8 Ranking ∗\\nW e conclude this chapter by brieﬂy discussing the problem of ranking.\\nWhen one has available ranked examples, ranking can be formu lated\\nas a supervised learning problem [\\n133]. Here, we focus instead on the\\nproblem of ranking a set of webpages based only on the knowled ge of\\ntheir underlying graph of mutual hyperlinks. This set-up ma y be con-\\nsidered as a special instance of unsupervised learning. W e s peciﬁcally\\ndescribe a representative, popular, scheme known as PageRa nk [ 110],\\nwhich uses solely the web of hyperlinks as a form of supervisi on signal\\nto guide the ranking.\\nT o elaborate, we deﬁne the connectivity graph by including a vertex\\nfor each webpage and writing the adjacent matrix as\\nLij =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if page j links to page i\\n0 otherwise\\n. (6.56)\\nThe outgoing degree of a webpage is hence given as\\nCj =\\n∑\\ni\\nLij . (6.57)\\nPageRank computes the rank pi of a webpage i as\\npi = (1 −d) + d\\n∑\\nj̸=i\\nLij\\nCj\\npj , (6.58)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 169, 'page_label': '164', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='164 Unsupervised Learning\\nwhere 0 <d< 1 is a parameter. Hence, the rank of a page is a weighted\\nsum of a generic rank of equal to 1, which enables the choice of new\\npages, and of an aggregate “vote” from other pages. The latte r term\\nis such that any other page j votes for page i if it links to page i and\\nits vote equals its own rank divided by the total number of out going\\nlinks, that is, pj /Cj . In essence, a page iis highly ranked if it is linked\\nby pages with high rank. The equation ( 6.58) can be solved recursively\\nto obtain the ranks of all pages. A variation of PageRank that tailors\\nranking to an individual’s preferences can be obtained as de scribed in\\n[63].\\n6.9 Summary\\nIn this chapter, we have reviewed the basics of unsupervised learning. A\\ncommon aspect of all considered approaches is the presence o f hidden,\\nor latent, variables that help explain the structure of the d ata. W e have\\nﬁrst reviewed ML learning via EM, and variations thereof, fo r directed'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 169, 'page_label': '164', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='or latent, variables that help explain the structure of the d ata. W e have\\nﬁrst reviewed ML learning via EM, and variations thereof, fo r directed\\nand undirected models. W e have then introduced the GAN metho d\\nas a generalization of ML in which the KL divergence is replac ed by\\na divergence measure that is learned from the data. W e have th en\\nreviewed discriminative models, which may be trained via th e InfoMax\\nprinciple, and autoencoders.\\nIn the next section, we broaden the expressive power of the pr oba-\\nbilistic models considered so far by discussing the powerfu l framework\\nof probabilistic graphical models.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 170, 'page_label': '165', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part IV\\nAdvanced Modelling and\\nInference'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 171, 'page_label': '166', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7\\nProbabilistic Graphical Models\\nAs we have seen in the previous chapters, probabilistic mode ls are\\nwidely used in machine learning. Using Fig. 6.1 as an example, we\\nhave encountered both directed and undirected models, whic h have\\nbeen used to carry out supervised and unsupervised learning tasks.\\nGraphical models encode structural information about the r vs of inter-\\nest, both observed and latent. They hence provide a principl ed way to\\ndeﬁne parametric probabilistic models with desired featur es.\\nThe selection of a probabilistic graphical model hence foll ows the\\nsame general rules that have been discussed so far: A more spe cialized,\\nor structured, model may help reduce overﬁtting, and hence t he gener-\\nalization gap. This is done, as we will see, by reducing the nu mber of\\nparameters to be learned. On the ﬂip side, specialization ma y come at\\nthe cost of an irrecoverable bias.\\nIn this chapter, we provide an introduction to the vast ﬁeld p rob-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 171, 'page_label': '166', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='parameters to be learned. On the ﬂip side, specialization ma y come at\\nthe cost of an irrecoverable bias.\\nIn this chapter, we provide an introduction to the vast ﬁeld p rob-\\nabilistic graphical models, which is a powerful framework t hat allows\\nus to represent and learn structured probabilistic models. The goal\\nhere is to introduce the main concepts and tools, while refer ring to the\\nextensive treatments in [ 81, 15, 104, 151] for additional information.\\n166'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 172, 'page_label': '167', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.1. Introduction 167\\n7.1 Introduction\\nIn this section, we start by discussing two examples that ill ustrate\\nthe type of structural information that can be encoded by mea ns of\\nprobabilistic graphical models. W e then provide an overvie w of this\\nchapter.\\nAs illustrated by the two examples below, structured probab ilistic\\nmodels can be used to set up parametric models for both superv ised\\nand unsupervised learning. In the former case, all variable s are observed\\nin the training set, with some rvs being inputs, i.e., covari ates ( x), and\\nothers being considered as outputs, or targets ( t). In contrast, in the\\nlatter case, some variables are unobserved and play the role of latent\\nvariables ( z) that help explain or generate the observed variables ( x).\\n1\\nExample 7.1. Consider the tasks of text classiﬁcation via supervised\\nlearning or text clustering via unsupervised learning. In t he supervised\\nlearning case, the problem is to classify documents dependi ng on their'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 172, 'page_label': '167', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning or text clustering via unsupervised learning. In t he supervised\\nlearning case, the problem is to classify documents dependi ng on their\\ntopic, e.g., sport, politics or entertainment, based on set of labelled\\ndocuments. With unsupervised learning, the problem is to cl uster doc-\\numents according to the similarity of their contents based o n the sole\\nobservation of the documents themselves.\\nA minimal model for this problem should include a variable t repre-\\nsenting the topic and a variable x for the document. The topic can\\nbe represented by a categorical variable taking T values, i.e.., t ∈\\n{1,...,T },which is observed for supervised learning and latent for uns u-\\npervised learning. As for the document, with “bag-of-words ” encoding,\\na set of W words of interest is selected, and a document is encoded as\\na W ×1 binary vector x= [ x1 ,...,xW ]T , in which xw = 1 if word w is\\ncontained in the document. 2\\nT o start, we could try to use an unstructured directed model d eﬁned\\nas'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 172, 'page_label': '167', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a W ×1 binary vector x= [ x1 ,...,xW ]T , in which xw = 1 if word w is\\ncontained in the document. 2\\nT o start, we could try to use an unstructured directed model d eﬁned\\nas\\nt ∼Cat(π) (7.1a)\\nx|t = t∼Cat(πt), (7.1b)\\n1 Strictly speaking, this distinction applies to the frequen tist approach, since in\\nthe Bayesian approach the model parameters are always treat ed as unobserved rvs.\\n2 Note that W here does not represent a matrix of weights!'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 173, 'page_label': '168', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='168 Probabilistic Graphical Models\\nwhere the parameter vector includes the T×1 probability vector πand\\nthe T probability vectors πt, one for each class, each of dimension 2W .\\nNote, in fact, that the vector x can take 2W possible values. As such,\\nthis model would require to learn (T−1)+ T(2W −1) parameters, which\\nquickly becomes impractical when the number W of words of interest\\nis large enough. F urthermore, as we have seen, a learned mode l with\\na large number of parameters is bound to suﬀer from overﬁttin g if the\\navailable data is relatively limited.\\nInstead of using this unstructured model, we can adopt a mode l that\\nencodes some additional assumptions that can be reasonably made on\\nthe data. Here is one possible such assumption: once the topi c is ﬁxed,\\nthe presence of a word is independent on the presence of other words.\\nThe resulting model is known as Bernoulli naive Bayes , and can be\\ndescribed as follows\\nt ∼Cat(π) (7.2a)\\nx|t = t∼\\nW∏\\nw=1\\nBern(xw |πw|t), (7.2b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 173, 'page_label': '168', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The resulting model is known as Bernoulli naive Bayes , and can be\\ndescribed as follows\\nt ∼Cat(π) (7.2a)\\nx|t = t∼\\nW∏\\nw=1\\nBern(xw |πw|t), (7.2b)\\nwith parameter vector including the T ×1 probability vector π and T\\nsets of W probabilities πw|t, w = 1 ,...,W , for each topic t. Parameter\\nπw|t represents the probability of word w occurring in a document of\\ntopic t. The mentioned independence assumption hence allowed us to\\nbring the number of parameters down to (T −1) + TW, which corre-\\nsponds to an exponential reduction.\\nFigure 7.1: BN for the naive Bayes model using the plate notation. Learna ble\\nparameters are represented as dots.\\nThe naive Bayes model can be represented graphically by the B N'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 174, 'page_label': '169', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.1. Introduction 169\\nillustrated in Fig. 7.1, where we have considered N i.i.d. documents.\\nNote that the graph is directed: in this problem, it is sensib le to model\\nthe document as being caused by the topic, entailing a directed causal-\\nity relationship. Learnable parameters are represented as dots. BNs are\\ncovered in Sec. 7.2.\\nFigure 7.2: MRF for the image denoising example. Only one image is shown a nd\\nthe learnable parameters are not indicated in order to simpl ify the illustration.\\nExample 7.2. The second example concerns image denoising using su-\\npervised learning. F or this task, we wish to learn a joint dis tribution\\np(x,z|θ) of the noisy image x and of the corresponding desired noise-\\nless image z. W e encode the images using a matrix representing the\\nnumerical values of the pixels. A structured model in this pr oblem can\\naccount for the following reasonable assumptions: ( i ) neighboring pixels\\nof the noiseless image are correlated, while pixels further apart are not'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 174, 'page_label': '169', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='account for the following reasonable assumptions: ( i ) neighboring pixels\\nof the noiseless image are correlated, while pixels further apart are not\\ndirectly dependent on one another; and ( ii ) noise acts independently\\non each pixel of the noiseless image to generate the noisy ima ge. These\\nassumptions are encoded by the MRF shown in Fig. 7.2. Note that this\\nis an undirected model. This choice is justiﬁed by the need to capture\\nthe mutual correlation among neighboring pixels, which can not be de-\\nscribed as a directed causality relationship. W e will study MRF s in Sec.\\n7.3.\\nAs suggested by the examples above, structure in probabilis tic mod-\\nels can be conveniently represented in the form of graphs. At a fun-\\ndamental level, structural properties in a probabilistic m odel amount'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 175, 'page_label': '170', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='170 Probabilistic Graphical Models\\nto conditional independence assumptions. F or instance, in the naive\\nBayes model, the word indicators are conditionally indepen dent given\\nthe topic. As we will see in the rest of this chapter, conditio nal in-\\ndependence assumptions translate into factorizations of t he joint dis-\\ntributions of the variables under study . F actorizations, a nd associated\\nconditional independence properties, can be represented b y three diﬀer-\\nent graphical frameworks, namely BNs, MRF s and factor graph s. F or\\nbrevity , this chapter will only focus on the ﬁrst two.\\n7.2 Bayesian Networks\\nThis section provides a brief introduction to BNs by focusin g on key\\ndeﬁnitions and on the problem of ML learning with some note on MAP\\nand Bayesian viewpoints.\\n7.2.1 Deﬁnitions and Basics\\nBNs encode a probability factorization or, equivalently , a set of condi-\\ntional independence relationships through a directed grap h. The start-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 175, 'page_label': '170', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and Bayesian viewpoints.\\n7.2.1 Deﬁnitions and Basics\\nBNs encode a probability factorization or, equivalently , a set of condi-\\ntional independence relationships through a directed grap h. The start-\\ning point is the chain rule for probabilities for a generic se t of K rvs\\n{x1 ,...,xK }:\\np(x1,...,xk ) = p(x1)p(x2 |x1 )...p(xK |x1 ,...,xK −1 ),\\n=\\nK∏\\nk=1\\np(xk |x1 ,...,xk−1 ), (7.3)\\nwhere the order of the variables is arbitrary . The factoriza tion (\\n7.3)\\napplies for a generic joint distribution, and it does not enc ode any\\nadditional structural information. Note that the notation here is general\\nand not meant to indicate that the variables are necessary ob served.\\nExample 7.3. Consider again the naive Bayes model for text classiﬁ-\\ncation/ clustering. There, we imposed the structural const raint that\\nword indicator variables {xw }W\\nw=1 be conditionally independent given\\nthe topic t. This conditional independence assumption can be expresse d\\nusing the “perp” notation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 175, 'page_label': '170', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='word indicator variables {xw }W\\nw=1 be conditionally independent given\\nthe topic t. This conditional independence assumption can be expresse d\\nusing the “perp” notation\\nxw ⊥{xw′ }w′ ̸=w |t, (7.4)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 176, 'page_label': '171', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 171\\nor the Markov chain notation\\nxw −t −{xw′ }w′ ̸=w . (7.5)\\nMathematically , this condition means that we have p(xw |t,{xw′ }) =\\np(xw |t), where {xw′ }is any subset of the variables {xw′ }w′ ̸=w . Applying\\nthe chain rule to the rvs ({xw }W\\nw=1 ,t) using order t,x1 ,...,xW (or any\\nother order on the {xw }W\\nw=1 variables), we can hence write\\np(x,t) = p(t)\\nW∏\\nw=1\\np(xw |t). (7.6)\\nThis factorization is represented by the BN in Fig.\\n7.1. In the di-\\nrected graph shown in the ﬁgure, each vertex corresponds to a rv, and\\na directed edge is included from t to each variable xw . This edge cap-\\ntures the fact that the conditional probability of the varia ble xw in ( 7.6)\\nis conditioned on rv t. Informally , t “causes” all variables in vector x.\\nThe graph accounts for multiple i.i.d. realization (xD ,tD ) = {xn,tn }N\\nn=1 ,\\nwhere we denote the nth sample as xn = [x 1n ···xW n ]T . The joint dis-\\ntribution factorizes as\\np(xD ,tD ) =\\nN∏\\nn=1\\np(tn)\\nW∏\\nw=1\\np(xwn |tn). (7.7)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 176, 'page_label': '171', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='n=1 ,\\nwhere we denote the nth sample as xn = [x 1n ···xW n ]T . The joint dis-\\ntribution factorizes as\\np(xD ,tD ) =\\nN∏\\nn=1\\np(tn)\\nW∏\\nw=1\\np(xwn |tn). (7.7)\\nThe BN uses the tile notation that will be formalized below to indicate\\nmultiple independent realizations of rvs with the same dist ribution.\\nGeneralizing the example above, we deﬁne BNs as follows.\\nDeﬁnition 7.1. A BN is a directed acyclic graph (DAG)\\n3 , whose ver-\\ntices represent rvs {x1 ,....,xK }with an associated joint distribution\\nthat factorizes as\\np(x1,...,xK ) =\\nK∏\\nk=1\\np(xk |xP (k)) (7.8)\\nwhere P(k) denotes the set of parents of node k in the DAG. In a BN,\\nrvs are represented by full circles, while learnable parame ters deﬁning\\nthe conditional distributions are represented by dots.\\n3 In a DAG, there are no directed cycles, that is, no closed path s following the\\ndirection of the arrows.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 177, 'page_label': '172', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='172 Probabilistic Graphical Models\\nAs per the deﬁnition, the parents xP (k) of a rv xk in the DAG\\naccount for the statistical dependence of xk with all the preceding vari-\\nables x1,...,xk−1 according to the selected order. That is, the BN en-\\ncodes the local conditional independence relationships\\nxk ⊥{x1 ,...,xk−1 }|xP (k) (7.9)\\nusing the “perp” notation, or equivalently xk −xP (k) −{x1,...,xk−1 }\\nusing the Markov chain notation, for k = 1 ,...,K . As seen in Fig. 7.1,\\nplates are used to represent independent replicas of a part of the gr aph.\\nWhen to use BNs. BNs are suitable models when one can identify\\ncausality relationships among the variables. In such cases , there exists\\na natural order on the variables, such that rvs that appear la ter in the\\norder are caused by a subset of the preceding variables. The c ausing\\nrvs for each rv xk are included in the parent set P(k), and are such\\nthat, when conditioning on rvs xP (k), rv xk is independent on all other'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 177, 'page_label': '172', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='rvs for each rv xk are included in the parent set P(k), and are such\\nthat, when conditioning on rvs xP (k), rv xk is independent on all other\\npreceding rvs {x1 ,...,xk−1 }. BNs also underlie the framework of inter-\\nventions that allows the assessment of causality , as oppose d to mere\\ncorrelation, among observed variables, as brieﬂy discusse d in Sec. 2.7\\n[113].\\nSampling from a BN. The causality relationship among the or-\\ndered variables {x1 ,...,xK }encoded by a BN makes it easy , at least\\nin principle, to draw samples from a BN. This can be done by usi ng\\nancestral sampling : Generate rv x1 ∼p(x1); then, x2 ∼p(x2 |xP (2)); and\\nso on, with rv xk being generated as xk ∼p(xk |xP (k)).\\nExample 7.4. Hidden Markov Models (HMMs) are used to study time\\nseries, or more generally sequential data, measured throug h a memo-\\nryless transformation, such as an additive noise channel. M athemati-\\ncally , HMMs can be represented by two sets of variables: the u nderly-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 177, 'page_label': '172', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ryless transformation, such as an additive noise channel. M athemati-\\ncally , HMMs can be represented by two sets of variables: the u nderly-\\ning sequence z1 ,z2 ,...,zD ,and the measured “noisy” data x1,x2 ,...,xD .\\nHMMs encode two assumptions: ( i ) each sample zi depends on the past\\nsamples only through the previous sample zi−1; and ( ii ) each measured\\ndata xi depends only on zi. Assumption ( i ) makes process z1 ,z2 ,... a\\nMarkov chain.\\nUsing the order z1,x1 ,z2 ,x2 ,..., we can write the joint distribution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 178, 'page_label': '173', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 173\\nas\\np(x,z) = p(z1 )p(x1 |z1 )\\nD∏\\ni=1\\np(zi|zi−1 )p(xi |zi ) (7.10)\\nby enforcing the local independencies zi −zi−1 −{z1 ,...,zi−2 ,x1 ,...,xi−2 }\\nand xi −zi −{z1 ,...,zi−1 ,x1 ,...,xi−1 }.This factorization is represented\\nby the BN in Fig. 7.3. While not indicated in the ﬁgure for clarity , an\\nimportant aspect of HMMs is that the learnable parameters de ﬁning\\nthe transitions probabilities p(zi|zi−1 ) and the transformations p(xi|zi )\\nare respectively imposed to be equal, or tied, for all i, hence reducing\\nthe number of parameters to be leaned.\\nAmong the many relevant examples of applications of HMMs (se e\\n[81, 104, 15, 117]), we mention here text autocorrection, in which the\\nunderlying sequential data z1 ,z2 ,... amount to the correct text while\\nthe measured data x1,x2 ,... to the typed text; and speech recognition,\\nin which the underlying time series z1 ,z2 ,... is a sequence of words and\\nthe transformation to the measured recorded speech x1,x2 ,... translates'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 178, 'page_label': '173', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in which the underlying time series z1 ,z2 ,... is a sequence of words and\\nthe transformation to the measured recorded speech x1,x2 ,... translates\\nwords into sounds.\\nFigure 7.3: BN representing an HMM. The lernable parameters are not expl icitly\\nindicated.\\nIn supervised learning applications, both sequences are ob served in\\nthe training data, with the goal of learning to predict the se quence\\nz1 ,z2 ,..., for new measured data points x1,x2 ,... via to the trained\\nmodel. This task, in this context, is also known as denoising, since\\nx1 ,x2 ,... can be thought of as a noisy version of z1 ,z2 ,... With unsu-\\npervised learning, only the sequence x1,x2 ,... is observed.\\nExample 7.5. This example demonstrates how easily Bayesian mod-\\nelling can be incorporated in a BN. T o this end, consider agai n the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 179, 'page_label': '174', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='174 Probabilistic Graphical Models\\nBernoulli naive Bayes model ( 7.2) for text classiﬁcation. T aking a Bayesian\\nviewpoint, parameters πand {πw|t}are to be considered as rvs. W e fur-\\nther assume them to be a priori independent, which is known as the\\nglobal independence assumption . As a result, the joint probability dis-\\ntribution for each document factorizes as\\np(x,t,π,π w|t|α,a,b) = Dir(π|α)\\nT∏\\nt=1\\nW∏\\nw=1\\nBeta(πw|t|a,b)\\n×Cat(t|π)\\nW∏\\nw=1\\nBern(xw |πw|t). (7.11)\\nIn the factorization above, we have made the standard assump tion\\nof a Dirichlet prior for the probability vector π and a Beta prior for\\nparameters {πw|t}, as discussed in Chapter 3. The quantities α,a,b\\nare hyperparameters. Note that the hyperparameters (a,b) are shared\\nfor all variables πw|t in this example. The corresponding BN is shown\\nin Fig. 7.4, which can be compared to Fig. 7.1 for the corresponding\\nfrequentist model.\\nFigure 7.4: BN for the Bayesian version of the naive Bayes model ( 7.11). Hyper-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 179, 'page_label': '174', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in Fig. 7.4, which can be compared to Fig. 7.1 for the corresponding\\nfrequentist model.\\nFigure 7.4: BN for the Bayesian version of the naive Bayes model ( 7.11). Hyper-\\nparameters are not indicated and tiles indices are marked wi thout their ranges for\\nclarity .\\nW e invite the reader to consider also the Latent Dirichlet Al loca-\\ntion (LDA) model and the other examples available in the ment ioned\\ntextbooks.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 180, 'page_label': '175', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 175\\n7.2.2 Global Conditional Independence\\nAs we have discussed, BNs are deﬁned by local conditional ind epen-\\ndence properties that are encoded in the factorization of a j oint dis-\\ntribution and in the supporting DAG. BNs can also be used to as sess\\ngeneric global conditional independence queries of the typ e: Is a given\\nsubset of variables Aindependent of another set Bconditioned on a\\nthird subset Cof variables? The d-separation algorithm outputs either\\na positive response or a “maybe” answer to this question. It i s brieﬂy\\ndescribed as follows:\\n•Build a subgraph G′ from the original DAG by keeping all ver-\\ntices in the subsets A, B and C, as well as all the edges and vertices\\nencountered by moving backwards on the DAG one or more edges f rom\\nthe vertices in A, B and C;\\n•Build a subgraph G′′ from G′ by deleting all edges coming out of\\nthe vertices in C;\\n•If there no path, neglecting the directionality of the edges , between'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 180, 'page_label': '175', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the vertices in A, B and C;\\n•Build a subgraph G′′ from G′ by deleting all edges coming out of\\nthe vertices in C;\\n•If there no path, neglecting the directionality of the edges , between\\na node in Aand a node in B, then the conditional independence relation\\nA⊥B|C holds. Else, if one such path exists, then there is at least on e\\njoint distribution that factorizes as for the given DAG for w hich the\\ncondition A⊥B|C does not hold.\\nExample 7.6. Consider the so-called V-structure x →y ←z. Using d-\\nseparation, it can be seen that the conditional independenc e x−y−z\\ndoes not hold in general.\\n7.2.3 Learning\\nAssume that the DAG of a BN is given. Structure learning, that is,\\nthe decision of which edges should be included in the graph ba sed\\non available training data, is also an important problem tha t will not\\nbe considered here. Making explicit the dependence of the pr obability\\nfactors on learnable parameters µ, the joint distribution encoded by a\\nBN can be written as\\np(x1,...,xK ) =\\nK∏\\nk=1'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 180, 'page_label': '175', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='be considered here. Making explicit the dependence of the pr obability\\nfactors on learnable parameters µ, the joint distribution encoded by a\\nBN can be written as\\np(x1,...,xK ) =\\nK∏\\nk=1\\np(xk |xP (k),µk|xP (k) ), (7.12)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 181, 'page_label': '176', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='176 Probabilistic Graphical Models\\nwhere µk|xP (k) are the parameters deﬁning the conditional distribu-\\ntion p(xk |xP (k)). Note that the parameters µk|xP (k) are generally dif-\\nferent for diﬀerent values of k and of the parents’ variables xP (k) (see,\\ne.g., ( 7.11)). In most cases of interest, the probability distribution\\np(xk |xP (k),µk|xP (k) ) is in the exponential family or is a GLM (see Chap-\\nter 3).\\nAs we have already seen in previous examples, the parameters\\nµk|xP (k) can either be separate, that is, distinct for each k and each\\nvalue of xP (k), or they can be tied. In the latter case, some of the pa-\\nrameters µk|xP (k) are constrained to be equal across diﬀerent values of\\nxP (k) and/or across diﬀerent values of k. As a special case of tied pa-\\nrameters, the value of µk|xP (k) may also be independent of xP (k), such\\nas in the case for GLMs.\\nAs for the data, we have seen that the rvs x1,...,xK can be either'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 181, 'page_label': '176', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='rameters, the value of µk|xP (k) may also be independent of xP (k), such\\nas in the case for GLMs.\\nAs for the data, we have seen that the rvs x1,...,xK can be either\\nfully observed in the training set, as in supervised learnin g, or they can\\nbe partially observed as in unsupervised learning.\\nF or the sake of brevity , here we describe learning only for th e case of\\nfully observed data with separate parameters, and we brieﬂy mention\\nextensions to the other cases.\\nFully Observed Data with Separate Parameters\\nW e are given a fully observed data set D= {xn}N\\nn=1 , with each data\\npoint written as xn = [ x1n ,...,xK n ]T . F or concreteness, assume that\\nall variables are categorical. Denoting as xP (k)n the parents of variable\\nxkn , the LL function can be factorized as:\\nln p(D|µ) =\\nN∑\\nn=1\\nK∑\\nk=1\\nln p(xkn |xP (k)n ,µk|xP (k)n ) (7.13a)\\n=\\nK∑\\nk=1\\nN∑\\nn=1\\nln p(xkn |xP (k)n ,µk|xP (k)n ) (7.13b)\\n=\\nK∑\\nk=1\\n∑\\nxP (k)\\n∑\\nn∈NxP (k)\\nln p(xkn |xP (k),µk|xP (k) ), (7.13c)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 182, 'page_label': '177', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 177\\nwhere we have deﬁned the set of indices\\nNxP (k) = {n: xP (k)n = xP (k)}. (7.14)\\nThis set includes the indices n for which the parents xP (k)n of node k\\ntake a speciﬁc vector of values xP (k). In ( 7.13c), the inner sum depends\\nonly on the parameters µk|xP (k) corresponding to the given value xP (k)\\nof the rvs xP (k)n for n = 1 ,...,N . Therefore, in the case of separate\\nparameters, the ML estimate for each parameter µk|xP (k) can be carried\\nout independently . While this simpliﬁes the problem, it may also cause\\noverﬁtting issues owing to the problem of data fragmentatio n, as each\\nparameter is estimated based only on a fraction of the data se t.\\nAs an even more concrete example, consider binary variables mod-\\nelled as xk ∼Bern(µk|xP (k) ). Accordingly , the probability of each rv\\ndepends on the value xP (k) of the parents. F or this case, we can write\\nthe ML estimate as\\nˆµk|xP (k),M L =\\n∑\\nn∈NxP (k)\\nxkn\\n⏐\\n⏐\\n⏐NxP (k)\\n⏐\\n⏐\\n⏐\\n. (7.15)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 182, 'page_label': '177', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='depends on the value xP (k) of the parents. F or this case, we can write\\nthe ML estimate as\\nˆµk|xP (k),M L =\\n∑\\nn∈NxP (k)\\nxkn\\n⏐\\n⏐\\n⏐NxP (k)\\n⏐\\n⏐\\n⏐\\n. (7.15)\\nFigure 7.5: BN for Example 7.7.\\nExample 7.7. Consider the BN shown in Fig. 7.5 with binary rvs in'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 183, 'page_label': '178', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='178 Probabilistic Graphical Models\\nthe alphabet {0,1}. The observed data Dis given as\\n\\uf8f1\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f3\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n0\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n10\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n1\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n14\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n1\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n8\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n0\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n12\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n0\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n1\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n1\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n2\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n1\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n1\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n0\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n2\\n\\uf8fc\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8fd\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8fe\\n,\\nwhere the bottom row indicates the number of observations eq ual to the\\nvector above it. The ML estimates are: µ1,M L = 10+8+1+1\\n50 = 20\\n50 = 2\\n5 ,\\nµ2,M L = 14+8+2+1\\n50 = 1\\n2 , ˆµ3|00 = 2\\n12+2 = 1\\n7 , ˆµ3|11 = 1\\n8+1 = 1\\n9 , ˆµ3|01 =\\n14\\n14+2 = 7\\n8 and ˆµ3|10 = 10\\n10+1 = 10\\n11 .\\nMAP estimates can be seen to decompose in a similar way un-\\nder global independence assumptions on the parameters, and the same\\nholds for Bayesian approach [ 81].\\nNotes on the General Case\\nWith shared parameters, obtaining ML and MAP estimates requ ire\\naggregating statistics across all variables that share the same parame-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 183, 'page_label': '178', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='holds for Bayesian approach [ 81].\\nNotes on the General Case\\nWith shared parameters, obtaining ML and MAP estimates requ ire\\naggregating statistics across all variables that share the same parame-\\nters. The Bayesian approach is more complex, and we refer to [ 81] for\\ndiscussion. An alternative approach with “soft sharing” is the hierar-\\nchical Bayes model (see [ 81, Fig. 17.11]). In the presence of missing\\ndata, learning typically involves the EM algorithm describ ed in Chap-\\nter 6 or approximate learning counterparts to be introduced in the next\\nchapter.\\n7.3 Markov Random Fields\\nIn this section, we turn to MRF by following the same approach as for\\nBNs in the previous section.\\n7.3.1 Deﬁnitions and Basics\\nAs BNs, MRF s encode a probability factorization or, equival ently , a\\nset of conditional independence relationships. They do so, however,\\nthrough an undirected graph.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 184, 'page_label': '179', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.3. Markov Random Fields 179\\nDeﬁnition 7.2. A MRF is an undirected graph, whose vertices repre-\\nsent rvs with associated joint distribution that factorize s as\\np(x) = 1\\nZ\\n∏\\nc\\nψc(xc), (7.16)\\nwhere c is the index of a clique 4 in the graph; xc is the set of rvs\\nassociated with the vertices in clique c; ψc(xc) ≥0 is the factor or\\npotential for clique c; and Z = ∑\\nx\\n∏\\nc\\nψc(xc) is the partition function.\\nWith no loss of generality , the sum can be limited to maximal c liques\\n(i.e., cliques that are not fully included in a larger clique ). In a MRF,\\nrvs are represented by full circles, while learnable parame ters deﬁning\\nthe conditional distributions are represented by dots.\\nEach factor ψc(xc) in ( 7.16) encodes the compatibility of the values\\nxc in each clique, with larger values of ψc(xc) corresponding to con-\\nﬁgurations xc that are more likely to occur. F actors are generally not\\nprobability distributions, i.e., they are not normalized t o sum or inte-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 184, 'page_label': '179', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ﬁgurations xc that are more likely to occur. F actors are generally not\\nprobability distributions, i.e., they are not normalized t o sum or inte-\\ngrate to one. F urthermore, unlike BNs, each factor does not d istinguish\\nbetween conditioning and conditioned rvs. Rather, all vari ables in the\\nclique xc can play the same role in deﬁning the value of the potential\\nψc(xc).\\nWhen to use MRF s. This discussion points to the fact that MRF s\\nare especially well suited to model mutual relationships of compatibility ,\\nor lack thereof, among variables, rather than causality eﬀe cts.\\nEv aluating Probabilities and Sampling from an MRF . This\\ndistinguishing feature of MRF, which brings potential mode lling advan-\\ntages in some applications, comes with the added diﬃculty of evaluating\\nthe joint probability distribution and sampling from the joint distribu-\\ntion. In fact, the computation of the probability ( 7.16) requires the\\ncalculation of the partition function Z, which is generally intractable'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 184, 'page_label': '179', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion. In fact, the computation of the probability ( 7.16) requires the\\ncalculation of the partition function Z, which is generally intractable\\nwhen the alphabet of the vector x is large enough. This is typically not\\nthe case for BNs, in which each conditional probability is co nventionally\\nselected from a known (normalized) distribution. F urtherm ore, unlike\\nBNs, MRF s do not allow ancestral sampling, as all the conditi onal dis-\\n4 A clique is a fully connected subgraph.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 185, 'page_label': '180', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='180 Probabilistic Graphical Models\\ntributions of the individual rvs in x are generally tied together via the\\npartition function.\\nExample 7.8. The image denoising example described at the beginning\\nof this chapter leverages the MRF in Fig.\\n7.2. In it, the maximal cliques\\nare given by the pairs of rvs { zi ,zj } and {xi ,zi }that are connected by\\nan edge. Associating a factor or potential to each clique yie lds the\\nfactorized joint distribution\\np(x,z) = 1\\nZ\\n∏\\n{i,j }\\nψi,j (zi,zj ) ·\\n∏\\ni\\nψi(zi ,xi), (7.17)\\nwhere {i,j}represents an edge of the undirected graph. As a notable\\nexample, in the Ising model , the variables are bipolar, i.e., zi,xi ∈\\n{−1,+1}, and the potentials are deﬁned as ψij (zi,zj |η1) = exp(−E(zi ,zj |η1 ))\\nand ψi(zi ,xi|η2 ) = exp(−E(zi ,xi|η2 )), with energy functions\\nE(zi ,zj |η1 ) = −η1 zizj and E(zi ,xi |η) = −η2zi xi. (7.18)\\nF rom this deﬁnition, a large natural parameter η1 > 0 yields a large\\nprobability – or a low energy – when zi and zj are equal; and, similarly ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 185, 'page_label': '180', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='F rom this deﬁnition, a large natural parameter η1 > 0 yields a large\\nprobability – or a low energy – when zi and zj are equal; and, similarly ,\\na large η2 >0 favors conﬁgurations in which zi = xi, that is, with low\\nnoise.\\nExample 7.9. Another related example is given by the RBMs studied\\nin Sec.\\n6.5.1, whose undirected graph is shown in Fig. 6.6.\\nAs illustrated by the previous examples, potentials are typ ically\\nparameterized using the energy-based form\\nψc(xc) = exp(−Ec(xc|ηc)), (7.19)\\nwith parameter vector ηc.This form ensures that the factors are strictly\\npositive as long as the energy is upper bounded. A special cla ss of such\\nmodels is given by log-linear models, such as the Ising model , in which,\\nas seen in Chapter 3, the energy is a linear function of the par ameters.\\n7.3.2 Global Conditional Independence\\nMRF, in a manner similar to BNs, enable the assessment of cond itional\\nindependence properties globally in the graph. The procedu re is, in'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 186, 'page_label': '181', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.3. Markov Random Fields 181\\nfact, easier with MRF s thanks to the Hammersley–Cliﬀord the orem.\\nThe latter says that, if the potentials ψc(xc) are strictly positive for\\nall cliques c, as for the energy-based potentials ( 7.19), the conditional\\nindependence relationship A ⊥ B|Ccan be tested via the following\\nsimple algorithm.\\n•Eliminate all variables in Cand all the connected edges;\\n•If there is no path between rvs in Aand B, then the relationship\\nA⊥B|C holds; if, instead, there is a path, then there exists at leas t one\\njoint distribution that factorizes as for the undirected gr aph at hand\\nfor which the relationship A⊥B|C does not hold.\\n7.3.3 Learning\\nLearning in MRF s is made complicated by the partition functi on. In\\nfact, the partition function couples together all the param eters. This\\nmakes it impossible to carry out separately the estimate of t he param-\\neters ηc associated with each clique even in the fully observed case'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 186, 'page_label': '181', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='makes it impossible to carry out separately the estimate of t he param-\\neters ηc associated with each clique even in the fully observed case\\nwith separate parameters. Nevertheless, MRF s with energy- based po-\\ntentials (\\n7.19) fall either in the exponential family , when the factors\\nare log-normal, or in the more general class of energy-based models. In\\nboth cases, gradient-based algorithms can be devised by usi ng methods\\nsimilar to those used in Sec. 6.5.1 for RBMs.\\n7.3.4 Converting BNs to MRFs\\nAs suggested by the discussion above, BNs and MRF s are suitab le to\\nencode diﬀerent types of statistical dependencies, with th e former cap-\\nturing causality while the latter accounting for mutual com patibility .\\nThere are in fact conditional independence properties that can be ex-\\npressed by BN or MRF but not by both. An example is the V-struct ure\\nx →y ←z discussed in Example 7.6, whose independencies cannot be\\ncaptured by an MRF.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 186, 'page_label': '181', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='pressed by BN or MRF but not by both. An example is the V-struct ure\\nx →y ←z discussed in Example 7.6, whose independencies cannot be\\ncaptured by an MRF.\\nThat said, given a BN with factorization ( 7.8), we can deﬁne poten-\\ntial functions\\nψk (xk ,xP (k)) = p(xk |xP (k)) (7.20)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 187, 'page_label': '182', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='182 Probabilistic Graphical Models\\nto obtain the factorization\\np(x) =\\nK∏\\nk=1\\nψk (xk ,xP (k)) (7.21)\\nwith partition function Z = 1 . This factorization deﬁnes an MRF in\\nwhich each maximal clique contains a rv xk and its parents xP (k). The\\ncorresponding undirected graph can be directly obtained fr om the DAG\\nthat deﬁnes the BN via the following two steps:\\n•Connect all pairs of parents by an undirected edge – this step is\\nknown as “moralization”;\\n•Make all edges undirected.\\nAs per the discussion above, the resulting MRF may not accoun t\\nfor all the independencies encoded in the original graph. Th is can be\\neasily seen by applying the procedure to the V-structure.\\n7.4 Bayesian Inference in Probabilistic Graphical Models\\nBayesian inference amounts to the computation of the poster ior prob-\\nability of unobserved, or latent, variables given observed variables. In\\nthis regard, it is useful to diﬀerentiate between intensive and extensive'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 187, 'page_label': '182', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ability of unobserved, or latent, variables given observed variables. In\\nthis regard, it is useful to diﬀerentiate between intensive and extensive\\nlatent variables. Intensive latent variables are model par ameters whose\\nnumber does not increase with the number N of data points, such as\\nthe probability vectors (π,{πw|t}) in the Bernoulli naive Bayes model.\\nExtensive latent variables are instead rvs indexed by the ex ample index\\nn, whose number grows with the sample size N. These correspond to\\nthe latent variables zn introduced in the previous chapter.\\nBayesian inference is a fundamental task that lies at the hea rt of\\nboth inference and learning problems. As seen in Chapter 2, i t un-\\nderlies supervised learning for generative probabilistic models, which\\nrequires the computation of the predictive probability p(t|x,θ) for the\\nnew sample ( x,t) from the learned model p(x,t|θ). It is also at the core\\nof Bayesian supervised learning, which evaluates the poste rior p(θ|D)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 187, 'page_label': '182', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='new sample ( x,t) from the learned model p(x,t|θ). It is also at the core\\nof Bayesian supervised learning, which evaluates the poste rior p(θ|D)\\nof the parameter vector θ (an intensive variable) in order to obtain the\\npredictive posterior p(t|x,D) =\\n∫\\np(θ|D)p(t|x,θ)dθ for the new sam-\\nple ( x,t). As studied in Chapter 6, Bayesian inference is a key step\\nin unsupervised learning even under a frequentist viewpoin t, since the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 188, 'page_label': '183', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.4. Bayesian Inference in Probabilistic Graphical Models 183\\nEM algorithm requires the evaluation of the posterior p(zn|xn,θ) of the\\nlatent (extensive) variables {zn}given the current iterate θ.\\nAs discussed, when performing Bayesian inference, we can di stin-\\nguish between observed variables, say x, and latent variables z. In gen-\\neral, only a subset of latent variables may be of interest, sa y zi , with the\\nrest of the rvs in z being denoted as z−i.The quantity to be computed\\nis the posterior distribution\\np(zi|x) = p(x,zi )\\np(x) , (7.22)\\nwhere\\np(x,zi ) =\\n∑\\nz−i\\np(x,z) (7.23)\\nand\\np(x) =\\n∑\\nzi\\np(x,zi ), (7.24)\\nwith the sum being replaced by an integral for continuous var iables.\\nThe key complication in evaluating these expressions is the need to\\nsum over potentially large sets, namely the domains of varia bles z−i\\nand zi . Note that the sum in ( 7.23), which appears at the numerator of\\n(7.22), is over all hidden variables that are of no interest. In con trast,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 188, 'page_label': '183', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and zi . Note that the sum in ( 7.23), which appears at the numerator of\\n(7.22), is over all hidden variables that are of no interest. In con trast,\\nthe sum in ( 7.24), which is at the denominator of ( 7.22), is over the\\nvariables whose posterior probability ( 7.22) is the ﬁnal objective of the\\ncalculation.\\nThe complexity of the steps ( 7.23) and ( 7.24) is exponential in the\\nrespective numbers of latent variables over which the sums a re com-\\nputed, and hence it can be prohibitive.\\nExample 7.10. Consider an HMM, whose BN is shown in Fig.\\n7.3. Hav-\\ning learned the probabilistic model, a typical problem is th at of infer-\\nring a given hidden variable zi given the observed variables x = {x1,....,xD }.\\nComputing the posterior p(zi |x) requires the evaluation of the sums in\\n(7.23) and ( 7.24). When the hidden variables z1 ,...,zD are discrete with\\nalphabet size Z, the complexity of step ( 7.23) is of the order |Z|D−1 ,\\nsince one needs to sum over the |Z|D−1 possible values of the hidden'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 188, 'page_label': '183', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='alphabet size Z, the complexity of step ( 7.23) is of the order |Z|D−1 ,\\nsince one needs to sum over the |Z|D−1 possible values of the hidden\\nvariables.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 189, 'page_label': '184', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='184 Probabilistic Graphical Models\\nThe structure encoded by probabilistic graphic models can h elp\\nreduce the discussed complexity of Bayesian inference. The refore, prob-\\nabilistic graphical models can not only enhance learning by controlling\\nthe capacity of the model, but also enable Bayesian inferenc e. T o elab-\\norate, consider a joint distributions deﬁned by an MRF as in ( 7.16).\\nNote that, as we have seen in Sec. 7.3.4, one can easily convert BNs into\\nMRF s, although possibly at the cost of not preserving some li near in-\\ndependence relationship. With this factorization, the mar ginalizations\\n(7.23)-(7.24) require solving the so-called sum-product inference task\\n∑\\nz\\n∏\\nc\\nψc(xc), (7.25)\\nwhere the variables z are a subset of the variables in x.\\nAs an important observation, formulation ( 7.25) highlights the fact\\nthat the problem of computing the partition function Z for MRF s is\\na special case of the sum-product inference task. In fact, in order to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 189, 'page_label': '184', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='that the problem of computing the partition function Z for MRF s is\\na special case of the sum-product inference task. In fact, in order to\\ncompute Z, the sum in ( 7.25) is carried out over all variables in x.\\nWhen the undirected graph describing the joint distributio n is a\\ntree5 , the complexity of sum-product inference becomes exponent ial\\nonly in the maximum number of variables in each factor, also k nown as\\ntreewidth of the graph. In this case, the sum-product inference proble m\\ncan be exactly solved via message passing belief propagation over the\\nfactor graph associated to the MRF. W e refer to the textbooks [81, 15,\\n104] for details on factor graphs and belief propagation.\\nExample 7.11. The MRF associated with an HMM is obtained from\\nthe BN in Fig. 7.3 by simply substituting directed for undirected edges,\\nand the distribution ( 7.10) factorizes as\\np(x,z) = ψ(z1 )ψ(x1 ,z1 )\\nD∏\\ni=1\\nψ(zi ,zi−1 )ψ(xi ,zi ). (7.26)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 189, 'page_label': '184', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the BN in Fig. 7.3 by simply substituting directed for undirected edges,\\nand the distribution ( 7.10) factorizes as\\np(x,z) = ψ(z1 )ψ(x1 ,z1 )\\nD∏\\ni=1\\nψ(zi ,zi−1 )ψ(xi ,zi ). (7.26)\\nThe undirected graph is a tree with treewidth equal to 2, sinc e, as per\\n(7.26), there are at most two variables in each clique. Therefore, belief\\npropagation allows to evaluate the posteriors p(zi|x) with a complexity\\nof the order |Z|2 , which does not scale exponentially with the number\\nD of time samples.\\n5 In a tree, there is only one path between any pairs of nodes (no loops).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 190, 'page_label': '185', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.5. Summary 185\\nWhen the undirected graph is not a tree, one can use the junction\\ntree algorithm for exact Bayesian inference. The idea is to group subsets\\nof variables together in cliques, in such a way that the resul ting graph is\\na tree. The complexity depends on the treewidth of the result ing graph.\\nWhen this complexity is too high for the given application, a pproximate\\ninference methods are necessary . This is the subject of the n ext chapter.\\n7.5 Summary\\nProbabilistic graphical models encode a priori informatio n about the\\nstructure of the data in the form of causality relationships – via di-\\nrected graphs and BNs – or mutual aﬃnities – via undirected gr aphs\\nand MRF s. This structure translates into conditional indep endence con-\\nditions. The structural properties encoded by probabilist ic graphical\\nmodels have the potential advantage of controlling the capa city of a\\nmodel, hence contributing to the reduction of overﬁtting at the expense'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 190, 'page_label': '185', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='models have the potential advantage of controlling the capa city of a\\nmodel, hence contributing to the reduction of overﬁtting at the expense\\nof possible bias eﬀects (see Chapter 5). They also facilitat e Bayesian\\ninference (Chapters 2-4), at least in graphs with tree-like structures.\\nProbabilistic graphical models can be used as the underlyin g proba-\\nbilistic framework for supervised, unsupervised, and semi -supervised\\nlearning problems, depending on which subsets of rvs are obs erved or\\nlatent.\\nWhile graphical models can reduce the complexity of Bayesia n infer-\\nence, this generally remains computationally infeasible f or most models\\nof interest. T o address this problem, the next chapter discu sses ap-\\nproximate Bayesian inference, as well as associated learni ng problems\\n(Chapter 6).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 191, 'page_label': '186', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8\\nApproximate Inference and Learning\\nIn Chapters 6 and 7, we have seen that learning and inference t asks are\\noften made diﬃcult by the need to compute the posterior distr ibution\\np(z|x) of an unobserved variables z given an observed variables x. This\\ntask requires the computation of the normalizing marginal\\np(x) =\\n∑\\nz\\np(x,z), (8.1)\\nwhere the sum is replaced by an integral for continuous varia bles.1 This\\ncomputation is intractable when the alphabet of the hidden v ariable z\\nis large enough. Chapter 7 has shown that the complexity of co mput-\\ning ( 8.1) can be alleviated in the special case in which the factorize d\\njoint distribution p(x,z) is deﬁned by speciﬁc classes of probabilistic\\ngraphical models.\\nWhat to do when the complexity of computing ( 8.1) is excessive?\\nIn this chapter, we provide a brief introduction to two popul ar ap-\\nproximate inference approaches, namely MC methods and V ari ational\\nInference (VI). W e also discuss their application to learni ng. As for the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 191, 'page_label': '186', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='proximate inference approaches, namely MC methods and V ari ational\\nInference (VI). W e also discuss their application to learni ng. As for the\\n1 Note that this task subsumes ( 7.23) after appropriate redeﬁnitions of the vari-\\nables.\\n186'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 192, 'page_label': '187', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.1. Monte Carlo Methods 187\\nprevious chapter, the reader is referred to [ 81, 15, 104, 151] for details\\nand generalizations (see also [ 114]).\\n8.1 Monte Carlo Methods\\nT o introduce MC methods, we start by observing that the expre ssion\\n(8.1) can be rewritten as the ensemble average\\np(x) =\\n∑\\nz\\np(z)p(x|z) = Ez∼p(z)[p(x|z)] (8.2)\\nover the latent rvs z∼p(z). The general idea behind MC methods is re-\\nplacing ensemble averages with empirical averages over ran domly gen-\\nerated samples. In the most basic incarnation of MC, M i.i.d. samples\\nzm ∼p(z), m = 1 ,...,M, are generated from the marginal distribu-\\ntion p(z) of the latent variables, and then the ensemble average ( 8.2)\\nis approximated by the empirical average\\np(x) ≃ 1\\nM\\nM∑\\nm=1\\np(x|zm). (8.3)\\nBy the law of large numbers, we know that this estimate is cons istent,\\nin the sense that it tends with probability one to the ensembl e average\\n(8.2) when M is large. F urthermore, the error of the approximation\\nscales as 1/\\n√\\nM.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 192, 'page_label': '187', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in the sense that it tends with probability one to the ensembl e average\\n(8.2) when M is large. F urthermore, the error of the approximation\\nscales as 1/\\n√\\nM.\\nExample 8.1. Consider the Ising model for image denoising introduced\\nin Example 7.8. W e recall that the joint distribution can be factorized\\nas\\np(x,z) = 1\\nZ\\n∏\\n{i,j }\\nψi,j (zi,zj ) ·\\n∏\\ni\\nψi(zi ,xi), (8.4)\\nwhere {i,j}represents an edge of the undirected graph, with energy-\\nbased potentials ψij (zi,zj ) = exp(η1 zizj ) and ψi(zi ,xi ) = exp(η2 zixi ).\\nW e have removed the dependence of the potentials on the (natu ral)\\nparameters η1 and η2 for simplicity of notation. In order to compute\\nthe posterior p(z|x), which may be used for image denoising, the MC\\napproach ( 8.3) requires to sample from the marginal p(z). This is, how-\\never, not easy given the impossibility to perform ancestral sampling\\nover MRF s as discussed in Sec. 7.3.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 193, 'page_label': '188', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='188 Approximate Inference and Learning\\nImportance Sampling. As seen in the previous example, the MC\\nprocedure explained above is not always feasible in practic e, since draw-\\ning samples from the marginal p(z) may not be tractable. F or instance,\\nthe marginal p(z) may not be known or it may be diﬃcult to draw\\nsamples from it. In such common cases, one can instead resort to a sim-\\npliﬁed distribution q(z) from which sampling is easy . This distribution\\ntypically has convenient factorization properties that en able ancestral\\nsampling.\\nThe starting observation is that the marginal distribution (8.1) can\\nbe expressed as an ensemble average over a rv z ∼q(z) as\\np(x) =\\n∑\\nz\\np(z)p(x|z) q(z)\\nq(z)\\n=\\n∑\\nz\\nq(z) p(z)\\nq(z) p(x|z)\\n= Ez∼q(z)\\n[p(z)\\nq(z) p(x|z)\\n]\\n,\\n(8.5)\\nas long as the support of distribution q(z) contains that of p(z). This\\nexpression suggests the following empirical estimate, whi ch goes by the\\nname of Importance Sampling: Generate M i.i.d. samples zm ∼q(z),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 193, 'page_label': '188', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='expression suggests the following empirical estimate, whi ch goes by the\\nname of Importance Sampling: Generate M i.i.d. samples zm ∼q(z),\\nm= 1 ,...,M, and then compute the empirical approximation\\np(x) ≃ 1\\nM\\nM∑\\nm=1\\np(zm)\\nq(zm) p(x|zm). (8.6)\\nThis estimate is again consistent, but its variance depends on how well\\nq(z) approximates p(z). Note this approach requires knowledge of the\\nmarginal p(z) but not the ability to sample from it.\\nMarkov Chain Monte Carlo (MCMC) via Gibbs Sampling.\\nRather than drawing samples from a distribution that mimics p(z) in or-\\nder to compute an approximation of the posterior p(z|x) = p(x,z)/p(x),\\nMCMC methods aim at obtaining samples {zm } directly from the poste-\\nrior p(z|x). With such samples, one can compute empirical approxima-\\ntions of any ensemble average with respect to p(z|x). This is suﬃcient\\nto carry out most tasks of interest, including the expectati on needed\\nto evaluate the predictive posterior in Bayesian methods fo r supervised'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 193, 'page_label': '188', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to carry out most tasks of interest, including the expectati on needed\\nto evaluate the predictive posterior in Bayesian methods fo r supervised\\nlearning or the average energy in the EM algorithm.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 194, 'page_label': '189', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 189\\nMCMC methods generate a sequence of correlated samples z1 ,z2 ,...\\nfrom an easy-to-sample Markov chain z1 −z2 −...that has the key prop-\\nerty of having the desired distribution p(z|x) as the stationary distri-\\nbution. Such a Markov chain can be designed automatically on ce a BN\\nor MRF factorization of the joint distribution is available . T o this end,\\nGibbs sampling samples sequentially subsets of rvs. F or eac h subset,\\nthe sampling distribution is obtained by normalizing the pr oduct of all\\nfactors including the rv being sampled (see, e.g., [ 81]).\\nThe mechanical nature of this procedure makes it a universal, or\\nblack-box, inference method, in the sense that it can be applied to\\nany typical probabilistic graphical model in an automatic f ashion. This\\nhas led to the recent emergence of probabilistic programming, whereby\\nBayesian inference is automatically performed by software libraries that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 194, 'page_label': '189', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='has led to the recent emergence of probabilistic programming, whereby\\nBayesian inference is automatically performed by software libraries that\\nare given as input a probabilistic graphical model for the jo int distri-\\nbution (see, e.g., [ 41, 148]).\\nMC methods are often used in combination with VI, as discusse d\\nin Sec. 8.3.\\n8.2 Variational Inference\\nThe general idea behind VI is to replace the ensemble average in ( 8.2)\\nwith a suitable optimization that returns an approximation of the pos-\\nterior distribution p(z|x). Speciﬁcally , VI methods introduce an addi-\\ntional distribution on the hidden variables z that is optimized in order\\nto approximate the desired posterior p(z|x).\\nI-projection. W e start with the observation that the solution to\\nthe optimization problem\\nmin\\nq(z)\\nKL(q(z)||p(z|x)) (8.7)\\nfor a ﬁxed value x, yields the unique solution q(z) = p(z|x) if no con-\\nstraints are imposed on q(z). This is due to Gibbs’ inequality ( 2.44).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 194, 'page_label': '189', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='min\\nq(z)\\nKL(q(z)||p(z|x)) (8.7)\\nfor a ﬁxed value x, yields the unique solution q(z) = p(z|x) if no con-\\nstraints are imposed on q(z). This is due to Gibbs’ inequality ( 2.44).\\nThis result is, by itself, not useful, since evaluating the K L divergence\\nKL(q(z)||p(z|x)) requires knowledge of p(z|x), which is exactly what\\nwe are after.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 195, 'page_label': '190', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='190 Approximate Inference and Learning\\nHowever, the equality between ( 6.13) and ( 6.14), namely\\nKL(q(z)||p(x,z)) = KL(q(z)||p(z|x)) −ln p(x), (8.8)\\ndemonstrates that problem ( 8.7) is equivalent to solving\\nmin\\nq(z)\\nKL(q(z)||p(x,z)), (8.9)\\nwhere, by ( 6.11), we can write\\nKL(q(z)||p(x,z)) = −Ez∼q(z)[ln p(x,z)] −H(q). (8.10)\\nIn words, solving problem ( 8.7) is equivalent to minimizing the varia-\\ntional free energy or Gibbs free energy (8.10) – or the negative of the\\nELBO. A key feature of this alternative formulation is that i t does not\\nrequire knowledge of the unavailable posterior p(z|x).\\nF rom the derivation above, solving problem ( 8.9) exactly without\\nimposing any constraint on q(z) would yield the desired posterior p(z|x)\\nas the output. The key idea of VI is to choose a parametric form q(z|ϕ)\\nfor the variational posterior that enables the solution of p roblem\\nminϕ KL(q(z|ϕ)||p(x,z)). (8.11)\\nBy the discussion above, this is equivalent to minimizing KL (q(z|ϕ)||p(z|x)),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 195, 'page_label': '190', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for the variational posterior that enables the solution of p roblem\\nminϕ KL(q(z|ϕ)||p(x,z)). (8.11)\\nBy the discussion above, this is equivalent to minimizing KL (q(z|ϕ)||p(z|x)),\\ndespite the fact that p(z|x) is not known.\\nThe solution q(z|ϕ∗ ) to problem ( 8.11) is known as I-projection of\\nthe distribution p(z|x) in the set of distributions {q(z|ϕ)}deﬁned by\\nthe given parametrization. The I-projection can be taken as an estimate\\nof the posterior p(z|x). In fact, if the parametrized family {q(z|ϕ)}is\\nrich enough to contain distributions close to the true poste rior p(z|x),\\nthe minimization ( 8.11) guarantees the approximate equality q(z|ϕ∗ ) ≃\\np(z|x).\\nIn order to ensure the feasibility of the optimization ( 8.11), the\\nparametrized distribution q(z|ϕ) is typically selected to have a conve-\\nnient factorization and to have factors with tractable anal ytical forms,\\nsuch as members of the exponential family or GLMs [ 16].\\nAmortized VI. ∗ The variational posterior q(z|ϕ) obtained from'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 195, 'page_label': '190', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='nient factorization and to have factors with tractable anal ytical forms,\\nsuch as members of the exponential family or GLMs [ 16].\\nAmortized VI. ∗ The variational posterior q(z|ϕ) obtained from\\nthe I-projection ( 8.11) depends on the speciﬁc value of the observed\\nvariables x = x. Problem ( 8.11) is, in fact, solved separately for each'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 196, 'page_label': '191', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 191\\nvalue x = x. A potentially more eﬃcient solution is to deﬁne an in-\\nference variational distribution q(z|x,ϕ), which models the posterior\\ndistribution of z for any value of x = x. The inference distribution is\\nparametrized by a vector ϕ, and is typically implemented using a multi-\\nlayer neural network. In this case, it is typically referred to as inference\\nnetwork. This approach is referred to as amortized VI.\\nAmortized VI has the key advantage that, once the inference d is-\\ntribution is learned, one does not need to carry out I-projec tions for\\npreviously unobserved values of x = x. Instead, one can directly apply\\nq(z|x,ϕ) for the learned values of parameter ϕ [80].\\nThe inference distribution q(z|x,ϕ) can be obtained by solving the\\namortized I-projection problem\\nminϕ Ex∼p(x)[KL(q(z|x,ϕ)||p(x,z))], (8.12)\\nwhere the ensemble average is, in practice, replaced by an em pirical\\naverage over available data points {xn}. The solution of the VI problem'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 196, 'page_label': '191', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='minϕ Ex∼p(x)[KL(q(z|x,ϕ)||p(x,z))], (8.12)\\nwhere the ensemble average is, in practice, replaced by an em pirical\\naverage over available data points {xn}. The solution of the VI problem\\n(8.12) is hence “amortized” across multiple values of x.\\nM-projection.∗ By Theorem 6.1, the I-projection maximizes a\\nlower bound – the ELBO – on the log-distribution of the observ ed data\\nx. This gives I-projections a strong theoretical justiﬁcati on grounded\\nin the ML learning principle. Recalling that the KL divergen ce is not\\nsymmetric (see Sec. 2.6 and Appendix A), one could also deﬁne the\\nalternative problem\\nminϕ KL(p(z|x)||q(z|ϕ)). (8.13)\\nThe solution q(z|ϕ∗ ) to this problem is known as M-projection of the\\ndistribution p(z|x) in the set of distributions {q(z|ϕ)}deﬁned by the\\ngiven parametrization.\\nAs for the counterpart ( 8.7), this problem does not appear to be\\nsolvable since it requires knowledge of the desired posteri or p(z|x). How-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 196, 'page_label': '191', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='given parametrization.\\nAs for the counterpart ( 8.7), this problem does not appear to be\\nsolvable since it requires knowledge of the desired posteri or p(z|x). How-\\never, the problem turns out to have an easy solution if q(z|ϕ) belongs to\\nthe exponential family . In fact, the gradient with respect t o the natural\\nparameters ϕof the KL divergence in ( 8.7) can be computed by follow-\\ning the same steps detailed for ML learning in Sec. 3.3. The upshot of\\nthis computation and of the enforcement of the optimality co ndition'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 197, 'page_label': '192', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='192 Approximate Inference and Learning\\nis that the M-projection is obtained by moment matching. Speciﬁcally ,\\none needs to ﬁnd a value of parameter ϕ such that the expectations\\nof the suﬃcient statistics of the model q(z|ϕ) under distribution q(z|ϕ)\\nmatch with the same expectations under the true distributio n p(z|x).\\nIn mathematical terms, the M-projection in the exponential fam-\\nily model q(z|ϕ) ∝exp(ϕT u(z)), with suﬃcient statistics u(z), yields\\nnatural parameters ϕ∗ that satisfy the moment matching condition\\nEz∼p(z|x)[u(z)] = Ez∼q(z|ϕ ∗) [u(z)]. (8.14)\\nThis derivation is detailed in the Appendix of this chapter. Amortized\\ninference can be deﬁned in a similar way as for I-projection.\\n-3 -2 -1 0 1 2 3\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\nI-projection\\nM-projection\\nFigure 8.1: Example of I- and M-projections of a mixture of Gaussians dis tribution\\n(dashed line).\\nExample 8.2. This simple example is meant to provide an intuitive'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 197, 'page_label': '192', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.2\\n1.4\\nI-projection\\nM-projection\\nFigure 8.1: Example of I- and M-projections of a mixture of Gaussians dis tribution\\n(dashed line).\\nExample 8.2. This simple example is meant to provide an intuitive\\ncomparison between the approximations produced by I- and M- projections.\\nT o this end, consider a mixture of Gaussians distribution\\np(z|x) = 0 .3N(z|µ1 = −1,σ2\\n1 = 0 .3) + 0 .7N(z|µ2 = 1 ,σ2\\n2 = 0 .3),\\n(8.15)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 198, 'page_label': '193', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 193\\nas shown in Fig. 8.1. Note that this example is clearly idealized, since\\nin practice the conditional distribution p(z|x) is not known. Assume\\nthe variational distribution q(z|ϕ) = N(z|m,γ2 ) with variational pa-\\nrameters ϕ= ( m,γ2 ). The M-projection returns the moment matching\\nestimates m = Ez∼p(z|x)[z] = 0 .4 and γ2 = varz∼p(z|x)[z] = 0 .3((µ1 −\\nm)2 + σ2\\n1 ) + 0 .7((µ2 −m)2 + σ2\\n2 ) = 1 .93 for i = 1 ,2. Instead, the I-\\nprojection can be computed numerically , yielding m= 1 and γ2 = 0 .3.\\nThe I- and M-projections are also plotted in Fig. 8.1.\\nThe previous example illustrates a few important facts abou t I-\\nand M-projections. First, the I-projection tends to be mode-seeking\\nand exclusive. Mathematically , this is because the variational posterio r\\nq(z|ϕ) determines the support over which the distributions p(z|x) and\\nq(z|ϕ) are compared by the KL divergence. Therefore, I-projection s\\ntend to underestimate the variance of a distribution 2. F urthermore,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 198, 'page_label': '193', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='q(z|ϕ) are compared by the KL divergence. Therefore, I-projection s\\ntend to underestimate the variance of a distribution 2. F urthermore,\\nthe I-projection is generally more accurate where p(z|x) is larger. In\\ncontrast, the M-projection tends to be inclusive and to span the entire\\nsupport of p(z|x). This is because the M-projection prefers to avoid zero\\nvalues for q(z|ϕ) at values of z such that p(z|x) ̸= 0 in order to avoid\\nan inﬁnite KL divergence. W e refer to Fig. 6.5 for a related example.\\nα−Divergence.∗ As already discussed in Sec. 6.4.3, the KL diver-\\ngence is only one among many possible ways to deﬁne a measure o f\\ndistance between two distributions. A metric that has found useful ap-\\nplications in the context of VI is the α-divergence introduced in [ 96].\\nThe α-divergence between two distributions p(x) and q(x) is deﬁned as\\nDα (p||q) =\\n∑\\nx αp(x) + (1 −α)q(x) −p(x)α q(x)1−α\\nα(1 −α) , (8.16)\\nwhere p and q need not be normalized, and α is a parameter. It can'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 198, 'page_label': '193', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Dα (p||q) =\\n∑\\nx αp(x) + (1 −α)q(x) −p(x)α q(x)1−α\\nα(1 −α) , (8.16)\\nwhere p and q need not be normalized, and α is a parameter. It can\\nbe proved that, as α →0, we obtain Dα (p||q) = KL(q||p), and, when\\nα →1, we have Dα(p||q) = KL(p||q). Consistently with the discus-\\nsion about I- and M-projections in the previous example, per form-\\ning projections of the type min ϕDα (p(x|z)||q(z|ϕ)) with α ≤0 and\\ndecreasing values of α yields an increasingly mode-seeking, or exclu-\\nsive, solution; while increasing values of α ≥ 1 yield progressively\\n2 See [ 147] for an example that demonstrates the limitations of this ge neral state-\\nment.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 199, 'page_label': '194', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='194 Approximate Inference and Learning\\nmore inclusive and zero-avoiding solutions (see [ 96, Fig. 1]). Finally ,\\nfor all α ̸= 0 , it can be proved that the stationary points of the pro-\\njection min ϕDα(p(x|z)||q(z|ϕ)) coincide with those of the projection\\nminϕKL(p(x|z)||p(x|z)α q(z|ϕ)1−α ). The α-divergence can be further\\ngeneralized as discussed in Appendix A.\\n8.2.1 Mean Field Variational Inference\\nMean Field VI (MFVI) is a VI method that leads to a universal, o r\\nblack-box, Bayesian inference technique, such as Gibbs sam pling for\\nMC techniques. MFVI assumes the factorization q(z) = ∏\\nj q(zj ), and\\nperforms an I-projection iteratively for one hidden variab le zi at a time,\\nwhile ﬁxing the factors qj (zj ) for the other latent variables zj with j ̸= i.\\nNo constraints are imposed on each factor qj (zj ). This corresponds to\\ntackling the I-projection problem using block coordinate d escent within\\nthe given factorized family of distributions.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 199, 'page_label': '194', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='No constraints are imposed on each factor qj (zj ). This corresponds to\\ntackling the I-projection problem using block coordinate d escent within\\nthe given factorized family of distributions.\\nF or each factor qi(zi ), the I-projection problem minimizes the vari-\\national free energy\\n−Ezi ∼qi(zi ) [Ej̸=i[lnp(x,z)]] −\\n∑\\nj\\nH(qj (zj )), (8.17)\\nwhere we have deﬁned for brevity the expectation\\nEj̸=i[lnp(x,z)] = E{zj }j̸=i ∼\\n∏\\nj̸=i qj (zj )[lnp(x,zi ,{zj }j̸=i)]. (8.18)\\nNeglecting constants independent of qi(zi ), this problem is equivalent\\nto the minimization\\nminqi\\nKL(qi(zi )||exp(Ej̸=i[lnp(x,z)])). (8.19)\\nThe solution to this problem can be easily seen to be obtained by\\nnormalizing the right-hand argument of the divergence as\\nqi(zi) = exp(Ej̸=i[lnp(x,z)])\\n∑\\nzi exp(Ej̸=i[lnp(x,z)]) . (8.20)\\nMFVI solves the system of equations ( 8.20) for all i by cycling\\nthrough the factors qi(zi ) or by choosing them randomly . Note that, as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 200, 'page_label': '195', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 195\\ndiscussed more generally above, this procedure does not req uire knowl-\\nedge of the desired posterior p(z|x) but only of the joint distribution\\np(x,z). The MFVI iterations are guaranteed to converge to a station ary\\npoint of the KL minimization problem.\\nIt remains to discuss how to evaluate the expectations in ( 8.20). T o\\nthis end, let us assume that the joint distribution p(x,z) factorizes as\\np(x,z) = Z−1 ∏\\nc ψc(xc,zc) as for MRF s or BNs – recall that in the\\nlatter case, we have Z = 1 . The MFVI equation ( 8.20) can be written\\nas\\nqi(zi ) ∝exp\\n(\\nEj̸=i\\n[∑\\nc\\nlnψc(xc,zc)\\n])\\n= exp\\n(\\nEj̸=i\\n[ ∑\\nc: zi ∈ zc\\nlnψc(xc,zc)\\n])\\n.\\n(8.21)\\nIn the second line we have used the fact that it is suﬃcient to c onsider\\nonly the factors corresponding to cliques that include zi. This enables\\nimplementations by means of local message passing (see, e.g ., [ 81]).\\nF urthermore, additional simpliﬁcations are possible when the factors'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 200, 'page_label': '195', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='implementations by means of local message passing (see, e.g ., [ 81]).\\nF urthermore, additional simpliﬁcations are possible when the factors\\nψc(xc,zc) are log-linear, as illustrated by the next example.\\n0 1 2 3 4\\nnumber of iterations\\n10-4\\n10-2\\n100\\nKL divergence\\nFigure 8.2: KL divergence between actual posterior and mean-ﬁeld appro ximation\\nas a function of the number of iterations of MFVI ( η1 = 0 .15).\\nExample 8.3. Consider again the Ising model ( 8.4). The MFVI equa-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 201, 'page_label': '196', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='196 Approximate Inference and Learning\\ntions ( 8.21) for approximating the posterior p(z|x) are given as\\nqi(zi ) ∝exp\\n(\\nη1\\n∑\\n{i,j }\\nEzj ∼q(zj )[zi zj ] + η2 xizi\\n)\\n= exp\\n(\\nzi\\n(\\nη1\\n∑\\n{i,j }\\nEzj ∼q(zj )[zj ] + η2xi\\n))\\n,\\n(8.22)\\nand hence, upon normalization, we have\\nqi(zi = 1) = 1\\n1 + exp( −2(η1\\n∑\\n{i,j } µj + η2 xi)) , (8.23)\\n= σ\\n\\uf8eb\\n\\uf8ed2\\n\\uf8eb\\n\\uf8edη1\\n∑\\n{i,j }\\nµj + η2xi\\n\\uf8f6\\n\\uf8f8\\n\\uf8f6\\n\\uf8f8,\\nwhere µi = qi(zi = 1) −qi(zi = −1) = 2 qi(zi = 1) −1.\\nF or a numerical example, consider a 4 ×4 binary image z observed\\nas matrix x, where the joint distribution of x and z is given by the\\nIsing model. Note that, according to this model, the observe d matrix x\\nis such that each pixel of the original matrix z is ﬂipped independently\\nwith probability σ(−2η2 ). In this small example, it is easy to generate\\nan image x distributed according to the model, as well as to compute\\nthe exact posterior p(z|x) by enumeration of all possible images z. The\\nKL divergence KL (p(x|z)||∏\\ni qi(zi)) obtained at the end of each iter-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 201, 'page_label': '196', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the exact posterior p(z|x) by enumeration of all possible images z. The\\nKL divergence KL (p(x|z)||∏\\ni qi(zi)) obtained at the end of each iter-\\nation of MFVI – with one iteration applying (\\n8.23) one by one to all\\nvariables – is shown in Fig. 8.2 for η1 = 0 .15 and various values of η2 .\\nAs η2 increases, the posterior distribution tends to become dete rminis-\\ntic, since x is an increasingly accurate measurement of z. As a result,\\nthe ﬁnal mean-ﬁeld approximation is more faithful to the rea l poste-\\nrior, since a product distribution can capture a determinis tic pmf. F or\\nsmaller values of η2 ,however, the bias due to the mean-ﬁeld assumption\\nyields a signiﬁcant ﬂoor on the achievable KL divergence.\\nBeyond MFVI. ∗ MFVI assumes a fully factorized variational dis-\\ntribution q(z). It is also possible to develop methods that are based on\\nthe same factorization as the joint distribution p(x,z). This is known\\nas the Bethe approach , and yields Loopy Belief Propagation (LBP) as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 201, 'page_label': '196', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the same factorization as the joint distribution p(x,z). This is known\\nas the Bethe approach , and yields Loopy Belief Propagation (LBP) as\\na speciﬁc solution technique. LBP can also be interpreted as the ap-\\nplication of message passing belief propagation, which was described'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 202, 'page_label': '197', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.3. Monte Carlo-Based Variational Inference ∗ 197\\nin Sec. 7.4, to factor graphs with loops. Simpliﬁcations of loopy belie f\\npropagation include Approximate Message Passing (AMP). Wh en ap-\\nplied to M-projections with factors restricted to lie in the exponential\\nfamily , the approach yields the Expectation Propagation method. W e\\nrefer to [ 81, 114] for details.\\n8.3 Monte Carlo-Based Variational Inference ∗\\nThe VI methods described in the previous section require the evalua-\\ntion of expectations with respect to the variational poster ior (see, e.g.,\\n(8.20)). The feasibility of this operation relies on speciﬁc assu mptions\\nabout the variational posterior, such as its factorization properties and\\nmembership of the exponential family . It is hence desirable to devise\\nmethods that do not require the exact computation of the ense mble\\naverages with respect to the variational posterior q(z|ϕ). As we will\\nsee below, this is possible by combining VI methods with MC ap proxi-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 202, 'page_label': '197', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='averages with respect to the variational posterior q(z|ϕ). As we will\\nsee below, this is possible by combining VI methods with MC ap proxi-\\nmations. The resulting methods can leverage SGD, scale to la rge data\\nsets, and have found a large number of recent applications [ 24, 25, 7].\\nThe key idea of MC-based VI is to approximate the KL divergenc e\\n(8.10) via MC by drawing one or more samples zm ∼q(z), with m =\\n1,...,M , and by computing the empirical average\\nKL(q(z)||p(x,z)) ≃ 1\\nM\\nM∑\\nm=1\\n(lnq(zm) −ln p(x,zm)). (8.24)\\nIn order to optimize over the parameters ϕof the variational posterior\\nq(z|ϕ), it is in fact more useful to approximate the gradient of the K L\\ndivergence, as discussed next.\\nREINFORCE approach. T o proceed, assume the following two\\nrather mild conditions on the parametrized variational pos terior: ( i ) it\\nis easy to draw samples z ∼q(z|ϕ); and ( ii ) it is possible to compute\\nthe gradient ∇ϕlnq(z|ϕ). W e can now develop an SGD-based scheme as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 202, 'page_label': '197', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is easy to draw samples z ∼q(z|ϕ); and ( ii ) it is possible to compute\\nthe gradient ∇ϕlnq(z|ϕ). W e can now develop an SGD-based scheme as\\nfollows. The main result is that the gradient of the KL diverg ence in the\\nI-projection problem ( 8.11) with respect to the variational parameters\\nϕ can be written as\\n∇ϕKL(q(z|ϕ)||p(x,z)) = Ez∼q(z|ϕ) [∇ϕlnq(z|ϕ)lϕ (x,z)] , (8.25)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 203, 'page_label': '198', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='198 Approximate Inference and Learning\\nwhere we have deﬁned the learning signal\\nlϕ (x,z) = lnq(z|ϕ) −lnp(x,z). (8.26)\\nT o obtain ( 8.25), we have used the identity ∇ϕlnq(z|ϕ) = ∇ϕq(z|ϕ)/q(z|ϕ),\\nwhich follows from the chain rule for diﬀerentiation, as wel l as the equal-\\nity E z∼q(z|ϕ) [∇ϕlnq(z|ϕ)] = 0 (see [ 25] for details).\\nMC-based VI methods evaluate an MC approximation of the grad i-\\nent ( 8.25) at a given value ϕby drawing one or more samples zm ∼q(z|ϕ),\\nwith m= 1 ,...,M , and then computing\\n∇ϕKL(q(z|ϕ)||p(x,z)) ≃ 1\\nM\\nM∑\\nm=1\\n[∇ϕlnq(zm|ϕ)lϕ (x,zm)] . (8.27)\\nThis estimate is also known as likelihood ratio or REINFORCE gradi-\\nent, and it can be used to update the value of ϕ using SGD (see Sec.\\n4.1). The name reﬂects the origin and the importance of the appro ach\\nin the reinforcement learning literature, as we brieﬂy disc uss in Chapter\\n93\\nIn practice, these gradients have high variance. This is int uitively\\ndue to the fact that this estimator does not use any informati on about'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 203, 'page_label': '198', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='93\\nIn practice, these gradients have high variance. This is int uitively\\ndue to the fact that this estimator does not use any informati on about\\nhow a change in z aﬀects the learning signal lϕ (x,z), since it only\\ndepends on the value of this signal. Therefore, techniques s uch as Rao-\\nBlackwellization or control variates need to be introduced in order to\\nreduce its variance (see [ 89] for a review). Simpliﬁcations are possible\\nwhen the variational posterior is assumed to factorize, e.g ., according to\\nthe mean-ﬁeld full factorization. This approach is used in t he black-box\\ninference method of [ 120].\\nReparametrization trick. In order to mitigate the problem of\\nthe high variance of the REINFORCE estimator, the reparamet riza-\\ntion trick leverage additional information about the depen dence of the\\nvariational distribution q(z|ϕ),and hence of the learning signal lϕ(x,z),\\non the variable z. This approach is applicable if: ( i ) the latent variable'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 203, 'page_label': '198', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='variational distribution q(z|ϕ),and hence of the learning signal lϕ(x,z),\\non the variable z. This approach is applicable if: ( i ) the latent variable\\nz ∼q(z|ϕ) can be written as z = Gϕ (w) for some diﬀerentiable function\\n3 In reinforcement learning, it is useful to compute the gradi ent of the average\\nreward E t∼q(t|x,ϕ ) [R(t, x )] with respect to the parameters ϕ deﬁning the distribution\\nq(t|x, ϕ ) of the action t given the current state x of the environment. The reward\\nR(t, x ) is a function, possibly stochastic, of the action and of the state.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 204, 'page_label': '199', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.4. Approximate Learning ∗ 199\\nGϕ(·) and for some rv w ∼s(z) whose distribution does not depend on\\nϕ; and ( ii ) the variational regularization term KL (q(z|ϕ)||p(z)) in ( 6.12)\\ncan be computed and diﬀerentiated with respect to ϕ. Assumption ( ii )\\nis satisﬁed by members of the exponential family (see Append ix B). A\\ntypical choice that satisﬁes these conditions is to set p(z) to be an i.i.d.\\nGaussian distribution; w as i.i.d. Gaussian rvs; and function Gϕ(w) as\\nGϕ(w) = Aϕw+ bϕ, where matrix Aϕ and vector bϕ are parametrized\\nby a multi-layer neural networks. Note that, with this choic e, we have\\nq(z|ϕ) = N(z|bϕ ,AϕAT\\nϕ ). W e refer to [\\n73, 95] for other examples.\\nT o see why these assumptions are useful, let us ﬁrst rewrite t he\\nobjective of the I-projection problem using ( 6.12) as\\nKL(q(z|ϕ)||p(x,z)) = −Ew∼s(z) [lnp(x|Gϕ (w))] + KL(q(z|ϕ)||p(z)).\\n(8.28)\\nW e can now approximate the expectation in the ﬁrst term via an em-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 204, 'page_label': '199', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='objective of the I-projection problem using ( 6.12) as\\nKL(q(z|ϕ)||p(x,z)) = −Ew∼s(z) [lnp(x|Gϕ (w))] + KL(q(z|ϕ)||p(z)).\\n(8.28)\\nW e can now approximate the expectation in the ﬁrst term via an em-\\npirical average by generating i.i.d. samples wm ∼s(w), m= 1 ,...,M 4 .\\nNote that this distribution does not depend on the current it erate ϕ.\\nW e can then estimate the gradient by writing\\n∇ϕKL(q(z|ϕ)||p(x,z)) ≃− 1\\nM\\nM∑\\nm=1\\n[∇ϕlnp(x|Gϕ (wm))]+∇ϕKL(q(z|ϕ)||p(z)).\\n(8.29)\\nThis approach tends to provide estimate with lower variance than the\\nREINFORCE gradient, since it exploits the structure of the d istribu-\\ntion q(z|ϕ).\\nBoth REINFORCE and reparametrization trick can be naturall y\\ncombined with amortized inference. W e also refer to [ 59] for a proposed\\ncombination of both methods.\\n8.4 Approximate Learning ∗\\nAs we have discussed, Bayesian inference plays a key role in l earning\\nproblems. In this section, we brieﬂy discuss representativ e schemes that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 204, 'page_label': '199', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.4 Approximate Learning ∗\\nAs we have discussed, Bayesian inference plays a key role in l earning\\nproblems. In this section, we brieﬂy discuss representativ e schemes that\\nincorporate approximate inference for learning. Since Bay esian learning\\n4 This can be seen as an application of the Law of the Unconsciou s Statistician.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 205, 'page_label': '200', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='200 Approximate Inference and Learning\\ncan directly beneﬁt from approximate inference in evaluati ng the pos-\\nterior of the parameters and the variational posterior, we f ocus here on\\nthe frequentist viewpoint.\\nML learning in the presence of hidden variables can be approx i-\\nmated by maximizing the ELBO with respect to both the model pa -\\nrameters θ that deﬁne the forward model p(x|z,θ) and the parameters\\nϕ of the variational (amortized) model q(z|x,ϕ). T o understand what\\nis accomplished with this optimization, it is useful to writ e the ELBO\\nover a data set D={xn}N\\nn=1 using (\\n6.14) as\\nN∑\\nn=1\\nln p(xn|θ) −KL (q(z|xn ,ϕ)||p(z|xn ,θ)) . (8.30)\\nAs such, for any ﬁxed ϕ, optimizing the ELBO over θ maximizes the\\nlikelihood function in the ﬁrst term under a variational reg ularization\\nterm that penalizes posteriors p(z|x,θ) that are signiﬁcantly diﬀerent\\nfrom the selected variational posteriors q(z|x,ϕ). The choice of a given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 205, 'page_label': '200', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='term that penalizes posteriors p(z|x,θ) that are signiﬁcantly diﬀerent\\nfrom the selected variational posteriors q(z|x,ϕ). The choice of a given\\nmodel for the variational posterior hence drives learning, and should\\nbe treated as model or hyperparameter selection [ 68].\\nThe maximization of the ELBO over both model and variational\\nparameters can be carried out in diﬀerent ways. As a ﬁrst appr oach,\\none can use EM by performing the E step via approximate infere nce\\nto evaluate the posterior of the latent variables. When VI is used for\\nthis purpose, the resulting scheme is known as variational EM . Alterna-\\ntively , one can use SGD with respect to both parameter vector s θand ϕ\\nby leveraging the REINFORCE method or the reparametrizatio n trick.\\nThe reparametrization trick approach is for instance used i n the V AE\\nmethod for generative modelling [ 80], also known as Deep Gaussian\\nLatent Models [ 122], as well as in the black-box learning approach of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 205, 'page_label': '200', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='method for generative modelling [ 80], also known as Deep Gaussian\\nLatent Models [ 122], as well as in the black-box learning approach of\\n[121] (see also [ 98]). The KL divergence can also be substituted by an\\nadversarially learned divergence as in the GAN approach [ 47] (see Sec.\\n6.4.3).\\nWhen the variational parameters are updated using an M-proj ection,\\nrather than the I-projection that results from the maximiza tion of the\\nELBO, the approach of jointly optimizing model and variatio nal pa-\\nrameters yields the wake-sleep algorithm [65].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 206, 'page_label': '201', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.5. Summary 201\\n8.5 Summary\\nHaving observed in previous chapters that learning in proba bilistic mod-\\nels is often held back by the complexity of exact Bayesian inf erence for\\nhidden variables, this chapter has provided an overview of a pproximate,\\nlower-complexity , inference techniques. W e have focused o n MC and VI\\nmethods, which are most commonly used. The treatment stress ed the\\nimpact of design choices in the selection of diﬀerent types o f approxi-\\nmation criteria, such as M- and I-projection. It also covere d the use of\\napproximate inference in learning problems. T echniques th at improve\\nover the state of the art discussed in this chapter are being a ctively\\ninvestigated. Some additional topics for future research a re covered in\\nthe next chapter.\\nAppendix: M-Projection with the Exponential Family\\nIn this appendix, we consider the problem of obtaining the M- projection\\nof a distribution p(z) into a model q(z|ϕ) = Z(ϕ)−1 exp(ϕT u(z)) from'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 206, 'page_label': '201', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Appendix: M-Projection with the Exponential Family\\nIn this appendix, we consider the problem of obtaining the M- projection\\nof a distribution p(z) into a model q(z|ϕ) = Z(ϕ)−1 exp(ϕT u(z)) from\\nthe exponential family with suﬃcient statistics u(z). W e will prove\\nthat, if there exists a value of ϕ∗ of the natural parameter vector that\\nsatisﬁes the moment matching condition (\\n8.14), then q(z|ϕ∗ ) is the\\nM-projection.\\nW e ﬁrst write the KL divergence as\\nKL(p(z)||q(z|ϕ)) = lnZ(ϕ) −ϕT Ez∼p(z)[u(z)] −H(p). (8.31)\\nThe diﬀerence between the KL divergence for a generic parame ter vec-\\ntor ϕand for the vector ϕ∗ satisfying ( 8.14) can be written as\\nKL(p(z)||q(z|ϕ)) −KL(p(z)||q(z|ϕ∗ ))\\n=ln\\n( Z(ϕ)\\nZ(ϕ∗ )\\n)\\n−(ϕ−ϕ∗ )T Ez∼p(z)[u(z)]\\n=Ez∼q(z|ϕ∗)\\n[\\nln\\n( q(z|ϕ∗ )\\nq(z|ϕ)\\n) ]\\n=KL(q(z|ϕ∗ )||q(z|ϕ)). (8.32)\\nSince the latter inequality is non-negative and equal to zer o when ϕ=\\nϕ∗ ,this choice of the natural parameters minimizes the KL diver gence.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 207, 'page_label': '202', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part V\\nConclusions'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 208, 'page_label': '203', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='9\\nConcluding Remarks\\nThis monograph has provided a brief introduction to machine learn-\\ning by focusing on parametric probabilistic models for supe rvised and\\nunsupervised learning problems. It has endeavored to descr ibe funda-\\nmental concepts within a uniﬁed treatment starting from ﬁrs t princi-\\nples. Throughout the text, we have also provided pointers to advanced\\ntopics that we have only been able only to mention or shortly t ouch\\nupon. Here, we oﬀer a brief list of additional important aspe cts and\\nopen problems that have not been covered in the preceding cha pters.\\n•Privacy: In many applications, data sets used to train machine\\nlearning algorithms contain sensitive private informatio n, such as per-\\nsonal preferences for recommendation systems. It is hence i mportant to\\nensure that the learned model does not reveal any informatio n about\\nthe individual entries of the training set. This constraint can be for-\\nmulated using the concept of diﬀerential privacy . Typical t echniques'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 208, 'page_label': '203', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the individual entries of the training set. This constraint can be for-\\nmulated using the concept of diﬀerential privacy . Typical t echniques\\nto guarantee privacy of individual data points include addi ng noise to\\ngradients when training via SGD and relying on mixture of exp erts\\ntrained with diﬀerent subsets of the data [ 1].\\n•Robustness: It has been reported that various machine learning\\nmodels, including neural networks, are sensitive to small v ariations in\\n203'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 209, 'page_label': '204', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='204 Concluding Remarks\\nthe data, producing the wrong response upon minor, properly chosen,\\nchanges in the explanatory variables. Note that such advers arially cho-\\nsen examples, which cause a speciﬁc machine to fail, are conc eptually\\ndiﬀerent from the randomly selected examples that are assum ed when\\ndeﬁning the generalization properties of a network. There i s evidence\\nthat ﬁnding such examples is possible even without knowing t he inter-\\nnal structure of a machine, but solely based on black-box obs ervations\\n[111]. Modifying the training procedure in order to ensure robus tness\\nto adversarial examples is an active area of research with im portant\\npractical implications [ 55].\\n•Computing platforms and programming frameworks : In order to\\nscale up machine learning applications, it is necessary to l everage dis-\\ntributed computing architectures and related standard pro gramming\\nframeworks [ 17, 7]. As a complementary and more futuristic approach,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 209, 'page_label': '204', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tributed computing architectures and related standard pro gramming\\nframeworks [ 17, 7]. As a complementary and more futuristic approach,\\nrecent work has even proposed to leverage the capabilities o f annealing-\\nbased quantum computers as samplers [ 82] or discrete optimizers [ 103].\\n•T ransfer learning : Machines trained for a certain task currently\\nneed to be re-trained in order to be re-purposed for a diﬀeren t task.\\nF or instance, a machine that learned how to drive a car would n eed to\\nbe retrained in order to learn how to drive a truck. The ﬁeld of transfer\\nlearning covers scenarios in which one wishes to transfer th e expertise\\nacquired from some tasks to others. T ransfer learning inclu des diﬀerent\\nrelated paradigms, such as multitask learning, lifelong le arning, zero-\\nshot learning, and domain adaptation [ 149]. In multitask learning , sev-\\neral tasks are learned simultaneously . Typical solutions f or multitask'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 209, 'page_label': '204', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='shot learning, and domain adaptation [ 149]. In multitask learning , sev-\\neral tasks are learned simultaneously . Typical solutions f or multitask\\nlearning based on neural networks prescribe the presence of common\\nhidden layers among neural networks trained for diﬀerent ta sks [ 19].\\nLifelong learning updates a machine trained on a number of tasks to\\ncarry out a new task by leveraging the knowledge accumulated during\\nthe previous training phases [ 143]. Zero-shot learning refers to models\\ncapable of recognizing unseen classes with training exampl es available\\nonly for related, but diﬀerent, classes. This often entails the task of\\nlearning representation of classes, such as prototype vect ors, that gen-\\nerate data in the class through a ﬁxed probabilistic mechani sm [ 52].\\nDomain adaptation will be discussed separately in the next p oint.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 210, 'page_label': '205', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='205\\n• Domain adaptation : In many learning problems, the available\\ndata has a diﬀerent distribution from the data on which the al gorithm\\nwill be tested. F or instance, in speech recognition, one has available\\ndata for a given user at learning time, but it may be desirable , after\\nlearning, to use the same machine for another user. F or super vised\\nlearning, this is typically modeled by assuming that the dis tribution of\\nthe covariates x is diﬀerent during training and test, while the discrim-\\ninative conditional distribution p(t|x) is the same for both phases [ 149].\\nA generalization of P AC theory analyses domain adaptation, obtaining\\nbounds on the generalization error under the desired test di stribution\\nas a function of the diﬀerence between the training and test d istribu-\\ntions [ 26].\\n•Communication-eﬃcient learning : In distributed computing plat-\\nforms, data is typically partitioned among the processors a nd commu-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 210, 'page_label': '205', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tions [ 26].\\n•Communication-eﬃcient learning : In distributed computing plat-\\nforms, data is typically partitioned among the processors a nd commu-\\nnication among the processor entails latency and energy con sumption.\\nAn important research problem is that of characterizing the best trade-\\noﬀ between learning performance and communication overhea d [ 160].\\n•Reinforcement learning : Reinforcement learning is at the heart\\nof recent successes of machine learning methods in acquirin g the skills\\nnecessary to play video games or games against human opponen ts (see,\\ne.g., [ 99]). In reinforcement learning, one wishes to learn the optim al\\nmapping, say q(t|x,θ), between the observed state xof the world and an\\naction t. Unlike supervised learning, the optimal action tis not known,\\nbut the machine observes a reward/ punishment signal depend ing on\\nthe eﬀect of the action. A popular approach, referred to as de ep rein-\\nforcement learning, models the mapping q(t|x,θ) using a deep neural'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 210, 'page_label': '205', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the eﬀect of the action. A popular approach, referred to as de ep rein-\\nforcement learning, models the mapping q(t|x,θ) using a deep neural\\nnetwork. This is trained to maximize the average reward via S GD by\\nusing the REINFORCE method (Chapter 8) to estimate the gradi ent\\n[135, 88, 77, 9].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 211, 'page_label': '206', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Appendices'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 212, 'page_label': '207', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A\\nAppendix A: Information Measures\\nIn this appendix, we describe a principled and intuitive int roduction to\\ninformation measures that builds on inference, namely esti mation and\\nhypothesis testing. W e focus on entropy , mutual informatio n and diver-\\ngence measures. W e also concentrate on discrete rvs. In the m onograph,\\nwe have taken the pragmatic approach of extending the deﬁnit ions to\\ncontinuous variables by substituting sums with integrals. It is worth\\nnoting that this approach does not come with any practical co mplica-\\ntions when dealing with mutual information and divergence. Instead,\\nthe continuous version of the entropy , known as diﬀerential entropy ,\\nshould be treated with care, as it does not satisfy some key pr operties\\nof the entropy such as non-negativity .\\nA.1 Entropy\\nAs proposed by Claude Shannon, the amount of information rec eived\\nfrom the observation of a discrete random variable x ∼p(x) deﬁned over'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 212, 'page_label': '207', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of the entropy such as non-negativity .\\nA.1 Entropy\\nAs proposed by Claude Shannon, the amount of information rec eived\\nfrom the observation of a discrete random variable x ∼p(x) deﬁned over\\na ﬁnite alphabet Xshould be measured by the amount of uncertainty\\nabout its value prior to its measurement [\\n134]. T o this end, we consider\\nthe problem of estimating the value of x when one only knows the\\n207'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 213, 'page_label': '208', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='208 Appendix A: Information Measures\\nprobabilistic model p(x). The key idea is that the observation of a\\nrandom variable x is more informative if its value is more diﬃcult to\\npredict a priori, that is, based only on the knowledge of p(x).\\nT o formalize this notion, we need to specify: ( i ) the type of estimates\\nthat one is allowed to make on the value of x; and ( ii ) the loss function\\nℓthat is used to measure the accuracy of the estimate. W e will p roceed\\nby considering two types of estimates, namely point estimates , whereby\\none needs to commit to a speciﬁc value ˆx as the estimate of x; and\\ndistributional estimates , in which instead we are allowed to produce a\\npmf ˆp(x) over alphabet X, hence deﬁning a proﬁle of \"beliefs\" over the\\npossible values of rv x. W e will see below that the second approach\\nyields Shannon entropy , ﬁrst encountered in this monograph in ( 2.45).\\nPoint Estimates. Given a point estimate ˆxand an observed value'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 213, 'page_label': '208', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='yields Shannon entropy , ﬁrst encountered in this monograph in ( 2.45).\\nPoint Estimates. Given a point estimate ˆxand an observed value\\nx∈X, as we have seen, the estimation error can be measured by a non -\\nnegative loss function ℓ(x,ˆx), such the quadratic loss function and the\\n0-1 loss function. F or any given loss function ℓ, based on the discussion\\nabove, we can measure the information accrued by the observa tion\\nof x ∼px by evaluating the average loss that is incurred by the best\\npossible a priori estimate of x. This leads to the deﬁnition of generalized\\nentropy [ 61]\\nHℓ(px ) = min\\nˆx\\nEx∼px [ℓ(x,ˆx)], (A.1)\\nwhere the estimate ˆx is not necessarily constrained to lie in the alpha-\\nbet X. As highlighted by the notation Hℓ(px ), the generalized entropy\\ndepends on the pmf px and on the loss function ℓ. The notion of gen-\\neralized entropy ( A.1) coincides with that of minimum Bayes risk for\\nthe given loss function ℓ.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 213, 'page_label': '208', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='depends on the pmf px and on the loss function ℓ. The notion of gen-\\neralized entropy ( A.1) coincides with that of minimum Bayes risk for\\nthe given loss function ℓ.\\nF or the quadratic loss function, the generalized entropy is the vari-\\nance of the distribution Hℓ2 (px ) = var(px ). T o see this, impose the\\noptimality condition dE[(x −ˆx)2 ]/dˆx = 0 to conclude that the opti-\\nmal point estimate is the mean ˆx = Ex∼px [x]. As for the 0-1 loss, the\\ngeneralized entropy equals the minimum probability of erro r for the\\ndetection of x, that is,\\nHℓ0 (px ) = min\\nˆx\\n∑\\nx̸=ˆx\\np(x) = 1 −max\\nˆx\\np(ˆx). (A.2)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 214, 'page_label': '209', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A.1. Entropy 209\\nThis is because the optimal estimate is the mode, i.e., the va lue ˆxwith\\nthe largest probability p(ˆx).\\nDistributional Estimate. W e now consider a diﬀerent type of\\nestimation problem in which we are permitted to choose a pmf ˆp(x)\\non the alphabet X as the estimate for the outcome of variable x. T o\\nfacilitate intuition, we can imagine ˆp(x) to represent the fraction of\\none’s wager that is invested on the outcome of x being a speciﬁc value\\nx. Note that it may not be necessarily optimal to put all of one’ s money\\non one value x! In fact, this depends on how we measure the reward,\\nor conversely the cost, obtained when a value x = x is realized.\\nT o this end, we deﬁne a non-negative loss function ℓ(x,ˆpx ) repre-\\nsenting the loss, or the “negative gain”, suﬀered when the va lue x = x\\nis observed. This loss should sensibly be a decreasing funct ion of ˆp(x)\\n– we register a smaller loss, or conversely a larger gain, whe n we have'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 214, 'page_label': '209', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is observed. This loss should sensibly be a decreasing funct ion of ˆp(x)\\n– we register a smaller loss, or conversely a larger gain, whe n we have\\nwagered more on the actual outcome x. As a fairly general class of loss\\nfunctions, we can hence deﬁne\\nℓ(x,ˆpx ) = f( ˆp(x)), (A.3)\\nwhere f is a decreasing function. More general classes of loss funct ions\\nare considered in [ 46].\\nDenote as ∆( X) the simplex of pmfs deﬁned over alphabet X. The\\ngeneralized entropy can now be deﬁned in a way that is formall y equiv-\\nalent to ( A.1), with the only diﬀerence being the optimization over pmf\\nˆpx rather than over point estimate ˆx:\\nHℓ(px ) = min\\nˆpx∈∆( X )\\nEx∼px [ℓ(x,ˆpx )]. (A.4)\\nA key e xample of loss function ℓ(x,ˆpx ) in class ( A.3) is the log-loss\\nℓ(x,ˆpx ) = −log ˆp(x). The log-loss has a strong motivation in terms of\\nlossless compression. In fact, as discussed in Sec. 2.5, by Kraft’s inequal-\\nity , it is possible to design a preﬁx-free – and hence decodab le without'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 214, 'page_label': '209', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='lossless compression. In fact, as discussed in Sec. 2.5, by Kraft’s inequal-\\nity , it is possible to design a preﬁx-free – and hence decodab le without\\ndelay – lossless compression scheme that uses ⌈−log ˆp(x)⌉bits to repre-\\nsent value x. As a result, the choice of a pmf ˆpx is akin to the selection\\nof a preﬁx-free lossless compression scheme that requires a description\\nof around −ln ˆp(x) bits to represent value x. The expectation in ( A.4)\\nmeasures the corresponding average number of bits required for lossless\\ncompression by the given scheme.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 215, 'page_label': '210', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='210 Appendix A: Information Measures\\nUsing the log-loss in ( A.1), we obtain the Shannon entropy\\nmin\\nˆpx∈∆( X )\\nEx∼px [−ln ˆp(x)], (A.5)\\n= Ex∼px [−lnp(x)] = H(px ). (A.6)\\nIn fact, imposing the optimality condition yields the optim al pmf ˆp(x)\\nas ˆp(x) = p(x). Equation ( A.5) reveals that the entropy H(px ) is the\\nminimum average log-loss when optimizing over all possible pmfs ˆpx.\\nIt may seem at ﬁrst glance that the choice ˆp(x) = p(x) should be\\noptimal for most reasonable loss functions in class ( A.3), but this is not\\nthe case. In fact, when the alphabet Xhas more than two elements, it\\ncan be proved that the log-loss – more generally deﬁned as ℓ(x,ˆpx ) =\\nblog ˆp(x) + c with b ≤0 and any c – is the only loss function of the\\nform ( A.3) for which ˆp(x) = p(x) is optimal [ 74].\\nAs a ﬁnal note, the generalized entropy Hℓ(px ) is a concave function\\nof px , which means that we have the inequality Hℓ(λpx + (1 −λ)qx ) ≥\\nλHℓ(px ) + (1 −λ)Hℓ(qx ) for any two distributions px and qx and any'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 215, 'page_label': '210', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of px , which means that we have the inequality Hℓ(λpx + (1 −λ)qx ) ≥\\nλHℓ(px ) + (1 −λ)Hℓ(qx ) for any two distributions px and qx and any\\n0 ≤λ≤1. This follows from the fact that the entropy is the minimum\\nover a family of linear functionals of px [28]. The concavity of Hℓ(px )\\nimplies that a variable x ∼λpx + (1 −λ)qx distributed according to the\\nmixture of two distributions is more “random”, i.e., it is mo re diﬃcult\\nto estimate, than both variables x ∼px and x ∼qx .\\nA.2 Conditional Entropy and Mutual Information\\nGiven two random variables x and y jointly distributed according to\\na known probabilistic model p(x,y), i.e., (x,y) ∼pxy, we now discuss\\nhow to quantify the information that the observation of one v ariable,\\nsay y, brings about the other, namely x. F ollowing the same approach\\nadopted above, we can distinguish two inferential scenario s for this\\npurpose: in the ﬁrst, a point estimate ˆx(y) of x needs to be produced'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 215, 'page_label': '210', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='adopted above, we can distinguish two inferential scenario s for this\\npurpose: in the ﬁrst, a point estimate ˆx(y) of x needs to be produced\\nbased on the observation of a value y = y and the knowledge of the\\njoint pmf pxy; while, in the second, we are allowed to choose a pmf\\nˆpx|y=y as the estimate of x given the observation y = y.\\nPoint Estimate : Assuming point estimates and given a loss function\\nℓ(x,ˆx), the generalized conditional entropy for an observation y = y is'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 216, 'page_label': '211', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A.2. Conditional Entropy and Mutual Information 211\\ndeﬁned as the minimum average loss\\nHℓ(px|y=y ) = min\\nˆx(y)\\nEx∼px|y=y [ℓ(x,ˆx(y))|y = y]. (A.7)\\nNote that this deﬁnition is consistent with ( A.1) as applied to the con-\\nditional pmf px|y=y . A veraging over the distribution of the observation\\ny yields the generalized conditional entropy\\nHℓ(x|y) = Ey∼py [Hℓ(px|y )]. (A.8)\\nIt is emphasized that the generalized conditional entropy d epends on\\nthe joint distribution pxy, while ( A.7) depends only on the conditional\\npmf px|y=y .\\nF or the squared error, the generalized conditional entropy can be\\neasily seen to be the average conditional variance Hℓ2 (x|y) = Ey∼py [var(px|y)],\\nsince the a posteriori mean ˆx(y) = Ex∼px|y=y [x|y = y] is the optimal\\nestimate. F or the 0-1 loss, the generalized conditional ent ropy Hℓ0 (x|y)\\nis instead equal to the minimum probability of error for the d etection\\nof x given y and the MAP estimate ˆx(y) = argmaxˆx∈x p(ˆx|y) is optimal.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 216, 'page_label': '211', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is instead equal to the minimum probability of error for the d etection\\nof x given y and the MAP estimate ˆx(y) = argmaxˆx∈x p(ˆx|y) is optimal.\\nDistributional Estimate : Assume now that we are allowed to choose\\na pmf ˆpx|y=y as the estimate of x given the observation y = y, and that\\nwe measure the estimation loss via a function ℓ(x,ˆpx ) as in ( A.3). The\\ndeﬁnition of generalized conditional entropy for a given va lue of y = y\\nfollows directly from the arguments above and is given as Hℓ(px|y=y ),\\nwhile the generalized conditional entropy is ( A.8). With the log-loss\\nfunction, the deﬁnition above can be again seen to coincide w ith Shan-\\nnon conditional entropy H(x|y) = Ex,y∼px, y [ −ln p(x|y)].\\nIf x and y are independent, we have the equality Hℓ(x|y) = Hℓ(x).\\nF urthermore, since in ( A.7) we can always choose estimates that are\\nindependent of y, we generally have the inequality Hℓ(x|y) ≤Hℓ(x):\\nobserving y, on average, can only decrease the entropy . Note, however,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 216, 'page_label': '211', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='independent of y, we generally have the inequality Hℓ(x|y) ≤Hℓ(x):\\nobserving y, on average, can only decrease the entropy . Note, however,\\nthat it is not true that Hℓ(px|y=y ) is necessarily smaller than Hℓ(x) [38].\\nMutual Information : The inequality Hℓ(x|y) ≤Hℓ(x) justiﬁes the\\ndeﬁnition of generalized mutual information with respect t o the given\\nloss function ℓ as\\nIℓ(x; y) = Hℓ(x) −Hℓ(x|y). (A.9)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 217, 'page_label': '212', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='212 Appendix A: Information Measures\\nThe mutual information measures the decrease in average los s that is\\nobtained by observing y as compared to having only prior informa-\\ntion about px . This notion of mutual information is in line with the\\nconcept of statistical information proposed by DeGroot (se e [ 46] for\\na recent treatment). With the log-loss, the generalized mut ual infor-\\nmation ( A.9) reduces to Shannon’s mutual information. As shown in\\n[75], the log-loss is in fact the only loss function, up to multip licative\\nfactors, under which the generalized mutual information ( A.9) satisﬁes\\nthe data processing inequality , as long as the alphabet of x has more\\nthan two elements.\\nA.3 Divergence Measures\\nW e now discuss a way to quantify the “diﬀerence” between two g iven\\nprobabilistic models px and qx deﬁned over the same alphabet X. W e\\nconsider here the viewpoint of binary hypothesis testing as a theoret-\\nical framework in which to tackle the issue. Other related ap proaches'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 217, 'page_label': '212', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='consider here the viewpoint of binary hypothesis testing as a theoret-\\nical framework in which to tackle the issue. Other related ap proaches\\nhave also found applications in machine learning, includin g optimal\\ntransport theory and kernel methods [\\n8].\\nW e consider the following standard binary hypothesis testi ng prob-\\nlem. Given an observation x, decide whether x was generated from pmf\\npx or from pmf qx . T o proceed, we deﬁne a decision rule T(x), which\\nshould have the property that it is increasing with the certa inty that\\na value x = x is generated from px rather than qx. F or e xample, in\\npractice, one may impose a threshold on the rule T(x) so that, when\\nT(x) is larger than the threshold, a decision is made that x = x was\\ngenerated from px .\\nIn order to design the decision rule T(x), we again minimize a loss\\nfunction or, equivalently , maximize a merit function. F or c onvenience,\\nhere we take the latter approach, and deﬁne the problem of max imizing\\nthe merit function'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 217, 'page_label': '212', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function or, equivalently , maximize a merit function. F or c onvenience,\\nhere we take the latter approach, and deﬁne the problem of max imizing\\nthe merit function\\nEx∼px [T(x)] −Ex∼qx [g(T(x))] (A.10)\\nover the rule T(x), where g is a concave increasing function. This cri-\\nterion can be motivated as follows: ( i ) It increases if T(x) is large, on\\naverage, for values of x generated from px ; and ( ii ) it decreases if, upon'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 218, 'page_label': '213', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A.3. Divergence Measures 213\\nexpectation, T(x) is large for values of x generated from qx . The func-\\ntion g can be used to deﬁne the relative importance of errors made in\\nfavor of one distribution or the other. F rom this discussion , the optimal\\nvalue of ( A.10) can be taken to be a measure of the distance between\\nthe two pmfs. This yields the following deﬁnition of diverge nce between\\ntwo pmfs\\nDf (px ||qx ) = max\\nT (x)\\nEx∼px [T(x)] −Ex∼qx [g(T(x))], (A.11)\\nwhere the subscript f will be justiﬁed below.\\nUnder suitable diﬀerentiability assumptions on function g(see [ 107]\\nfor generalizations), taking the derivative with respect t o T(x) for all\\nx ∈x yields the optimality condition g′ (T(x)) = p(x)/q(x). This rela-\\ntionship reveals the connection between the optimal detect or T(x) and\\nthe LLR p(x)/q(x). Plugging this result into ( A.11), it can be directly\\nchecked that the following equality holds [ 105]\\nDf (px ||qx ) = Ex∼qx\\n[\\nf\\n( px (x)\\nqx (x)\\n)]\\n, (A.12)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 218, 'page_label': '213', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the LLR p(x)/q(x). Plugging this result into ( A.11), it can be directly\\nchecked that the following equality holds [ 105]\\nDf (px ||qx ) = Ex∼qx\\n[\\nf\\n( px (x)\\nqx (x)\\n)]\\n, (A.12)\\nwhere the function f(x) = g∗ (x) is the convex dual function of g(t),\\nwhich is deﬁned as g∗ (x) = sup t (xt−g(t)). Note that dual function f\\nis always convex [ 28].\\nUnder the additional constraint f(1) = 0 , deﬁnition ( A.12) de-\\nscribes a large class of divergence measures parametrized b y the con-\\nvex function f, which are known as f-divergences or Ali-Silvey distance\\nmeasures [ 45]. Note that the constraint f(1) = 0 ensures that the diver-\\ngence is zero when the pmfs px and qx are identical. Among their key\\nproperties, f-divergences satisfy the data processing inequality [ 45].\\nF or e xample, the choice g(t) = exp( t−1), which gives the dual con-\\nvex f(x) = xln x, yields the optimal detector T(x) = 1 + ln( p(x)/q(x))\\nand the corresponding divergence measure ( A.12) is the standard KL'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 218, 'page_label': '213', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='vex f(x) = xln x, yields the optimal detector T(x) = 1 + ln( p(x)/q(x))\\nand the corresponding divergence measure ( A.12) is the standard KL\\ndivergence KL (px ||qx ). As another instance of f-divergence, with g(t) =\\n−ln(2−exp(t)) we obtain the optimal detector T(x) = ln(2 px (x)/px (x)+\\nqx (x)), and Df (px ||qx ) becomes the Jensen-Shannon divergence 1 . F or\\n1 The Jensen-Shannon divergence can also be interpreted as th e mutual informa-\\ntion I (s; x)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 219, 'page_label': '214', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='214 Appendix A: Information Measures\\nreference, the latter can be written as\\nJS(px ||qx ) = KL(px ∥ mx )+KL(qx ∥ mx ), (A.13)\\nwhere mx (x) = ( px (x) + qx (x))/2.2 Another special case, which general-\\nizes the KL divergence and other metrics, is the α-divergence discussed\\nin Chapter 8 (see ( 8.16)), which is obtained with f(x) = ( α(x−1) −\\n(xα −1))/(α(1 −α)) for some real-valued parameter α. W e refer to [ 107,\\n45] for other examples.\\nThe discussion above justiﬁed the adoption of the loss funct ion\\n(A.11) in a heuristic fashion. It is, however, possible to derive f ormal\\nrelationships between the error probability of binary hypo thesis testing\\nand f -divergences [ 21]. W e also refer to the classical Sanov lemma and\\nStein lemma as fundamental applications of KL divergence to large\\ndeviation and hypothesis testing [ 38].\\n2 The Jensen-Shannon divergence, as deﬁned above, is proport ional to the mutual'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 219, 'page_label': '214', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Stein lemma as fundamental applications of KL divergence to large\\ndeviation and hypothesis testing [ 38].\\n2 The Jensen-Shannon divergence, as deﬁned above, is proport ional to the mutual\\ninformation I (s; x) for the joint distribution ps, x (s, x ) = 1 /2 · px|s (x|s) with binary\\ns, and conditional pmf deﬁned as px|s (x|0) = px (x) and px|s (x|s)(x|1) = qx (x).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 220, 'page_label': '215', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='B\\nAppendix B: KL Divergence and Exponential\\nFamily\\nIn this appendix, we provide a general expression for the KL d ivergence\\nbetween two distributions p(x|η1 ) and p(x|η2 ) from the same regular\\nexponential family with log-partition function A(·), suﬃcient statistics\\nu(x), and moment parameters µ1 and µ2, respectively . W e recall from\\nChapter 3 that the log-partition function is convex and that we have\\nthe identity ∇A(η) = µ.\\nThe KL divergence between the two distributions can be trans lated\\ninto a divergence on the space of natural parameters. In part icular, the\\nfollowing relationship holds [ 6]\\nKL(p(x|η1 )||p(x|η2 )) = DA(η2 ,η1 ), (B.1)\\nwhere DA(η2 ,η1 ) represents the Bregman divergence with generator\\nfunction given by the log-partition function A(·), that is\\nDA (η2 ,η1 ) = A(η2 ) −A(η1 ) −(η2 −η1 )T ∇A(η1 )\\n= A(η2 ) −A(η1 ) −(η2 −η1 )T µ1 . (B.2)\\nThe ﬁrst line of ( B.2) is the general deﬁnition of the Bregman diver-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 220, 'page_label': '215', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='DA (η2 ,η1 ) = A(η2 ) −A(η1 ) −(η2 −η1 )T ∇A(η1 )\\n= A(η2 ) −A(η1 ) −(η2 −η1 )T µ1 . (B.2)\\nThe ﬁrst line of ( B.2) is the general deﬁnition of the Bregman diver-\\ngence DA(·,·) with a generator function A(·), while the second follows\\nfrom the relationship ( 3.10). Note that the Bregman divergence can be\\n215'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 221, 'page_label': '216', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='216 Appendix B: KL Divergence and Exponential Family\\nproved to be non-negative, and convex in its ﬁrst argument, b ut not\\nnecessarily in the second argument. The equality ( B.1)-(B.2) can be\\nproved by using the deﬁnition of exponential family via the f ollowing\\nequality\\nKL(p(x|η1 )||p(x|η2 )) = Ex∼p(x|η1 )\\n[\\nlog p(x|η1 )\\np(x|η2 )\\n]\\n= Ex∼p(x|η1 )[(η1 −η2)T u(x)] −A(η1 ) + A(η2 ).\\n(B.3)\\nRecalling again that we have the equality ∇A(η1 ) = µ1, the rela-\\ntionship ( B.1)-(B.2) can be approximated as\\nKL(p(x|η1 )||p(x|η2 )) = 1\\nN(η1 −η2)T Jη1 (η1 −η2 ) + O(||η1 −η2||3 ),\\n(B.4)\\nwhere Jη = −E\\n[\\n∇2\\nη lnp(x|η)\\n]\\nis the Fisher information matrix. This\\nexpansion holds given the relationship ∇2\\nη A(η) = Jη [\\n45].\\nIt is also possible to write a relationship analogous to ( B.1)-(B.2) in\\nterms of mean parameters. This is done by using the convex con jugate\\nfunction\\nA∗ (µ) = sup\\nη\\nηT µ−A(η), (B.5)\\nwhere the maximization is over the feasible set of natural pa rameters.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 221, 'page_label': '216', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='terms of mean parameters. This is done by using the convex con jugate\\nfunction\\nA∗ (µ) = sup\\nη\\nηT µ−A(η), (B.5)\\nwhere the maximization is over the feasible set of natural pa rameters.\\nIn fact, the optimization over η yields the natural parameter η corre-\\nsponding to the mean parameter µ, i.e., ∇A(η) = µ. It hence follows\\nfrom ( B.2) that we have\\nKL(p(x|µ1)||p(x|µ2 )) = A∗(µ1 ) −A∗ (µ2 ) −(µ1 −µ2)T η2\\n= DA∗ (µ1 ,µ2), (B.6)\\nwhere in the second line we have used the inverse mapping ∇A∗(µ) = η\\nbetween mean and natural parameters (which holds for minima l fami-\\nlies).\\nChernoﬀ divergence measures, including the Bhattacharyya distance,\\ncan also be written in closed form for exponential families [ 106].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 222, 'page_label': '217', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Acknowledgements\\nOsvaldo Simeone has received funding from the European Rese arch\\nCouncil (ERC) under the European Union’s Horizon 2020 resea rch and\\ninnovation programme (grant agreement No 725731).\\n217'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 223, 'page_label': '218', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Abadi, M., Ú. Erlingsson, I. Goodfellow, H. Brendan McMa -\\nhan, I. Mironov, N. Papernot, K. T alwar, and L. Zhang. 2017.\\n“On the Protection of Private Information in Machine Learni ng\\nSystems: T wo Recent Approaches”. ArXiv e-prints . Aug. arXiv:\\n1708.08022 [stat.ML].\\n[2] Abu-Mostafa, Y. S., M. Magdon-Ismail, and H.-T. Lin. 201 2.\\nLearning from data . V ol. 4. AMLBook New Y ork, NY, USA.\\n[3] Agakov, F. 2005. V ariational Information Maximization in Stochas-\\ntic Environments (PhD thesis) . University of Edinburgh.\\n[4] Alemi, A. A., B. Poole, and E. a. Fischer. 2017. “An Inform ation-\\nTheoretic Analysis of Deep Latent-V ariable Models”. ArXiv e-\\nprints. Nov. arXiv: 1711.00464v1.\\n[5] Amari, S.-I. 1998. “Natural gradient works eﬃciently in learn-\\ning”. Neural computation . 10(2): 251–276.\\n[6] Amari, S.-i. 2016. Information geometry and its applications .\\nSpringer.\\n[7] Angelino, E., M. J. Johnson, R. P . Adams, et al. 2016. “Patterns'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 223, 'page_label': '218', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ing”. Neural computation . 10(2): 251–276.\\n[6] Amari, S.-i. 2016. Information geometry and its applications .\\nSpringer.\\n[7] Angelino, E., M. J. Johnson, R. P . Adams, et al. 2016. “Patterns\\nof scalable Bayesian inference”. F oundations and T rends R⃝ in\\nMachine Learning . 9(2-3): 119–247.\\n[8] Arjovsky , M., S. Chintala, and L. Bottou. 2017. “W assers tein\\nGAN”. arXiv preprint arXiv:1701.07875 .\\n218'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 224, 'page_label': '219', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 219\\n[9] Arulkumaran, K., M. P . Deisenroth, M. Brundage, and A. A.\\nBharath. 2017. “Deep Reinforcement Learning: A Brief Surve y”.\\nIEEE Signal Processing Magazine . 34(6): 26–38. issn: 1053-5888.\\ndoi: 10.1109/MSP .2017.2743240.\\n[10] Azoury , K. S. and M. K. W armuth. 2001. “Relative loss bou nds\\nfor on-line density estimation with the exponential family of\\ndistributions”. Machine Learning . 43(3): 211–246.\\n[11] Bagheri, A., O. Simeone, and B. Rajendran. 2017. “T rain ing\\nProbabilistic Spiking Neural Networks with First-to-spik e De-\\ncoding”. ArXiv e-prints . Oct. arXiv: 1710.10704 [stat.ML].\\n[12] Baldi, P ., P . Sadowski, and Z. Lu. 2016. “Learning in the ma-\\nchine: Random backpropagation and the learning channel”. arXiv\\npreprint arXiv:1612.02734 .\\n[13] Bamler, R., C. Zhang, M. Opper, and S. Mandt. 2017. “Pert ur-\\nbative Black Box V ariational Inference”. ArXiv e-prints . Sept.\\narXiv: 1709.07433 [stat.ML].\\n[14] Baraniuk, R. G. 2007. “Compressive sensing [lecture no tes]”.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 224, 'page_label': '219', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='bative Black Box V ariational Inference”. ArXiv e-prints . Sept.\\narXiv: 1709.07433 [stat.ML].\\n[14] Baraniuk, R. G. 2007. “Compressive sensing [lecture no tes]”.\\nIEEE signal processing magazine . 24(4): 118–121.\\n[15] Barber, D. 2012. Bayesian reasoning and machine learning . Cam-\\nbridge University Press.\\n[16] Beal, M. J. 2003. V ariational algorithms for approximate Bayesian\\ninference. University of London London.\\n[17] Bekkerman, R., M. Bilenko, and J. Langford. 2011. Scaling up\\nmachine learning: Paral lel and distributed approaches . Cambridge\\nUniversity Press.\\n[18] Belghazi, I., S. Rajeswar, A. Baratin, R. D. Hjelm, and A . Courville.\\n2018. “MINE: Mutual Information Neural Estimation”. arXiv\\npreprint arXiv:1801.04062 .\\n[19] Bengio, Y. 2012. “Deep learning of representations for unsuper-\\nvised and transfer learning”. In: Proceedings of ICML W orkshop\\non Unsupervised and T ransfer Learning . 17–36.\\n[20] Bengio, Y., A. Courville, and P . Vincent. 2013. “Repres entation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 224, 'page_label': '219', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='vised and transfer learning”. In: Proceedings of ICML W orkshop\\non Unsupervised and T ransfer Learning . 17–36.\\n[20] Bengio, Y., A. Courville, and P . Vincent. 2013. “Repres entation\\nlearning: A review and new perspectives”. IEEE transactions on\\npattern analysis and machine intel ligence . 35(8): 1798–1828.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 225, 'page_label': '220', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='220 References\\n[21] Berisha, V., A. Wisler, A. O. Hero, and A. Spanias. 2016. “Em-\\npirically estimable classiﬁcation bounds based on a nonpar amet-\\nric divergence measure”. IEEE T ransactions on Signal Process-\\ning. 64(3): 580–591.\\n[22] Bertsekas, D. P . 2011. “Incremental gradient, subgrad ient, and\\nproximal methods for convex optimization: A survey”. Optimiza-\\ntion for Machine Learning . 2010(1-38): 3.\\n[23] Bishop, C. M. 2006. Pattern recognition and machine learning .\\nSpringer.\\n[24] Blei, D. M., A. Kucukelbir, and J. D. McAuliﬀe. 2017. “V a ria-\\ntional inference: A review for statisticians”. Journal of the Amer-\\nican Statistical Association . (just-accepted).\\n[25] Blei, D., R. Ranganath, and S. Mohamed. “V ariational In ference:\\nF oundations and Modern Methods”.\\n[26] Blitzer, J., K. Crammer, A. Kulesza, F. Pereira, and J. W ortman.\\n2008. “Learning bounds for domain adaptation”. In: Advances\\nin neural information processing systems . 129–136.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 225, 'page_label': '220', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[26] Blitzer, J., K. Crammer, A. Kulesza, F. Pereira, and J. W ortman.\\n2008. “Learning bounds for domain adaptation”. In: Advances\\nin neural information processing systems . 129–136.\\n[27] Blundell, C., J. Cornebise, K. Kavukcuoglu, and D. Wier stra.\\n2015. “W eight uncertainty in neural networks”. arXiv preprint\\narXiv:1505.05424.\\n[28] Boyd, S. and L. V andenberghe. 2004. Convex optimization . Cam-\\nbridge university press.\\n[29] Brakel, P . and Y. Bengio. 2017. “Learning Independent F eatures\\nwith Adversarial Nets for Non-linear ICA”. ArXiv e-prints . Oct.\\narXiv: 1710.05050 [stat.ML].\\n[30] Bronstein, M. M., J. Bruna, Y. LeCun, A. Szlam, and P . V an -\\ndergheynst. 2017. “Geometric deep learning: going beyond e u-\\nclidean data”. IEEE Signal Processing Magazine . 34(4): 18–42.\\n[31] Brynjolfsson, E. and T. Mitchell. 2017. “What can machi ne\\nlearning do? W orkforce implications”. Science. 358(6370): 1530–\\n1534.\\n[32] Burda, Y., R. Grosse, and R. Salakhutdinov. 2015. “Impo rtance'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 225, 'page_label': '220', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning do? W orkforce implications”. Science. 358(6370): 1530–\\n1534.\\n[32] Burda, Y., R. Grosse, and R. Salakhutdinov. 2015. “Impo rtance\\nweighted autoencoders”. arXiv preprint arXiv:1509.00519 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 226, 'page_label': '221', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 221\\n[33] Cevher, V., S. Becker, and M. Schmidt. 2014. “Convex opt imiza-\\ntion for big data: Scalable, randomized, and parallel algor ithms\\nfor big data analytics”. IEEE Signal Processing Magazine . 31(5):\\n32–43.\\n[34] Cheeseman, P . C. 1985. “In Defense of Probability .” In: IJCAI.\\nV ol. 85. 1002–1009.\\n[35] Cichocki, A., D. Mandic, L. De Lathauwer, G. Zhou, Q. Zha o, C.\\nCaiafa, and H. A. Phan. 2015. “T ensor decompositions for sig nal\\nprocessing applications: F rom two-way to multiway compone nt\\nanalysis”. IEEE Signal Processing Magazine . 32(2): 145–163.\\n[36] Collins, M., S. Dasgupta, and R. E. Schapire. 2002. “A ge ner-\\nalization of principal components analysis to the exponent ial\\nfamily”. In: Advances in neural information processing systems .\\n617–624.\\n[37] Cortes, C. and V. V apnik. 1995. “Support-vector networ ks”. Ma-\\nchine learning . 20(3): 273–297.\\n[38] Cover, T. M. and J. A. Thomas. 2012. Elements of information\\ntheory. John Wiley & Sons.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 226, 'page_label': '221', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[37] Cortes, C. and V. V apnik. 1995. “Support-vector networ ks”. Ma-\\nchine learning . 20(3): 273–297.\\n[38] Cover, T. M. and J. A. Thomas. 2012. Elements of information\\ntheory. John Wiley & Sons.\\n[39] Cristianini, N. and J. Shawe-T aylor. 2000. An introduction to\\nsupport vector machines and other kernel-based learning me th-\\nods. Cambridge university press.\\n[40] Csiszár, I. and P . C. Shields. 2004. “Information theor y and\\nstatistics: A tutorial”. F oundations and T rends R⃝ in Communi-\\ncations and Information Theory . 1(4): 417–528.\\n[41] Davidson-Pilon, C. 2015. “Probabilistic Programming & Bayesian\\nMethods for Hackers”.\\n[42] Dayan, P ., G. E. Hinton, R. M. Neal, and R. S. Zemel. 1995.\\n“The helmholtz machine”. Neural computation . 7(5): 889–904.\\n[43] De, S., G. T aylor, and T. Goldstein. 2015. “V ariance Red uction\\nfor Distributed Stochastic Gradient Descent”. arXiv preprint\\narXiv:1512.01708.\\n[44] Di Lorenzo, P . and G. Scutari. 2016. “Next: In-network n oncon-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 226, 'page_label': '221', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for Distributed Stochastic Gradient Descent”. arXiv preprint\\narXiv:1512.01708.\\n[44] Di Lorenzo, P . and G. Scutari. 2016. “Next: In-network n oncon-\\nvex optimization”. IEEE T ransactions on Signal and Informa-\\ntion Processing over Networks . 2(2): 120–136.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 227, 'page_label': '222', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='222 References\\n[45] Duchi, J. 2016. “Lecture Notes for Statistics 311/Elec trical En-\\ngineering 377”.\\n[46] Duchi, J. C., K. Khosravi, and F. Ruan. 2016. “Informati on\\nMeasures, Experiments, Multi-category Hypothesis T ests, and\\nSurrogate Losses”. arXiv preprint arXiv:1603.00126 .\\n[47] Dumoulin, V., I. Belghazi, B. Poole, O. Mastropietro, A . Lamb,\\nM. Arjovsky , and A. Courville. 2016. “Adversarially learne d in-\\nference”. arXiv preprint arXiv:1606.00704 .\\n[48] Efron, B. and T. Hastie. 2016. Computer Age Statistical Infer-\\nence. V ol. 5. Cambridge University Press.\\n[49] F edus, W., M. Rosca, B. Lakshminarayanan, A. M. Dai, S. M o-\\nhamed, and I. Goodfellow. 2017. “Many Paths to Equilibrium:\\nGANs Do Not Need to Decrease a Divergence At Every Step”.\\nArXiv e-prints . Oct. arXiv:\\n1710.08446 [stat.ML].\\n[50] F eutry , C., P . Piantanida, Y. Bengio, and P . Duhamel. 20 18.\\n“Learning Anonymized Representations with Adversarial Ne ural'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 227, 'page_label': '222', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ArXiv e-prints . Oct. arXiv:\\n1710.08446 [stat.ML].\\n[50] F eutry , C., P . Piantanida, Y. Bengio, and P . Duhamel. 20 18.\\n“Learning Anonymized Representations with Adversarial Ne ural\\nNetworks”. ArXiv e-prints . F eb. arXiv: 1802.09386 [stat.ML].\\n[51] F riedman, J., T. Hastie, and R. Tibshirani. 2001. The elements\\nof statistical learning . V ol. 1. Springer series in statistics New\\nY ork.\\n[52] F u, Y., T. Xiang, Y.-G. Jiang, X. Xue, L. Sigal, and S. Gon g.\\n2017. “Recent advances in zero-shot recognition”. arXiv preprint\\narXiv:1710.04837.\\n[53] Gal, Y. 2016. “Uncertainty in Deep Learning”. PhD thesis . Uni-\\nversity of Cambridge.\\n[54] Gersho, A. and R. M. Gray. 2012. V ector quantization and signal\\ncompression. V ol. 159. Springer Science & Business Media.\\n[55] Goodfellow, I. J., J. Shlens, and C. Szegedy. 2014a. “Ex plaining\\nand harnessing adversarial examples”. arXiv preprint arXiv:1412.6572 .\\n[56] Goodfellow, I., Y. Bengio, and A. Courville. 2016. Deep learning .\\nMIT press.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 227, 'page_label': '222', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and harnessing adversarial examples”. arXiv preprint arXiv:1412.6572 .\\n[56] Goodfellow, I., Y. Bengio, and A. Courville. 2016. Deep learning .\\nMIT press.\\n[57] Goodfellow, I., J. Pouget-Abadie, M. Mirza, B. Xu, D. W a rde-\\nF arley, S. Ozair, A. Courville, and Y. Bengio. 2014b. “Gener a-\\ntive adversarial nets”. In: Advances in neural information pro-\\ncessing systems . 2672–2680.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 228, 'page_label': '223', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 223\\n[58] Grant, M., and Y. Y e. arti. “cvx users’ guide”.\\n[59] Grathwohl, W., D. Choi, Y. W u, G. Roeder, and D. Duvenaud .\\n2017. “Backpropagation through the V oid: Optimizing contr ol\\nvariates for black-box gradient estimation”. ArXiv e-prints . Oct.\\narXiv:\\n1711.00123 [cs.LG].\\n[60] Grunwald, P . D. 2007. The minimum description length princi-\\nple. MIT press.\\n[61] Grünwald, P . D., A. P . Dawid, et al. 2004. “Game theory , max-\\nimum entropy , minimum discrepancy and robust Bayesian deci -\\nsion theory”. the Annals of Statistics . 32(4): 1367–1433.\\n[62] Guardian), S. L. ( 2016. A beauty contest was judged by AI and\\nthe robots didn ’t like dark skin . url: http://www.nytimes.com/1958/07/08/archives/new-navy-device-learns-by-doing-psychologist-shows-embryo-o f.html.\\n[63] Haveliwala, T. H. 2003. “T opic-sensitive pagerank: A c ontext-\\nsensitive ranking algorithm for web search”. IEEE transactions\\non knowledge and data engineering . 15(4): 784–796.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 228, 'page_label': '223', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[63] Haveliwala, T. H. 2003. “T opic-sensitive pagerank: A c ontext-\\nsensitive ranking algorithm for web search”. IEEE transactions\\non knowledge and data engineering . 15(4): 784–796.\\n[64] Hinton, G. 2016. “Neural Networks for Machine Learning (online\\ncourse)”.\\n[65] Hinton, G. E., P . Dayan, B. J. F rey, and R. M. Neal. 1995.\\n“The\" wake-sleep\" algorithm for unsupervised neural netwo rks”.\\nScience. 268(5214): 1158.\\n[66] Hochreiter, S. and J. Schmidhuber. 1997. “Flat minima” . Neural\\nComputation. 9(1): 1–42.\\n[67] Huang, G.-B., Q.-Y. Zhu, and C.-K. Siew. 2006. “Extreme learn-\\ning machine: theory and applications”. Neurocomputing. 70(1):\\n489–501.\\n[68] Huszár, F. 2017a. “Choice of Recognition Models in V AEs : a\\nregularisation view”.\\n[69] Huszár, F. 2017b. “Is Maximum Likelihood Useful for Rep resen-\\ntation Learning?”\\n[70] Huszár, F. 2017c. “V ariational Inference using Implic it Distribu-\\ntions”. arXiv preprint arXiv:1702.08235 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 228, 'page_label': '223', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tation Learning?”\\n[70] Huszár, F. 2017c. “V ariational Inference using Implic it Distribu-\\ntions”. arXiv preprint arXiv:1702.08235 .\\n[71] Huszár, F. “Everything that W orks W orks Because it’s Ba yesian:\\nWhy Deep Nets Generalize?”'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 229, 'page_label': '224', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='224 References\\n[72] Jain, P . and P . Kar. 2017. “Non-convex Optimization for Ma-\\nchine Learning”. F oundations and T rends R⃝ in Machine Learn-\\ning. 10(3-4): 142–336. issn: 1935-8237. url: http://dx.doi.org/10.1561/2200000058.\\n[73] Jang, E., S. Gu, and B. Poole. 2016. “Categorical repara meteri-\\nzation with gumbel-softmax”. arXiv preprint arXiv:1611.01144 .\\n[74] Jiao, J., T. A. Courtade, A. No, K. V enkat, and T. W eissma n.\\n2014. “Information measures: the curious case of the binary\\nalphabet”. IEEE T ransactions on Information Theory . 60(12):\\n7616–7626.\\n[75] Jiao, J., T. A. Courtade, K. V enkat, and T. W eissman. 201 5.\\n“Justiﬁcation of logarithmic loss via the beneﬁt of side inf orma-\\ntion”. IEEE T ransactions on Information Theory . 61(10): 5357–\\n5365.\\n[76] Johnson, R. and T. Zhang. 2013. “Accelerating stochast ic gra-\\ndient descent using predictive variance reduction”. In: Advances\\nin neural information processing systems . 315–323.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 229, 'page_label': '224', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5365.\\n[76] Johnson, R. and T. Zhang. 2013. “Accelerating stochast ic gra-\\ndient descent using predictive variance reduction”. In: Advances\\nin neural information processing systems . 315–323.\\n[77] Karpathy , A. “Deep Reinforcement Learning: Pong from P ixels”.\\nurl: http://karpathy .github.io/2016/05/31/rl/.\\n[78] Kawaguchi, K., L. Pack Kaelbling, and Y. Bengio. 2017. “ Gener-\\nalization in Deep Learning”. ArXiv e-prints . Oct. arXiv: 1710.05468 [stat.ML].\\n[79] Keskar, N. S., D. Mudigere, J. Nocedal, M. Smelyanskiy , and\\nP . T. P . T ang. 2016. “On large-batch training for deep learni ng:\\nGeneralization gap and sharp minima”. arXiv preprint arXiv:1609.04836 .\\n[80] Kingma, D. P . and M. W elling. 2013. “Auto-encoding vari ational\\nbayes”. arXiv preprint arXiv:1312.6114 .\\n[81] Koller, D. and N. F riedman. 2009. Probabilistic graphical models:\\nprinciples and techniques . MIT press.\\n[82] Korenkevych, D., Y. Xue, Z. Bian, F. Chudak, W. G. Macrea dy,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 229, 'page_label': '224', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[81] Koller, D. and N. F riedman. 2009. Probabilistic graphical models:\\nprinciples and techniques . MIT press.\\n[82] Korenkevych, D., Y. Xue, Z. Bian, F. Chudak, W. G. Macrea dy,\\nJ. Rolfe, and E. Andriyash. 2016. “Benchmarking quantum har d-\\nware for training of fully visible boltzmann machines”. arXiv\\npreprint arXiv:1611.04528 .\\n[83] LeCun, Y., S. Chopra, R. Hadsell, M. Ranzato, and F. Huan g.\\n2006. “A tutorial on energy-based learning”. Predicting struc-\\ntured data . 1.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 230, 'page_label': '225', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 225\\n[84] Lee, J. H., T. Delbruck, and M. Pfeiﬀer. 2016. “T raining deep\\nspiking neural networks using backpropagation”. F rontiers in\\nneuroscience. 10.\\n[85] Lee, T.-W., M. Girolami, and T. J. Sejnowski. 1999. “Ind epen-\\ndent component analysis using an extended infomax algorith m\\nfor mixed subgaussian and supergaussian sources”. Neural com-\\nputation. 11(2): 417–441.\\n[86] Lehmann, E. L. and G. Casella. 2006. Theory of point estimation .\\nSpringer Science & Business Media.\\n[87] Levesque, H. J. 2017. Common Sense, the T uring T est, and the\\nQuest for Real AI . MIT University Press.\\n[88] Levine, S. 2017. Deep Reinforcement Learning. url: http://rll.berkeley .edu/deeprlcourse/#lecture-videos.\\n[89] Li, Y. “T opics in Approximate Inference”. url: http://yingzhenli.net/home/pdf/topics_approx_infer.pdf .\\n[90] Li, Y. and R. E. T urner. 2016. “Rényi divergence variati onal\\ninference”. In: Advances in Neural Information Processing Sys-\\ntems. 1073–1081.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 230, 'page_label': '225', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[90] Li, Y. and R. E. T urner. 2016. “Rényi divergence variati onal\\ninference”. In: Advances in Neural Information Processing Sys-\\ntems. 1073–1081.\\n[91] Loh, P .-L. 2017. “On Lower Bounds for Statistical Learn ing The-\\nory”. Entropy. 19(11): 617.\\n[92] Lunn, D., C. Jackson, N. Best, A. Thomas, and D. Spiegelh al-\\nter. 2012. The BUGS book: A practical introduction to Bayesian\\nanalysis. CRC press.\\n[93] Maaten, L. v. d. and G. Hinton. 2008. “Visualizing data u sing\\nt-SNE”. Journal of Machine Learning Research . 9(Nov): 2579–\\n2605.\\n[94] MacKay , D. J. 2003. Information theory, inference and learning\\nalgorithms. Cambridge university press.\\n[95] Maddison, C. J., A. Mnih, and Y. W. T eh. 2016. “The concre te\\ndistribution: A continuous relaxation of discrete random v ari-\\nables”. arXiv preprint arXiv:1611.00712 .\\n[96] Minka, T. 2005. “Divergence measures and message passi ng”.\\nT ech. rep. T echnical report, Microsoft Research.\\n[97] Minsky , M. and S. Papert. 1969. “Perceptrons.”'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 230, 'page_label': '225', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[96] Minka, T. 2005. “Divergence measures and message passi ng”.\\nT ech. rep. T echnical report, Microsoft Research.\\n[97] Minsky , M. and S. Papert. 1969. “Perceptrons.”\\n[98] Mnih, A. and K. Gregor. 2014. “Neural variational infer ence and\\nlearning in belief networks”. arXiv preprint arXiv:1402.0030 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 231, 'page_label': '226', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='226 References\\n[99] Mnih, V., K. Kavukcuoglu, D. Silver, A. Graves, I. Anton oglou,\\nD. Wierstra, and M. Riedmiller. 2013. “Playing atari with de ep\\nreinforcement learning”. arXiv preprint arXiv:1312.5602 .\\n[100] Mohamed, S. and B. Lakshminarayanan. 2016. “Learning in im-\\nplicit generative models”. arXiv preprint arXiv:1610.03483 .\\n[101] Mokhtari, A. and A. Ribeiro. 2017. “First-Order Adapt ive Sam-\\nple Size Methods to Reduce Complexity of Empirical Risk Min-\\nimization”. ArXiv e-prints . Sept. arXiv:\\n1709.00599 [cs.LG].\\n[102] Montavon, G., W. Samek, and K.-R. Müller. 2017. “Metho ds for\\ninterpreting and understanding deep neural networks”. arXiv\\npreprint arXiv:1706.07979 .\\n[103] Mott, A., J. Job, J.-R. Vlimant, D. Lidar, and M. Spirop ulu.\\n2017. “Solving a Higgs optimization problem with quantum an -\\nnealing for machine learning”. Nature. 550(7676): 375.\\n[104] Murphy , K. P . 2012. Machine learning: a probabilistic perspec-\\ntive. MIT press.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 231, 'page_label': '226', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='nealing for machine learning”. Nature. 550(7676): 375.\\n[104] Murphy , K. P . 2012. Machine learning: a probabilistic perspec-\\ntive. MIT press.\\n[105] Nguyen, X., M. J. W ainwright, and M. I. Jordan. 2010. “E sti-\\nmating divergence functionals and the likelihood ratio by c onvex\\nrisk minimization”. IEEE T ransactions on Information Theory .\\n56(11): 5847–5861.\\n[106] Nielsen, F. 2011. “Chernoﬀ information of exponentia l families”.\\narXiv preprint arXiv:1102.2684 .\\n[107] Nowozin, S., B. Cseke, and R. T omioka. 2016. “f-GAN: T r ain-\\ning generative neural samplers using variational divergen ce min-\\nimization”. In: Advances in Neural Information Processing Sys-\\ntems. 271–279.\\n[108] Odena, A., C. Olah, and J. Shlens. 2016. “Conditional i mage syn-\\nthesis with auxiliary classiﬁer gans”. arXiv preprint arXiv:1610.09585 .\\n[109] O’Neil, K. 2016. W eapons of Math Destruction . Penguin Books.\\n[110] Page, L., S. Brin, R. Motwani, and T. Winograd. 1999. “T he'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 231, 'page_label': '226', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[109] O’Neil, K. 2016. W eapons of Math Destruction . Penguin Books.\\n[110] Page, L., S. Brin, R. Motwani, and T. Winograd. 1999. “T he\\nPageRank citation ranking: Bringing order to the web.” T ech.\\nrep. Stanford InfoLab.\\n[111] Papernot, N., P . McDaniel, I. Goodfellow, S. Jha, Z. Be rkay Ce-\\nlik, and A. Swami. 2016. “Practical Black-Box Attacks again st\\nMachine Learning”. ArXiv e-prints . F eb. arXiv: 1602.02697 [cs.CR].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 232, 'page_label': '227', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 227\\n[112] Pearl, J. 2018. “Theoretical Impediments to Machine L earning\\nWith Seven Sparks from the Causal Revolution”. ArXiv e-prints .\\nJan. arXiv: 1801.04016 [cs.LG].\\n[113] Pearl, J., M. Glymour, and N. P . Jewell. 2016. Causal inference\\nin statistics: a primer . John Wiley & Sons.\\n[114] Pereyra, M., P . Schniter, E. Chouzenoux, J.-C. Pesque t, J.-Y.\\nT ourneret, A. O. Hero, and S. McLaughlin. 2016. “A survey of\\nstochastic simulation and optimization methods in signal p ro-\\ncessing”. IEEE Journal of Selected T opics in Signal Processing .\\n10(2): 224–241.\\n[115] Peters, J., D. Janzing, and B. Scholkopf. 2017. Elements of\\nCausal Inference: F oundations and Learning Algorithms . MIT\\nPress (available on-line).\\n[116] Pinker, S. 1997. How the Mind W orks . Penguin Press Science.\\n[117] Rabiner, L. and B. Juang. 1986. “An introduction to hid den\\nMarkov models”. IEEE ASSP magazine . 3(1): 4–16.\\n[118] Raginsky , M. 2011. “Directed information and Pearl’s causal cal-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 232, 'page_label': '227', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[117] Rabiner, L. and B. Juang. 1986. “An introduction to hid den\\nMarkov models”. IEEE ASSP magazine . 3(1): 4–16.\\n[118] Raginsky , M. 2011. “Directed information and Pearl’s causal cal-\\nculus”. In: Communication, Control, and Computing (Al lerton),\\n2011 49th Annual Al lerton Conference on . IEEE. 958–965.\\n[119] Raginsky , M., A. Rakhlin, M. T sao, Y. W u, and A. Xu. 2016 .\\n“Information-theoretic analysis of stability and bias of l earn-\\ning algorithms”. In: Information Theory W orkshop (ITW), 2016\\nIEEE. IEEE. 26–30.\\n[120] Ranganath, R., S. Gerrish, and D. Blei. 2014. “Black bo x vari-\\national inference”. In: Artiﬁcial Intel ligence and Statistics . 814–\\n822.\\n[121] Ranganath, R., L. T ang, L. Charlin, and D. Blei. 2015. “ Deep\\nexponential families”. In: Artiﬁcial Intel ligence and Statistics .\\n762–771.\\n[122] Rezende, D. J., S. Mohamed, and D. Wierstra. 2014. “Sto chastic\\nbackpropagation and approximate inference in deep generat ive\\nmodels”. arXiv preprint arXiv:1401.4082 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 232, 'page_label': '227', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='762–771.\\n[122] Rezende, D. J., S. Mohamed, and D. Wierstra. 2014. “Sto chastic\\nbackpropagation and approximate inference in deep generat ive\\nmodels”. arXiv preprint arXiv:1401.4082 .\\n[123] Roth, K., A. Lucchi, S. Nowozin, and T. Hofmann. 2017. “ Sta-\\nbilizing T raining of Generative Adversarial Networks thro ugh\\nRegularization”. arXiv preprint arXiv:1705.09367 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 233, 'page_label': '228', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='228 References\\n[124] Rudolph, M., F. Ruiz, S. Athey, and D. Blei. 2017. “Stru ctured\\nEmbedding Models for Grouped Data”. ArXiv e-prints . Sept.\\narXiv: 1709.10367 [stat.ML].\\n[125] Rumelhart, D. E., G. E. Hinton, and R. J. Williams. 1988 . “Learn-\\ning representations by back-propagating errors”. Cognitive mod-\\neling. 5(3): 1.\\n[126] Russel, S. and P . Norvig. 2009. Artiﬁcial Intel ligence: A Modern\\nApproach. Pearson.\\n[127] Salakhutdinov, R., A. Mnih, and G. Hinton. 2007. “Rest ricted\\nBoltzmann machines for collaborative ﬁltering”. In: Proceedings\\nof the 24th international conference on Machine learning . ACM.\\n791–798.\\n[128] Salimans, T., J. Ho, X. Chen, and I. Sutskever. 2017. “E volution\\nstrategies as a scalable alternative to reinforcement lear ning”.\\narXiv preprint arXiv:1703.03864 .\\n[129] Samadi, A., T. P . Lillicrap, and D. B. T weed. 2017. “Dee p\\nLearning with Dynamic Spiking Neurons and Fixed F eedback\\nW eights”. Neural Computation . 29(3): 578–602.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 233, 'page_label': '228', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[129] Samadi, A., T. P . Lillicrap, and D. B. T weed. 2017. “Dee p\\nLearning with Dynamic Spiking Neurons and Fixed F eedback\\nW eights”. Neural Computation . 29(3): 578–602.\\n[130] Scutari, G., F. F acchinei, L. Lampariello, and P . Song . 2014.\\n“Distributed methods for constrained nonconvex multi-age nt optimization-\\npart I: theory”. arXiv preprint arXiv:1410.4754 .\\n[131] Scutari, M. 2017. “Bayesian Dirichlet Bayesian Netwo rk Scores\\nand the Maximum Entropy Principle”. arXiv preprint arXiv:1708.00689 .\\n[132] Shahriari, B., K. Swersky, Z. W ang, R. P . Adams, and N. d e\\nF reitas. 2016. “T aking the human out of the loop: A review of\\nbayesian optimization”. Proceedings of the IEEE . 104(1): 148–\\n175.\\n[133] Shalev-Shwartz, S. and S. Ben-David. 2014. Understanding ma-\\nchine learning: F rom theory to algorithms . Cambridge university\\npress.\\n[134] Shannon, C. E. 1948. “A mathematical theory of communi ca-\\ntion”. The Bel l System T echnical Journal . 27(3): 379–423.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 233, 'page_label': '228', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='chine learning: F rom theory to algorithms . Cambridge university\\npress.\\n[134] Shannon, C. E. 1948. “A mathematical theory of communi ca-\\ntion”. The Bel l System T echnical Journal . 27(3): 379–423.\\n[135] Silver, D. 2015. Course on reinforcement learning . url:\\nhttp://www0.cs.ucl.ac.uk/staﬀ/d.silver/web/T eaching.html.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 234, 'page_label': '229', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 229\\n[136] Smith, S. L., P .-J. Kindermans, and Q. V. Le. 2017. “Don ’t\\nDecay the Learning Rate, Increase the Batch Size”. ArXiv e-\\nprints. Nov. arXiv: 1711.00489 [cs.LG].\\n[137] Spectrum, I. Wil l the F uture of AI Learning Depend More on\\nNature or Nurture? url: https://spectrum.ieee.org/tech-talk/robotics/artiﬁc ial-intelligence/ai-and-psychology-researchers-deba te-the-future-of-deep-learning .\\n[138] Stigler, S. M. 2016. The seven pil lars of statistical wisdom . Har-\\nvard University Press.\\n[139] Subramaniam, S., T. Palpanas, D. Papadopoulos, V. Kal oger-\\naki, and D. Gunopulos. 2006. “Online outlier detection in se n-\\nsor data using non-parametric models”. In: Proceedings of the\\n32nd international conference on V ery large data bases . VLDB\\nEndowment. 187–198.\\n[140] Sugiyama, M., T. Suzuki, and T. Kanamori. 2012. Density ratio\\nestimation in machine learning . Cambridge University Press.\\n[141] Sun, Y., P . Babu, and D. P . Palomar. 2017. “Majorizatio n-minimization'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 234, 'page_label': '229', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='estimation in machine learning . Cambridge University Press.\\n[141] Sun, Y., P . Babu, and D. P . Palomar. 2017. “Majorizatio n-minimization\\nalgorithms in signal processing, communications, and mach ine\\nlearning”. IEEE T ransactions on Signal Processing . 65(3): 794–\\n816.\\n[142] T egmark, M. 2017. Life 3.0: Being Human in the Age of Artiﬁ-\\ncial Intel ligence . Allen Lane.\\n[143] Thrun, S. 1996. “Is learning the n-th thing any easier t han learn-\\ning the ﬁrst?” In: Advances in neural information processing\\nsystems. 640–646.\\n[144] Times, T. N. Y. 1958. NEW NA VY DEVICE LEARNS BY DO-\\nING; Psychologist Shows Embryo of Computer Designed to Read\\nand Grow Wiser . url: http://www.nytimes.com/1958/07/08/archives/new-navy-device-learns-by-doing-psychologist-shows-embryo-o f.html.\\n[145] Tishby , N., F. C. Pereira, and W. Bialek. 2000. “The inf ormation\\nbottleneck method”. arXiv preprint physics/0004057 .\\n[146] T sybakov, A. B. 2009. “Introduction to nonparametric estima-\\ntion”.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 234, 'page_label': '229', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='bottleneck method”. arXiv preprint physics/0004057 .\\n[146] T sybakov, A. B. 2009. “Introduction to nonparametric estima-\\ntion”.\\n[147] T urner, R. E. and M. Sahani. 2011. “T wo problems with va ria-\\ntional expectation maximisation for time-series models”. Bayesian\\nTime series models : 115–138.\\n[148] Uber. Pyro: Deep universal probabilistic programming . url: http://pyro.ai/.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 235, 'page_label': '230', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='230 References\\n[149] V enkateswara, H., S. Chakraborty, and S. Panchanatha n. 2017.\\n“Deep-Learning Systems for Domain Adaptation in Computer\\nVision: Learning T ransferable F eature Representations”. IEEE\\nSignal Processing Magazine . 34(6): 117–129. issn: 1053-5888.\\ndoi: 10.1109/MSP .2017.2740460.\\n[150] Vincent, P ., H. Larochelle, I. Lajoie, Y. Bengio, and P .-A. Man-\\nzagol. 2010. “Stacked denoising autoencoders: Learning us eful\\nrepresentations in a deep network with a local denoising cri te-\\nrion”. Journal of Machine Learning Research . 11(Dec): 3371–\\n3408.\\n[151] W ainwright, M. J. and M. I. Jordan. 2008. “Graphical mo d-\\nels, exponential families, and variational inference”. F oundations\\nand T rends R⃝ in Machine Learning . 1(1–2): 1–305.\\n[152] W att, J., R. Borhani, and A. Katsaggelos. 2016. Machine Learn-\\ning Reﬁned: F oundations, Algorithms, and Applications . Cam-\\nbridge University Press.\\n[153] W elling, M., M. Rosen-Zvi, and G. E. Hinton. 2005. “Exp onen-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 235, 'page_label': '230', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ing Reﬁned: F oundations, Algorithms, and Applications . Cam-\\nbridge University Press.\\n[153] W elling, M., M. Rosen-Zvi, and G. E. Hinton. 2005. “Exp onen-\\ntial family harmoniums with an application to information r e-\\ntrieval”. In: Advances in neural information processing systems .\\n1481–1488.\\n[154] Wikipedia. AI Winter . url: https://en.wikipedia.org/wiki/AI_winter.\\n[155] Wikipedia. Conjugate priors . url: https://en.wikipedia.org/wiki/Conjugate_prior.\\n[156] Wikipedia. Exponential family . url: https://en.wikipedia.org/wiki/Exponential_family.\\n[157] Wilson, A. C., R. Roelofs, M. Stern, N. Srebro, and B. Re cht.\\n2017. “The Marginal V alue of Adaptive Gradient Methods in\\nMachine Learning”. arXiv preprint arXiv:1705.08292 .\\n[158] Witten, I. H., E. F rank, M. A. Hall, and C. J. Pal. 2016. Data\\nMining: Practical machine learning tools and techniques . Mor-\\ngan Kaufmann.\\n[159] Zhang, C., J. Butepage, H. Kjellstrom, and S. Mandt. 20 17.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 235, 'page_label': '230', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Mining: Practical machine learning tools and techniques . Mor-\\ngan Kaufmann.\\n[159] Zhang, C., J. Butepage, H. Kjellstrom, and S. Mandt. 20 17.\\n“Advances in V ariational Inference”. ArXiv e-prints . Nov. arXiv:\\n1711.05597 [cs.LG].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 236, 'page_label': '231', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 231\\n[160] Zhang, Y., J. Duchi, M. I. Jordan, and M. J. W ainwright. 2013.\\n“Information-theoretic lower bounds for distributed stat istical\\nestimation with communication constraints”. In: Advances in\\nNeural Information Processing Systems . 2328–2336.\\n[161] Zhao, X. and A. H. Sayed. 2015. “Asynchronous adaptati on and\\nlearning over networks—Part I: Modeling and stability anal ysis”.\\nIEEE T ransactions on Signal Processing . 63(4): 811–826.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='A Very Brief Introduction to Machine Learning\\nWith Applications to Communication Systems\\nOsvaldo Simeone, Fellow, IEEE\\nAbstract—Given the unprecedented availability of data\\nand computing resources, there is widespread renewed\\ninterest in applying data-driven machine learning methods\\nto problems for which the development of conventional\\nengineering solutions is challenged by modelling or al-\\ngorithmic deﬁciencies. This tutorial-style paper starts by\\naddressing the questions of why and when such techniques\\ncan be useful. It then provides a high-level introduction\\nto the basics of supervised and unsupervised learning. For\\nboth supervised and unsupervised learning, exemplifying\\napplications to communication networks are discussed by\\ndistinguishing tasks carried out at the edge and at the\\ncloud segments of the network at different layers of the\\nprotocol stack, with an emphasis on the physical layer.\\nI. I NTRODUCTION\\nAfter the “AI winter” of the 80s and the 90s, interest in'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='cloud segments of the network at different layers of the\\nprotocol stack, with an emphasis on the physical layer.\\nI. I NTRODUCTION\\nAfter the “AI winter” of the 80s and the 90s, interest in\\nthe application of data-driven Artiﬁcial Intelligence (AI)\\ntechniques has been steadily increasing in a number of\\nengineering ﬁelds, including speech and image analysis\\n[1] and communications [2]. Unlike the logic-based\\nexpert systems that were dominant in the earlier work\\non AI (see, e.g., [3]), the renewed conﬁdence in data-\\ndriven methods is motivated by the successes of pattern\\nrecognition tools based on machine learning. These tools\\nrely on decades-old algorithms, such as backpropagation\\n[4], the Expectation Maximization (EM) algorithm [5],\\nand Q-learning [6], with a number of modern algorithmic\\nadvances, including novel regularization techniques and\\nadaptive learning rate schedules (see review in [7]). Their\\nsuccess is built on the unprecedented availability of data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='advances, including novel regularization techniques and\\nadaptive learning rate schedules (see review in [7]). Their\\nsuccess is built on the unprecedented availability of data\\nand computing resources in many engineering domains.\\nWhile the new wave of promises and breakthroughs\\naround machine learning arguably falls short, at least for\\nnow, of the requirements that drove early AI research\\n[3], [8], learning algorithms have proven to be useful\\nin a number of important applications – and more is\\ncertainly on the way.\\nKing’s College London, United Kingdom (email:\\nosvaldo.simeone@kcl.ac.uk). This work has received funding\\nfrom the European Research Council (ERC) under the European\\nUnion Horizon 2020 research and innovation program (grant\\nagreement 725731).\\nThis paper provides a very brief introduction to key\\nconcepts in machine learning and to the literature on\\nmachine learning for communication systems. Unlike\\nother review papers such as [9]–[11], the presentation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='concepts in machine learning and to the literature on\\nmachine learning for communication systems. Unlike\\nother review papers such as [9]–[11], the presentation\\naims at highlighting conditions under which the use of\\nmachine learning is justiﬁed in engineering problems, as\\nwell as speciﬁc classes of learning algorithms that are\\nsuitable for their solution. The presentation is organized\\naround the description of general technical concepts, for\\nwhich an overview of applications to communication\\nnetworks is subsequently provided. These applications\\nare chosen to exemplify general design criteria and tools\\nand not to offer a comprehensive review of the state of\\nthe art and of the historical progression of advances on\\nthe topic.\\nWe proceed in this section by addressing the question\\n“What is machine learning?”, by providing a taxonomy\\nof machine learning methods, and by ﬁnally considering\\nthe question “When to use machine learning?”.\\nA. What is Machine Learning?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='“What is machine learning?”, by providing a taxonomy\\nof machine learning methods, and by ﬁnally considering\\nthe question “When to use machine learning?”.\\nA. What is Machine Learning?\\nIn order to ﬁx the ideas, it is useful to introduce\\nthe machine learning methodology as an alternative to\\nthe conventional engineering approach for the design of\\nan algorithmic solution. As illustrated in Fig. 1(a), the\\nconventional engineering design ﬂow starts with the ac-\\nquisition of domain knowledge : The problem of interest\\nis studied in detail, producing a mathematical model that\\ncapture the physics of the set-up under study. Based on\\nthe model, an optimized algorithm is produced that offers\\nperformance guarantees under the assumption that the\\ngiven physics-based model is an accurate representation\\nof reality.\\nAs an example, designing a decoding algorithm for\\na wireless fading channel under the conventional engi-\\nneering approach would require the development, or the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of reality.\\nAs an example, designing a decoding algorithm for\\na wireless fading channel under the conventional engi-\\nneering approach would require the development, or the\\nselection, of a physical model for the channel connecting\\ntransmitter and receiver. The solution would be obtained\\nby tackling an optimization problem, and it would yield\\noptimality guarantees under the given channel model.\\nTypical example of channel models include Gaussian and\\nfading channels (see, e.g., [12]).\\n1\\narXiv:1808.02342v4  [cs.IT]  5 Nov 2018'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='acquisition \\nof domain \\nknowledge\\nalgorithm \\ndevelopment\\nphysics-based \\nmathematical model\\nalgorithm with \\nperformance \\nguarantees\\nacquisition \\nof data\\nlearning\\ntraining set\\nblack-box\\nmachine\\nhypothesis \\nclass\\n(a)\\n(b)\\nFig. 1. (a) Conventional engineering design ﬂow; and (b) baseline\\nmachine learning methodology.\\nIn contrast, in its most basic form, the machine\\nlearning approach substitutes the step of acquiring do-\\nmain knowledge with the potentially easier task of\\ncollecting a sufﬁciently large number of examples of\\ndesired behaviour for the algorithm of interest. These\\nexamples constitute the training set. As seen in Fig. 1(b),\\nthe examples in the training set are fed to a learning\\nalgorithm to produce a trained “machine” that carries\\nout the desired task. Learning is made possible by the\\nchoice of a set of possible “machines”, also known as\\nthe hypothesis class, from which the learning algorithm\\nmakes a selection during training. An example of an'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='choice of a set of possible “machines”, also known as\\nthe hypothesis class, from which the learning algorithm\\nmakes a selection during training. An example of an\\nhypothesis class is given by a neural network architecture\\nwith learnable synaptic weights. Learning algorithms are\\ngenerally based on the optimization of a performance\\ncriterion that measures how well the selected “machine”\\nmatches the available data.\\nFor the problem of designing a channel decoder, a\\nmachine learning approach can hence operate even in the\\nabsence of a well-established channel model. It is in fact\\nenough to have a sufﬁciently large number of examples\\nof received signals – the inputs to the decoding machine\\n– and transmitted messages – the desired outputs of the\\ndecoding machine – to be used for the training of a given\\nclass of decoding functions [13].\\nacquisition \\nof domain \\nknowledge\\nacquisition \\nof data\\nlearning\\ntraining set\\n machine\\nhypothesis \\nclass'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='decoding machine – to be used for the training of a given\\nclass of decoding functions [13].\\nacquisition \\nof domain \\nknowledge\\nacquisition \\nof data\\nlearning\\ntraining set\\n machine\\nhypothesis \\nclass\\nFig. 2. Machine learning methodology that integrates domain knowl-\\nedge during model selection.\\nMoving beyond the basic formulation described above,\\nmachine learning tools can integrate available domain\\nknowledge in the learning process. This is indeed the\\nkey to the success of machine learning tools in a number\\nof applications. A notable example is image processing,\\nwhereby knowledge of the translational invariance of vi-\\nsual features is reﬂected in the adoption of convolutional\\nneural networks as the hypothesis class to be trained.\\nMore generally, as illustrated in Fig. 2, domain knowl-\\nedge can dictate the choice of a speciﬁc hypothesis class\\nfor use in the training process. Examples of applications\\nof this idea to communication systems, including to the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='edge can dictate the choice of a speciﬁc hypothesis class\\nfor use in the training process. Examples of applications\\nof this idea to communication systems, including to the\\nproblem of decoding, will be discussed later in the paper.\\nB. Taxonomy of Machine Learning Methods\\nThere are three main classes of machine learning\\ntechniques, as discussed next.\\n• Supervised learning : In supervised learning, the\\ntraining set consists of pairs of input and desired\\noutput, and the goal is that of learning a mapping\\nbetween input and output spaces. As an illustration,\\nin Fig. 3(a), the inputs are points in the two-\\ndimensional plane, the outputs are the labels as-\\nsigned to each input (circles or crosses), and the\\ngoal is to learn a binary classiﬁer. Applications\\ninclude the channel decoder discussed above, as\\nwell as email spam classiﬁcation on the basis of\\nexamples of spam/ non-spam emails.\\n• Unsupervised learning : In unsupervised learning,\\nthe training set consists of unlabelled inputs, that is,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='well as email spam classiﬁcation on the basis of\\nexamples of spam/ non-spam emails.\\n• Unsupervised learning : In unsupervised learning,\\nthe training set consists of unlabelled inputs, that is,\\nof inputs without any assigned desired output. For\\ninstance, in Fig. 3(b), the inputs are again points\\nin the two-dimensional plane, but no indication is\\nprovided by the data about the corresponding de-\\nsired output. Unsupervised learning generally aims\\nat discovering properties of the mechanism gen-\\nerating the data. In the example of Fig. 3(b), the\\ngoal of unsupervised learning is to cluster together\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='input points that are close to each other, hence\\nassigning a label – the cluster index – to each\\ninput point (clusters are delimited by dashed lines).\\nApplications include clustering of documents with\\nsimilar topics. It is emphasized that clustering is\\nonly one of the learning tasks that fall under the\\ncategory of unsupervised learning (see Sec. V).\\n• Reinforcement learning : Reinforcement learning\\nlies, in a sense, between supervised and unsuper-\\nvised learning. Unlike unsupervised learning, some\\nform of supervision exists, but this does not come\\nin the form of the speciﬁcation of a desired output\\nfor every input in the data. Instead, a reinforcement\\nlearning algorithm receives feedback from the envi-\\nronment only after selecting an output for a given\\ninput or observation. The feedback indicates the\\ndegree to which the output, known as action in re-\\ninforcement learning, fulﬁls the goals of the learner.\\nReinforcement learning applies to sequential deci-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='degree to which the output, known as action in re-\\ninforcement learning, fulﬁls the goals of the learner.\\nReinforcement learning applies to sequential deci-\\nsion making problems in which the learner interacts\\nwith an environment by sequentially taking actions\\n– the outputs – on the basis of its observations –\\nits inputs – while receiving feedback regarding each\\nselected action.\\nMost current machine learning applications fall in\\nthe supervised learning category, and hence aim at\\nlearning an existing pattern between inputs and outputs.\\nSupervised learning is relatively well-understood at a\\ntheoretical level [14], [15], and it beneﬁts from well-\\nestablished algorithmic tools. Unsupervised learning has\\nso far deﬁed a uniﬁed theoretical treatment [16]. Never-\\ntheless, it arguably poses a more fundamental practical\\nproblem in that it directly tackles the challenge of learn-\\ning by direct observation without any form of explicit\\nfeedback. Reinforcement learning has found extensive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='problem in that it directly tackles the challenge of learn-\\ning by direct observation without any form of explicit\\nfeedback. Reinforcement learning has found extensive\\napplications in problems that are characterized by clear\\nfeedback signals, such as win/lose outcomes in games,\\nand that entail searches over large trees of possible\\naction-observation histories [17], [18].\\nThis paper only covers supervised and unsupervised\\nlearning. Reinforcement learning requires a different\\nanalytical framework grounded in Markov Decision Pro-\\ncesses and will not be discussed here (see [17]). For a\\nbroader discussion on the technical aspects of supervised\\nand unsupervised learning, we point to [19] and refer-\\nences therein.\\nC. When to Use Machine Learning?\\nBased on the discussion in Sec. I-A, the use of a\\nmachine learning approach in lieu of a more conventional\\nengineering design should be justiﬁed on a case-by-\\ncase basis on the basis of its suitability and potential'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='machine learning approach in lieu of a more conventional\\nengineering design should be justiﬁed on a case-by-\\ncase basis on the basis of its suitability and potential\\nadvantages. The following criteria, inspired by [20], offer\\nuseful guidelines on the type of engineering tasks that\\ncan beneﬁt from the use of machine learning tools.\\n1. The traditional engineering ﬂow is not applicable or\\nis undesirable due to a model deﬁcit or to an algorithm\\ndeﬁcit [21].\\n• With a model deﬁcit, no physics-based mathematical\\nmodels exist for the problem due to insufﬁcient\\ndomain knowledge. As a result, a conventional\\nmodel-based design is inapplicable.\\n• With an algorithm deﬁcit, a well-established math-\\nematical model is available, but existing algorithms\\noptimized on the basis of such model are too com-\\nplex to be implemented for the given application.\\nIn this case, the use of hypothesis classes including\\nefﬁcient “machines”, such as neural network of lim-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='plex to be implemented for the given application.\\nIn this case, the use of hypothesis classes including\\nefﬁcient “machines”, such as neural network of lim-\\nited size or with tailored hardware implementations\\n(see, e.g., [22], [23] and references therein), can\\nyield lower-complexity solutions.\\n2. A sufﬁciently large training data sets exist or can be\\ncreated.\\n3. The task does not require the application of logic,\\ncommon sense, or explicit reasoning based on back-\\nground knowledge.\\n4. The task does not require detailed explanations for\\nhow the decision was made . The trained machine is by\\nand large a black box that maps inputs to outputs. As\\nsuch, it does not provide direct means to ascertain why a\\ngiven output has been produced in response to an input,\\nalthough recent research has made some progress on\\nthis front [24]. This contrasts with engineered optimal\\nsolutions, which can be typically interpreted on the\\nbasis of physical performance criteria. For instance, a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='this front [24]. This contrasts with engineered optimal\\nsolutions, which can be typically interpreted on the\\nbasis of physical performance criteria. For instance, a\\nmaximum likelihood decoder chooses a given output\\nbecause it minimizes the probability of error under the\\nassumed model.\\n5. The phenomenon or function being learned is station-\\nary for a sufﬁciently long period of time. This is in order\\nto enable data collection and learning.\\n6. The task has either loose requirement constraints,\\nor, in the case of an algorithm deﬁcit, the required\\nperformance guarantees can be provided via numeri-\\ncal simulations . With the conventional engineering ap-\\nproach, theoretical performance guarantees can be ob-\\ntained that are backed by a physics-based mathematical\\nmodel. These guarantees can be relied upon insofar as\\nthe model is trusted to be an accurate representation\\nof reality. If a machine learning approach is used to\\naddress an algorithm deﬁcit and a physics-based model'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='the model is trusted to be an accurate representation\\nof reality. If a machine learning approach is used to\\naddress an algorithm deﬁcit and a physics-based model\\nis available, then numerical results may be sufﬁcient in\\norder to compute satisfactory performance measures. In\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='4 5 6 7 8 90\\n1\\n2\\n3\\n4\\n5\\n4 5 6 7 80\\n1\\n2\\n3\\n4\\n5\\n(a)\\n(b)\\nFig. 3. Illustration of (a) supervised learning and (b) unsupervised\\nlearning.\\ncontrast, weaker guarantees can be offered by machine\\nlearning in the absence of a physics-based model. In this\\ncase, one can provide performance bounds only under\\nthe assumptions that the hypothesis class is sufﬁciently\\ngeneral to include “machines” that can perform well on\\nthe problem and that the data is representative of the\\nactual data distribution to be encountered at runtime (see,\\ne.g., [19][Ch. 5]). The selection of a biased hypothesis\\nclass or the use of an unrepresentative data set may hence\\nyield strongly suboptimal performance.\\nWe will return to these criteria when discussing ap-\\nplications to communication systems.\\nII. M ACHINE LEARNING FOR COMMUNICATION\\nNETWORKS\\nIn order to exemplify applications of supervised and\\nunsupervised learning, we will offer annotated pointers\\nto the literature on machine learning for communication'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='NETWORKS\\nIn order to exemplify applications of supervised and\\nunsupervised learning, we will offer annotated pointers\\nto the literature on machine learning for communication\\nsystems. Rather than striving for a comprehensive, and\\nhistorically minded, review, the applications and refer-\\nences have been selected with the goal of illustrating\\nkey aspects regarding the use of machine learning in\\nengineering problems.\\nCore \\nNetwork\\nEdge \\nCloud\\nWireless \\nEdge\\nAccess \\nNetwork\\nCore \\nCloud\\nCloud\\nEdge\\nFig. 4. A generic cellular wireless network architecture that dis-\\ntinguishes between edge segment, with base stations, access points,\\nand associated computing resources, and cloud segment, consisting\\nof core network and associated cloud computing platforms.\\nThroughout, we focus on tasks carried out at the\\nnetwork side, rather than at the users, and organize the\\napplications along two axes. On one, with reference to\\nFig. 4, we distinguish tasks that are carried out at the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='network side, rather than at the users, and organize the\\napplications along two axes. On one, with reference to\\nFig. 4, we distinguish tasks that are carried out at the\\nedge of the network, that is, at the base stations or\\naccess points and at the associated computing platforms,\\nfrom tasks that are instead responsibility of a centralized\\ncloud processor connected to the core network (see, e.g.,\\n[25]). The edge operates on the basis of timely local\\ninformation collected at different layers of the protocol\\nstack, which may include all layers from the physical up\\nto the application layer. In contrast, the centralized cloud\\nprocesses longer-term and global information collected\\nfrom multiple nodes in the edge network, which typically\\nencompasses only the higher layers of the protocol stack,\\nnamely networking and application layers. Examples of\\ndata that may be available at the cloud and at the edge\\ncan be found in Table I and Table II, respectively.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='namely networking and application layers. Examples of\\ndata that may be available at the cloud and at the edge\\ncan be found in Table I and Table II, respectively.\\nAs a preliminary discussion, it is useful to ask which\\ntasks of a communication network, if any, may beneﬁt\\nfrom machine learning through the lens of the criteria re-\\nviewed in Sec. I-C. First, as seen, there should be either a\\nmodel deﬁcit or an algorithm deﬁcit that prevents the use\\nof a conventional model-based engineering design. As an\\nexample of model deﬁcit, proactive resource allocation\\nthat is based on predictions of human behaviour, e.g., for\\ncaching popular contents, may not beneﬁt from well-\\nestablished and reliable models, making a data-driven\\napproach desirable (see, e.g., [26], [27]). For an instance\\nof algorithm deﬁcit, consider the problem of channel\\ndecoding for channels with known and accurate models\\nbased on which the maximum likelihood decoder entails\\nan excessive complexity.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of algorithm deﬁcit, consider the problem of channel\\ndecoding for channels with known and accurate models\\nbased on which the maximum likelihood decoder entails\\nan excessive complexity.\\nAssuming that the problem at hand is characterized\\nby model or algorithm deﬁcits, one should then consider\\nthe rest of the criteria discussed in Sec. I-C. Most are\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='TABLE I\\nEXAMPLES OF DATA AVAILABLE AT THE EDGE SEGMENT OF A COMMUNICATION NETWORK\\nLayer Data\\nPhysical Baseband signals, channel state information\\nMedium Access Control/ Link Throughput, FER, random access load and latency\\nNetwork Location, trafﬁc loads across services, users’ device types, battery levels\\nApplication Users’ preferences, content demands, computing loads, QoS metrics\\nTABLE II\\nEXAMPLES OF DATA AVAILABLE AT THE CLOUD SEGMENT OF A COMMUNICATION NETWORK\\nLayer Data\\nNetwork Mobility patterns, network-wide trafﬁc statistics, outage rates\\nApplication User’s behaviour patterns, subscription information, service usage statistics, TCP/IP trafﬁc statistics\\ntypically satisﬁed by communication problems. Indeed,\\nfor most tasks in communication networks, it is possible\\nto collect or generate training data sets and there is\\nno need to apply common sense or to provide detailed\\nexplanations for how a decision was made.\\nThe remaining two criteria need to be checked on a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='no need to apply common sense or to provide detailed\\nexplanations for how a decision was made.\\nThe remaining two criteria need to be checked on a\\ncase-by-case basis. First, the phenomenon or function\\nbeing learned should not change too rapidly over time.\\nFor example, designing a channel decoder based on\\nsamples obtained from a limited number of realizations\\nof a given propagation channel requires the channel is\\nstationary over a sufﬁciently long period of time (see\\n[28]).\\nSecond, in the case of a model deﬁcit, the task should\\nhave some tolerance for error in the sense of not requir-\\ning provable performance guarantees. For instance, the\\nperformance of a decoder trained on a channel lacking\\na well-established channel model, such as a biological\\ncommunication link, can only be relied upon insofar\\nas one trusts the available data to be representative of\\nthe complete set of possible realizations of the problem\\nunder study. Alternatively, under an algorithm deﬁcit, a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='as one trusts the available data to be representative of\\nthe complete set of possible realizations of the problem\\nunder study. Alternatively, under an algorithm deﬁcit, a\\nphysics-based model, if available, can be possibly used\\nto carry out computer simulations and obtain numerical\\nperformance guarantees.\\nIn Sec. IV and Sec. VI, we will provide some pointers\\nto speciﬁc applications to supervised and unsupervised\\nlearning, respectively.\\nIII. S UPERVISED LEARNING\\nAs introduced in Sec. I, supervised learning aims at\\ndiscovering patterns that relate inputs to outputs on the\\nbasis of a training set of input-output examples. We can\\ndistinguish two classes of supervised learning problems\\ndepending on whether the outputs are continuous or dis-\\ncrete variables. In the former case, we have a regression\\nproblem, while in the latter we have a classiﬁcation\\n0 0.2 0.4 0.6 0.8 1-1.5\\n-1\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n?\\nFig. 5. Illustration of the supervised learning problem of regression:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='problem, while in the latter we have a classiﬁcation\\n0 0.2 0.4 0.6 0.8 1-1.5\\n-1\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n?\\nFig. 5. Illustration of the supervised learning problem of regression:\\nGiven input-output training examples (xn,tn), with n = 1,...,N ,\\nhow should we predict the output t for an unobserved value of the\\ninput x?\\nproblem. We discuss the respective goals of the two\\nproblems next. This is followed by a formal deﬁnition of\\nclassiﬁcation and regression, and by a discussion of the\\nmethodology and of the main steps involved in tackling\\nthe two classes of problems.\\nA. Goals\\nAs illustrated in Fig. 5, in a regression problem, we\\nare given a training set Dof N training points (xn,tn),\\nwith n= 1,...,N , where the variables xn are the inputs,\\nalso known as covariates, domain points, or explanatory\\nvariables; while the variables tn are the outputs, also\\nknown as dependent variables, labels, or responses. In\\nregression, the outputs are continuous variables. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='variables; while the variables tn are the outputs, also\\nknown as dependent variables, labels, or responses. In\\nregression, the outputs are continuous variables. The\\nproblem is to predict the output t for a new, that is,\\nas of yet unobserved, input x.\\nAs illustrated in Fig. 6, classiﬁcation is similarly\\ndeﬁned with the only caveat that the outputstare discrete\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='4 5 6 7 8 90.5\\n1\\n1.5\\n2\\n2.5\\n3\\n3.5\\n4\\n4.5\\n?\\nFig. 6. Illustration of the supervised learning problem of classi-\\nﬁcation: Given input-output training examples (xn,tn), with n =\\n1,...,N , how should we predict the output tfor an unobserved value\\nof the input x?\\nvariables that take a ﬁnite number of possible values. The\\nvalue of the output t for a given input x indicates the\\nclass to which x belongs. For instance, the label t is a\\nbinary variable as in Fig. 6 for a binary classiﬁcation\\nproblem. Based on the training set D, the goal is to\\npredict the label, or the class, t for a new, as of yet\\nunobserved, input x.\\nTo sum up, the goal of both regression and clas-\\nsiﬁcation is to derive from the training data set D a\\npredictor ˆt(x) that generalizes the input-output mapping\\nin Dto inputs x that are not present in D. As such,\\nlearning is markedly distinct from memorizing: while\\nmemorizing would require producing a value tn for some\\nrecorded input xn in the training set, learning is about'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='learning is markedly distinct from memorizing: while\\nmemorizing would require producing a value tn for some\\nrecorded input xn in the training set, learning is about\\ngeneralization from the data set to the rest of the relevant\\ninput space.\\nThe problem of extrapolating a predictor from the\\ntraining set is evidently impossible unless one is willing\\nto make some assumption about the underlying input-\\noutput mapping. In fact, the output t may well equal\\nany value for an unobserved xif nothing else is speciﬁed\\nabout the problem. This impossibility is formalized by\\nthe no free-lunch theorem: without making assumptions\\nabout the relationship between input and output, it is not\\npossible to generalize the available observations outside\\nthe training set [14]. The set of assumptions made in\\norder to enable learning are known as inductive bias .\\nAs an example, for the regression problem in Fig. 5,\\na possible inductive bias is to postulate that the input-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='order to enable learning are known as inductive bias .\\nAs an example, for the regression problem in Fig. 5,\\na possible inductive bias is to postulate that the input-\\noutput mapping is a polynomial function of some order.\\nB. Deﬁning Supervised Learning\\nHaving introduced the goal of supervised learning, we\\nnow provide a more formal deﬁnition of the problem.\\nThroughout, we use Roman font to denote random\\nvariables and the corresponding letter in regular font for\\nrealizations.\\nAs a starting point, we assume that the training set D\\nis generated as\\n(xn,tn) ∼\\ni.i.d.\\np(x,t), n= 1,...,N, (1)\\nthat is, each training sample pair (xn,tn) is generated\\nfrom the same true joint distribution p(x,t) and the sam-\\nple pairs are independent identically distributed (i.i.d.).\\nAs discussed, based on the training set D, we wish\\nto obtain a predictor ˆt(x) that performs well on any\\npossible relevant input x. This requirement is formalized\\nby imposing that the predictor is accurate for any test'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to obtain a predictor ˆt(x) that performs well on any\\npossible relevant input x. This requirement is formalized\\nby imposing that the predictor is accurate for any test\\npair (x,t) ∼p(x,t), which is generated independently\\nof all the pairs in the training set D.\\nThe quality of the prediction ˆt(x) for a test pair ( x,t)\\nis measured by a given loss function ℓ(t,ˆt) as ℓ(t,ˆt(x)).\\nTypical examples of loss functions include the quadratic\\nloss ℓ(t,ˆt) = (t−ˆt)2 for regression problems; and the\\nerror rate ℓ(t,ˆt) = 1(t ̸= ˆt), which equals 1 when the\\nprediction is incorrect, i.e., t ̸= ˆt, and 0 otherwise, for\\nclassiﬁcation problems.\\nThe formal goal of learning is that of minimizing the\\naverage loss on the test pair, which is referred to as the\\ngeneralization loss. For a given predictorˆt, this is deﬁned\\nas\\nLp(ˆt) =E(x,t)∼p(x,t)[ℓ(t,ˆt(x))]. (2)\\nThe generalization loss (2) is averaged over the distribu-\\ntion of the test pair ( x,t).\\nBefore moving on to the solution of the problem of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='as\\nLp(ˆt) =E(x,t)∼p(x,t)[ℓ(t,ˆt(x))]. (2)\\nThe generalization loss (2) is averaged over the distribu-\\ntion of the test pair ( x,t).\\nBefore moving on to the solution of the problem of\\nminimizing the generalization loss, we mention that the\\nformulation provided here is only one, albeit arguably\\nthe most popular, of a number of alternative formula-\\ntions of supervised learning. The frequentist framework\\ndescribed above is in fact complemented by other view-\\npoints, including Bayesian and Minimum Description\\nLength (MDL) (see [19] and references therein).\\nC. When The True Distribution p(x,t) is Known: Infer-\\nence\\nConsider ﬁrst the case in which the true joint dis-\\ntribution p(x,t) relating input and output is known.\\nThis scenario can be considered as an idealization of\\nthe situation resulting from the conventional engineering\\ndesign ﬂow when the available physics-based model is\\naccurate (see Sec. I). Under this assumption, the data set\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Dis not necessary, since the mapping between input and\\noutput is fully described by the distribution p(x,t).\\nIf the true distribution p(x,t) is known, the problem\\nof minimizing the generalization loss reduces to a stan-\\ndard inference problem, i.e., an estimation problem in a\\nregression set-up, in which the outputs are continuous\\nvariables, or a detection problem in a classiﬁcation set-\\nup, in which the outputs are ﬁnite discrete variables.\\nIn an inference problem, the optimal predictor ˆt can\\nbe directly computed from the posterior distribution\\np(t|x) =p(x,t)\\np(x) , (3)\\nwhere p(x) is the marginal distribution of the input x.\\nThe latter can be computed from the joint distribution\\np(x,t) by summing or integrating out all the values of t.\\nIn fact, given a loss function ℓ(t,ˆt), the optimal predictor\\nfor any input x is obtained as\\nˆt∗(x) =arg min\\nˆt\\nEt∼p(t|x)[ℓ(t,ˆt)|x]. (4)\\nIn words, the optimal predictor ˆt∗(x) is obtained by\\nidentifying the value (or values) of t that minimizes the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='for any input x is obtained as\\nˆt∗(x) =arg min\\nˆt\\nEt∼p(t|x)[ℓ(t,ˆt)|x]. (4)\\nIn words, the optimal predictor ˆt∗(x) is obtained by\\nidentifying the value (or values) of t that minimizes the\\naverage loss, where the average is taken with respect\\nto the posterior distribution p(t|x) of the output given\\nthe input. Given that the posterior p(t|x) yields the\\noptimal predictor, it is also known as the true predictive\\ndistribution.\\nThe optimal predictor (4) can be explicitly evaluated\\nfor given loss functions. For instance, for the quadratic\\nloss, which is typical for regression, the optimal predictor\\nis given by the mean of the predictive distribution, or the\\nposterior mean, i.e.,\\nˆt∗(x) =Et∼p(t|x)[t|x], (5)\\nwhile, with the error rate loss, which is typical for\\nclassiﬁcation, problems, the optimal predictor is given\\nby the maximum of the predictive distribution, or the\\nmaximum a posteriori (MAP) estimate, i.e.,\\nˆt∗(x) =arg max\\nt\\np(t|x). (6)\\nFor a numerical example, consider binary inputs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='by the maximum of the predictive distribution, or the\\nmaximum a posteriori (MAP) estimate, i.e.,\\nˆt∗(x) =arg max\\nt\\np(t|x). (6)\\nFor a numerical example, consider binary inputs\\nand outputs and the joint distribution p(x,t) such that\\np(0,0) = 0 .05, p(0,1) = 0 .45, p(1,0) = 0 .4 and\\np(1,1) = 0.1. The predictive distribution for input x= 0\\nis then given as p(t = 1|x = 0) = 0.9, and hence\\nwe have the optimal predictor given by the average\\nˆt∗(x = 0) = 0.9 ×1 + 0.1 ×0 = 0.9 for the quadratic\\nloss, and by the MAP solution ˆt∗(x = 0) = 1for the\\nerror rate loss.\\nD. When the True Distribution p(x,t) is Not Known:\\nMachine Learning\\nConsider now the case of interest in which domain\\nknowledge is not available and hence the true joint\\ndistribution is unknown. In such a scenario, we have a\\nlearning problem and we need to use the examples in the\\ntraining set Din order to obtain a meaningful predictor\\nthat approximately minimizes the generalization loss.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='learning problem and we need to use the examples in the\\ntraining set Din order to obtain a meaningful predictor\\nthat approximately minimizes the generalization loss.\\nAt a high level, the methodology applied by machine\\nlearning follows three main steps, which are described\\nnext.\\n1. Model selection (inductive bias) : As a ﬁrst step,\\none needs to commit to a speciﬁc class of hypotheses that\\nthe learning algorithm may choose from. The hypothesis\\nclass is also referred to as model. The selection of the hy-\\npothesis class characterizes the inductive bias mentioned\\nabove as a pre-requisite for learning. In a probabilistic\\nframework, the hypothesis class, or model, is deﬁned\\nby a family of probability distributions parameterized\\nby a vector θ. Speciﬁcally, there are two main ways\\nof specifying a parametric family of distributions as a\\nmodel for supervised learning:\\n• Generative model : Generative models specify a\\nfamily of joint distributions p(x,t|θ);'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of specifying a parametric family of distributions as a\\nmodel for supervised learning:\\n• Generative model : Generative models specify a\\nfamily of joint distributions p(x,t|θ);\\n• Discriminative model : Discriminative models pa-\\nrameterize directly the predictive distribution as\\np(t|x,θ).\\nBroadly speaking, discriminative models do not make\\nany assumptions about the distribution of the inputs\\nx and hence may be less prone to bias caused by a\\nmisspeciﬁcation of the hypothesis class. On the ﬂip side,\\ngenerative models may be able to capture more of the\\nstructure present in the data and consequently improve\\nthe performance of the predictor [29]. For both types of\\nmodels, the hypothesis class is typically selected from\\na common set of probability distributions that lead to\\nefﬁcient learning algorithms in Step 2. Furthermore, any\\navailable basic domain knowledge can be in principle\\nincorporated in the selection of the model (see also Sec.\\nVII).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='efﬁcient learning algorithms in Step 2. Furthermore, any\\navailable basic domain knowledge can be in principle\\nincorporated in the selection of the model (see also Sec.\\nVII).\\n2. Learning: Given data D, in the learning step, a\\nlearning criterion is optimized in order to obtain the\\nparameter vector θ and identify a distribution p(x,t|θ)\\nor p(t|x,θ), depending on whether a generative or dis-\\ncriminative model was selected at Step 1.\\n3. Inference: In the inference step, the learned model\\nis used to obtain the predictor ˆt(x) by using (4) with\\nthe learned model in lieu of the true distribution. Note\\nthat generative models require the calculation of the\\npredictive distribution p(t|x) via marginalization, while\\ndiscriminative models provide directly the predictive\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='distribution. As mentioned, the predictor should be eval-\\nuated on test data that is different from the training set\\nD. As we will discuss, the design cycle typically entails\\na loop between validation of the predictor at Step 3 and\\nmodel selection at Step 1.\\nThe next examples illustrate the three steps introduced\\nabove for a binary classiﬁcation problem.\\nExample 1 : Consider a binary classiﬁcation problem\\nin which the input is a generic D-dimensional vector\\nx = [x1,...,x D]T and the output is binary, i.e., t ∈\\n{0,1}. The superscript “ T” represents transposition. In\\nStep 1, we select a model, that is, a parameterized family\\nof distributions. A common choice is given by logistic\\nregression1, which is a discriminative model whereby\\nthe predictive distribution p(t|x,θ) is parameterized as\\nillustrated in Fig. 7. The model ﬁrst computes D′ ﬁxed\\nfeatures φ(x) = [φ1(x) ···φD′(x)]T of the input, where\\na feature is a function of the data. Then, it computes the\\npredictive probability as'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='illustrated in Fig. 7. The model ﬁrst computes D′ ﬁxed\\nfeatures φ(x) = [φ1(x) ···φD′(x)]T of the input, where\\na feature is a function of the data. Then, it computes the\\npredictive probability as\\np(t= 1|x,w) =σ(wTφ(x)), (7)\\nwhere w is the set of learnable weights – i.e., the pa-\\nrameter θ deﬁned above – and σ(a) = (1 + exp(−a))−1\\nis the sigmoid function.\\nUnder logistic regression, the probability that the label\\nis t= 1 increases as the linear combination of features\\nbecomes more positive, and we havep(t= 1|x,w) >0.5\\nfor wTφ(x) > 0. Conversely, the probability that the\\nlabel is t = 0 increases as the linear combination of\\nfeatures becomes more negative, with p(t = 0|x,w) >\\n0.5 for wTφ(x) < 0. As a speciﬁc instance of this\\nproblem, if we wish to classify emails between spam\\nand non-spam ones, possible useful features may count\\nthe number of times that certain suspicious words appear\\nin the text.\\nStep 2 amounts to the identiﬁcation of the weight'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='and non-spam ones, possible useful features may count\\nthe number of times that certain suspicious words appear\\nin the text.\\nStep 2 amounts to the identiﬁcation of the weight\\nvector w on the basis of the training set D with the\\nideal goal of minimizing the generalization loss (2). This\\nstep will be further discussed in the next subsection.\\nFinally, in Step 3, the optimal predictor is obtained\\nby assuming that the learned model p(t|x,w) is the\\ntrue predictive distribution. Assuming an error rate loss\\nfunction, following the discussion in Sec. III-C, the\\noptimal predictor is given by the MAP choice ˆt∗(x) = 1\\nif wTφ(x) >0 and ˆt∗(x) = 0otherwise. It is noted that\\nthe linear combination wTφ(x) is also known as logit\\nor log-likelihood ratio (LLR) . This rule can be seen to\\ncorrespond to a linear classiﬁer [19]. The performance\\n1The term ”regression” may be confusing, since the model applies\\nto classiﬁcation.\\nFig. 7. An illustration of the hypothesis class p(t|x,w) assumed by'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='1The term ”regression” may be confusing, since the model applies\\nto classiﬁcation.\\nFig. 7. An illustration of the hypothesis class p(t|x,w) assumed by\\nlogistic regression using a neural network representation: functions\\nφi, with i = 1,...,D ′, are ﬁxed and compute features of the input\\nvector x = [x1,...,x D]. The learnable parameter vector θ here\\ncorresponds to the weights w used to linearly combine the features\\nin (7).\\nof the predictor should be tested on new, test, input-\\noutput pairs, e.g., new emails in the spam classiﬁcation\\nexample. □\\nExample 2 : Logistic regression requires to specify a\\nsuitable vector of features φ(x). As seen in the email\\nspam classiﬁcation example, this entails the availability\\nof some domain knowledge to be able to ascertain which\\nfunctions of the input x may be more relevant for the\\nclassiﬁcation task at hand. As discussed in Sec. I, this\\nknowledge may not be available due to, e.g., cost or\\ntime constraints. Multi-layer neural networks provide an'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='classiﬁcation task at hand. As discussed in Sec. I, this\\nknowledge may not be available due to, e.g., cost or\\ntime constraints. Multi-layer neural networks provide an\\nalternative model choice at Step 1 that obviates the need\\nfor hand-crafted features. The model is illustrated in\\nFig. 8. Unlike linear regression, in a multi-layer neural\\nnetwork, the feature vector φ(x) used by the last layer to\\ncompute the logit, or LLR, that determines the predictive\\nprobability (7) is not ﬁxed a priori. Rather, the feature\\nvector is computed by the previous layers. To this end,\\neach neuron, represented as a circle in Fig. 8, computes\\na ﬁxed non-linear function, e.g., sigmoid, of a linear\\ncombination of the values obtained from the previous\\nlayer. The weights of these linear combinations are part\\nof the learnable parameters θ, along with the weights of\\nthe last layer. By allowing the weights at all layers of the\\nmodel to be trained simultaneously, multi-layer neural'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of the learnable parameters θ, along with the weights of\\nthe last layer. By allowing the weights at all layers of the\\nmodel to be trained simultaneously, multi-layer neural\\nnetworks enable the joint learning of the last-layer linear\\nclassiﬁer and of the features φ(x) the classiﬁer operates\\non. As a notable example, deep neural networks are\\ncharacterized by a large number of intermediate layers\\nthat tend to learn increasingly abstract features of the\\ninput [7]. □\\nIn the rest of this section, we ﬁrst provide some\\ntechnical details about Step 2, i.e., learning, and then we\\nreturn to Step 1, i.e., model selection. As it will be seen,\\nthis order is dictated by the fact that model selection\\nrequires some understanding of the learning process.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Fig. 8. An illustration of the hypothesis class p(t|x,w) assumed\\nby multi-layer neural networks. The learnable parameter vector θ\\nhere corresponds to the weights wL used at the last layer to linearly\\ncombine the features φ(x) and the weight matrices W1,...,W L−1\\nused at the preceding layers in order to compute the feature vector.\\nE. Learning\\nIdeally, a learning rule should obtain a predictor\\nthat minimizes the generalization error (2). However, as\\ndiscussed in Sec. III-C, this task is out of reach without\\nknowledge of the true joint distribution p(x,t). There-\\nfore, alternative learning criteria need to be considered\\nthat rely on the training set Drather than on the true\\ndistribution.\\nIn the context of probabilistic models, the most basic\\nlearning criterion is Maximum Likelihood (ML). ML\\nselects a value of θin the parameterized family of models\\np(x,t|θ) or p(t|x,θ) that is the most likely to have\\ngenerated the observed training set D. Mathematically,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='selects a value of θin the parameterized family of models\\np(x,t|θ) or p(t|x,θ) that is the most likely to have\\ngenerated the observed training set D. Mathematically,\\nML solves the problem of maximizing the log-likelihood\\nfunction\\nmaximize ln p(D|θ) (8)\\nover θ, where p(D|θ) is the probability of the data set\\nDfor a given value of θ. Given the assumption of i.i.d.\\ndata points in D(see Sec. III-B), the log-likelihood can\\nbe written as\\nln p(D|θ) =\\nN∑\\nn=1\\nln p(tn|xn,θ), (9)\\nwhere we have used as an example the case of discrim-\\ninative models. Note that most learning criteria used in\\npractice can be interpreted as ML problems, including\\nthe least squares criterion – ML for Gaussian models –\\nand cross-entropy – ML for categorical models.\\nThe ML problem (8) rarely has analytical solutions\\nand is typically addressed by Stochastic Gradient De-\\nscent (SGD). Accordingly, at each iteration, subsets of\\nexamples, also known as mini-batches, are selected from'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='and is typically addressed by Stochastic Gradient De-\\nscent (SGD). Accordingly, at each iteration, subsets of\\nexamples, also known as mini-batches, are selected from\\nthe training set, and the parameter vector is updated in\\nthe direction of gradient of the log-likelihood function\\nas evaluated on these examples. The resulting learning\\nrule can be written as\\nθnew ←θold + γ∇θln p(tn|xn,θ)|θ=θold , (10)\\nwhere we have deﬁned as γ >0 the learning rate, and,\\nfor simplicity of notation, we have considered a mini-\\nbatch given by a single example (xn,tn). It is noted\\nthat, with multi-layer neural networks, the computation\\nof the gradient ∇θln p(tn|xn,θ) yields the standard\\nbackpropagation algorithm [7], [19]. The learning rate is\\nan example of hyperparameters that deﬁne the learning\\nalgorithm. Many variations of SGD have been proposed\\nthat aim at improving convergence (see, e.g., [7], [19]).\\nML has evident drawbacks as an indirect means of\\nminimizing the generalization error. In fact, ML only'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='that aim at improving convergence (see, e.g., [7], [19]).\\nML has evident drawbacks as an indirect means of\\nminimizing the generalization error. In fact, ML only\\nconsiders the ﬁt of the probabilistic model on the training\\nset without any consideration for the performance on\\nunobserved input-output pairs. This weakness can be\\nsomewhat mitigated by regularization [7], [19] during\\nlearning and by a proper selection of the model via\\nvalidation, as discussed in the next subsection. Regu-\\nlarization adds a penalty term to the log-likelihood that\\ndepends on the model parameters θ. The goal is to\\nprevent the learned model parameters θto assume values\\nthat are a priori too unlikely and that are hence possible\\nsymptoms of overﬁtting. As an example, for logistic\\nregression, one can add a penalty that is proportional\\nto the norm ||w||2 of the weight vector w in order to\\nprevent the weights to assume excessively high values\\nwhen ﬁtting the data in the learning step.\\nF . Model Selection'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to the norm ||w||2 of the weight vector w in order to\\nprevent the weights to assume excessively high values\\nwhen ﬁtting the data in the learning step.\\nF . Model Selection\\nWe now discuss the ﬁrst, key, step of model selection,\\nwhich deﬁnes the inductive bias adopted in the learning\\nprocess. In order to illustrate the main ideas, here we\\nstudy a particular aspect of model selection, namely that\\nof model order selection . To this end, we consider a\\nhierarchical set of models of increasing complexity and\\nwe address the problem of selecting (in Step 1) the order,\\nor the complexity, of the speciﬁc model to be posited\\nfor learning (in Step 2). As an example of model order\\nselection, one may ﬁx a set of models including multi-\\nlayer networks of varying number of intermediate layers\\nand focus on determining the number of layers. It is\\nemphasized that the scope of model selection goes much\\nbeyond model order selection, including the possible\\nincorporation of domain knowledge and the tuning of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='emphasized that the scope of model selection goes much\\nbeyond model order selection, including the possible\\nincorporation of domain knowledge and the tuning of\\nthe hyperparameters of the learning algorithm.\\nFor concreteness, we focus on the regression problem\\nillustrated in Fig. 5 and assume a set of discriminative\\nmodels p(t|x,w) under which the output tis distributed\\nas\\nM∑\\nm=0\\nwmxm + N(0,1). (11)\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='0 0.2 0.4 0.6 0.8 1\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n= 9M\\nM = 1\\nM = 3\\nFig. 9. Training set in Fig. 5, along with a predictor trained by\\nusing the discriminative model (11) and ML for different values of\\nthe model order M.\\nIn words, the output tis given by a polynomial function\\nof order M of the input xplus zero-mean Gaussian noise\\nof power equal to one. The learnable parameter vector\\nθ is given by the weights w = [w0,...,w M−1]T. Model\\nselection, to be carried out in Step 1, amounts to the\\nchoice of the model order M.\\nHaving chosen M in Step 1, the weights w can be\\nlearned in Step 2 using ML, and then the optimal pre-\\ndictor can be obtained for inference in Step 3. Assuming\\nthe quadratic loss, the optimal predictor is given by the\\nposterior mean ˆt(x) = ∑M\\nm=0 wmxm for the learned\\nparameters w. This predictor is plotted in Fig. 9 for\\ndifferent values of M, along with the training set of Fig.\\n5.\\nWith M = 1, the predictor ˆt(x) is seen to underﬁt\\nthe training data. This is in the sense that the model is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='different values of M, along with the training set of Fig.\\n5.\\nWith M = 1, the predictor ˆt(x) is seen to underﬁt\\nthe training data. This is in the sense that the model is\\nnot rich enough to capture the variations present in the\\ntraining data, and, as a result, we obtain a large training\\nloss\\nLD(w) = 1\\nN\\nN∑\\nn=1\\n(tn −ˆt(xn))2. (12)\\nThe training loss measures the quality of the predictor\\ndeﬁned by weights won the points in the training set. In\\ncontrast, with M = 9, the predictor ﬁts well the training\\ndata – so much so that it appears to overﬁt it. In other\\nwords, the model is too rich and, in order to account\\nfor the observations in the training set, it appears to\\nyield inaccurate predictions outside it. As a compromise\\nbetween underﬁtting and overﬁtting, the selection M = 3\\nseems to be preferable.\\nAs implied by the discussion above, underﬁtting can\\nbe detected by observing solely the training data Dvia\\nthe evaluation of the training loss (12). In contrast, over-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='seems to be preferable.\\nAs implied by the discussion above, underﬁtting can\\nbe detected by observing solely the training data Dvia\\nthe evaluation of the training loss (12). In contrast, over-\\nﬁtting cannot be ascertained on the basis of the training\\ndata as it refers to the performance of the predictor out-\\nside D. It follows that model selection cannot be carried\\nout by observing only the training set. Rather, some\\ninformation must be available about the generalization\\nperformance of the predictor. This is typically obtained\\nby means of validation. In its simplest instantiation,\\nvalidation partitions the available data into two sets, a\\ntraining set Dand a validation set . The training set is\\nused for learning as discussed in Sec. III-E, while the\\nvalidation set is used to estimate the generalization loss.\\nThis is done by computing the average in (12) only over\\nthe validation set. More sophisticated forms of validation\\nexist, including cross-validation [7].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='This is done by computing the average in (12) only over\\nthe validation set. More sophisticated forms of validation\\nexist, including cross-validation [7].\\nKeeping some data aside for validation, one can obtain\\na plot as in Fig. 10, where the training loss (12) is\\ncompared with the generalization loss (2) estimated\\nvia validation. The ﬁgure allows us to conclude that,\\nwhen M is large enough, the generalization loss starts\\nincreasing, indicating overﬁtting. Note, in contrast, that\\nunderﬁtting is detectable by observing the training loss.\\nA ﬁgure such as Fig. 10 can be used to choose a value\\nof M that approximately minimizes the generalization\\nloss.\\nMore generally, validation allows for model selection,\\nas well as for the selection of the parameters used\\nby learning the algorithm, such as the learning rate γ\\nin (10). To this end, one compares the generalization\\nloss, estimated via validation, for a number of models\\nand then chooses the one with the smallest estimated\\ngeneralization loss.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='in (10). To this end, one compares the generalization\\nloss, estimated via validation, for a number of models\\nand then chooses the one with the smallest estimated\\ngeneralization loss.\\nFinally, it is important to remark that the performance\\nof the model selected via validation should be estimated\\non the basis of a separate data set, typically called\\nthe test set . This is because the generalization loss\\nestimated using validation is a biased estimate of the\\ntrue generalization loss (2) due to the process of model\\nselection. In particular, the loss on the validation set will\\ntend to be small, since the model was selected during\\nvalidation with the aim of minimizing it. Importantly, the\\ntest set should never be used during the three steps that\\nmake up the machine learning methodology and should\\nideally only be used once to test the trained predictor.\\nIV. A PPLICATIONS OF SUPERVISED LEARNING TO\\nCOMMUNICATION SYSTEMS\\nIn this section, we provide some pointers to existing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='ideally only be used once to test the trained predictor.\\nIV. A PPLICATIONS OF SUPERVISED LEARNING TO\\nCOMMUNICATION SYSTEMS\\nIn this section, we provide some pointers to existing\\napplications of supervised learning to communication\\nnetworks. The discussion is organized by following the\\napproach described in Sec. II. Accordingly, we distin-\\nguish between tasks carried out at edge and cloud (see\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='1 2 3 4 5 6 7 8 9\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\n1.6root average squared loss\\ntraining\\ngeneralization \\n(via validation)\\noverfitting\\nunderfitting\\nFig. 10. Training loss and generalization loss, estimated via valida-\\ntion, as a function of the model order M for the example in Fig.\\n9.\\nFig. 4), as well as at different layers of the protocol\\nstack. We refer to Table I and Table II for examples of\\ndata types that may be available at the edge and cloud\\nsegments.\\nA. At the Edge\\nConsider ﬁrst tasks to be carried out at the edge, i.e.,\\nat the base stations or at the associated edge computing\\nplatform.\\n1) Physical Layer: For the physical layer, we focus\\nﬁrst on the receiver side and then on the transmitter.\\nAt the receiver, a central task that can potentially ben-\\neﬁt from machine learning is channel detection and\\ndecoding. This amounts to a multi-class classiﬁcation\\nproblem, in which the input x is given by the received\\nbaseband signal and the output is the label of the correct'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='decoding. This amounts to a multi-class classiﬁcation\\nproblem, in which the input x is given by the received\\nbaseband signal and the output is the label of the correct\\ntransmitted message (e.g., the transmitted bits) [13],\\n[30]. When can machine learning help? Recalling the\\ndiscussion in Sec. II, we should ﬁrst ask whether a\\nmodelling or algorithmic deﬁcit exists. A model deﬁcit\\nmay occur when operating over channels that do not\\nhave well-established mathematical models, such as\\nfor molecular communications [31]. Algorithm deﬁcit\\nis more common, given that optimal decoders over a\\nnumber of well-established channel models tend to be\\ncomputationally complex. This is the case for channels\\nwith strong non-linearities, as recognized as early as the\\nnineties in the context of satellite communication [2],\\n[32] and more recently for optical communications [33];\\nor for modulation schemes such as continuous phase\\nmodulation [34] – another work from the nineties – or\\nin multi–user networks [35].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[32] and more recently for optical communications [33];\\nor for modulation schemes such as continuous phase\\nmodulation [34] – another work from the nineties – or\\nin multi–user networks [35].\\nAssuming that the problem at hand is characterized by\\na modelling or algorithmic deﬁcit, then one should also\\ncheck the remaining criteria listed in Sec. II, particularly\\nthose regarding the rate of change of the phenomenon\\nunder study and the requirements in terms of perfor-\\nmance guarantees. For channel decoding, the presence\\nof fast-varying channels may make the ﬁrst criterion\\nhard to be satisﬁed in practice (unless channel estimation\\nis made part of the learning process); while stringent\\nreliability requirements may preclude the use of machine\\nlearning in the presence of a model deﬁcit.\\nAs mentioned, a generally beneﬁcial idea in the use\\nof data-aided methods is that of incorporating domain\\nknowledge in the deﬁnition of the hypothesis class . As'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='As mentioned, a generally beneﬁcial idea in the use\\nof data-aided methods is that of incorporating domain\\nknowledge in the deﬁnition of the hypothesis class . As\\nnotable examples related to channel decoding, in [36],\\n[37], knowledge of the near-optimality of message pass-\\ning methods for the decoding of sparse graphical codes\\nis used to set up a parameterized model that borrows the\\nmessage passing structure and that is trained to decode\\nmore general codes. A related approach is investigated\\nin [38] for polar codes.\\nAnother useful idea is that of directly integrating\\nalgorithms designed using the standard engineering ﬂow\\nwith trained machines. Instances of this idea include [39]\\nin which a conventional channel decoder is deployed in\\ntandem with a channel equalizer at its input that is trained\\nto compensate for hardware impairments. A related\\napproach is proposed in [40], whereby a conventional\\ndecoder is implemented within a turbo-like iterative loop'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to compensate for hardware impairments. A related\\napproach is proposed in [40], whereby a conventional\\ndecoder is implemented within a turbo-like iterative loop\\nwith a machine learning-based regressor that has the role\\nof estimating the channel noise.\\nOther tasks that can potentially beneﬁt from machine\\nlearning at the receiver’s side include modulation clas-\\nsiﬁcation, which is a classiﬁcation problem justiﬁed by\\nthe complexity of optimal solutions (algorithm deﬁcit)\\n[41]; localization, which is a regression problem, typ-\\nically motivated by the lack of tractable channels for\\ncomplex propagation environments (model deﬁcit) [42];\\nand channel state information-based authentication, a\\nclassiﬁcation problem made difﬁcult by the absence of\\nwell-established models relating channel features with\\ndevices’ identities (model deﬁcit) [43].\\nTurning to the transmitter side, most emerging ap-\\nplications tackle the algorithmic deﬁcit related to the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='devices’ identities (model deﬁcit) [43].\\nTurning to the transmitter side, most emerging ap-\\nplications tackle the algorithmic deﬁcit related to the\\ncomplexity of the non-convex programs that typically\\nunderlie power control and precoding optimization for\\nthe downlink. Notably, in [44], a training set is ob-\\ntained by running a non-convex solver to produce an\\noptimized output power vector for given input channels.\\nNote that the approach does not directly optimize the\\nperformance criterion of interest, such as the sum-rate.\\nRather, it relies on the assumption that similar inputs –\\nthe channel coefﬁcients – generally yield similar optimal\\nsolutions – the power allocation vector. if the analytical\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='model available based on domain knowledge is only a\\ncoarse approximation of the physical model, the resulting\\ntraining set can be used to augment the data in order to\\ncarry out a preliminary training of a machine learning\\nmodel [45]2.\\nFor an application at a full-duplex transceiver, we refer\\nto [47], which learns how to cancel self-interference in\\norder to overcome the lack of well-established models\\nfor the transmitter-receiver chain of non-linearities.\\n2) Link and Medium Access Control Layers: At the\\nmedium access control layer, we highlight some ap-\\nplications of machine learning that tackle the lack of\\nmathematical models for complex access protocols and\\ncommunication environments. In [48], a mechanism is\\nproposed to predict whether a channel decoder will suc-\\nceed on the basis of the outputs of the ﬁrst few iterations\\nof the iterative decoding process. This binary predictor\\nis useful in order to request an early retransmission at'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='ceed on the basis of the outputs of the ﬁrst few iterations\\nof the iterative decoding process. This binary predictor\\nis useful in order to request an early retransmission at\\nthe link layer using Automatic Retransmission Request\\n(ARQ) or Hybrid ARQ (HARQ) in order to reduce\\nlatency. At the medium access control layer, data-aided\\nmethods can instead be used to predict the availability\\nof spectrum in the presence of interfering incumbent\\ndevices with complex activation patterns for cognitive\\nradio applications [49] (see also [50]). An approach\\nthat leverages depth images to detect the availability of\\nmmwave channels is proposed in [51].\\n3) Network and Application Layers: A task that\\nis particularly well-suited for machine learning is the\\ncaching of popular contents for reduced latency and\\nnetwork congestion [52]. Caching may take place at the\\nedge and, more traditionally, within the core network\\nsegment. Caching at the edge has the advantage of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='network congestion [52]. Caching may take place at the\\nedge and, more traditionally, within the core network\\nsegment. Caching at the edge has the advantage of\\ncatering directly to the preference of the local population\\nof users, but it generally suffers from a reduced hit rate\\ndue to the smaller available storage capacity. Optimizing\\nthe selection of contents to be stored at the edge can be\\nformulated as a classiﬁcation problem that can beneﬁt\\nfrom a data-driven approach in order to adapt to the\\nspeciﬁc features of the local trafﬁc [52].\\nB. At the Cloud\\nWe now turn to some relevant tasks to be carried out\\nat the cloud at both network and application layers.\\n1) Network: The main task of the network layer is\\nrouting (see [53] for further discussion). Considering a\\nsoftware-deﬁned networking implementation, routing re-\\nquires the availability at a network controller of informa-\\ntion regarding the quality of individual communication'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='software-deﬁned networking implementation, routing re-\\nquires the availability at a network controller of informa-\\ntion regarding the quality of individual communication\\n2This can be thought of as an example of experience learning as\\npart of small-sample learning techniques [46].\\nlinks in the core network, as well as regarding the status\\nof the queues at the network routers. In the presence\\nof wireless or optical communications, the quality of a\\nlink may not be available at the network controller, but\\nit may be predicted using available historical data [33],\\n[54] in the absence of agreed-upon dynamic availability\\nmodels. In a similar manner, predicting congestion can\\nbe framed as a data-aided classiﬁcation problem [55].\\n2) Application: Finally, a relevant supervised learning\\ntask is that of trafﬁc classiﬁcation, whereby data streams\\nare classiﬁed on the basis of some extracted features,\\nsuch as packet sizes and inter-arrival times, in terms of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='task is that of trafﬁc classiﬁcation, whereby data streams\\nare classiﬁed on the basis of some extracted features,\\nsuch as packet sizes and inter-arrival times, in terms of\\ntheir applications, e.g., V oice over IP. [56]\\nV. U NSUPERVISED LEARNING\\nAs introduced in Sec. I, unlike supervised learning,\\nunsupervised learning tasks operate over unlabelled data\\nsets consisting solely of the inputs xn, with n= 1,...,N ,\\nand the general goal is that of discovering properties\\nof the data. We start this section by reviewing some\\nof the typical speciﬁc unsupervised learning tasks. We\\nthen cover methodology, models, and learning, includ-\\ning advanced methods such as Generative Adversarial\\nNetworks (GANs) [7].\\nA. Goals and Deﬁnitions\\nIn unsupervised learning, taking a frequentist formu-\\nlation (see Sec. III-A), we are given a training set D\\nconsisting of N i.i.d. samples xn ∼ p(x) with n =\\n1,...,N generated from an unknown true distribution\\np(x). The high-level goal is that of learning some useful'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='consisting of N i.i.d. samples xn ∼ p(x) with n =\\n1,...,N generated from an unknown true distribution\\np(x). The high-level goal is that of learning some useful\\nproperties of the distribution p(x). More speciﬁcally, we\\ncan identify the following tasks.\\n• Density estimation : Density estimation aims at es-\\ntimating directly the distribution p(x). This may be\\nuseful, for example, for use in plug-in estimators of\\ninformation-theoretic quantities, for the design of\\ncompression algorithms, or to detect outliers;\\n• Clustering: Clustering aims at partitioning all points\\nin the data set Din groups of similar objects, where\\nthe notion of similarity is domain-dependent;\\n• Dimensionality reduction , representation, and fea-\\nture extraction: These three related tasks represent\\neach data point xn in a different space, typically\\nof lower dimensionality, in order to highlight in-\\ndependent explanatory factors and/or to ease visu-\\nalization, interpretation, or the implementation of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of lower dimensionality, in order to highlight in-\\ndependent explanatory factors and/or to ease visu-\\nalization, interpretation, or the implementation of\\nsuccessive tasks, e.g., classiﬁcation;\\n• Generation of new samples : Given the data set D,\\nwe wish to learn a machine that produces sam-\\nples that are approximately distributed according\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to p(x). As an example, if the data set contains\\nimages of celebrities, the idea is to produce plausi-\\nble images of non-existent celebrities. This can be\\nuseful, e.g., to produce artiﬁcial scenes for video\\nparameterizes or ﬁlms.\\nAs suggested by the variety of tasks listed above,\\nunsupervised learning does not have a formal uniﬁed\\nformulation as supervised learning. Nevertheless, the\\ngeneral methodology follows three main steps in a\\nmanner similar to supervised learning (see Sec. III-D). In\\nStep 1 (model selection), a model, or a hypothesis class,\\nis selected, deﬁning the inductive bias of the learning\\nprocess. This is done by positing a family of probability\\ndistributions p(x|θ) parameterized by a vector θ. In\\nStep 2 (learning), the data D is used to optimize a\\nlearning criterion with the aim of choosing a value for the\\nparameter vector θ. Finally, in Step 3, the trained model\\nis leveraged in order to carry out the task of interest,\\ne.g., clustering or sample generation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='parameter vector θ. Finally, in Step 3, the trained model\\nis leveraged in order to carry out the task of interest,\\ne.g., clustering or sample generation.\\nIn the following, we discuss Step 1 (model selection)\\nand Step 2 (learning). For the formulation of speciﬁc\\ntasks to be carried out at Step 3, we refer to, e.g., [7],\\n[19], [57].\\nB. Models\\nUnsupervised learning models, selected at Step 1 of\\nthe machine learning process, typically involve a hidden\\nor latent (vector of) variables zn for each data point xn.\\nFor example, in a clustering problem, the latent variable\\nzn represents the cluster index of xn. Latent variables are\\nhidden or unobserved in the sense that they do not appear\\nfor any of the data points xn in D.3 The relationship\\nbetween latent variables zn and observable variables xn\\ncan be modelled in different ways, giving rise to a\\nnumber of different types of models for unsupervised\\nlearning. These are illustrated in Fig. 11 and discussed\\nnext.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='can be modelled in different ways, giving rise to a\\nnumber of different types of models for unsupervised\\nlearning. These are illustrated in Fig. 11 and discussed\\nnext.\\nBy way of a short round-up of types of models,\\nwith reference to Fig. 11, directed generative models ,\\nillustrated by Fig. 11(a), posit that there exist hidden\\ncauses z yielding the observation x. Undirected genera-\\ntive models, represented in Fig. 11(b) model the mutual\\ncorrelation between x and z. Discriminative models ,\\nillustrated by Fig. 11(c) model the extraction of the\\nlatent representation z from x. Finally, autoencoders,\\nrepresented in Fig. 11(d) assume that x is encoded into\\na latent representation z in such as way that x can then\\nbe approximately recovered from z. In the following, we\\nprovide some additional details about directed generative\\n3Problems in which some of the inputs in Dare labelled by a value\\nzn are ﬁled under the rubric of semi-supervised learning [29].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='provide some additional details about directed generative\\n3Problems in which some of the inputs in Dare labelled by a value\\nzn are ﬁled under the rubric of semi-supervised learning [29].\\nFig. 11. Illustration of typical unsupervised learning models: (a)\\ndirected generative models; (b) undirected generative models; (c)\\ndiscriminative models; and (d) autoencoders.\\nmodels and autoencoders, and we point to [19] and\\nreferences therein for a discussion about the remaining\\nmodels.\\nAs illustrated in Fig. 11(a), directed generative models\\nassume that each data point x is caused 4 by a hidden\\nvariable z. This is in the sense that the joint distribution\\np(x,z|θ) is parameterized as p(x,z|θ) =p(z|θ)p(x|z,θ),\\nwhere p(z|θ) is the distribution of the hidden cause and\\np(x|z,θ) is the conditional distribution of the data x\\ngiven the cause z. As a result, under a directed generative\\nmodel, the distribution of an observation x =x can be\\nwritten as\\np(x|θ) =\\n∑\\nz\\np(z|θ)p(x|z,θ) =Ez∼p(z|θ)[ln p(x|z,θ)],'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='given the cause z. As a result, under a directed generative\\nmodel, the distribution of an observation x =x can be\\nwritten as\\np(x|θ) =\\n∑\\nz\\np(z|θ)p(x|z,θ) =Ez∼p(z|θ)[ln p(x|z,θ)],\\n(13)\\nwhere the sum in the second term should be replaced by\\nan integration for continuous hidden variables, and the\\nlast equality expresses the marginalization over z as an\\nexpectation.\\nAs an example, for the problem of document clus-\\ntering, variable x represents a document in the training\\nset and z is interpreted as a latent topic that “causes”\\nthe generation of the document. Model selection requires\\nthe speciﬁcation of a parameterized distribution p(z|θ)\\nover the topics, e.g., a categorical distribution with\\nparameters equals to the probability of each possible\\nvalue, and the distribution p(x|z,θ) of the document\\ngiven a topic. Basic representatives of directed generative\\nmodels include mixture of Gaussians and likelihood-free\\nmodels [19], [58].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='value, and the distribution p(x|z,θ) of the document\\ngiven a topic. Basic representatives of directed generative\\nmodels include mixture of Gaussians and likelihood-free\\nmodels [19], [58].\\n4The use of the term “cause” is meant to be taken in an intuitive,\\nrather than formal, way. For a discussion on the study of causality,\\nwe refer to [8].\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='As represented in Fig. 11(d), autoencoders model\\nencoding from data x to hidden variables z, as well as de-\\ncoding from hidden variables back to data. Accordingly,\\nmodel selection for autoencoders requires the speciﬁca-\\ntion of a parameterized family of encoders p(z|x,θ) and\\ndecoders p(x|z,θ). As an example, autoencoders can be\\nused to learn how to compress an input signal x into a\\nrepresentation z in a smaller space so as to ensure that\\nx can be recovered from z within an admissible level of\\ndistortion. Representatives of autoencoders, which cor-\\nrespond to speciﬁc choices for the encoder and decoder\\nfamilies of distributions, include Principal Component\\nAnalysis (PCA), dictionary learning, and neural network-\\nbased autoencoders [19], [57], [58].\\nC. Learning\\nWe now discuss learning, to be carried out as Step 2.\\nFor brevity, we focus on directed generative models and\\nrefer to [19] and references therein for a treatment of\\nlearning for the other models in Fig. 11. In this regard,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='For brevity, we focus on directed generative models and\\nrefer to [19] and references therein for a treatment of\\nlearning for the other models in Fig. 11. In this regard,\\nwe note that the problem of training autoencoders is\\nakin to supervised learning in the sense that autoencoders\\nspecify the desired output for each input in the training\\nset.\\nAs for supervised learning, the most basic learning\\ncriterion for probabilistic models is ML. Following the\\ndiscussion in Sec. III-E, ML tackles the problem of\\nmaximizing the log-likelihood of the data, i.e.,\\nmaximize\\nθ\\nln p(x|θ) = lnEz∼p(z|θ)[ln p(x|z,θ)]. (14)\\nNote that problem (14) considers only one data point xin\\nthe data set for the purpose of simplifying the notation,\\nbut in practice the log-likelihood needs to be summed\\nover the N examples in D.\\nUnlike the corresponding problem for supervised\\nlearning (8), the likelihood in (14) requires an average\\nover the hidden variables. This is because the value'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='over the N examples in D.\\nUnlike the corresponding problem for supervised\\nlearning (8), the likelihood in (14) requires an average\\nover the hidden variables. This is because the value\\nof the hidden variables z is not known, and hence the\\nprobability of the observation x needs to account for\\nall possible values of z weighted by their probabilities\\np(z|θ). This creates a number of technical challenges.\\nFirst, the objective in (14) is generally more complex to\\noptimize, since the average over z destroys the typical\\nstructure of the model p(x|z,θ), whose logarithm is often\\nselected as a tractable function (see, e.g., logistic re-\\ngression). Second, the average in (14) cannot be directly\\napproximated using Monte Carlo methods if the goal is\\nto optimize over the model parameters θ, given that the\\ndistribution p(z|θ) generally depends on θ itself.\\nTo tackle these issues, a standard approach is based\\non the introduction of a variational distribution q(z)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='distribution p(z|θ) generally depends on θ itself.\\nTo tackle these issues, a standard approach is based\\non the introduction of a variational distribution q(z)\\nover the hidden variables and on the optimization of a\\ntractable lower bound on the log-likelihood known as\\nthe Evidence Lower BOund (ELBO) . To elaborate, for\\nany ﬁxed value xand any distribution q(z) on the latent\\nvariables z (possibly dependent on x), the ELBO L(q,θ)\\nis deﬁned as\\nL(q,θ) =Ez∼q(z)[ln p(x|z,θ)]−KL(q(z)||p(z|θ)), (15)\\nwhere KL(q||p) = Ez∼q(z)[ln(q(z)/p(z))] is the\\nKullback-Leibler (KL) divergence. The latter is a mea-\\nsure of the distance between the two distributions, as\\nwe will further discuss in Sec. V-D (see [59], [60]).\\nThe analytical advantages of the ELBO L(q,θ) over\\nthe original log-likelihood are that: ( i) it entails an\\nexpectation of the logarithm of the model p(x|z,θ),\\nwhich, as mentioned, is typically a tractable function;\\nand ( ii) the average is over a ﬁxed distribution q(z),'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='expectation of the logarithm of the model p(x|z,θ),\\nwhich, as mentioned, is typically a tractable function;\\nand ( ii) the average is over a ﬁxed distribution q(z),\\nwhich does not depend on the model parameter θ.\\nUsing Jensen’s inequality, it can be seen that the\\nELBO (15) is a global lower bound on the log-likelihood\\nfunction, that is,\\nln p(x|θ) ≥L(q,θ). (16)\\nAn illustration of the lower bounding property of the\\nELBO can be found in Fig. 12. An important feature\\nof this inequality is that the ELBO “touches” the log-\\nlikelihood function at values θ0, if any, for which the\\ndistribution q(z) satisﬁes the equality\\nq(z) =p(z|x,θ0). (17)\\nIn words, the ELBO is tight if the variational distribution\\nis selected to equal the posterior distribution of the\\nhidden variables given the observation xunder the model\\nparameter θ0. Stated less formally, in order to ensure\\nthat the ELBO is tight at a value θ0, one needs to solve\\nthe problem of inferring the distribution of the hidden'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='parameter θ0. Stated less formally, in order to ensure\\nthat the ELBO is tight at a value θ0, one needs to solve\\nthe problem of inferring the distribution of the hidden\\nvariables z given the observation x under the model\\nidentiﬁed by the value θ0.\\nThe property (16) leads to the natural idea of the\\nExpectation-Maximization (EM) algorithm as a means\\nto tackle the ML problem. As illustrated in Fig. 13,\\nEM maximizes the ELBO iteratively, where the ELBO\\nat each iteration is computed to be tight at the current\\niterate for θ. More formally, the EM algorithm can be\\nsummarized as follows 5. The model vector is initialized\\nto some value θold and then for each iteration the\\nfollowing two steps are performed.\\n5EM is an instance of the more general Majorization-Minimization\\nalgorithm [61].\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='-4 -3 -2 -1 0 1 2 3 4\\n-5\\n-4.5\\n-4\\n-3.5\\n-3\\n-2.5\\n-2\\n-1.5Log-likelihood\\nELBO ( 0=  3)\\nELBO ( 0 =  2)\\nLL\\nFig. 12. The ELBO (15) is a global lower bound on the log-likelihood\\nthat is tight at values of the model parameters θ0 for which equality\\n(17) holds.\\n• Expectation, or E, step: For ﬁxed parameter vector\\nθold, solve the problem\\nmaximize\\nq\\nL(q,θold). (18)\\nThe solution of this problem is given by qnew(z) =\\np(z|x,θold). In fact, as discussed, the tightest (i.e.,\\nlargest) value of the ELBO is obtained by choosing\\nthe variational distribution q(z) as the posterior\\nof the latent variables under the current model\\nθold. This step can be interpreted as estimating the\\nlatent variables z, via the predictive distribution\\np(z|x,θold), assuming that the current model θold\\nis correct.\\n• Maximization, or M, step: For ﬁxed variational\\ndistribution qnew(z), solve the problem\\nmaximize\\nθ\\nL(qnew,θ) =Ez∼qnew(z) [ln p(x,z|θ)] .\\n(19)\\nThis optimization is akin to that carried out in'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='• Maximization, or M, step: For ﬁxed variational\\ndistribution qnew(z), solve the problem\\nmaximize\\nθ\\nL(qnew,θ) =Ez∼qnew(z) [ln p(x,z|θ)] .\\n(19)\\nThis optimization is akin to that carried out in\\nthe corresponding supervised learning problem with\\nknown latent variables z with the difference that\\nthese are randomly selected from the ﬁxed varia-\\ntional distribution qnew(z) obtained in the E step.\\nGiven that the EM algorithm maximizes at each step\\na lower bound on the log-likelihood that is tight at the\\ncurrent iterate θold, EM guarantees decreasing objective\\nvalues along the iterations, which ensures convergence\\nto a local optimum of the original problem. We refer to\\n[57], [58] for detailed examples.\\nThe EM algorithm is generally impractical for large-\\nscale problems due to the complexity of computing the\\nposterior of the latent variables in the E step and of\\naveraging over such distribution in the M step. Many\\nstate-of-the-art solutions to the problem of unsupervised\\n...\\nLL\\nnewold'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='posterior of the latent variables in the E step and of\\naveraging over such distribution in the M step. Many\\nstate-of-the-art solutions to the problem of unsupervised\\n...\\nLL\\nnewold\\nFig. 13. Illustration of the EM algorithm: At each iteration, a tight\\nELBO is evaluated in the E step by solving the problem of estimating\\nthe latent variables (via the posterior distribution p(z|x,θ)), and then\\nthe ELBO is maximized in the M step by solving a problem akin to\\nsupervised learning with the estimated latent variables.\\nlearning with probabilistic models entail some approxi-\\nmation of the EM algorithm. Notably, the E step can be\\napproximated by parametrizing the variational distribu-\\ntion with some function q(z|ϕ), or q(z|x,ϕ) to include\\nthe dependence on x, and by maximizing ELBO over\\nthe variational parameters ϕ. This approach underlies\\nthe popular variational autoencoder technique [7]. In the\\nM step, instead, one can approximate the expectation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='the variational parameters ϕ. This approach underlies\\nthe popular variational autoencoder technique [7]. In the\\nM step, instead, one can approximate the expectation\\nin (19) using Monte Carlo stochastic approximation\\nbased on randomly sampled values of z from the current\\ndistribution q(z). Finally, gradient descent can be used\\nto carry out the mentioned optimizations for both E and\\nM steps (see, e.g., [62]).\\nD. Advanced Learning Methods\\nAs discussed in the previous section, ML is generally\\nprone to overﬁtting for supervised learning. For unsu-\\npervised learning, the performance of ML depends on\\nthe task of interest. For example, consider the tasks of\\ndensity estimation or of generation of new samples (see\\nSec. V-A). In order to illustrate some of the typical issues\\nencountered when applying the ML criterion, in Fig. 14\\nwe report a numerical result for a problem in which\\nthe true data distribution p(x) is multi-modal and the\\nmodel distribution p(x|θ) is assumed to be a mixture'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='we report a numerical result for a problem in which\\nthe true data distribution p(x) is multi-modal and the\\nmodel distribution p(x|θ) is assumed to be a mixture\\nof Gaussians, i.e., a directed generative model. The\\nML problem is tackled by using EM based on samples\\ngenerated from the true distribution (see [19] for details).\\nThe learned distribution is seen to be a rather“blurry”\\nestimate that misses the modes of p(x) in an attempt\\nof being inclusive of the full support of p(x). Being a\\npoor estimate of the true distribution, the learned model\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='-5 0 5\\n0\\n0.05\\n0.1\\n0.15\\n0.2\\n0.25\\n0.3\\n0.35\\nFig. 14. Illustration of the limitations of ML unsupervised learning,\\nhere obtained via the EM algorithm: The ML solution tends to be\\nblurry, missing the modes of the true distribution p(x).\\ncan clearly also be problematic for sample generation in\\nthe sense that samples generated from the model would\\ntend to be quite different from the data samples. In the\\nrest of this section, we brieﬂy review advanced learning\\nmethods that address this limitation of ML.\\nIn order to move beyond ML, we ﬁrst observe that\\nML can be proven to minimize the KL divergence\\nKL(pD(x)||p(x|θ)) =Ez∼pD(x)\\n[\\nln pD(x)\\np(x|θ)\\n]\\n(20)\\nbetween the empirical distribution, or histogram, of the\\ndata\\npD(x) =N[x]\\nN , (21)\\nwhere N[x] counts the number of occurrences of value\\nx in the data, and the parameterized model distribution\\np(x|θ). In other words, ML ﬁts the model to the his-\\ntogram of the data by using the KL divergence as a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='x in the data, and the parameterized model distribution\\np(x|θ). In other words, ML ﬁts the model to the his-\\ntogram of the data by using the KL divergence as a\\nmeasure of ﬁtness. Indeed, as mentioned in Sec. V-C, the\\nKL divergence is a quantitative measure of “difference”\\nbetween two distributions. More precisely, as per (20),\\nthe KL divergence KL (p||q) quantiﬁes the difference\\nbetween two distributions p(x) and q(x) by evaluating\\nthe average of the LLR ln(p(x)/q(x)) with respect to\\np(x).\\nConsider now the problem illustrated in Fig. 15, in\\nwhich a discriminator wishes to distinguish between two\\nhypotheses, namely the hypothesis that the data x is a\\nsample from distribution p(x) and the hypothesis that it\\nis instead generated from q(x). To ﬁx the ideas, one can\\nfocus as an example on the case where p(x) and q(x)\\nare two Gaussian distributions with different means. To\\nthis end, the discriminator computes a statistic, that is,\\na function, T(x) of the data x, and then decides for the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='are two Gaussian distributions with different means. To\\nthis end, the discriminator computes a statistic, that is,\\na function, T(x) of the data x, and then decides for the\\nformer hypothesis if T(x) is sufﬁciently large and for\\n𝑇(𝑥)\\n𝑥~𝑝(𝑥)\\n𝑥~𝑞(𝑥)\\n𝑝 𝑥 if𝑇 𝑥 large\\ndiscriminator\\n𝑞 𝑥 if𝑇 𝑥 small\\nFig. 15. Discriminator between the hypotheses x ∼p(x) and x ∼\\nq(x) based on the statistic T(x). The performance of the optimal\\ndiscriminator function T(x) under different design criteria yields a\\nmeasure of the difference between the two distributions.\\nthe latter hypothesis otherwise. Intuitively, one should\\nexpect that, the more distinct the two distributions p(x)\\nand q(x) are, the easier it is to design a discriminator\\nthat is able to choose the correct hypothesis with high\\nprobability.\\nThe connection between the hypothesis testing prob-\\nlem in Fig. 15 and the KL divergence becomes evident\\nif one recalls that the LLR ln(p(x)/q(x)) is known\\nto be the best statistic T(x) in the Neyman-Pearson'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='lem in Fig. 15 and the KL divergence becomes evident\\nif one recalls that the LLR ln(p(x)/q(x)) is known\\nto be the best statistic T(x) in the Neyman-Pearson\\nsense [63]. The KL divergence is hence associated to\\na particular way of evaluating the performance of the\\ndiscriminator between the two distributions. Considering\\na broader formulation of the problem of designing the\\ndiscriminator in Fig. 15, one can generalize the notion\\nof KL divergence to the class of f-divergences. These\\nare deﬁned as\\nDf(p||q) = max\\nT(x)\\nEx∼p(x)[T(x)] −Ex∼q(x)[g(T(x))],\\n(22)\\nfor some concave increasing function g(·). The expres-\\nsion above can be interpreted as measuring the perfor-\\nmance of the best discriminator T(x) when the design\\ncriterion is given by the right-hand side of (22), i.e.,\\nEx∼p(x)[T(x)] −Ex∼q(x)[g(T(x))], for a given function\\ng(·). Note that this criterion is indeed larger for a\\ndiscriminator that is able to output a large value of the\\nstatistic T(x) under p(x) and a small value under q(x).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='g(·). Note that this criterion is indeed larger for a\\ndiscriminator that is able to output a large value of the\\nstatistic T(x) under p(x) and a small value under q(x).\\nThe KL divergence corresponds to a speciﬁc choice of\\nsuch function (see [19] for details).\\nIn order to move beyond ML, one can then consider\\nﬁtting the model distribution to the data histogram by\\nusing a divergence measure that is tailored to the data and\\nthat captures the features of the empirical distribution\\nthat are most relevant for a given application. Such\\na divergence measure can be obtained by choosing a\\nsuitable function g(·) in (22) and by optimizing (22) over\\na parameterized (differentiable) discriminator function\\nTϕ(x). Integrating the evaluation of the divergence with\\nthe problem of learning the model parameters yields the\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='min-max problem\\nmin\\nθ\\nmax\\nϕ\\nEx∼pD(x)[Tϕ(x)] −Ex∼p(x|θ)[g(Tϕ(x))]. (23)\\nThis can be famously interpreted as a game between the\\nlearner, which optimizes the model parameters θ, and the\\ndiscriminator, which tries to ﬁnd the best function Tϕ(x)\\nto distinguish between data and generated samples. The\\nresulting method, known as GAN, has recently led to\\nimpressive improvements of ML for sample generation\\n[64].\\nVI. A PPLICATIONS OF UNSUPERVISED LEARNING TO\\nCOMMUNICATION SYSTEMS\\nIn this section, we highlight some applications of\\nunsupervised learning to communication networks.\\nA. At the Edge\\n1) Physical Layer: Let us ﬁrst consider some appli-\\ncations of autoencoders at the physical layer as imple-\\nmented by the network edge nodes. A fundamental idea\\nis to treat the chain of encoder, channel, and decoder in\\na communication link as an autoencoder, where, with\\nreference to Fig. 11(d), the input message is x, the\\ntransmitted codewords and received signals represent'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='a communication link as an autoencoder, where, with\\nreference to Fig. 11(d), the input message is x, the\\ntransmitted codewords and received signals represent\\nthe intermediate representation z, and the output of the\\ndecoder should match the input [30]. Note that, for this\\nparticular autoencoder, the mapping p(x|z) can only be\\npartially learned, as it includes not only the encoder but\\nalso the communication channel, while the conditional\\ndistribution p(x|z) deﬁning the decoder can be learned.\\nWe should now ask when this viewpoint can be beneﬁcial\\nin light of the criteria reviewed in Sec. I-C.\\nTo address this question, one should check whether\\na model or algorithm deﬁcit exists to justify the use of\\nmachine learning tools. Training an autoencoder requires\\nthe availability of a model for the channel, and hence\\na model deﬁcit would make this approach inapplicable\\nunless further mechanisms are put in place (see below).\\nExamples of algorithm deﬁcit include channels with'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='a model deﬁcit would make this approach inapplicable\\nunless further mechanisms are put in place (see below).\\nExamples of algorithm deﬁcit include channels with\\ncomplex non-linear dynamical models, such as optical\\nlinks [65]; Gaussian channels with feedback, for which\\noptimal practical encoding schemes are not known [66];\\nmultiple access channels with sparse transmission codes\\n[67]; and joint source-channel coding [68].\\nOther applications at the physical layer leverage the\\nuse of autoencoders as compressors (see Sec. V-B) or\\ndenoisers. For channels with a complex structure with\\nunavailable channel models or with unknown optimal\\ncompression algorithms, autoencoders can be used to\\ncompress channel state information for the purpose\\nof feedback on frequency-division duplex links [69].\\nAutoencoders can also be used for their capacity to\\ndenoise the input signal by means of ﬁltering through\\nthe lower dimensional representation z. This is done'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Autoencoders can also be used for their capacity to\\ndenoise the input signal by means of ﬁltering through\\nthe lower dimensional representation z. This is done\\nin [70] for the task of localization on the basis of the\\nreceived baseband signal. To this end, an autoencoder\\nis learned for every reference position in space with the\\nobjective of denoising signals received from the given\\nlocation. At test time, the location that corresponds to\\nthe autoencoder with the smallest reconstruction error is\\ntaken as an estimate of the unknown transmitting device.\\nWe now review some applications of the generative\\nmodels illustrated in Fig. 11(a). A natural idea is that\\nof using generative models to learn how to generate\\nsamples from a given channel [71], [72]. This approach\\nis sound for scenarios that lack tractable channel models.\\nAs a pertinent example, generative models can be used to\\nmimic and identify non-linear channels for satellite com-\\nmunications [2]. The early works on the subject carried'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='As a pertinent example, generative models can be used to\\nmimic and identify non-linear channels for satellite com-\\nmunications [2]. The early works on the subject carried\\nout in the nineties are also notable for the integration\\nof the domain knowledge into the deﬁnition of machine\\nlearning models (see Sec. IV). In fact, mindful of the\\nstrong linear components of the channels, these works\\nposit a learnable model that includes linear ﬁlters and\\nnon-linearities [2].\\nAnother approach that can be considered as unsu-\\npervised was proposed in [73] in order to solve the\\nchallenging problem of power control for interference\\nchannels. The approach tackles the resulting algorithm\\ndeﬁcit by means of a direct optimization of the sum-rate\\nwith the aim of obtaining the power allocation vector (as\\nfractions of the maximal available powers) at the output\\nof a neural network. Related supervised learning methods\\nwere discussed in Sec. IV. A similar approach – also'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='fractions of the maximal available powers) at the output\\nof a neural network. Related supervised learning methods\\nwere discussed in Sec. IV. A similar approach – also\\nbased on the idea of directly maximizing the criterion\\nof interest so as to obtain an approximate solution at the\\noutput of a neural network – was considered in [74] for\\nminimum mean squared error channel estimation with\\nnon-Gaussian channels, e.g., multi-path channels.\\n2) Medium Access Layer: At the medium access\\nlayer, generative models have been advocated in [75] as a\\nway to generate new examples so as to augment a data\\nset used to train a classiﬁer for spectrum sensing (see\\nSec. IV). An unsupervised learning task that has found\\nmany applications in communications is clustering. For\\nexample, in [76], clustering is used to support radio\\nresource allocation in a heterogeneous network.\\nB. At the Cloud\\n1) Network Layer: Another typical application of\\nclustering is to enable hierarchical clustering for routing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='resource allocation in a heterogeneous network.\\nB. At the Cloud\\n1) Network Layer: Another typical application of\\nclustering is to enable hierarchical clustering for routing\\nin self-organizing multi-hop networks. Thanks to cluster-\\ning, routing can be carried out more efﬁciently by routing\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='ﬁrst at the level of clusters, and then locally within\\neach cluster [77]. For an application of the unsupervised\\nlearning task of density estimation, consider the problem\\nof detecting anomalies in networks. For instance, by\\nlearning the typical distribution of the features of a\\nworking link, one can identify malfunctioning ones. This\\napproach may be applied, e.g., to optical networks [54].\\n2) Application Layer: Finally, we point to two in-\\nstances of unsupervised learning at the application layer\\nthat are usually carried out at data centers in the cloud.\\nThese tasks follow a conceptually different approach\\nas they are based on discovering structure in graphs.\\nThe ﬁrst problem is community detection in social\\nnetworks. This amounts to a clustering problem whereby\\none wishes to isolate communities of nodes in a social\\ngraph on the basis of the observation of a realization of\\nthe underlying true graph of relationships [78]. Another\\napplication is the ranking of webpages based on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='graph on the basis of the observation of a realization of\\nthe underlying true graph of relationships [78]. Another\\napplication is the ranking of webpages based on the\\ngraph of hyperlinks carried out by PageRank [19], [79].\\nVII. C ONCLUDING REMARKS\\nIn the presence of modelling or algorithmic deﬁcien-\\ncies in the conventional engineering ﬂow based on the\\nacquisition of domain knowledge, data-driven machine\\nlearning tools can speed up the design cycle, reduce\\nthe complexity and cost of implementation, and improve\\nover the performance of known algorithms. To this end,\\nmachine learning can leverage the availability of data\\nand computing resources in many engineering domains,\\nincluding modern communication systems. Supervised,\\nunsupervised, and reinforcement learning paradigms lend\\nthemselves to different tasks depending on the availabil-\\nity of examples of desired behaviour or of feedback.\\nThe applicability of learning methods hinges on speciﬁc'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='themselves to different tasks depending on the availabil-\\nity of examples of desired behaviour or of feedback.\\nThe applicability of learning methods hinges on speciﬁc\\nfeatures of the problem under study, including its time\\nvariability and its tolerance to errors. As such, a data-\\ndriven approach should not be considered as a universal\\nsolution, but rather as a useful tool whose suitability\\nshould be assessed on a case-by-case basis. Further-\\nmore, machine learning tools allow for the integration\\nof traditional model-based engineering techniques and\\nof existing domain knowledge in order to leverage the\\ncomplementarity and synergy of the two solutions (see\\nFig. 2).\\nAs a ﬁnal note, while this paper has focused on appli-\\ncations of machine learning to communication systems,\\ncommunication is conversely a key element of distributed\\nmachine learning platforms. In these systems, learning\\ntasks are carried out at distributed machines that need'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='communication is conversely a key element of distributed\\nmachine learning platforms. In these systems, learning\\ntasks are carried out at distributed machines that need\\nto coordinate via communication, e.g., by transferring\\nthe results of intermediate computations. A recent line\\nof work investigates the resulting interplay between\\ncomputation and communication [80].\\nREFERENCES\\n[1] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed,\\nN. Jaitly, A. Senior, V . Vanhoucke, P. Nguyen, T. N. Sainath\\net al., “Deep neural networks for acoustic modeling in speech\\nrecognition: The shared views of four research groups,” IEEE\\nSignal processing magazine , vol. 29, no. 6, pp. 82–97, 2012.\\n[2] M. Ibnkahla, “Applications of neural networks to digital\\ncommunications–a survey,” Signal processing , vol. 80, no. 7,\\npp. 1185–1215, 2000.\\n[3] H. J. Levesque, Common Sense, the Turing Test, and the Quest\\nfor Real AI: Reﬂections on Natural and Artiﬁcial Intelligence .\\nMIT Press, 2017.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='pp. 1185–1215, 2000.\\n[3] H. J. Levesque, Common Sense, the Turing Test, and the Quest\\nfor Real AI: Reﬂections on Natural and Artiﬁcial Intelligence .\\nMIT Press, 2017.\\n[4] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning\\ninternal representations by error propagation,” California Univ\\nSan Diego La Jolla Inst for Cognitive Science, Tech. Rep., 1985.\\n[5] A. P. Dempster, N. M. Laird, and D. B. Rubin, “Maximum\\nlikelihood from incomplete data via the em algorithm,” Journal\\nof the royal statistical society. Series B (methodological) , pp.\\n1–38, 1977.\\n[6] C. Watkins, “Learning form delayed rewards,” Ph. D. thesis,\\nKing’s College, University of Cambridge, 1989.\\n[7] I. Goodfellow, Y . Bengio, A. Courville, and Y . Bengio, Deep\\nlearning. MIT press Cambridge, 2016, vol. 1.\\n[8] J. Pearl and D. Mackenzie, The Book of Why: The New Science\\nof Cause and Effect . Basic Books, 2018.\\n[9] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Machine'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[8] J. Pearl and D. Mackenzie, The Book of Why: The New Science\\nof Cause and Effect . Basic Books, 2018.\\n[9] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Machine\\nlearning in wireless sensor networks: Algorithms, strategies,\\nand applications,” IEEE Communications Surveys & Tutorials ,\\nvol. 16, no. 4, pp. 1996–2018, 2014.\\n[10] C. Jiang, H. Zhang, Y . Ren, Z. Han, K.-C. Chen, and L. Hanzo,\\n“Machine learning paradigms for next-generation wireless net-\\nworks,” IEEE Wireless Communications, vol. 24, no. 2, pp. 98–\\n105, 2017.\\n[11] Z. Qin, H. Ye, G. Y . Li, and B.-H. F. Juang, “Deep Learning\\nin Physical Layer Communications,” ArXiv e-prints, Jul. 2018.\\n[12] S. Lin and D. J. Costello, Error control coding . Pearson\\nEducation India, 2001.\\n[13] T. Gruber, S. Cammerer, J. Hoydis, and S. ten Brink, “On deep\\nlearning-based channel decoding,” in CISS 2017, 2017, pp. 1–6.\\n[14] S. Shalev-Shwartz and S. Ben-David, Understanding machine\\nlearning: From theory to algorithms . Cambridge university'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='learning-based channel decoding,” in CISS 2017, 2017, pp. 1–6.\\n[14] S. Shalev-Shwartz and S. Ben-David, Understanding machine\\nlearning: From theory to algorithms . Cambridge university\\npress, 2014.\\n[15] D. Arpit, S. Jastrze ¸bski, N. Ballas, D. Krueger, E. Bengio, M. S.\\nKanwal, T. Maharaj, A. Fischer, A. Courville, Y . Bengio, and\\nS. Lacoste-Julien, “A Closer Look at Memorization in Deep\\nNetworks,” ArXiv e-prints, Jun. 2017.\\n[16] T. Hastie, R. Tibshirani, and J. Friedman, “Unsupervised learn-\\ning,” in The elements of statistical learning . Springer, 2009,\\npp. 485–585.\\n[17] R. S. Sutton, A. G. Barto et al. , Reinforcement learning: An\\nintroduction. MIT press, 2018.\\n[18] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van\\nDen Driessche, J. Schrittwieser, I. Antonoglou, V . Panneershel-\\nvam, M. Lanctot et al. , “Mastering the game of go with deep\\nneural networks and tree search,” Nature, vol. 529, no. 7587,\\np. 484, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='vam, M. Lanctot et al. , “Mastering the game of go with deep\\nneural networks and tree search,” Nature, vol. 529, no. 7587,\\np. 484, 2016.\\n[19] O. Simeone, “A brief introduction to machine learning for en-\\ngineers,” Foundations and Trends in Signal Processing, vol. 12,\\nno. 3-4, pp. 200–431, 2018.\\n[20] E. Brynjolfsson and T. Mitchell, “What can machine learning\\ndo? Workforce implications,” Science, vol. 358, no. 6370, pp.\\n1530–1534, 2017.\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[21] S. Kannan, H. Kim, and S. Oh, “Deep learning and information\\ntheory: An emerging interface,” IEEE ISIT 2018 Tutorial .\\n[22] M. Davies, N. Srinivasa, T.-H. Lin, G. Chinya, Y . Cao, S. H.\\nChoday, G. Dimou, P. Joshi, N. Imam, S. Jain et al. , “Loihi:\\nA neuromorphic manycore processor with on-chip learning,”\\nIEEE Micro, vol. 38, no. 1, pp. 82–99, 2018.\\n[23] A. Bagheri, O. Simeone, and B. Rajendran, “Training proba-\\nbilistic spiking neural networks with ﬁrst-to-spike decoding,”\\narXiv preprint arXiv:1710.10704 , 2017.\\n[24] J. Chen, L. Song, M. J. Wainwright, and M. I. Jordan, “Learn-\\ning to explain: An information-theoretic perspective on model\\ninterpretation,” arXiv preprint arXiv:1802.07814 , 2018.\\n[25] M. Polese, R. Jana, V . Kounev, K. Zhang, S. Deb, and M. Zorzi,\\n“Machine Learning at the Edge: A Data-Driven Architecture\\nwith Applications to 5G Cellular Networks,” ArXiv e-prints ,\\nAug. 2018.\\n[26] G. Paschos, E. Bastug, I. Land, G. Caire, and M. Debbah,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='“Machine Learning at the Edge: A Data-Driven Architecture\\nwith Applications to 5G Cellular Networks,” ArXiv e-prints ,\\nAug. 2018.\\n[26] G. Paschos, E. Bastug, I. Land, G. Caire, and M. Debbah,\\n“Wireless caching: Technical misconceptions and business bar-\\nriers,” IEEE Communications Magazine, vol. 54, no. 8, pp. 16–\\n22, 2016.\\n[27] M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah,\\n“Machine learning for wireless networks with artiﬁcial in-\\ntelligence: A tutorial on neural networks,” arXiv preprint\\narXiv:1710.02913, 2017.\\n[28] M. Angjelichinoski, K. F. Trillingsgaard, and P. Popovski,\\n“A statistical learning approach to ultra-reliable low latency\\ncommunication,” arXiv preprint arXiv:1809.05515 , 2018.\\n[29] M. Seeger, “A taxonomy for semi-supervised learning methods,”\\nMIT Press, Tech. Rep., 2006.\\n[30] T. J. O’Shea and J. Hoydis, “An introduction to machine\\nlearning communications systems,” arXiv preprint , vol. 1702,\\n2017.\\n[31] N. Farsad and A. Goldsmith, “Neural network detection of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[30] T. J. O’Shea and J. Hoydis, “An introduction to machine\\nlearning communications systems,” arXiv preprint , vol. 1702,\\n2017.\\n[31] N. Farsad and A. Goldsmith, “Neural network detection of\\ndata sequences in communication systems,” arXiv preprint\\narXiv:1802.02046, 2018.\\n[32] S. Bouchired, D. Roviras, and F. Castani ´e, “Equalisation of\\nsatellite mobile channels with neural network techniques,”\\nSpace Communications, vol. 15, no. 4, pp. 209–220, 1998.\\n[33] Y . Wang, M. Martonosi, and L.-S. Peh, “A supervised learning\\napproach for routing optimizations in wireless sensor networks,”\\nin Proc. Int. Workshop on Multi-hop ad hoc Networks . ACM,\\n2006, pp. 79–86.\\n[34] G. De Veciana and A. Zakhor, “Neural net-based continuous\\nphase modulation receivers,” IEEE Transactions on Communi-\\ncations, vol. 40, no. 8, pp. 1396–1408, 1992.\\n[35] X. Jin and H.-N. Kim, “Deep Learning Detection Networks in\\nMIMO Decode-Forward Relay Channels,” ArXiv e-prints , Jul.\\n2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='cations, vol. 40, no. 8, pp. 1396–1408, 1992.\\n[35] X. Jin and H.-N. Kim, “Deep Learning Detection Networks in\\nMIMO Decode-Forward Relay Channels,” ArXiv e-prints , Jul.\\n2018.\\n[36] E. Nachmani, E. Marciano, L. Lugosch, W. J. Gross, D. Bur-\\nshtein, and Y . Be’ery, “Deep learning methods for improved\\ndecoding of linear codes,” IEEE Journal of Selected Topics in\\nSignal Processing, vol. 12, no. 1, pp. 119–131, 2018.\\n[37] L. Lugosch and W. J. Gross, “Neural offset min-sum decoding,”\\nin IEEE int. Symp. Information Theory (ISIT 2017) . IEEE,\\n2017, pp. 1361–1365.\\n[38] S. Cammerer, T. Gruber, J. Hoydis, and S. ten Brink, “Scaling\\ndeep learning-based decoding of polar codes via partitioning,”\\nin IEEE GLOBECOM 2017 , 2017, pp. 1–6.\\n[39] S. Schibisch, S. Cammerer, S. D ¨orner, J. Hoydis, and S. t.\\nBrink, “Online label recovery for deep learning-based com-\\nmunication through error correcting codes,” arXiv preprint\\narXiv:1807.00747, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Brink, “Online label recovery for deep learning-based com-\\nmunication through error correcting codes,” arXiv preprint\\narXiv:1807.00747, 2018.\\n[40] F. Liang, C. Shen, and F. Wu, “An iterative bp-cnn architecture\\nfor channel decoding,” IEEE Journal of Selected Topics in\\nSignal Processing, vol. 12, no. 1, pp. 144–159, Feb 2018.\\n[41] H. Agirman-Tosun, Y . Liu, A. M. Haimovich, O. Simeone,\\nW. Su, J. Dabin, and E. Kanterakis, “Modulation classiﬁcation\\nof mimo-ofdm signals by independent component analysis and\\nsupport vector machines,” in Proc. ASILOMAR 2011, 2011, pp.\\n1903–1907.\\n[42] S.-H. Fang and T.-N. Lin, “Indoor location system based on\\ndiscriminant-adaptive neural network in ieee 802.11 environ-\\nments,” IEEE Transactions on Neural networks, vol. 19, no. 11,\\npp. 1973–1978, 2008.\\n[43] Q. Wang, H. Li, Z. Chen, D. Zhao, S. Ye, and J. Cai, “Su-\\npervised and Semi-Supervised Deep Neural Networks for CSI-\\nBased Authentication,” ArXiv e-prints, Jul. 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='pp. 1973–1978, 2008.\\n[43] Q. Wang, H. Li, Z. Chen, D. Zhao, S. Ye, and J. Cai, “Su-\\npervised and Semi-Supervised Deep Neural Networks for CSI-\\nBased Authentication,” ArXiv e-prints, Jul. 2018.\\n[44] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropou-\\nlos, “Learning to optimize: Training deep neural networks for\\nwireless resource management,” in IEEE Signal Processing\\nAdvances in Wireless Communications (SPAWC) 2017 , 2017,\\npp. 1–6.\\n[45] A. Zappone, M. Di Renzo, M. Debbah, T. T. Lam, and X. Qian,\\n“Model-Aided Wireless Artiﬁcial Intelligence: Embedding Ex-\\npert Knowledge in Deep Neural Networks Towards Wireless\\nSystems Optimization,” ArXiv e-prints, Aug. 2018.\\n[46] J. Shu, Z. Xu, and D. Meng, “Small Sample Learning in Big\\nData Era,” ArXiv e-prints, Aug. 2018.\\n[47] A. Balatsoukas-Stimming, “Non-linear digital self-interference\\ncancellation for in-band full-duplex radios using neural net-\\nworks,” arXiv preprint arXiv:1711.00379 , 2017.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[47] A. Balatsoukas-Stimming, “Non-linear digital self-interference\\ncancellation for in-band full-duplex radios using neural net-\\nworks,” arXiv preprint arXiv:1711.00379 , 2017.\\n[48] N. Strodthoff, B. G ¨oktepe, T. Schierl, C. Hellge, and W. Samek,\\n“Enhanced Machine Learning Techniques for Early HARQ\\nFeedback Prediction in 5G,” ArXiv e-prints, Jul. 2018.\\n[49] V . K. Tumuluru, P. Wang, and D. Niyato, “A neural net-\\nwork based spectrum prediction scheme for cognitive radio,”\\nin IEEE International Conference on Communications (ICC\\n2010), 2010, pp. 1–5.\\n[50] D. Del Testa, M. Danieletto, G. M. Di Nunzio, and M. Zorzi,\\n“Estimating the number of receiving nodes in 802.11 networks\\nvia machine learning techniques,” in IEEE Global Communica-\\ntions Conference (GLOBECOM) , 2016, pp. 1–7.\\n[51] H. Okamoto, T. Nishio, K. Nakashima, Y . Koda, K. Ya-\\nmamoto, M. Morikura, Y . Asai, and R. Miyatake, “Machine-\\nlearning-based future received signal strength prediction using'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[51] H. Okamoto, T. Nishio, K. Nakashima, Y . Koda, K. Ya-\\nmamoto, M. Morikura, Y . Asai, and R. Miyatake, “Machine-\\nlearning-based future received signal strength prediction using\\ndepth images for mmwave communications,” arXiv preprint\\narXiv:1803.09698, 2018.\\n[52] M. Chen, W. Saad, C. Yin, and M. Debbah, “Echo state\\nnetworks for proactive caching in cloud-based radio access\\nnetworks with mobile users,” IEEE Transactions on Wireless\\nCommunications, vol. 16, no. 6, pp. 3520–3535, 2017.\\n[53] M. Zorzi, A. Zanella, A. Testolin, M. D. F. De Grazia, and\\nM. Zorzi, “Cognition-based networks: A new perspective on\\nnetwork optimization using learning and distributed intelli-\\ngence,” IEEE Access, vol. 3, pp. 1512–1530, 2015.\\n[54] F. Musumeci, C. Rottondi, A. Nag, I. Macaluso, D. Zibar,\\nM. Rufﬁni, and M. Tornatore, “A survey on application of ma-\\nchine learning techniques in optical networks,” arXiv preprint\\narXiv:1803.07976, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='M. Rufﬁni, and M. Tornatore, “A survey on application of ma-\\nchine learning techniques in optical networks,” arXiv preprint\\narXiv:1803.07976, 2018.\\n[55] F. Tang, B. Mao, Z. M. Fadlullah, N. Kato, O. Akashi, T. Inoue,\\nand K. Mizutani, “On removing routing protocol from future\\nwireless networks: A real-time deep learning approach for intel-\\nligent trafﬁc control,” IEEE Wireless Communications, vol. 25,\\nno. 1, pp. 154–160, 2018.\\n[56] T. T. Nguyen and G. Armitage, “A survey of techniques for\\ninternet trafﬁc classiﬁcation using machine learning,” IEEE\\nCommunications Surveys & Tutorials, vol. 10, no. 4, pp. 56–76,\\n2008.\\n[57] C. M. Bishop, Pattern recognition and machine learning .\\nspringer, 2006.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[58] K. P. Murphy, Machine learning: a probabilistic perspective .\\nMIT press, 2012.\\n[59] T. M. Cover and J. A. Thomas, Elements of information theory.\\nJohn Wiley & Sons, 2012.\\n[60] O. Simeone, “Introducing information measures via inference\\n[lecture notes],” IEEE Signal Processing Magazine , vol. 35,\\nno. 1, pp. 167–171, 2018.\\n[61] Y . Sun, P. Babu, and D. P. Palomar, “Majorization-minimization\\nalgorithms in signal processing, communications, and machine\\nlearning,” IEEE Transactions on Signal Processing , vol. 65,\\nno. 3, pp. 794–816, 2017.\\n[62] A. Mnih and K. Gregor, “Neural variational inference and\\nlearning in belief networks,” arXiv preprint arXiv:1402.0030 ,\\n2014.\\n[63] H. V . Poor, An introduction to signal detection and estimation .\\nSpringer Science & Business Media, 2013.\\n[64] I. Goodfellow, “NIPS 2016 tutorial: Generative adversarial\\nnetworks,” arXiv preprint arXiv:1701.00160 , 2016.\\n[65] B. Karanov, M. Chagnon, F. Thouin, T. A. Eriksson, H. B ¨ulow,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[64] I. Goodfellow, “NIPS 2016 tutorial: Generative adversarial\\nnetworks,” arXiv preprint arXiv:1701.00160 , 2016.\\n[65] B. Karanov, M. Chagnon, F. Thouin, T. A. Eriksson, H. B ¨ulow,\\nD. Lavery, P. Bayvel, and L. Schmalen, “End-to-end deep\\nlearning of optical ﬁber communications,” arXiv preprint\\narXiv:1804.04097, 2018.\\n[66] H. Kim, Y . Jiang, S. Kannan, S. Oh, and P. Viswanath,\\n“Deepcode: Feedback codes via deep learning,” arXiv preprint\\narXiv:1807.00801, 2018.\\n[67] M. Kim, N. I. Kim, W. Lee, and D. H. Cho, “Deep learning-\\naided scma,” IEEE Communications Letters , vol. 22, no. 4, pp.\\n720–723, April 2018.\\n[68] E. Bourtsoulatze, D. Burth Kurka, and D. Gunduz, “Deep Joint\\nSource-Channel Coding for Wireless Image Transmission,”\\nArXiv e-prints, Sep. 2018.\\n[69] C.-K. Wen, W.-T. Shih, and S. Jin, “Deep learning for massive\\nmimo csi feedback,” IEEE Wireless Communications Letters ,\\n2018.\\n[70] C. Xiao, D. Yang, Z. Chen, and G. Tan, “3-d ble indoor'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[69] C.-K. Wen, W.-T. Shih, and S. Jin, “Deep learning for massive\\nmimo csi feedback,” IEEE Wireless Communications Letters ,\\n2018.\\n[70] C. Xiao, D. Yang, Z. Chen, and G. Tan, “3-d ble indoor\\nlocalization based on denoising autoencoder,” IEEE Access ,\\nvol. 5, pp. 12 751–12 760, 2017.\\n[71] T. J. O’Shea, T. Roy, and N. West, “Approximating the void:\\nLearning stochastic channel models from observation with\\nvariational generative adversarial networks,” arXiv preprint\\narXiv:1805.06350, 2018.\\n[72] H. Ye, G. Y . Li, B.-H. F. Juang, and K. Sivanesan, “Channel\\nagnostic end-to-end learning based communication systems\\nwith conditional gan,” arXiv preprint arXiv:1807.00447 , 2018.\\n[73] F. Liang, C. Shen, W. Yu, and F. Wu, “Towards Optimal Power\\nControl via Ensembling Deep Neural Networks,”ArXiv e-prints,\\nJul. 2018.\\n[74] D. Neumann, T. Wiese, and W. Utschick, “Learning the mmse\\nchannel estimator,” IEEE Transactions on Signal Processing ,\\n2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Jul. 2018.\\n[74] D. Neumann, T. Wiese, and W. Utschick, “Learning the mmse\\nchannel estimator,” IEEE Transactions on Signal Processing ,\\n2018.\\n[75] K. Davaslioglu and Y . E. Sagduyu, “Generative ad-\\nversarial learning for spectrum sensing,” arXiv preprint\\narXiv:1804.00709, 2018.\\n[76] A. Abdelnasser, E. Hossain, and D. I. Kim, “Clustering and\\nresource allocation for dense femtocells in a two-tier cellular\\nofdma network,” IEEE Transactions on Wireless Communica-\\ntions, vol. 13, no. 3, pp. 1628–1641, 2014.\\n[77] A. A. Abbasi and M. Younis, “A survey on clustering algo-\\nrithms for wireless sensor networks,” Computer communica-\\ntions, vol. 30, no. 14-15, pp. 2826–2841, 2007.\\n[78] E. Abbe, A. S. Bandeira, and G. Hall, “Exact recovery in the\\nstochastic block model,” arXiv preprint arXiv:1405.3267, 2014.\\n[79] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank\\ncitation ranking: Bringing order to the web.” Stanford InfoLab,\\nTech. Rep., 1999.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[79] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank\\ncitation ranking: Bringing order to the web.” Stanford InfoLab,\\nTech. Rep., 1999.\\n[80] C. Karakus, Y . Sun, S. Diggavi, and W. Yin, “Redundancy\\ntechniques for straggler mitigation in distributed optimization\\nand learning,” arXiv preprint arXiv:1803.05397 , 2018.\\n20')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs\n",
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993c296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b52a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x26aff10ee40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae4a2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x26aff3c5550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa337992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 0, 'page_label': 'i', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='arXiv:1709.02840v3  [cs.LG]  17 May 2018\\nA Brief Introduction to Machine\\nLearning for Engineers\\n(2018), “A Brief Introduction to Machine Learning for Engin eers”, :\\nV ol. XX, No. XX, pp 1– 231. DOI: XXX.\\nOsvaldo Simeone\\nDepartment of Informatics\\nKing’s College London\\nosvaldo.simeone@kcl.ac.uk'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 1, 'page_label': 'ii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Contents\\nI Basics 5\\n1 Introduction 6\\n1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . 6\\n1.2 When to Use Machine Learning? . . . . . . . . . . . . . . 8\\n1.3 Goals and Outline . . . . . . . . . . . . . . . . . . . . . . 11\\n2 A Gentle Introduction through Linear Regression 15\\n2.1 Supervised Learning . . . . . . . . . . . . . . . . . . . . . 15\\n2.2 Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n2.3 Frequentist Approach . . . . . . . . . . . . . . . . . . . . 19\\n2.4 Bayesian Approach . . . . . . . . . . . . . . . . . . . . . 36\\n2.5 Minimum Description Length (MDL) ∗ . . . . . . . . . . . 42\\n2.6 Information-Theoretic Metrics . . . . . . . . . . . . . . . . 44\\n2.7 Interpretation and Causality ∗ . . . . . . . . . . . . . . . . 47\\n2.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n3 Probabilistic Models for Learning 51\\n3.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . 52'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 1, 'page_label': 'ii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n3 Probabilistic Models for Learning 51\\n3.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . 52\\n3.2 The Exponential Family . . . . . . . . . . . . . . . . . . . 53\\n3.3 Frequentist Learning . . . . . . . . . . . . . . . . . . . . . 59'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 2, 'page_label': 'iii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4 Bayesian Learning . . . . . . . . . . . . . . . . . . . . . . 63\\n3.5 Supervised Learning via Generalized Linear Models (GLM ) 69\\n3.6 Maximum Entropy Property ∗ . . . . . . . . . . . . . . . . 71\\n3.7 Energy-based Models ∗ . . . . . . . . . . . . . . . . . . . . 72\\n3.8 Some Advanced T opics ∗ . . . . . . . . . . . . . . . . . . . 73\\n3.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\nII Supervised Learning 75\\n4 Classiﬁcation 76\\n4.1 Preliminaries: Stochastic Gradient Descent . . . . . . . . . 77\\n4.2 Classiﬁcation as a Supervised Learning Problem . . . . . . 78\\n4.3 Discriminative Deterministic Models . . . . . . . . . . . . 80\\n4.4 Discriminative Probabilistic Models: Generalized Lin ear Mod-\\nels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\n4.5 Discriminative Probabilistic Models: Beyond GLM . . . . . 96\\n4.6 Generative Probabilistic Models . . . . . . . . . . . . . . . 102\\n4.7 Boosting ∗ . . . . . . . . . . . . . . . . . . . . . . . . . . 106'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 2, 'page_label': 'iii', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.6 Generative Probabilistic Models . . . . . . . . . . . . . . . 102\\n4.7 Boosting ∗ . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\n4.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\\n5 Statistical Learning Theory ∗ 113\\n5.1 A Formal Framework for Supervised Learning . . . . . . . 114\\n5.2 P AC Learnability and Sample Complexity . . . . . . . . . . 119\\n5.3 P AC Learnability for Finite Hypothesis Classes . . . . . . . 120\\n5.4 VC Dimension and Fundamental Theorem of P AC Learning 124\\n5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nIII Unsupervised Learning 129\\n6 Unsupervised Learning 130\\n6.1 Unsupervised Learning . . . . . . . . . . . . . . . . . . . . 131\\n6.2 K-Means Clustering . . . . . . . . . . . . . . . . . . . . . 134\\n6.3 ML, ELBO and EM . . . . . . . . . . . . . . . . . . . . . 136\\n6.4 Directed Generative Models . . . . . . . . . . . . . . . . 148\\n6.5 Undirected Generative Models . . . . . . . . . . . . . . . 155'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 3, 'page_label': 'iv', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.6 Discriminative Models . . . . . . . . . . . . . . . . . . . . 159\\n6.7 Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . 161\\n6.8 Ranking ∗ . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\n6.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\\nIV Advanced Modelling and Inference 165\\n7 Probabilistic Graphical Models 166\\n7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 167\\n7.2 Bayesian Networks . . . . . . . . . . . . . . . . . . . . . . 170\\n7.3 Markov Random Fields . . . . . . . . . . . . . . . . . . . 178\\n7.4 Bayesian Inference in Probabilistic Graphical Models . . . . 182\\n7.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\\n8 Approximate Inference and Learning 186\\n8.1 Monte Carlo Methods . . . . . . . . . . . . . . . . . . . . 187\\n8.2 Variational Inference . . . . . . . . . . . . . . . . . . . . . 189\\n8.3 Monte Carlo-Based Variational Inference ∗ . . . . . . . . . 197'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 3, 'page_label': 'iv', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2 Variational Inference . . . . . . . . . . . . . . . . . . . . . 189\\n8.3 Monte Carlo-Based Variational Inference ∗ . . . . . . . . . 197\\n8.4 Approximate Learning ∗ . . . . . . . . . . . . . . . . . . . 199\\n8.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nV Conclusions 202\\n9 Concluding Remarks 203\\nAppendices 206\\nA Appendix A: Information Measures 207\\nA.1 Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\\nA.2 Conditional Entropy and Mutual Information . . . . . . . . 210\\nA.3 Divergence Measures . . . . . . . . . . . . . . . . . . . . 212\\nB Appendix B: KL Divergence and Exponential Family 215\\nAcknowledgements 217'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 4, 'page_label': 'v', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 218'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 5, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A Brief Introduction to Machine\\nLearning for Engineers\\nOsvaldo Simeone 1\\n1 Department of Informatics, King’s Col lege London;\\nosvaldo.simeone@kcl.ac.uk\\nABSTRACT\\nThis monograph aims at providing an introduction to key\\nconcepts, algorithms, and theoretical results in machine l earn-\\ning. The treatment concentrates on probabilistic models\\nfor supervised and unsupervised learning problems. It in-\\ntroduces fundamental concepts and algorithms by building\\non ﬁrst principles, while also exposing the reader to more\\nadvanced topics with extensive pointers to the literature,\\nwithin a uniﬁed notation and mathematical framework. The\\nmaterial is organized according to clearly deﬁned categori es,\\nsuch as discriminative and generative models, frequentist\\nand Bayesian approaches, exact and approximate inference,\\nas well as directed and undirected models. This monograph\\nis meant as an entry point for researchers with an engineer-\\ning background in probability and linear algebra.\\nISSN ; DOI XXXXXXXX'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 5, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as well as directed and undirected models. This monograph\\nis meant as an entry point for researchers with an engineer-\\ning background in probability and linear algebra.\\nISSN ; DOI XXXXXXXX\\nc⃝ 2018 XXXXXXXX'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 6, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Notation\\n•Random variables or random vectors – both abbreviated as rvs\\n– are represented using roman typeface, while their values a nd realiza-\\ntions are indicated by the corresponding standard font. F or instance,\\nthe equality x = x indicates that rv x takes value x.\\n•Matrices are indicated using uppercase fonts, with roman ty pe-\\nface used for random matrices.\\n•V ectors will be taken to be in column form.\\n•XT and X† are the transpose and the pseudoinverse of matrix X,\\nrespectively .\\n•The distribution of a rv x, either probability mass function (pmf)\\nfor a discrete rv or probability density function (pdf) for c ontinuous\\nrvs, is denoted as px , px (x), or p(x).\\n•The notation x ∼px indicates that rv x is distributed according\\nto px .\\n•F or jointly distributed rvs (x ,y) ∼pxy, the conditional distribu-\\ntion of x given the observation y = y is indicated as px|y=y , px|y(x|y)\\nor p(x|y).\\n•The notation x |y = y ∼px|y=y indicates that rv x is drawn ac-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 6, 'page_label': '1', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion of x given the observation y = y is indicated as px|y=y , px|y(x|y)\\nor p(x|y).\\n•The notation x |y = y ∼px|y=y indicates that rv x is drawn ac-\\ncording to the conditional distribution px|y=y .\\n•The notation E x∼px [·] indicates the expectation of the argument\\nwith respect to the distribution of the rv x ∼px . Accordingly , we will\\nalso write E x∼px|y [·|y] for the conditional expectation with respect to\\nthe distribution px|y=y . When clear from the context, the distribution\\nover which the expectation is computed may be omitted.\\n•The notation Pr x∼px [·] indicates the probability of the argument\\nevent with respect to the distribution of the rv x ∼px. When clear\\n1'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 7, 'page_label': '2', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2 Notation\\nfrom the context, the subscript is dropped.\\n•The notation log represents the logarithm in base two, while ln\\nrepresents the natural logarithm.\\n•x ∼N(µ,Σ) indicates that random vector x is distributed accord-\\ning to a multivariate Gaussian pdf with mean vector µ and covariance\\nmatrix Σ. The multivariate Gaussian pdf is denoted as N(x|µ,Σ) as a\\nfunction of x.\\n•x ∼U(a,b) indicates that rv x is distributed according to a uni-\\nform distribution in the interval [ a,b]. The corresponding uniform pdf\\nis denoted as U(x|a,b).\\n•δ(x) denotes the Dirac delta function or the Kronecker delta fun c-\\ntion, as clear from the context.\\n•||a||2 = ∑ N\\ni=1 a2\\ni is the quadratic, or l2, norm of a vector a =\\n[a1 ,...,aN ]T . W e similarly deﬁne the l1 norm as ||a||1 = ∑ N\\ni=1 |ai |, and\\nthe l0 pseudo-norm ||a||0 as the number of non-zero entries of vector a.\\n•I denotes the identity matrix, whose dimensions will be clear from\\nthe context. Similarly , 1 represents a vector of all ones.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 7, 'page_label': '2', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•I denotes the identity matrix, whose dimensions will be clear from\\nthe context. Similarly , 1 represents a vector of all ones.\\n•R is the set of real numbers; R+ the set of non-negative real num-\\nbers; R− the set of non-positive real numbers; and RN is the set of all\\nvectors of N real numbers.\\n•1 ( ·) is the indicator function: 1 ( x) = 1 if xis true, and 1 ( x) = 0\\notherwise.\\n•|S| represents the cardinality of a set S.\\n•xS represents a set of rvs xk indexed by the integers k∈S.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 8, 'page_label': '3', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Acronyms\\nAI: Artiﬁcial Intelligence\\nAMP: Approximate Message Passing\\nBN: Bayesian Network\\nDAG: Directed Acyclic Graph\\nELBO: Evidence Lower BOund\\nEM: Expectation Maximization\\nERM: Empirical Risk Minimization\\nGAN: Generative Adversarial Network\\nGLM: Generalized Linear Model\\nHMM: Hidden Markov Model\\ni.i.d.: independent identically distributed\\nKL: Kullback-Leibler\\nLASSO: Least Absolute Shrinkage and Selection Operator\\nLBP: Loopy Belief Propagation\\nLL: Log-Likelihood\\nLLR: Log-Likelihood Ratio\\nLS: Least Squares\\nMC: Monte Carlo\\nMCMC: Markov Chain Monte Carlo\\nMDL: Minimum Description Length\\nMFVI: Mean Field V ariational Inference\\nML: Maximum Likelihood\\nMRF: Markov Random Field\\nNLL: Negative Log-Likelihood\\nP AC: Probably Approximately Correct\\npdf: probability density function\\n3'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 9, 'page_label': '4', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4 Acronyms\\npmf: probability mass function\\nPCA: Principal Component Analysis\\nPPCA: Probabilistic Principal Component Analysis\\nQDA: Quadratic Discriminant Analysis\\nRBM: Restricted Boltzmann Machine\\nSGD: Stochastic Gradient Descent\\nSVM: Support V ector Machine\\nrv: random variable or random vector (depending on the conte xt)\\ns.t.: subject to\\nV AE: V ariational AutoEncoder\\nVC: V apnik–Chervonenkis\\nVI: V ariational Inference'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 10, 'page_label': '5', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part I\\nBasics'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 11, 'page_label': '6', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1\\nIntroduction\\nHaving taught courses on machine learning, I am often asked b y col-\\nleagues and students with a background in engineering to sug gest “the\\nbest place to start” to get into this subject. I typically res pond with a\\nlist of books – for a general, but slightly outdated introduc tion, read\\nthis book; for a detailed survey of methods based on probabil istic mod-\\nels, check this other reference; to learn about statistical learning, I\\nfound this text useful; and so on. This answer strikes me, and most\\nlikely also my interlocutors, as quite unsatisfactory . Thi s is especially\\nso since the size of many of these books may be discouraging fo r busy\\nprofessionals and students working on other projects. This monograph\\nis an attempt to oﬀer a basic and compact reference that descr ibes key\\nideas and principles in simple terms and within a uniﬁed trea tment,\\nencompassing also more recent developments and pointers to the liter-\\nature for further study .\\n1.1 What is Machine Learning?'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 11, 'page_label': '6', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ideas and principles in simple terms and within a uniﬁed trea tment,\\nencompassing also more recent developments and pointers to the liter-\\nature for further study .\\n1.1 What is Machine Learning?\\nA useful way to introduce the machine learning methodology i s by\\nmeans of a comparison with the conventional engineering des ign ﬂow.\\n6'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 12, 'page_label': '7', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.1. What is Machine Learning? 7\\nThis starts with a in-depth analysis of the problem domain, w hich cul-\\nminates with the deﬁnition of a mathematical model. The math emat-\\nical model is meant to capture the key features of the problem under\\nstudy , and is typically the result of the work of a number of ex perts.\\nThe mathematical model is ﬁnally leveraged to derive hand-c rafted so-\\nlutions to the problem.\\nF or instance, consider the problem of deﬁning a chemical pro cess\\nto produce a given molecule. The conventional ﬂow requires c hemists\\nto leverage their knowledge of models that predict the outco me of indi-\\nvidual chemical reactions, in order to craft a sequence of su itable steps\\nthat synthesize the desired molecule. Another example is th e design\\nof speech translation or image/ video compression algorith ms. Both of\\nthese tasks involve the deﬁnition of models and algorithms b y teams\\nof experts, such as linguists, psychologists, and signal pr ocessing prac-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 12, 'page_label': '7', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='these tasks involve the deﬁnition of models and algorithms b y teams\\nof experts, such as linguists, psychologists, and signal pr ocessing prac-\\ntitioners, not infrequently during the course of long stand ardization\\nmeetings.\\nThe engineering design ﬂow outlined above may be too costly a nd\\nineﬃcient for problems in which faster or less expensive sol utions are\\ndesirable. The machine learning alternative is to collect l arge data sets,\\ne.g., of labelled speech, images or videos, and to use this in formation\\nto train general-purpose learning machines to carry out the desired\\ntask. While the standard engineering ﬂow relies on domain kn owledge\\nand on design optimized for the problem at hand, machine lear ning\\nlets large amounts of data dictate algorithms and solutions . T o this\\nend, rather than requiring a precise model of the set-up unde r study ,\\nmachine learning requires the speciﬁcation of an objective , of a model\\nto be trained, and of an optimization technique.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 12, 'page_label': '7', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='end, rather than requiring a precise model of the set-up unde r study ,\\nmachine learning requires the speciﬁcation of an objective , of a model\\nto be trained, and of an optimization technique.\\nReturning to the ﬁrst example above, a machine learning appr oach\\nwould proceed by training a general-purpose machine to pred ict the\\noutcome of known chemical reactions based on a large data set , and\\nby then using the trained algorithm to explore ways to produc e more\\ncomplex molecules. In a similar manner, large data sets of im ages or\\nvideos would be used to train a general-purpose algorithm wi th the aim\\nof obtaining compressed representations from which the ori ginal input\\ncan be recovered with some distortion.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 13, 'page_label': '8', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8 Introduction\\n1.2 When to Use Machine Learning?\\nBased on the discussion above, machine learning can oﬀer an e ﬃcient\\nalternative to the conventional engineering ﬂow when devel opment cost\\nand time are the main concerns, or when the problem appears to be\\ntoo complex to be studied in its full generality . On the ﬂip si de, the\\napproach has the key disadvantages of providing generally s uboptimal\\nperformance, or hindering interpretability of the solutio n, and to apply\\nonly to a limited set of problems.\\nIn order to identify tasks for which machine learning method s may\\nbe useful, reference [\\n31] suggests the following criteria:\\n1. the task involves a function that maps well-deﬁned inputs to well-\\ndeﬁned outputs;\\n2. large data sets exist or can be created containing input-o utput\\npairs;\\n3. the task provides clear feedback with clearly deﬁnable go als and\\nmetrics;\\n4. the task does not involve long chains of logic or reasoning that\\ndepend on diverse background knowledge or common sense;'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 13, 'page_label': '8', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='metrics;\\n4. the task does not involve long chains of logic or reasoning that\\ndepend on diverse background knowledge or common sense;\\n5. the task does not require detailed explanations for how th e deci-\\nsion was made;\\n6. the task has a tolerance for error and no need for provably c orrect\\nor optimal solutions;\\n7. the phenomenon or function being learned should not chang e\\nrapidly over time; and\\n8. no specialized dexterity , physical skills, or mobility i s required.\\nThese criteria are useful guidelines for the decision of whe ther machine\\nlearning methods are suitable for a given task of interest. T hey also oﬀer\\na convenient demarcation line between machine learning as i s intended\\ntoday , with its focus on training and computational statist ics tools, and\\nmore general notions of Artiﬁcial Intelligence (AI) based o n knowledge\\nand common sense [ 87] (see [ 126] for an overview on AI research).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 14, 'page_label': '9', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.2. When to Use Machine Learning? 9\\n1.2.1 Learning T asks\\nW e can distinguish among three diﬀerent main types of machin e learn-\\ning problems, which are brieﬂy introduced below. The discus sion re-\\nﬂects the focus of this monograph on parametric probabilist ic models,\\nas further elaborated on in the next section.\\n1. Supervised learning: W e have N labelled training examples\\nD={(xn ,tn)}N\\nn=1 ,where xn represents a covariate, or explanatory vari-\\nable, while tn is the corresponding label, or response. F or instance,\\nvariable xn may represent the text of an email, while the label tn may\\nbe a binary variable indicating whether the email is spam or n ot. The\\ngoal of supervised learning is to predict the value of the lab el t for\\nan input x that is not in the training set. In other words, supervised\\nlearning aims at generalizing the observations in the data s et Dto new\\ninputs. F or example, an algorithm trained on a set of emails s hould be'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 14, 'page_label': '9', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning aims at generalizing the observations in the data s et Dto new\\ninputs. F or example, an algorithm trained on a set of emails s hould be\\nable to classify a new email not present in the data set D.\\nW e can generally distinguish between classiﬁcation problems, in\\nwhich the label t is discrete, as in the example above, and regression\\nproblems, in which variable tis continuous. An example of a regression\\ntask is the prediction of tomorrow’s temperature t based on today’s\\nmeteorological observations x.\\nAn eﬀective way to learn a predictor is to identify from the da ta\\nset Da predictive distribution p(t|x) from a set of parametrized distri-\\nbutions. The conditional distribution p(t|x) deﬁnes a proﬁle of beliefs\\nover all possible of the label tgiven the input x. F or instance, for tem-\\nperature prediction, one could learn mean and variance of a G aussian\\ndistribution p(t|x) as a function of the input x. As a special case, the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 14, 'page_label': '9', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='perature prediction, one could learn mean and variance of a G aussian\\ndistribution p(t|x) as a function of the input x. As a special case, the\\noutput of a supervised learning algorithm may be in the form o f a\\ndeterministic predictive function t= ˆt(x).\\n2. Unsupervised learning: Suppose now that we have an un-\\nlabelled set of training examples D={xn}N\\nn=1 . Less well deﬁned than\\nsupervised learning, unsupervised learning generally ref ers to the task\\nof learning properties of the mechanism that generates this data set.\\nSpeciﬁc tasks and applications include clustering, which i s the prob-\\nlem of grouping similar examples xn; dimensionality reduction, feature\\nextraction, and representation learning, all related to th e problem of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 15, 'page_label': '10', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='10 Introduction\\nrepresenting the data in a smaller or more convenient space; and gen-\\nerative modelling, which is the problem of learning a genera ting mech-\\nanism to produce artiﬁcial examples that are similar to avai lable data\\nin the data set D.\\nAs a generalization of both supervised and unsupervised lea rning,\\nsemi-supervised learning refers to scenarios in which not all examples\\nare labelled, with the unlabelled examples providing infor mation about\\nthe distribution of the covariates x.\\n3. Reinforcement learning: Reinforcement learning refers to the\\nproblem of inferring optimal sequential decisions based on rewards or\\npunishments received as a result of previous actions. Under supervised\\nlearning, the “label” trefers to an action to be taken when the learner\\nis in an informational state about the environment given by a variable\\nx. Upon taking an action t in a state x, the learner is provided with\\nfeedback on the immediate reward accrued via this decision, and the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 15, 'page_label': '10', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x. Upon taking an action t in a state x, the learner is provided with\\nfeedback on the immediate reward accrued via this decision, and the\\nenvironment moves on to a diﬀerent state. As an example, an ag ent can\\nbe trained to navigate a given environment in the presence of obstacles\\nby penalizing decisions that result in collisions.\\nReinforcement learning is hence neither supervised, since the learner\\nis not provided with the optimal actions tto select in a given state x; nor\\nis it fully unsupervised, given the availability of feedbac k on the quality\\nof the chosen action. Reinforcement learning is also distin guished from\\nsupervised and unsupervised learning due to the inﬂuence of previous\\nactions on future states and rewards.\\nThis monograph focuses on supervised and unsupervised lear ning.\\nThese general tasks can be further classiﬁed along the follo wing dimen-\\nsions.\\n•Passive vs. active learning : A passive learner is given the train-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 15, 'page_label': '10', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='These general tasks can be further classiﬁed along the follo wing dimen-\\nsions.\\n•Passive vs. active learning : A passive learner is given the train-\\ning examples, while an active learner can aﬀect the choice of training\\nexamples on the basis of prior observations.\\n•Oﬄine vs. online learning : Oﬄine learning operates over a batch\\nof training samples, while online learning processes sampl es in a stream-\\ning fashion. Note that reinforcement learning operates inh erently in an\\nonline manner, while supervised and unsupervised learning can be car-\\nried out by following either oﬄine or online formulations.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 16, 'page_label': '11', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.3. Goals and Outline 11\\nThis monograph considers only passive and oﬄine learning.\\n1.3 Goals and Outline\\nThis monograph aims at providing an introduction to key conc epts, al-\\ngorithms, and theoretical results in machine learning. The treatment\\nconcentrates on probabilistic models for supervised and un supervised\\nlearning problems. It introduces fundamental concepts and algorithms\\nby building on ﬁrst principles, while also exposing the read er to more\\nadvanced topics with extensive pointers to the literature, within a uni-\\nﬁed notation and mathematical framework. Unlike other text s that are\\nfocused on one particular aspect of the ﬁeld, an eﬀort has bee n made\\nhere to provide a broad but concise overview in which the main ideas\\nand techniques are systematically presented. Speciﬁcally , the material\\nis organized according to clearly deﬁned categories, such a s discrim-\\ninative and generative models, frequentist and Bayesian ap proaches,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 16, 'page_label': '11', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is organized according to clearly deﬁned categories, such a s discrim-\\ninative and generative models, frequentist and Bayesian ap proaches,\\nexact and approximate inference, as well as directed and und irected\\nmodels. This monograph is meant as an entry point for researc hers\\nwith a background in probability and linear algebra. A prior exposure\\nto information theory is useful but not required.\\nDetailed discussions are provided on basic concepts and ide as, in-\\ncluding overﬁtting and generalization, Maximum Likelihoo d and regu-\\nlarization, and Bayesian inference. The text also endeavor s to provide\\nintuitive explanations and pointers to advanced topics and research di-\\nrections. Sections and subsections containing more advanc ed material\\nthat may be skipped at a ﬁrst reading are marked with a star ( ∗).\\nThe reader will ﬁnd here neither discussions on computing pl atform\\nor programming frameworks, such as map-reduce, nor details on spe-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 16, 'page_label': '11', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The reader will ﬁnd here neither discussions on computing pl atform\\nor programming frameworks, such as map-reduce, nor details on spe-\\nciﬁc applications involving large data sets. These can be ea sily found\\nin a vast and growing body of work. F urthermore, rather than p rovid-\\ning exhaustive details on the existing myriad solutions in e ach speciﬁc\\ncategory , techniques have been selected that are useful to i llustrate the\\nmost salient aspects. Historical notes have also been provi ded only for\\na few selected milestone events.\\nFinally , the monograph attempts to strike a balance between the\\nalgorithmic and theoretical viewpoints. In particular, al l learning al-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 17, 'page_label': '12', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='12 Introduction\\ngorithms are introduced on the basis of theoretical argumen ts, often\\nbased on information-theoretic measures. Moreover, a chap ter is de-\\nvoted to statistical learning theory , demonstrating how to set the ﬁeld\\nof supervised learning on solid theoretical foundations. T his chapter\\nis more theoretically involved than the others, and proofs o f some key\\nresults are included in order to illustrate the theoretical underpinnings\\nof learning. This contrasts with other chapters, in which pr oofs of the\\nfew theoretical results are kept at a minimum in order to focu s on the\\nmain ideas.\\nThe rest of the monograph is organized into ﬁve parts. The ﬁrs t part\\ncovers introductory material. Speciﬁcally , Chapter 2 intr oduces the fre-\\nquentist, Bayesian and Minimum Description Length (MDL) le arning\\nframeworks; the discriminative and generative categories of probabilis-\\ntic models; as well as key concepts such as training loss, gen eralization,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 17, 'page_label': '12', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='frameworks; the discriminative and generative categories of probabilis-\\ntic models; as well as key concepts such as training loss, gen eralization,\\nand overﬁtting – all in the context of a simple linear regress ion problem.\\nInformation-theoretic metrics are also brieﬂy introduced , as well as the\\nadvanced topics of interpretation and causality . Chapter 3 then pro-\\nvides an introduction to the exponential family of probabil istic models,\\nto Generalized Linear Models (GLMs), and to energy-based mo dels,\\nemphasizing main properties that will be invoked in later ch apters.\\nThe second part concerns supervised learning. Chapter 4 cov ers lin-\\near and non-linear classiﬁcation methods via discriminati ve and gen-\\nerative models, including Support V ector Machines (SVMs), kernel\\nmethods, logistic regression, multi-layer neural network s and boosting.\\nChapter 5 is a brief introduction to the statistical learnin g framework\\nof the Probably Approximately Correct (P AC) theory , coveri ng the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 17, 'page_label': '12', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Chapter 5 is a brief introduction to the statistical learnin g framework\\nof the Probably Approximately Correct (P AC) theory , coveri ng the\\nV apnik–Chervonenkis (VC) dimension and the fundamental th eorem\\nof P AC learning.\\nThe third part, consisting of a single chapter, introduced u nsuper-\\nvised learning. In particular, in Chapter 6, unsupervised l earning mod-\\nels are described by distinguishing among directed models, for which\\nExpectation Maximization (EM) is derived as the iterative m aximiza-\\ntion of the Evidence Lower BOund (ELBO); undirected models, for\\nwhich Restricted Boltzmann Machines (RBMs) are discussed a s a rep-\\nresentative example; discriminative models trained using the InfoMax'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 18, 'page_label': '13', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.3. Goals and Outline 13\\nprinciple; and autoencoders. Generative Adversarial Netw orks (GANs)\\nare also introduced.\\nThe fourth part covers more advanced modelling and inferenc e ap-\\nproaches. Chapter 7 provides an introduction to probabilis tic graphical\\nmodels, namely Bayesian Networks (BNs) and Markov Random Fi elds\\n(MRF s), as means to encode more complex probabilistic depen dencies\\nthan the models studied in previous chapters. Approximate i nference\\nand learning methods are introduced in Chapter 8 by focusing on Monte\\nCarlo (MC) and V ariational Inference (VI) techniques. The c hapter\\nbrieﬂy introduces in a uniﬁed way techniques such as variati onal EM,\\nV ariational AutoEncoders (V AE), and black-box inference. Some con-\\ncluding remarks are provided in the last part, consisting of Chapter\\n9.\\nW e conclude this chapter by emphasizing the importance of pr ob-\\nability as a common language for the deﬁnition of learning al gorithms'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 18, 'page_label': '13', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='9.\\nW e conclude this chapter by emphasizing the importance of pr ob-\\nability as a common language for the deﬁnition of learning al gorithms\\n[34]. The centrality of the probabilistic viewpoint was not alw ays rec-\\nognized, but has deep historical roots. This is demonstrate d by the\\nfollowing two quotes, the ﬁrst from the ﬁrst AI textbook publ ished by\\nP . H. Winston in 1977, and the second from an unﬁnished manusc ript\\nby J. von Neumann (see [ 126, 64] for more information).\\n“Many ancient Greeks supported Socrates opinion that deep,\\ninexplicable thoughts came from the gods. T oday’s equiva-\\nlent to those gods is the erratic, even probabilistic neuron .\\nIt is more likely that increased randomness of neural behav-\\nior is the problem of the epileptic and the drunk, not the\\nadvantage of the brilliant. ”\\nfrom Artiﬁcial Intel ligence , 1977.\\n“All of this will lead to theories of computation which are\\nmuch less rigidly of an all-or-none nature than past and'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 18, 'page_label': '13', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='advantage of the brilliant. ”\\nfrom Artiﬁcial Intel ligence , 1977.\\n“All of this will lead to theories of computation which are\\nmuch less rigidly of an all-or-none nature than past and\\npresent formal logic... There are numerous indications to\\nmake us believe that this new system of formal logic will\\nmove closer to another discipline which has been little link ed\\nin the past with logic. This is thermodynamics primarily in\\nthe form it was received from Boltzmann. ”'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 19, 'page_label': '14', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='14 Introduction\\nfrom The Computer and the Brain , 1958.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 20, 'page_label': '15', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2\\nA Gentle Introduction through Linear Regression\\nIn this chapter, we introduce the frequentist, Bayesian and MDL learn-\\ning frameworks, as well as key concepts in supervised learni ng, such as\\ndiscriminative and generative models, training loss, gene ralization, and\\noverﬁtting. This is done by considering a simple linear regr ession prob-\\nlem as a recurring example. W e start by introducing the probl em of su-\\npervised learning and by presenting some background on infe rence. W e\\nthen present the frequentist, Bayesian and MDL learning app roaches in\\nthis order. The treatment of MDL is limited to an introductor y discus-\\nsion, as the rest of monograph concentrates on frequentist a nd Bayesian\\nviewpoints. W e conclude with an introduction to the importa nt topic\\nof information-theoretic metrics, and with a brief introdu ction to the\\nadvanced topics of causal inference and interpretation.\\n2.1 Supervised Learning\\nIn the standard formulation of a supervised learning proble m, we are'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 20, 'page_label': '15', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='advanced topics of causal inference and interpretation.\\n2.1 Supervised Learning\\nIn the standard formulation of a supervised learning proble m, we are\\ngiven a training set Dcontaining N training points ( xn ,tn), n= 1 ,...,N .\\nThe observations xn are considered to be free variables, and known as\\ncovariates, domain points , or explanatory variables ; while the target\\n15'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 21, 'page_label': '16', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='16 A Gentle Introduction through Linear Regression\\nvariables tn are assumed to be dependent on xn and are referred to\\nas dependent variables, labels , or responses. An example is illustrated\\nin Fig. 2.1. W e use the notation xD = ( x1 ,....,xN )T for the covariates\\nand tD = ( t1 ,....,tN )T for the labels in the training set D. Based on\\nthis data, the goal of supervised learning is to identify an a lgorithm\\nto predict the label t for a new, that is, as of yet unobserved, domain\\npoint x.\\n0 0.2 0.4 0.6 0.8 1\\n-1.5\\n-1\\n-0.5\\n0\\n0.5\\n1\\n1.5\\nFigure 2.1: Example of a training set D with N = 10 points ( xn ,tn ), n = 1 , ..., N .\\nThe outlined learning task is clearly impossible in the abse nce of ad-\\nditional information on the mechanism relating variables xand t. With\\nreference to Fig. 2.1, unless we assume, say , that xand tare related by\\na function t= f(x) with some properties, such as smoothness, we have\\nno way of predicting the label tfor an unobserved domain point x. This'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 21, 'page_label': '16', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a function t= f(x) with some properties, such as smoothness, we have\\nno way of predicting the label tfor an unobserved domain point x. This\\nobservation is formalized by the no free lunch theorem to be reviewed\\nin Chapter 5: one cannot learn rules that generalize to unseen examples\\nwithout making assumptions about the mechanism generating the data.\\nThe set of all assumptions made by the learning algorithm is k nown as\\nthe inductive bias .\\nThis discussion points to a key diﬀerence between memorizing and\\nlearning. While the former amounts to mere retrieval of a val ue tn'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 22, 'page_label': '17', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.2. Inference 17\\ncorresponding to an already observed pair ( xn ,tn) ∈D,learning entails\\nthe capability to predict the value t for an unseen domain point x.\\nLearning, in other words, converts experience – in the form o f D– into\\nexpertise or knowledge – in the form of a predictive algorith m. This is\\nwell captured by the following quote by Jorge Luis Borges: “ T o think\\nis to forget details, generalize, make abstractions. ” [ 138].\\nBy and large, the goal of supervised learning is that of ident ifying a\\npredictive algorithm that minimizes the generalization loss , that is, the\\nerror in the prediction of a new label t for an unobserved explanatory\\nvariable x. How exactly to formulate this problem, however, depends\\non one’s viewpoint on the nature of the model that is being lea rned.\\nThis leads to the distinction between the frequentist and th e Bayesian\\napproaches, which is central to this chapter. As it will be al so discussed,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 22, 'page_label': '17', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='This leads to the distinction between the frequentist and th e Bayesian\\napproaches, which is central to this chapter. As it will be al so discussed,\\nthe MDL philosophy deviates from the mentioned focus on pred iction\\nas the goal of learning, by targeting instead a parsimonious description\\nof the data set D.\\n2.2 Inference\\nBefore we start our discussion of learning, it is useful to re view some\\nbasic concepts concerning statistical inference, as they w ill be needed\\nthroughout this chapter and in the rest of this monograph. W e specif-\\nically consider the inference problem of predicting a rv t gi ven the\\nobservation of another rv x under the assumption that their j oint dis-\\ntribution p(x,t) is known. As a matter of terminology , it is noted that\\nhere we will use the term “inference” as it is typically inten ded in the\\nliterature on probabilistic graphical models (see, e.g., [\\n81]), hence di-\\nverging from its use in other branches of the machine learnin g literature\\n(see, e.g., [ 23]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 22, 'page_label': '17', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='literature on probabilistic graphical models (see, e.g., [\\n81]), hence di-\\nverging from its use in other branches of the machine learnin g literature\\n(see, e.g., [ 23]).\\nIn order to deﬁne the problem of optimal inference, one start s by\\ndeﬁning a non-negative loss function ℓ(t,ˆt). This deﬁnes the cost, or\\nloss or risk, incurred when the correct value is twhile the estimate is ˆt.\\nAn important example is the ℓq loss\\nℓq (t,ˆt) = |t−ˆt|q , (2.1)\\nwhich includes as a special case the quadratic loss ℓ2(t,ˆt) = ( t−ˆt)2 ,and'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 23, 'page_label': '18', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='18 A Gentle Introduction through Linear Regression\\nthe 0-1 loss, or detection error , ℓ0(t,ˆt) = |t−ˆt|0,where |a|0 = 1 if a̸= 0\\nand |a|0 = 0 otherwise. Once a loss function is selected, the optimal\\nprediction ˆt(x) for a given value of the observation x is obtained by\\nminimizing the so-called generalization risk or generalization loss 1\\nLp(ˆt) = E (x,t)∼pxt [ℓ(t,ˆt(x))]. (2.2)\\nThe notation Lp emphasizes the dependence of the generalization loss\\non the distribution p(x,t).\\nThe solution of this problem is given by the optimal predicti on or\\ndecision rule 2\\nˆt∗(x) = arg min\\nˆt\\nEt∼pt|x [ℓ(t,ˆt)|x]. (2.3)\\nThis can be seen by using the law of iterated expectations E (x,t)∼pxt [·] =\\nEx∼px [Et∼pt|x [·|x]]. Equation ( 2.3) shows that the optimal estimate, or\\nprediction, ˆt∗ (x) is a function of the posterior distribution p(t|x) of the\\nlabel given the domain point x and of the loss function ℓ. Therefore,\\nonce the posterior p(t|x) is known, one can evaluate the optimal pre-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 23, 'page_label': '18', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='label given the domain point x and of the loss function ℓ. Therefore,\\nonce the posterior p(t|x) is known, one can evaluate the optimal pre-\\ndiction ( 2.3) for any desired loss function, without the need to know\\nthe joint distribution p(x,t).\\nAs a special case of ( 2.3), with the quadratic loss function ℓ2 , the\\noptimal prediction is the conditional mean ˆt∗(x) = E t∼pt|x [t|x]; while\\nfor the 0-1 loss function ℓ0, the optimal decision is the mode of the\\nposterior distribution, i.e., ˆt∗(x) = arg max t p(t|x).\\nF or example, assume that we have\\nt|x = x∼0.8δ(t−x) + 0 .2δ(t+ x), (2.4)\\nso that, conditioned on the event x = x, t equals x with probability\\n0.8 and −x with probability 0.2. The optimal prediction is ˆt∗(x) =\\n0.8x−0.2x= 0 .6x for the quadratic loss, while it is ˆt∗(x) = x for the\\n0-1 loss.\\n1 The term generalization error or population error are also o ften used, but they\\nwill not be adopted in this monograph.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 23, 'page_label': '18', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='0-1 loss.\\n1 The term generalization error or population error are also o ften used, but they\\nwill not be adopted in this monograph.\\n2 The optimal estimate ( 2.3) is also known as Bayes’ prediction or Bayes’ rule, but\\nhere we will not use this terminology in order to avoid confus ion with the Bayesian\\napproach discussed below.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 24, 'page_label': '19', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 19\\nThe goal of supervised learning methods is broadly speaking that of\\nobtaining a predictor ˆt(x) that performs close to the optimal predictor\\nˆt∗(x), based only on the training set D, and hence without knowledge\\nof the joint distribution p(x,t). The closeness in performance is mea-\\nsured by the diﬀerence between the generalization loss Lp(ˆt) achieved\\nby the trained predictor and the minimum generalization loss Lp(ˆt∗ ) of\\nthe optimal predictor, which depends on the true distributi on p(x,t).\\nStrictly speaking, this statement applies only for the freq uentist ap-\\nproach, which is discussed next. As it will be explained late r in the\\nchapter, in fact, while the Bayesian approach still centers around the\\ngoal of prediction, its modelling assumptions are diﬀerent . F urthermore,\\nthe MDL approach concentrates on the task of data compressio n rather\\nthan prediction.\\n2.3 Frequentist Approach'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 24, 'page_label': '19', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='goal of prediction, its modelling assumptions are diﬀerent . F urthermore,\\nthe MDL approach concentrates on the task of data compressio n rather\\nthan prediction.\\n2.3 Frequentist Approach\\nAccording to the frequentist viewpoint, the training data p oints (x n,tn ) ∈\\nDare independent identically distributed (i.i.d.) rvs draw n from a true,\\nand unknown, distribution p(x,t):\\n(xn ,tn) ∼\\ni.i.d.\\np(x,t), i= 1 ,...,N. (2.5)\\nThe new observation (x ,t) is also independently generated from the\\nsame true distribution p(x,t); the domain point x is observed and the\\nlabel t must be predicted. Since the probabilistic model p(x,t) is not\\nknown, one cannot solve directly problem (\\n2.3) to ﬁnd the optimal\\nprediction that minimizes the generalization loss Lp in ( 2.2).\\nBefore discussing the available solutions to this problem, it is worth\\nobserving that the deﬁnition of the “true” distribution p(x,t) depends\\nin practice on the way data is collected. As in the example of t he'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 24, 'page_label': '19', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='observing that the deﬁnition of the “true” distribution p(x,t) depends\\nin practice on the way data is collected. As in the example of t he\\n“beauty AI” context, if the rankings tn assigned to pictures xn of faces\\nare aﬀected by racial biases, the distribution p(x,t) will reﬂect these\\nprejudices and produce skewed results [ 62].\\nT axonomy of solutions. There are two main ways to address the\\nproblem of learning how to perform inference when not knowin g the\\ndistribution p(x,t):'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 25, 'page_label': '20', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='20 A Gentle Introduction through Linear Regression\\n•Separate learning and (plug-in) inference : Learn ﬁrst an approx-\\nimation, say pD (t|x), of the conditional distribution p(t|x) based on\\nthe data D, and then plug this approximation in ( 2.3) to obtain an\\napproximation of the optimal decision as\\nˆtD (x) = arg min\\nˆt\\nEt∼pD (t|x)[ℓ(t,ˆt)|x]. (2.6)\\n•Direct inference via Empirical Risk Minimization (ERM): Learn\\ndirectly an approximation ˆtD (·) of the optimal decision rule by mini-\\nmizing an empirical estimate of the generalization loss ( 2.2) obtained\\nfrom the data set as\\nˆtD (·) = arg min\\nˆt\\nLD (ˆt), (2.7)\\nwhere the empirical risk, or empirical loss , is\\nLD (ˆt) = 1\\nN\\nN∑\\nn=1\\nℓ(tn,ˆt(xn )). (2.8)\\nThe notation LD (ˆt) highlights the dependence of the empirical loss on\\nthe predictor ˆt(·) and on the training set D.\\nIn practice, as we will see, both approaches optimize a set of param-\\neters that deﬁne the probabilistic model or the predictor. F urthermore,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 25, 'page_label': '20', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the predictor ˆt(·) and on the training set D.\\nIn practice, as we will see, both approaches optimize a set of param-\\neters that deﬁne the probabilistic model or the predictor. F urthermore,\\nthe ﬁrst approach is generally more ﬂexible, since having an estimate\\npD (t|x) of the posterior distribution p(t|x) allows the prediction ( 2.6)\\nto be computed for any loss function. In contrast, the ERM sol ution\\n(2.7) is tied to a speciﬁc choice of the loss function ℓ. In the rest of this\\nsection, we will start by taking the ﬁrst approach, and discu ss later\\nhow this relates to the ERM formulation.\\nLinear regression example. F or concreteness, in the following,\\nwe will consider the following running example inspired by [ 23]. In the\\nexample, data is generated according to the true distributi on p(x,t) =\\np(x)p(t|x), where x ∼U(0,1) and\\nt|x = x∼N(sin(2πx),0.1). (2.9)\\nThe training set in Fig. 2.1 was generated from this distribution. If this'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 25, 'page_label': '20', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x)p(t|x), where x ∼U(0,1) and\\nt|x = x∼N(sin(2πx),0.1). (2.9)\\nThe training set in Fig. 2.1 was generated from this distribution. If this\\ntrue distribution were known, the optimal predictor under t he ℓ2 loss'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 26, 'page_label': '21', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 21\\nwould be equal to the conditional mean\\nˆt∗(x) = sin(2 πx). (2.10)\\nHence, the minimum generalization loss is Lp(ˆt∗ ) = 0 .1.\\nIt is emphasized that, while we consider this running exampl e in\\norder to ﬁx the ideas, all the deﬁnitions and ideas reported i n this\\nchapter apply more generally to supervised learning proble ms. This\\nwill be further discussed in Chapter 4 and Chapter 5.\\n2.3.1 Discriminative vs. Generative Probabilistic Models\\nIn order to learn an approximation pD (t|x) of the predictive distribution\\np(t|x) based on the data D, we will proceed by ﬁrst selecting a family\\nof parametric probabilistic models, also known as a hypothesis class ,\\nand by then learning the parameters of the model to ﬁt (in a sen se to\\nbe made precise later) the data D.\\nConsider as an example the linear regression problem introd uced\\nabove. W e start by modelling the label t as a polynomial function\\nof the domain point x added to a Gaussian noise with variance β−1 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 26, 'page_label': '21', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Consider as an example the linear regression problem introd uced\\nabove. W e start by modelling the label t as a polynomial function\\nof the domain point x added to a Gaussian noise with variance β−1 .\\nParameter β is the precision, i.e., the inverse variance of the additive\\nnoise. The polynomial function with degree M can be written as\\nµ(x,w) =\\nM∑\\nj=0\\nwj xj = wT φ(x), (2.11)\\nwhere we have deﬁned the weight vector w= [ w0 w1 ··· wM ]T and the\\nfeature vector φ(x) = [1 x x2 ···xM ]T . The vector wdeﬁnes the relative\\nweight of the powers in the sum (\\n2.11). This assumption corresponds\\nto adopting a parametric probabilistic model p(t|x,θ) deﬁned as\\nt|x = x∼N(µ(x,w),β−1 ), (2.12)\\nwith parameters θ = ( w,β). Having ﬁxed this hypothesis class, the\\nparameter vector θ can be then learned from the data D, as it will be\\ndiscussed.\\nIn the example above, we have parametrized the posterior dis tribu-\\ntion. Alternatively , we can parametrize, and learn, the ful l joint distri-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 26, 'page_label': '21', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='discussed.\\nIn the example above, we have parametrized the posterior dis tribu-\\ntion. Alternatively , we can parametrize, and learn, the ful l joint distri-\\nbution p(x,t). These two alternatives are introduced below.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 27, 'page_label': '22', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='22 A Gentle Introduction through Linear Regression\\n1. Discriminative probabilistic model. With this ﬁrst class of\\nmodels, the posterior, or predictive, distribution p(t|x) is assumed to\\nbelong to a hypothesis class p(t|x,θ) deﬁned by a parameter vector θ.\\nThe parameter vector θ is learned from the data set D. F or a given\\nparameter vector θ, the conditional distribution p(t|x,θ) allows the\\ndiﬀerent values of the label t to be discriminated on the basis of their\\nposterior probability . In particular, once the model is lea rned, one can\\ndirectly compute the predictor ( 2.6) for any loss function.\\nAs an example, for the linear regression problem, once a vect or of\\nparameters θD = ( wD ,βD ) is identiﬁed based on the data Dduring\\nlearning, the optimal prediction under the ℓ2 loss is the conditional\\nmean ˆtD (x) = E t∼p(t|x,θD )[t|x], that is, ˆtD (x) = µ(x,wD ).\\n2. Generative probabilistic model. Instead of learning directly'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 27, 'page_label': '22', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning, the optimal prediction under the ℓ2 loss is the conditional\\nmean ˆtD (x) = E t∼p(t|x,θD )[t|x], that is, ˆtD (x) = µ(x,wD ).\\n2. Generative probabilistic model. Instead of learning directly\\nthe posterior p(t|x), one can model the joint distribution p(x,t) as\\nbeing part of a parametric family p(x,t|θ). Note that, as opposed to\\ndiscriminative models, the joint distribution p(x,t|θ) models also the\\ndistribution of the covariates x. Accordingly , the term “generative” re-\\nﬂects the capacity of this type of models to generate a realiz ation of\\nthe covariates x by using the marginal p(x|θ).\\nOnce the joint distribution p(x,t|θ) is learned from the data, one\\ncan compute the posterior p(t|x,θ) using Bayes’ theorem, and, from\\nit, the optimal predictor ( 2.6) can be evaluated for any loss function.\\nGenerative models make stronger assumptions by modeling al so the\\ndistribution of the explanatory variables. As a result, an i mproper se-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 27, 'page_label': '22', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Generative models make stronger assumptions by modeling al so the\\ndistribution of the explanatory variables. As a result, an i mproper se-\\nlection of the model may lead to more signiﬁcant bias issues. However,\\nthere are potential advantages, such as the ability to deal w ith missing\\ndata or latent variables, such as in semi-supervised learni ng. W e refer\\nto Chapter 6 for further discussion (see also [ 23]).\\nIn the rest of this section, for concreteness, we consider di scrimi-\\nnative probabilistic models p(t|x,θ), although the main deﬁnitions will\\napply also to generative models.\\n2.3.2 Model Order and Model Parameters\\nIn the linear regression example, the selection of the hypot hesis class\\n(\\n2.12) required the deﬁnition of the polynomial degree M, while the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 28, 'page_label': '23', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 23\\ndetermination of a speciﬁc model p(t|x,θ) in the class called for the\\nselection of the parameter vector θ= ( w,β). As we will see, these two\\ntypes of variables play a signiﬁcantly diﬀerent role during learning and\\nshould be clearly distinguished, as discussed next.\\n1. Model order M (and hyperparameters): The model order\\ndeﬁnes the “capacity” of the hypothesis class, that is, the n umber of\\nthe degrees of freedom in the model. The larger M is, the more capable\\na model is to ﬁt the available data. F or instance, in the linea r regression\\nexample, the model order determines the size of the weight ve ctor w.\\nMore generally , variables that deﬁne the class of models to b e learned\\nare known as hyperparameters. As we will see, determining th e model\\norder, and more broadly the hyperparameters, requires a pro cess known\\nas validation.\\n2. Model parameters θ: Assigning speciﬁc values to the model\\nparameters θ identiﬁes a hypothesis within the given hypothesis class.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 28, 'page_label': '23', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as validation.\\n2. Model parameters θ: Assigning speciﬁc values to the model\\nparameters θ identiﬁes a hypothesis within the given hypothesis class.\\nThis can be done by using learning criteria such as Maximum Li keli-\\nhood (ML) and Maximum a Posteriori (MAP).\\nW e postpone a discussion of validation to the next section, a nd we\\nstart by introducing the ML and MAP learning criteria.\\n2.3.3 Maximum Likelihood (ML) Learning\\nAssume now that the model order M is ﬁxed, and that we are interested\\nin learning the model parameters θ.The ML criterion selects a value of\\nθunder which the training set Dhas the maximum probability of being\\nobserved. In other words, the value θ selected by ML is the most likely\\nto have generated the observed training set. Note that there might be\\nmore than one such value.\\nT o proceed, we need to write the probability (density) of the ob-\\nserved labels tD in the training set Dgiven the corresponding domain'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 28, 'page_label': '23', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='more than one such value.\\nT o proceed, we need to write the probability (density) of the ob-\\nserved labels tD in the training set Dgiven the corresponding domain\\npoints x. Under the assumed discriminative model, this is given as\\np(tD |xD ,w,β ) =\\nN∏\\nn=1\\np(tn|xn,w,β ), (2.13)\\n=\\nN∏\\nn=1\\nN(tn|µ(xn,w),β−1 )'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 29, 'page_label': '24', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='24 A Gentle Introduction through Linear Regression\\nwhere we have used the independence of diﬀerent data points. T aking\\nthe logarithm yields the Log-Likelihood (LL) function\\nln p(tD |xD ,w,β ) =\\nN∑\\nn=1\\nln p(tn|xn,w,β )\\n= - β\\n2\\nN∑\\nn=1\\n(µ(xn,w) −tn)2 + N\\n2 ln β\\n2π. (2.14)\\nThe LL function should be considered as a function of the mode l pa-\\nrameters θ = ( w,β), since the data set Dis ﬁxed and given. The ML\\nlearning problem is deﬁned by the minimization of the Negative LL\\n(NLL) function as\\nmin\\nw,β\\n−1\\nN\\nN∑\\nn=1\\nln p(tn|xn,w,β ). (2.15)\\nThis criterion is also referred to as cross-entropy or log-loss, as further\\ndiscussed in Sec. 2.6.\\nIf one is only interested in learning only the posterior mean , as is\\nthe case when the loss function is ℓ2, then one can tackle problem ( 2.14)\\nonly over the weights w, yielding the optimization\\nminw LD (w) = 1\\nN\\nN∑\\nn=1\\n(µ(xn ,w) −tn)2 . (2.16)\\nThe quantity LD (w) is known as the training loss . An interesting ob-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 29, 'page_label': '24', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='only over the weights w, yielding the optimization\\nminw LD (w) = 1\\nN\\nN∑\\nn=1\\n(µ(xn ,w) −tn)2 . (2.16)\\nThe quantity LD (w) is known as the training loss . An interesting ob-\\nservation is that this criterion coincides with the ERM prob lem ( 2.7)\\nfor the ℓ2 loss if one parametrizes the predictor as ˆt(x) = µ(x,w).\\nThe ERM problem ( 2.16) can be solved in closed form. T o this end,\\nwe write the empirical loss as LD (w) = N−1||tD −XD w||2 , with the\\nN ×(M + 1) matrix\\nXD = [ φ(x1 ) φ(x2 ) ··· φ(xN )]T . (2.17)\\nIts minimization hence amounts to a Least Squares (LS) probl em,\\nwhich yields the solution\\nwM L = ( XT\\nD XD )−1XT\\nD tD , (2.18)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 30, 'page_label': '25', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 25\\nNote that, in ( 2.18), we have assumed the typical overdetermined case\\nin which the inequality N >(M + 1) holds. More generally , one has\\nthe ML solution wM L = X†\\nD tD . Finally , diﬀerentiating the NLL with\\nrespect to β yields instead the ML estimate\\n1\\nβM L\\n= LD (wM L ). (2.19)\\n0 0.2 0.4 0.6 0.8 1\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n= 9M\\nM= 1\\nM= 3\\nFigure 2.2: Illustration of underﬁtting and overﬁtting in ML learning: The dashed\\nline is the optimal predictor ( 2.10), which depends on the unknown true distribution,\\nwhile the other lines correspond to the predictor ˆtM L (x) = µ(x, w M L ) learned via\\nML with diﬀerent model orders M .\\nOverﬁtting and Underﬁtting. Adopting the ℓ2 loss, let us now\\ncompare the predictor ˆtM L (x) = µ(x,wM L ) learned via ML with the\\noptimal, but unknown, predictor ˆt∗(x) in ( 2.10). T o this end, Fig. 2.2\\nshows the optimal predictor ˆt∗(x) as a dashed line and the ML-based\\npredictor ˆtM L (x) obtained with diﬀerent values of the model order M'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 30, 'page_label': '25', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='shows the optimal predictor ˆt∗(x) as a dashed line and the ML-based\\npredictor ˆtM L (x) obtained with diﬀerent values of the model order M\\nfor the training set Din Fig. 2.1 (also shown in Fig. 2.2 for reference).\\nW e begin by observing that, with M = 1, the ML predictor under-\\nﬁts the data: the model is not rich enough to capture the variatio ns\\npresent in the data. As a result, the training loss LD (wM L ) in ( 2.16) is\\nlarge.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 31, 'page_label': '26', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='26 A Gentle Introduction through Linear Regression\\nIn contrast, with M = 9, the ML predictor overﬁts the data: the\\nmodel is too rich and, in order to account for the observation s in the\\ntraining set, it yields inaccurate predictions outside it. In this case, the\\ntraining loss LD (w) in ( 2.16) is small, but the generalization loss\\nLp(wM L ) = E (x,t)∼pxt [ℓ(t,µ(x,wM L ))] (2.20)\\nis large. With overﬁtting, the model is memorizing the train ing set,\\nrather than learning how to generalize to unseen examples.\\nThe choice M = 3 appears to be the best by comparison with the\\noptimal predictor. Note that this observation is in practic e precluded\\ngiven the impossibility to determine ˆt∗(x) and hence the generalization\\nloss. W e will discuss below how to estimate the generalizati on loss using\\nvalidation.\\n1 2 3 4 5 6 7 8 9\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\n1.6root average squared loss\\ntraining\\ngeneralization \\n(via validation)\\noverfitting\\nunderfitting'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 31, 'page_label': '26', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='validation.\\n1 2 3 4 5 6 7 8 9\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\n1.6root average squared loss\\ntraining\\ngeneralization \\n(via validation)\\noverfitting\\nunderfitting\\nFigure 2.3: Square root of the generalization loss Lp (wM L ) and of the training loss\\nLD (wM L ) as a function of the model order M for the training data set in Fig. 2.1.\\nThe impact of the model order M on training and generalization\\nlosses is further elaborated on in Fig. 2.3, which shows the squared root\\nof the generalization loss Lp(wM L ) and of the training loss LD (wM L ) as\\na function of M for the same training data set. A ﬁrst remark is that,\\nas expected, the training loss is smaller than the generaliz ation loss,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 32, 'page_label': '27', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 27\\nsince the latter accounts for all pairs (x ,t)∼p(x,t), while the former\\nincludes only the training points used for learning. More im portantly ,\\nthe key observation here is that increasing M allows one to better ﬁt –\\nand possibly overﬁt – the training set, hence reducing LD (wM L ). The\\ngeneralization loss Lp(wM L ) instead tends to decrease at ﬁrst, as we\\nmove away from the underﬁtting regime, but it eventually inc reases\\nfor suﬃciently large M. The widening of the gap between training and\\ngeneralization provides evidence that overﬁtting is occur ring. F rom Fig.\\n2.3, we can hence conclude that, in this example, model orders la rger\\nthan M = 7 should be avoided since they lead to overﬁtting, while\\nmodel order less than M = 3 should also not be considered in order to\\navoid underﬁtting.\\n0 10 20 30 40 50 60 70\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nroot average quadratic loss\\nM\\nM\\n= 1\\n= 7\\ngeneralization (via validation)\\ntraining'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 32, 'page_label': '27', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='avoid underﬁtting.\\n0 10 20 30 40 50 60 70\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nroot average quadratic loss\\nM\\nM\\n= 1\\n= 7\\ngeneralization (via validation)\\ntraining\\nFigure 2.4: Square root of the generalization loss Lp (wM L ) and of the training loss\\nLD (wM L ) as a function of the training set size N . The asymptote of the general-\\nization and training losses is given by the minimum generali zation loss Lp (w∗ ) (cf.\\n(2.21)) achievable for the given model order (see Fig. 2.5).\\nWhat if we had more data? Extrapolating from the behavior ob-\\nserved in Fig. 2.2, we can surmise that, as the number N of data points\\nincreases, overﬁtting is avoided even for large values of M. In fact, when\\nthe training set is big as compared to the number of parameter s in θ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 33, 'page_label': '28', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='28 A Gentle Introduction through Linear Regression\\nwe expect the training loss LD (w) to provide an accurate measure of\\nthe generalization loss Lp(w) for al l possible values of w. Informally ,\\nwe have the approximation LD (w) ≃Lp(w) simultaneously for all val-\\nues of w as long as N is large enough. Therefore, the weight vector\\nwM L that minimizes the training loss LD (w) also (approximately) min-\\nimizes the generalization loss Lp(w). It follows that, for large N, the\\nML parameter vector wM L tends to the the optimal value w∗ (assum-\\ning for simplicity of argument that it is unique) that minimi zes the\\ngeneralization loss among all predictors in the model, i.e. ,\\nw∗ = argminw Lp(w). (2.21)\\nThis discussion will be made precise in Chapter 5.\\nT o oﬀer numerical evidence for the point just made, Fig. 2.4 plots\\nthe (square root of the) generalization and training losses versus N,\\nwhere the training sets were generated at random from the tru e distri-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 33, 'page_label': '28', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the (square root of the) generalization and training losses versus N,\\nwhere the training sets were generated at random from the tru e distri-\\nbution. F rom the ﬁgure, we can make the following important o bserva-\\ntions. First, overﬁtting – as measured by the gap between tra ining and\\ngeneralization losses – vanishes as N increases. This is a consequence of\\nthe discussed approximate equalities LD (w) ≃Lp(w) and wM L ≃w∗ ,\\nwhich are valid as N grows large, which imply the approximate equali-\\nties LD (wM L ) ≃Lp(wM L ) ≃Lp(w∗ ).\\nSecond, it is noted that the training loss LD (wM L ) tends to the\\nminimum generalization loss Lp(w∗ ) for the given M from below, while\\nthe generalization loss Lp(wM L ) tends to it from above. This is be-\\ncause, as N increases, it becomes more diﬃcult to ﬁt the data set D,\\nand hence LD (wM L ) increases. Conversely , as N grows large, the ML\\nestimate becomes more accurate, because of the increasingl y accurate'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 33, 'page_label': '28', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and hence LD (wM L ) increases. Conversely , as N grows large, the ML\\nestimate becomes more accurate, because of the increasingl y accurate\\napproximation wM L ≃w∗ , and thus the generalization loss Lp(wM L )\\ndecreases.\\nThird, selecting a smaller model order M yields an improved gener-\\nalization loss when the training set is small, while a larger value of M is\\ndesirable when the data set is bigger. In fact, as further dis cussed below,\\nwhen N is small, the estimation error caused by overﬁtting dominates\\nthe bias caused by the choice of a small hypothesis class. In contrast ,\\nfor suﬃciently large training sets, the estimation error va nishes and the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 34, 'page_label': '29', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 29\\nperformance is dominated by the bias induced by the selectio n of the\\nmodel.\\n0 10 20 30 40 50 60 70\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nroot average quadratic loss\\nestimation error\\nbias\\nFigure 2.5: Illustration of the bias and training error based on the deco mposition\\n(2.22).\\nBias and generalization gap. The previous paragraph intro-\\nduced the notions of estimation error and bias associated with the\\nselection of a given model order M. While Chapter 5 will provide a\\nmore extensive discussion on these concepts, it is useful to brieﬂy re-\\nview them here in the context of ML learning. Estimation erro r and bias\\nrefer to the following decomposition of the generalization loss achieved\\nby the given solution wM L\\nLp(wM L ) = Lp(ˆt∗ ) + ( Lp(w∗ ) −Lp(ˆt∗)) + ( Lp(wM L ) −Lp(w∗ )). (2.22)\\nThis decomposition is illustrated in Fig. 2.5 for M = 1. In ( 2.22),\\nthe term Lp(ˆt∗ ) = 0 .1 (the ﬁgure shows the square root) is, as seen,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 34, 'page_label': '29', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='This decomposition is illustrated in Fig. 2.5 for M = 1. In ( 2.22),\\nthe term Lp(ˆt∗ ) = 0 .1 (the ﬁgure shows the square root) is, as seen,\\nthe minimum achievable generalization loss without any con straint on\\nthe hypothesis class. The term ( Lp(w∗ ) −Lp(ˆt∗)) represents the bias,\\nor approximation error, caused by the choice of the given hyp othesis\\nclass, and hence also by the choice of M. This is because, by ( 2.21),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 35, 'page_label': '30', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='30 A Gentle Introduction through Linear Regression\\nLp(w∗ ) is the best generalization loss for the given model. Recall that\\nthe loss Lp(w∗ ) can be achieved when N is large enough. Finally , the\\nterm ( Lp(wM L )−Lp(w∗ )) is the estimation error or generalization gap 3\\nthat is incurred due to the fact that N is not large enough and hence\\nwe have wM L ̸= w∗ .\\nF rom the decomposition ( 2.22), a large N allows us to reduce the\\nestimation error, but it has no eﬀect on the bias. This is seen in Fig. 2.4,\\nwhere the asymptote achieved by the generalization loss as N increases\\nequals the minimum generalization loss Lp(w∗ ) for the given model\\norder. Choosing a small value of M in the regime of large data imposes a\\nﬂoor on the achievable generalization loss that no amount of additional\\ndata can overcome.\\nV alidation and testing. In the discussion above, it was assumed\\nthat the generalization loss Lp(w) can somehow be evaluated. Since'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 35, 'page_label': '30', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='data can overcome.\\nV alidation and testing. In the discussion above, it was assumed\\nthat the generalization loss Lp(w) can somehow be evaluated. Since\\nthis depend on the true unknown distribution p(x,t), this evaluation is,\\nstrictly speaking, not possible. How then to estimate the ge neralization\\nloss in order to enable model order selection using a plot as i n Fig. 2.3?\\nThe standard solution is to use validation.\\nThe most basic form of validation prescribes the division of the avail-\\nable data into two sets: a hold-out, or validation, set and the training\\nset. The validation set is used to evaluate an approximation of the\\ngeneralization loss Lp(w) via the empirical average\\nLp(w) ≃ 1\\nNv\\nNv∑\\nn=1\\nℓ(tn,µ(xn ,w)), (2.23)\\nwhere the sum is done over the Nv elements of the validation set.\\nThe just described hold-out approach to validation has a cle ar draw-\\nback, as part of the available data needs to be set aside and no t used\\nfor training. This means that the number of examples that can be'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 35, 'page_label': '30', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='back, as part of the available data needs to be set aside and no t used\\nfor training. This means that the number of examples that can be\\nused for training is smaller than the number of overall avail able data\\npoints. T o partially obviate this problem, a more sophistic ated, and\\ncommonly used, approach to validation is k-fold cross-validation . With\\nthis method, the available data points are partitioned, typ ically at ran-\\ndom, into k equally sized subsets. The generalization loss is then esti -\\n3 This is also deﬁned as generalization error in some referenc es.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 36, 'page_label': '31', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 31\\nmated by averaging k diﬀerent estimates. Each estimate is obtained by\\nretaining one of the k subsets for validation and the remaining k−1\\nsubsets for training. When k = N, this approach is also known as\\nleave-one-out cross-validation.\\nT est set. Once a model order M and model parameters θhave been\\nobtained via learning and validation, one typically needs t o produce\\nan estimate of the generalization loss obtained with this ch oice ( M,θ).\\nThe generalization loss estimated via validation cannot be used for this\\npurpose. In fact, the validation loss tends to be smaller tha n the actual\\nvalue of the generalization loss. After all, we have selecte d the model\\norder so as to yield the smallest possible error on the valida tion set. The\\nupshot is that the ﬁnal estimate of the generalization loss s hould be\\ndone on a separate set of data points, referred to as the test set , that are\\nset aside for this purpose and not used at any stage of learnin g. As an'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 36, 'page_label': '31', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='done on a separate set of data points, referred to as the test set , that are\\nset aside for this purpose and not used at any stage of learnin g. As an\\nexample, in competitions among diﬀerent machine learning a lgorithms,\\nthe test set is kept by a judge to evaluate the submissions and is never\\nshared with the contestants.\\n2.3.4 Maximum A Posteriori (MAP) Criterion\\nW e have seen that the decision regarding the model order M in ML\\nlearning concerns the tension between bias, whose reductio n calls for a\\nlarger M, and estimation error, whose decrease requires a smaller M.\\nML provides a single integer parameter, M, as a gauge to trade oﬀ bias\\nand estimation error. As we will discuss here, the MAP approa ch and,\\nmore generally , regularization, enable a ﬁner control of th ese two terms.\\nThe key idea is to leverage prior information available on th e behavior\\nof the parameters in the absence, or presence, of overﬁtting .\\nT o elaborate, consider the following experiment. Evaluate the ML'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 36, 'page_label': '31', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of the parameters in the absence, or presence, of overﬁtting .\\nT o elaborate, consider the following experiment. Evaluate the ML\\nsolution wM L in (\\n2.18) for diﬀerent values of M and observe how it\\nchanges as we move towards the overﬁtting regime by increasi ng M (see\\nalso [ 23, T able 1.1]). F or the experiment reported in Fig. 2.2, we obtain\\nthe following values: for M = 1, wM L = [0 .93, −1.76]T ; for M = 3,\\nwM L = [ −0.28, 13.32, −35.92, 22.56]T ; and for M = 9, wM L = [13 .86,\\n−780.33, 12.99×103 , −99.27 ×103 , 416.49 ×103 , −1.03 ×106 , 1.56 ×\\n106 , 1.40 ×106 , 0.69 ×106 , −1.44 ×106 ]. These results suggest that a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 37, 'page_label': '32', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='32 A Gentle Introduction through Linear Regression\\nmanifestation of overﬁtting is the large value of norm ∥w∥ of the vector\\nof weights. W e can use this observation as prior information , that is as\\npart of the inductive bias, in designing a learning algorith m.\\nT o this end, we can impose a prior distribution on the vector of\\nweights that gives lower probability to large values. A poss ible, but not\\nthe only , way to do this is to is to assume a Gaussian prior as\\nw∼N(0,α−1 I), (2.24)\\nso that all weights are a priori i.i.d. zero-mean Gaussian va riables with\\nvariance α−1 . Increasing α forces the weights to be smaller as it re-\\nduces the probability associated with large weights. The pr ecision vari-\\nable α is an example of a hyperparameter. In a Bayesian framework,\\nhyperparameters control the distribution of the model para meters. As\\nanticipated, hyperparameters are determined via validati on.\\nRather than maximizing the LL, that is, probability density p(tD |xD ,w,β )'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 37, 'page_label': '32', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='anticipated, hyperparameters are determined via validati on.\\nRather than maximizing the LL, that is, probability density p(tD |xD ,w,β )\\nof the labels in the training set, as for ML, the MAP criterion prescribes\\nthe maximization of the joint probability distribution of w eights and\\nof labels given the prior p(w) = N(w|0,α−1 I), that is,\\np(tD ,w|xD ,β) = p(w)\\nN∏\\nn=1\\np(tn|xn,w,β ). (2.25)\\nNote that a prior probability can also be assumed for the para meter β,\\nbut in this example we leave βas a deterministic parameter. The MAP\\nlearning criterion can hence be formulated as\\nmin\\nw,β\\n−\\nN∑\\nn=1\\nln p(tn|xn ,w,β ) −ln p(w). (2.26)\\nThe name “Maximum a Posteriori” is justiﬁed by the fact that\\nproblem ( 2.26) is equivalent to maximizing the posterior distribution\\nof the parameters w given the available data, as we will further discuss\\nin the next section. This yields the following problem for th e weight\\nvector\\nminw LD (w) + λ\\nN∥w∥2 , (2.27)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 37, 'page_label': '32', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of the parameters w given the available data, as we will further discuss\\nin the next section. This yields the following problem for th e weight\\nvector\\nminw LD (w) + λ\\nN∥w∥2 , (2.27)\\nwhere we have deﬁned λ= α/β and we recall that the training loss is\\nLD (w) = N−1 ∥tD −XD w∥2 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 38, 'page_label': '33', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 33\\nML vs. MAP . Observing ( 2.27), it is important to note the fol-\\nlowing general property of the MAP solution: As the number N of data\\npoints grows large, the MAP estimate tends to the ML estimate , given\\nthat the contribution of the prior information term decreas es as 1 /N.\\nWhen N is large enough, any prior credence is hence superseded by th e\\ninformation obtained from the data.\\nProblem ( 2.27), which is often referred to as ridge regression, mod-\\niﬁes the ML criterion by adding the quadratic (or Tikhonov) regular-\\nization function\\nR(w) = ∥w∥2 (2.28)\\nmultiplied by the term λ/N. The regularization function forces the\\nnorm of the solution to be small, particularly with larger va lues of the\\nhyperparameter λ, or equivalently α. The solution of problem ( 2.27)\\ncan be found by using standard LS analysis, yielding\\nwM AP = ( λI+ XT\\nD XD )−1 XT\\nD tD . (2.29)\\nThis expression conﬁrms that, as N grows large, the term λI becomes'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 38, 'page_label': '33', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='can be found by using standard LS analysis, yielding\\nwM AP = ( λI+ XT\\nD XD )−1 XT\\nD tD . (2.29)\\nThis expression conﬁrms that, as N grows large, the term λI becomes\\nnegligible and the solution tends to the ML estimate ( 2.18) (see [ 86]\\nfor a formal treatment).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 39, 'page_label': '34', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='34 A Gentle Introduction through Linear Regression\\n-40 -30 -20 -10 0\\n0\\n0.5\\n1\\n1.5\\n2\\ngeneralization \\n(via validation)\\ntraining\\nFigure 2.6: Square root of the generalization loss Lp (wM AP ) and of the training\\nloss LD (wM AP ) as a function of the regularization parameter λ for the training data\\nset in Fig. 2.1 with M = 9.\\nFig. 2.6 shows the squared root of the generalization loss Lp(wM AP )\\nand of the training loss LD (wM AP ) as a function of λ (in logarithmic\\nscale) for the training data set in Fig. 2.1 with M = 9. The general-\\nization loss is estimated using validation. W e observe that increasing\\nλ, and hence the relevance of the regularization term, has a si milar im-\\npact as decreasing the model order M. A larger λreduces the eﬀective\\ncapacity of the model. Stated in diﬀerent words, increasing λ reduces\\noverﬁtting but may entail a larger bias.\\nOther standard examples for the prior distribution include the Laplace'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 39, 'page_label': '34', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='capacity of the model. Stated in diﬀerent words, increasing λ reduces\\noverﬁtting but may entail a larger bias.\\nOther standard examples for the prior distribution include the Laplace\\npdf, which yields the l1 norm regularization function R(w) = ∥w∥1 =∑ M\\nj=0 |w|1 . This term promotes the sparsity of the solution, which is\\nuseful in many signal recovery algorithms [\\n14] and in non-parametric\\nfunction estimation [ 146]. The corresponding optimization problem\\nminw LD (w) + λ\\nN∥w∥1 (2.30)\\nis known as LASSO (Least Absolute Shrinkage and Selection Op era-\\ntor).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 40, 'page_label': '35', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.3. Frequentist Approach 35\\n2.3.5 Regularization\\nW e have seen above that the MAP learning criterion amounts to the\\naddition of a regularization function R(w) to the ML or ERM learning\\nlosses. This function penalizes values of the weight vector w that are\\nlikely to occur in the presence of overﬁtting, or, generally , that are im-\\nprobable on the basis of the available prior information. Th e net eﬀect\\nof this addition is to eﬀectively decrease the capacity of th e model, as\\nthe set of values for the parameter vector wthat the learning algorithm\\nis likely to choose from is reduced. As a result, as seen, regu larization\\ncan control overﬁtting and its optimization requires valid ation.\\nRegularization generally refers to techniques that aim at r educing\\noverﬁtting during training. The discussion in the previous subsection\\nhas focused on a speciﬁc form of regularization that is groun ded in a\\nprobabilistic interpretation in terms of MAP learning. W e n ote that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 40, 'page_label': '35', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='has focused on a speciﬁc form of regularization that is groun ded in a\\nprobabilistic interpretation in terms of MAP learning. W e n ote that\\nthe same techniques, such as ridge regression and LASSO, can also\\nbe introduced independently of a probabilistic framework i n an ERM\\nformulation. F urthermore, apart from the discussed additi on of regu-\\nlarization terms to the empirical risk, there are other ways to perform\\nregularization.\\nOne approach is to modify the optimization scheme by using te ch-\\nniques such as early stopping [56]. Another is to augment the training\\nset by generating artiﬁcial examples and hence eﬀectively i ncreasing\\nthe number N of training examples. Related to this idea is the tech-\\nnique known as bagging. With bagging, we ﬁrst create a number K of\\nbootstrap data sets. Bootstrap data sets are obtained by selecting N\\ndata points uniformly with replacement from D(so that the same data\\npoint generally appears multiple times in the bootstrap dat a set). Then,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 40, 'page_label': '35', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='data points uniformly with replacement from D(so that the same data\\npoint generally appears multiple times in the bootstrap dat a set). Then,\\nwe train the model K times, each time over a diﬀerent bootstrap set.\\nFinally , we average the results obtained from the models usi ng equal\\nweights. If the errors accrued by the diﬀerent models were in dependent,\\nbagging would yield an estimation error that decreases with K. In prac-\\ntice, signiﬁcantly smaller gains are obtained, particular ly for large K,\\ngiven that the bootstrap data sets are all drawn from Dand hence the\\nestimation errors are not independent [ 23].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 41, 'page_label': '36', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='36 A Gentle Introduction through Linear Regression\\n2.4 Bayesian Approach\\nThe frequentist approaches discussed in the previous secti on assume\\nthe existence of a true distribution, and aim at identifying a speciﬁc\\nvalue for the parameters θof a probabilistic model to derive a predictor\\n(cf. ( 2.3)). ML chooses the value θ that maximizes the probability of\\nthe training data, while MAP includes in this calculation al so prior\\ninformation about the parameter vector. With the frequenti st approach,\\nthere are hence two distributions on the data: the true distr ibution,\\napproximated by the empirical distribution of the data and t he model\\n(see further discussion in Sec. 2.8).\\nThe Bayesian viewpoint is conceptually diﬀerent: ( i ) It assumes\\nthat all data points are jointly distributed according to a d istribution\\nthat is known except for some hyperparameters; and ( ii ) the model\\nparameters θ are jointly distributed with the data. As a result, as it'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 41, 'page_label': '36', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='that is known except for some hyperparameters; and ( ii ) the model\\nparameters θ are jointly distributed with the data. As a result, as it\\nwill be discussed, rather than committing to a single value t o explain\\nthe data, the Bayesian approach considers the explanations provided by\\nall possible values of θ, each weighted according to a generally diﬀerent,\\nand data-dependent, “belief” .\\nMore formally , the Bayesian viewpoint sees the vector of par ameters\\nas rvs that are jointly distributed with the labels t D in the training data\\nDand with the new example t. W e hence have the joint distributi on\\np(tD ,w,t |xD ,x). W e recall that the conditioning on the domain points\\nxD and x in the training set and in the new example, respectively , are\\nhallmarks of discriminative probabilistic models. The Bay esian solution\\nsimply takes this modeling choice to its logical end point: i n order to\\npredict the new label t, it directly evaluates the posterior distribution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 41, 'page_label': '36', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='simply takes this modeling choice to its logical end point: i n order to\\npredict the new label t, it directly evaluates the posterior distribution\\np(t|xD ,tD ,x) = p(t|D,x) given the available information ( D,x) by ap-\\nplying the marginalization rules of probability to the join t distribution\\np(tD ,w,t |xD ,x).\\nAs seen, the posterior probability p(t|D,x) can be used as the predic-\\ntive distribution in ( 2.3) to evaluate a predictor ˆt(x). However, a fully\\nBayesian solution returns the entire posterior p(t|D,x), which provides\\nsigniﬁcantly more information about the unobserved label t . As we will\\ndiscuss below, this knowledge, encoded in the posterior p(t|D,x), com-\\nbines both the assumed prior information about the weight ve ctor w'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 42, 'page_label': '37', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.4. Bayesian Approach 37\\nand the information that is obtained from the data D.\\nT o elaborate, in the rest of this section, we assume that the p reci-\\nsion parameter β is ﬁxed and that the only learnable parameters are\\nthe weights in vector w.The joint distribution of the labels in the train-\\ning set, of the weight vector and of the new label, conditione d on the\\ndomain points xD in the training set and on the new point x, is given\\nas\\np(tD ,w,t |xD ,x) = p(w)\\ued19\\ued18\\ued17 \\ued1a\\na priori distribution\\np(tD |xD ,w)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\np(t|x,w)\\ued19 \\ued18\\ued17 \\ued1a\\ndistribution of new data\\n.\\n(2.31)\\nIn the previous equation, we have identiﬁed the a priori dist ribution of\\nthe data; the likelihood term p(tD |xD ,w) = ∏ N\\nn=1 N(tn|µ(xn,w),β−1 )\\nin (\\n2.13)4 ; and the pdf of the new label p(t|w,x) = N(t|µ(x,w),β−1 ).\\nIt is often useful to drop the dependence on the domain points xD and\\nx to write only the joint distribution of the random variables in the\\nmodel as\\np(tD ,w,t ) = p(w)\\ued19\\ued18\\ued17 \\ued1a\\na priori distribution\\np(tD |w)\\ued19 \\ued18\\ued17 \\ued1a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 42, 'page_label': '37', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x to write only the joint distribution of the random variables in the\\nmodel as\\np(tD ,w,t ) = p(w)\\ued19\\ued18\\ued17 \\ued1a\\na priori distribution\\np(tD |w)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\np(t|w)\\ued19 \\ued18\\ued17 \\ued1a\\ndistribution of new data\\n. (2.32)\\nThis factorization can be represented graphically by the Ba yesian Net-\\nwork (BN) in Fig. 2.7. The signiﬁcance of the graph should be clear by\\ninspection, and it will be discussed in detail in Chapter 7.\\nIt is worth pointing out that, by treating all quantities in t he model\\n– except for the hyperparameter α– as rvs, the Bayesian viewpoint does\\naway with the distinction between learning and inference. I n fact, since\\nthe joint distribution is assumed to be known in a Bayesian mo del, the\\nproblem at hand becomes that of inferring the unknown rv t. T o restate\\nthis important point, the Bayesian approach subsumes all pr oblems in\\nthe general inference task of estimating a subset of rvs give n other rvs\\nin a set of jointly distributed rvs with a known joint distrib ution.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 42, 'page_label': '37', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the general inference task of estimating a subset of rvs give n other rvs\\nin a set of jointly distributed rvs with a known joint distrib ution.\\n4 The likelihood is also known as sampling distribution withi n the Bayesian frame-\\nwork [ 92].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 43, 'page_label': '38', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='38 A Gentle Introduction through Linear Regression\\nFigure 2.7: Bayesian Network (BN) describing the joint distribution ( 2.32) of the\\nweight vector w, of the labels t D in the training data D and t in the new example,\\nas used in the Bayesian approach.\\nAs mentioned, we are interested in computing the posterior p roba-\\nbility p(t|D,x) of the new label t given the training data Dand the new\\ndomain point x = x. Dropping again the domain variables to simplify\\nthe notation, we apply standard rules of probability to obta in\\np(t|tD ) = p(tD ,t)\\np(tD ) =\\n∫ p(w)p(tD |w)\\np(tD ) p(t|w)dw\\n=\\n∫\\np(w|tD )p(t|w)dw, (2.33)\\nwhere the second equality follows from the marginalization rule p(tD ,t) =∫\\np(tD ,w,t )dwand the last equality from Bayes’ theorem. Putting back\\nthe dependence on the domain variables, we obtain the predic tive dis-\\ntribution as\\np(t|x,D) =\\n∫\\np(w|D)\\ued19 \\ued18\\ued17 \\ued1a\\nposterior distribution of w\\np(t|x,w)dw. (2.34)\\nThis is the key equation. Accordingly , the Bayesian approac h con-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 43, 'page_label': '38', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tribution as\\np(t|x,D) =\\n∫\\np(w|D)\\ued19 \\ued18\\ued17 \\ued1a\\nposterior distribution of w\\np(t|x,w)dw. (2.34)\\nThis is the key equation. Accordingly , the Bayesian approac h con-\\nsiders the predictive probability p(t|x,w) associated with each value of\\nthe weight vector w weighted by the posterior belief\\np(w|D) = p(w)p(tD |xD ,w)\\np(tD |xD ) . (2.35)\\nThe posterior belief p(w|D), which deﬁnes the weight of the parameter\\nvector w, is hence proportional to the prior belief p(w) multiplied by\\nthe correction p(tD |xD ,w) due to the observed data.\\nComputing the posterior p(w|D), and a fortiori also the predictive\\ndistribution p(t|x,D), is generally a diﬃcult task that requires the adop-\\ntion of approximate inference techniques covered in Chapte r 8. F or this'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 44, 'page_label': '39', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.4. Bayesian Approach 39\\nexample, however, we can directly compute the predictive di stribution\\nas [ 23]\\nt|x,D∼N (µ(x,wM AP ),s2 (x)), (2.36)\\nwhere s2(x) = β−1 (1 + φ(x)T\\n(\\nλI+ XT\\nD XD\\n) −1\\nφ(x)).Therefore, in this\\nparticular example, the optimal predictor under ℓ2 loss is MAP . This is\\nconsequence of the fact that mode and mean of a Gaussian pdf co incide,\\nand is not a general property . Even so, as discussed next, the Bayesian\\nviewpoint can provide signiﬁcantly more information on the label tthan\\nthe ML or MAP .\\nML and MAP vs. Bayesian approach. The Bayesian posterior\\n(2.36) provides a ﬁner prediction of the labels t given the explanatory\\nvariables x as compared to the predictive distribution p(t|x,θM L ) =\\nN(µ(x,wM L ),β−1 ) returned by ML and similarly by MAP . T o see this,\\nnote that the latter has the same variance for all values of x, namely\\nβ−1. Instead, the Bayesian approach reveals that, due to the unev en'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 44, 'page_label': '39', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='note that the latter has the same variance for all values of x, namely\\nβ−1. Instead, the Bayesian approach reveals that, due to the unev en\\ndistribution of the observed values of x, the accuracy of the prediction\\nof labels depends on the value of x: V alues of x closer to the existing\\npoints in the training sets generally exhibit a smaller vari ance.\\nThis is shown in Fig. 2.8, which plots a training set, along with the\\ncorresponding predictor µ(x,wM AP ) and the high-probability interval\\nµ(x,wM AP ) ±s(x) produced by the Bayesian method. W e set M = 9,\\nβ−1 = 0 .1 and α−1 = 0 .2 ×105 .F or reference, we also show the interval\\nµ(x,wM AP ) ±β−1/2 that would result from the MAP analysis. This\\nintervals illustrate the capability of the Bayesian approa ch to provide\\ninformation about the uncertainty associated with the esti mate of t.\\nThis advantage of the Bayesian approach reﬂects its concept ual dif-\\nference with respect to the frequentist approach: The frequ entist pre-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 44, 'page_label': '39', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='This advantage of the Bayesian approach reﬂects its concept ual dif-\\nference with respect to the frequentist approach: The frequ entist pre-\\ndictive distribution refers to a hypothetical new observat ion generated\\nwith the same mechanism as the training data; instead, the Ba yesian\\npredictive distribution quantiﬁes the statistician’s bel ief in the value of\\nt given the assumed prior and the training data.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 45, 'page_label': '40', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='40 A Gentle Introduction through Linear Regression\\n0 0.2 0.4 0.6 0.8 1\\nx\\n-2\\n-1\\n0\\n1\\n2\\n3\\n4\\n5\\n6\\nt\\nµ(x, wM AP)\\nBayesian:\\nµ(x, wM AP) ± s(x)\\nMAP: µ(x, wM AP) ± β− 1\\nFigure 2.8: Illustration of the predictive distribution p(t|x, D) produced by the\\nBayesian method for the training set shown in the ﬁgure as com pared to that ob-\\ntained with the MAP criterion. The larger interval correspo nds to µ(x, w M AP ) ± s(x)\\nfor the Bayesian method, while the smaller interval to µ(x, w M AP ) ± β−1/ 2 for MAP\\n(M = 9, β−1 = 0 .1 and α−1 = 0 .2 × 105 ).\\nF rom ( 2.36), we can make another important general observation\\nabout the relationship with ML and MAP concerning the asympt otic\\nbehavior when N is large. In particular, when N →∞, we have al-\\nready seen that, informally , the limit wM AP →wM L holds. W e now\\nobserve that it is also the case that the variance s2(x) of the Bayesian\\npredictive distribution tends to β−1.As a result, we can conclude that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 45, 'page_label': '40', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='observe that it is also the case that the variance s2(x) of the Bayesian\\npredictive distribution tends to β−1.As a result, we can conclude that\\nthe Bayesian predictive distribution approaches that retu rned by ML\\nwhen N is large. A way to think about this conclusion is that, when\\nN is large, the posterior distribution p(w|D) of the weights tends to\\nconcentrate around the ML estimate, hence limiting the aver age ( 2.34)\\nto the contribution of the ML solution.\\nMarginal likelihood. Another advantage of the Bayesian approach\\nis that, in principle, it allows model selection to be perfor med without\\nvalidation. T oward this end, compute the marginal likelihood\\np(tD |xD ) =\\n∫\\np(w)\\nN∏\\nn=1\\np(tn|xn ,w)dw, (2.37)\\nthat is, the probability density of the training set when mar ginalizing\\nover the weight distribution. With the ML approach, the corr esponding'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 46, 'page_label': '41', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.4. Bayesian Approach 41\\nquantity p(tD |xD ,wM L ) can only increase by choosing a larger model\\norder M. In fact, a larger M entails more degrees of freedom in the\\noptimization ( 2.16) of the LL. A similar discussion applies also to MAP .\\nHowever, this is not the case for ( 2.37): a larger M implies a more\\n“spread-out” prior distribution of the weights, which may r esult in a\\nmore diﬀuse distribution of the labels in ( 2.37). Hence, increasing M\\nmay yield a smaller marginal likelihood.\\n0 2 4 6 8\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1 10-7\\n = 0\\n = 0/8\\n = 0/2\\n = 0/4\\nFigure 2.9: Marginal likelihood versus the model order M for the training set of\\nFig. 2.1 (β = 10, α0 = 10 −3 ).\\nT o illustrate this point, Fig. 2.9 plots the marginal likelihood for\\nthe data set in Fig. 2.1 for β = 10 and three diﬀerent values of α as a\\nfunction of M. The marginal likelihood in this example can be easily\\ncomputed since we have\\ntD |xD = xD ∼N(0,α−1 XD XT\\nD + β−1 I). (2.38)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 46, 'page_label': '41', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function of M. The marginal likelihood in this example can be easily\\ncomputed since we have\\ntD |xD = xD ∼N(0,α−1 XD XT\\nD + β−1 I). (2.38)\\nIt is observed that the marginal likelihood presents a peak a t a given\\nvalue of M, while decreasing when moving away from the optimal value.\\nTherefore, we could take the value of M at which the marginal likeli-\\nhood is maximized as the selected model order.\\nDoes this mean that validation is really unnecessary when ad opting\\na Bayesian viewpoint? Unfortunately , this is not necessari ly the case.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 47, 'page_label': '42', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='42 A Gentle Introduction through Linear Regression\\nIn fact, one still needs to set the hyperparameter α. As seen in Fig.\\n2.9, varying α can lead to diﬀerent conclusions on the optimal value\\nof M. An alternative approach would be to treat α, and even M, as\\nrvs with given priors to be speciﬁed (see, e.g., [ 131]). This would not\\nobviate the problem of selecting hyperparameters – now deﬁn ing the\\nprior distributions of αand M – but it can lead to powerful hierarchical\\nmodels. The necessary tools will be discussed in Chapter 7.\\nAs a ﬁnal note, rather than using often impractical exhausti ve\\nsearch methods, the optimization over the hyperparameters and the\\nmodel order M for all criteria discussed so far, namely ML, MAP and\\nBayesian, can be carried out using so-called Bayesian optim ization tools\\n[132]. A drawback of these techniques is that they have their own h y-\\nperparameters that need to be selected.\\nEmpirical Bayes. Straddling both frequentist and Bayesian view-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 47, 'page_label': '42', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[132]. A drawback of these techniques is that they have their own h y-\\nperparameters that need to be selected.\\nEmpirical Bayes. Straddling both frequentist and Bayesian view-\\npoints is the so-called empirical Bayes method. This approa ch assumes\\nan a priori distribution for the parameters, but then estima tes the pa-\\nrameters of the prior – say mean and variance of a Gaussian pri or –\\nfrom the data [ 48].\\n2.5 Minimum Description Length (MDL) ∗\\nIn this section, we brieﬂy introduce a third, conceptually d istinct, learn-\\ning philosophy – the MDL criterion. The reader is warned that the\\ntreatment here is rather superﬁcial, and that a more formal d eﬁnition\\nof the MDL criterion would would require a more sophisticate d dis-\\ncussion, which can be found in [ 60]. F urthermore, some background\\nin information theory is preferable in order to fully beneﬁt from this\\ndiscussion.\\nT o start, we ﬁrst recall from the treatment above that learni ng'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 47, 'page_label': '42', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in information theory is preferable in order to fully beneﬁt from this\\ndiscussion.\\nT o start, we ﬁrst recall from the treatment above that learni ng\\nrequires the identiﬁcation of a model, or hypothesis class – here the\\nmodel order M – and of a speciﬁc hypothesis, deﬁned by parameters θ\\n– here θ = ( w,β) – within the class. While MDL can be used for both\\ntasks, we will focus here only on the ﬁrst.\\nT o build the necessary background, we now need to review the\\nrelationship between probabilistic models and compressio n. T o this end,\\nconsider a signal x taking values in a ﬁnite alphabet X, e.g., a pixel'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 48, 'page_label': '43', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.5. Minimum Description Length (MDL) ∗ 43\\nin a gray scale image. Fix some probability mass function (pm f) p(x)\\non this alphabet. A key result in information theory states t hat it is\\npossible to design a lossless compression scheme that uses ⌈−log p(x)⌉\\nbits to represent value x5\\nBy virtue of this result, the choice of a probability distrib ution p(x)\\nis akin to the selection of a lossless compression scheme tha t produces a\\ndescription of around −log p(x) bits to represent value x. Note that the\\ndescription length −log p(x) decreases with the probability assigned by\\np(x) to value x: more likely values under p(x) are assigned a smaller\\ndescription. Importantly , a decoder would need to know p(x) in order\\nto recover x from the bit description.\\nAt an informal level, the MDL criterion prescribes the selec tion\\nof a model that compresses the training data to the shortest p ossi-\\nble description. In other words, the model selected by MDL de ﬁnes a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 48, 'page_label': '43', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of a model that compresses the training data to the shortest p ossi-\\nble description. In other words, the model selected by MDL de ﬁnes a\\ncompression scheme that describes the data set Dwith the minimum\\nnumber of bits. As such, the MDL principle can be thought of as a for-\\nmalization of Occam’s razor: choose the model that yields th e simplest\\nexplanation of the data. As we will see below, this criterion naturally\\nleads to a solution that penalizes overﬁtting.\\nWhat is the length of the description of a data set Dthat results\\nfrom the selection of a speciﬁc value of M? The answer is not straight-\\nforward, since, for a given value of M, there are as many probability\\ndistributions as there are values for the corresponding par ameters θ\\nto choose from. A formal calculation of the description leng th would\\nhence require the introduction of the concept of universal c ompression\\nfor a given probabilistic model [ 60]. Here, we will limit ourselves to a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 48, 'page_label': '43', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='hence require the introduction of the concept of universal c ompression\\nfor a given probabilistic model [ 60]. Here, we will limit ourselves to a\\nparticular class of universal codes known as two-part codes .\\nUsing two-part codes, we can compute the description length for\\nthe data Dthat results from the choice of a model order M as fol-\\nlows. First, we obtain the ML solution ( wM L ,βM L ). Then, we describe\\nthe data set by using a compression scheme deﬁned by the proba bil-\\nity p(t|x,wM L ,βM L ) = N(t|µ(x,wM L ),β−1\\nM L ). As discussed, this pro-\\n5 This is known as Kraft’s inequality . More precisely , it stat es that the lossless\\ncompression scheme at hand is preﬁx-free and hence decodabl e, or invertible, without\\ndelay [ 38].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 49, 'page_label': '44', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='44 A Gentle Introduction through Linear Regression\\nduces a description of approximately −∑ N\\nn=1 logp(tn|xn,wM L ,βM L )\\nbits\\n6. This description is, however, not suﬃcient, since the deco der of\\nthe description should also be informed about the parameter s ( wM L ,βM L ).\\nUsing quantization, the parameters can be described by mean s of a\\nnumber C(M) of bits that is proportional to the number of parameters,\\nhere M+ 2.Concatenating these bits with the description produced by\\nthe ML model yields the overall description length\\n−\\nN∑\\nn=1\\nlogp(tn|xn,wM L ,βM L ) + C(M). (2.39)\\nMDL – in the simpliﬁed form discussed here – selects the model order\\nM that minimizes the description length ( 2.39). Accordingly , the term\\nC(M) acts as a regularizer. The optimal value of M for the MDL\\ncriterion is hence the result of the trade-oﬀ between the min imization\\nof the overhead C(M), which calls for a small value of M, and the\\nminimization of the NLL, which decreases with M.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 49, 'page_label': '44', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='criterion is hence the result of the trade-oﬀ between the min imization\\nof the overhead C(M), which calls for a small value of M, and the\\nminimization of the NLL, which decreases with M.\\nUnder some technical assumptions, the overhead term can be o ften\\nevaluated in the form ( K/2) ln N + c, where K is the number of pa-\\nrameters in the model and cis a constant. This expression is not quite\\nuseful in practice, but it provides intuition about the mech anism used\\nby MDL to combat overﬁtting.\\n2.6 Information-Theoretic Metrics\\nW e now provide a brief introduction to information theoreti c metrics\\nby leveraging the example studied in this chapter. As we will see in the\\nfollowing chapters, information-theoretic metrics are us ed extensively\\nin the deﬁnition of learning algorithms. Appendix A provide s a detailed\\nintroduction to information-theoretic measures in terms o f inferential\\ntasks. Here we introduce the key metrics of Kullback-Leible r (KL) di-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 49, 'page_label': '44', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='introduction to information-theoretic measures in terms o f inferential\\ntasks. Here we introduce the key metrics of Kullback-Leible r (KL) di-\\nvergence and entropy by examining the asymptotic behavior o f ML in\\nthe regime of large N. The case with ﬁnite N is covered in Chapter 6\\n(see Sec.\\n6.4.3).\\n6 This neglects the technical issue that the labels are actual ly continuous rvs,\\nwhich could be accounted for by using quantization.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 50, 'page_label': '45', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.6. Information-Theoretic Metrics 45\\nT o start, we revisit the ML problem ( 2.15), which amounts to the\\nminimization of the NLL −N−1 ∑ N\\nn=1 ln p(tn|xn,w,β ), also known as\\nlog-loss. According to the frequentist viewpoint, the trai ning set vari-\\nables are drawn i.i.d. according to the true distribution p(x,t), i.e.,\\n(xn,tn ) ∼pxt i.i.d. over n = 1 ,...,N . By the strong law of large num-\\nbers, we then have the following limit with probability one\\n−1\\nN\\nN∑\\nn=1\\nln p(tn |xn,w,β ) →E(x,t)∼pxt [−ln p(t|x,w,β )] . (2.40)\\nAs we will see next, this limit has a useful interpretation in terms of\\nthe KL divergence.\\nThe KL divergence between two distributions pand q is deﬁned as\\nKL(p∥q) = E x∼px\\n[\\nln p(x)\\nq(x)\\n]\\n. (2.41)\\nThe KL divergence is hence the expectation of the Log-Likeli hood Ratio\\n(LLR) ln( p(x)/q(x)) between the two distributions, where the expecta-\\ntion is taken with respect to the distribution at the numerat or. The'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 50, 'page_label': '45', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='(LLR) ln( p(x)/q(x)) between the two distributions, where the expecta-\\ntion is taken with respect to the distribution at the numerat or. The\\nLLR tends to be larger, on average, if the two distributions d iﬀer more\\nsigniﬁcantly , while being uniformly zero only when the two d istribu-\\ntions are equal. Therefore, the KL divergence measures the “ distance”\\nbetween two distributions. As an example, with p(x) = N(x|µ1,σ2\\n1 )\\nand q(x) = N(x|µ2 ,σ2\\n2 ), we have\\nKL(p∥q) = 1\\n2\\n(\\nσ2\\n1\\nσ2\\n2\\n+ (µ2 −µ1)2\\nσ2\\n2\\n−1 + ln σ2\\n2\\nσ2\\n1\\n)\\n, (2.42)\\nand, in the special case σ2\\n1 = σ2\\n2 = σ2, we can write\\nKL(p∥q) = 1\\n2\\n(µ2 −µ1)2\\nσ2 , (2.43)\\nwhich indeed increase as the two distributions become more d iﬀerent.\\nThe KL divergence is measured in nats when the natural logari thm\\nis used as in ( 2.41), while it is measured in bits if a logarithm in base 2\\nis used. In general, the KL divergence has several desirable properties\\nas a measure of the distance of two distributions [ 23, pp. 55-58]. The'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 50, 'page_label': '45', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is used. In general, the KL divergence has several desirable properties\\nas a measure of the distance of two distributions [ 23, pp. 55-58]. The\\nmost notable is Gibbs’ inequality\\nKL(p∥q) ≥0, (2.44)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 51, 'page_label': '46', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='46 A Gentle Introduction through Linear Regression\\nwhere equality holds if and only if the two distributions p and q are\\nidentical. Nevertheless, the KL divergence has also some se emingly un-\\nfavorable features, such as its non-symmetry , that is, the i nequality\\nKL(p∥q) ̸= KL( q∥p). W e will see in Chapter 8 that the absence of\\nsymmetry can be leveraged to deﬁne diﬀerent types of approxi mate\\ninference and learning techniques.\\nImportantly , the KL divergence can be written as\\nKL(p||q) = E x∼px [−ln q(x)]\\ued19 \\ued18\\ued17 \\ued1a\\nH (p||q)\\n−Ex∼px [−ln p(x)]\\ued19 \\ued18\\ued17 \\ued1a\\nH (p)\\n, (2.45)\\nwhere the ﬁrst term, H(p||q), is known as cross-entropy between p(x)\\nand q(x) and plays an important role as a learning criterion as discu ssed\\nbelow; while the second term, H(p), is the entropy of distribution p(x),\\nwhich is a measure of randomness. W e refer to Appendix A for fu rther\\ndiscussion on the entropy .\\nBased on the decomposition ( 2.45), we observe that the cross-entropy'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 51, 'page_label': '46', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='which is a measure of randomness. W e refer to Appendix A for fu rther\\ndiscussion on the entropy .\\nBased on the decomposition ( 2.45), we observe that the cross-entropy\\nH(p||q) can also be taken as a measure of divergence between two dis-\\ntributions when one is interested in optimizing over the dis tribution\\nq(x), since the latter does not appear in the entropy term. Note t hat\\nthe cross-entropy , unlike the KL divergence, can be negativ e.\\nUsing the deﬁnition ( 2.41), the expected log-loss on the right-hand\\nside of ( 2.40) can be expressed as\\nE(x,t)∼pxt [−ln p(t|x,w,β )] = E x∼px [H(p(t|x)||p(t|x,w,β ))], (2.46)\\nwhich can be easily veriﬁed by using the law of iterated expec tations.\\nTherefore, the average log-loss is the average over the doma in point x\\nof the cross-entropy between the real predictive distribut ion p(t|x) and\\nthe predictive distribution p(t|x,w,β ) dictated by the model. F rom\\n(2.46), the ML problem ( 2.15) can be interpreted as an attempt to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 51, 'page_label': '46', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the predictive distribution p(t|x,w,β ) dictated by the model. F rom\\n(2.46), the ML problem ( 2.15) can be interpreted as an attempt to\\nmake the model-based discriminative distribution p(t|x,w,β ) as close\\nas possible to the actual posterior p(t|x). This is done by minimizing\\nthe KL divergence, or equivalently the cross-entropy , upon averaging\\nover p(x).\\nAs ﬁnal remarks, in machine learning, it is common to use the\\nnotation KL( p∥q) even when q is unnormalized, that is, when q(x) is'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 52, 'page_label': '47', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.7. Interpretation and Causality ∗ 47\\nnon-negative, but we may have the inequality\\n∫\\nq(x)dx ̸= 1. W e also\\nobserve that the entropy H(p) = E x∼px [−ln p(x)] is non-negative for\\ndiscrete rvs, while it may be negative for continuous rvs. Du e to its\\ndiﬀerent properties when evaluated for continuous rvs, the quantity\\nH(p) should be more properly referred to as diﬀerential entropy when\\nthe distribution p is a pdf [ 38]. In the rest of this monograph, we will\\nnot always make this distinction.\\n2.7 Interpretation and Causality ∗\\nHaving learned a predictive model using any of the approache s dis-\\ncussed above, an important, and often overlooked, issue is t he interpre-\\ntation of the results returned by the learned algorithm. Thi s has in fact\\ngrown into a separate ﬁeld within the active research area of deep neu-\\nral networks (see Chapter 4) [\\n102]. Here, we describe a typical pitfall of\\ninterpretation that relates to the assessment of causality relationships'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 52, 'page_label': '47', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ral networks (see Chapter 4) [\\n102]. Here, we describe a typical pitfall of\\ninterpretation that relates to the assessment of causality relationships\\nbetween the variables in the model. W e follow an example in [ 113].\\nFig. 2.10 (top) shows a possible distribution of data points on the\\nplane deﬁned by coordinates x = exercise and t = cholesterol (the\\nnumerical values are arbitrary). Learning a model that rela tes tas the\\ndependent variable to the variable x would clearly identify an upward\\ntrend – an individual that exercises more can be predicted to have a\\nhigher cholesterol level. This prediction is legitimate an d supported by\\nthe available data, but can we also conclude that exercising less would\\nreduce one’s cholesterol? In other words, can we conclude th at there\\nexists a causal relationships between x and t? W e know the answer to\\nbe no, but this cannot be ascertained from the data in the ﬁgur e.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 53, 'page_label': '48', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='48 A Gentle Introduction through Linear Regression\\n-5 0 5 10 15 20 25\\nExercise\\n-20\\n0\\n20\\n40Cholesterol\\n-5 0 5 10 15 20 25\\nExercise\\n-20\\n0\\n20\\n40Cholesterol\\n20 30 40\\n50\\n10\\nFigure 2.10: Illustration of Simpson’s paradox [ 113].\\nThe way out of this conundrum is to leverage prior informatio n\\nwe have about the problem domain. In fact, we can explain away this\\nspurious correlation by including another measurable vari able in the\\nmodel, namely age. T o see this, consider the same data, now re drawn\\nby highlighting the age of the individual corresponding to e ach data\\npoint. The resulting plot, seen in Fig. 2.10 (bottom), reveals that older\\npeople — within the observed bracket — tend to have a higher ch oles-\\nterol as well as to exercise more. Therefore, age is a common c ause of\\nboth exercise and cholesterol levels. In order to capture th e causality\\nrelationship between the latter variables, we hence need to adjust for\\nage. Doing this requires to consider the trend within each ag e sepa-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 53, 'page_label': '48', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='relationship between the latter variables, we hence need to adjust for\\nage. Doing this requires to consider the trend within each ag e sepa-\\nrately , recovering the expected conclusion that exercisin g is useful to\\nlower one’s cholesterol. 7\\nW e conclude that in this example the correlation between x and t,\\nwhile useful for prediction, should not be acted upon for dec ision mak-\\ning. When assessing the causal relationship between xand t, we should\\nﬁrst understand which other variables may explain the obser vations\\nand then discount any spurious correlations.\\nThis discussion reveals an important limitation of most exi sting ma-\\nchine learning algorithms when it comes to identifying caus ality rela-\\ntionships, or, more generally , to answering counterfactua l queries [ 112].\\nThe study of causality can be carried out within the elegant f ramework\\n7 This example is an instance of the so called Simpson’s parado x: patterns visible'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 53, 'page_label': '48', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The study of causality can be carried out within the elegant f ramework\\n7 This example is an instance of the so called Simpson’s parado x: patterns visible\\nin the data disappear, or are even reversed, on the segregate d data.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 54, 'page_label': '49', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='2.8. Summary 49\\nof interventions on probabilistic graphical models developed by Pearl\\n[113, 81, 118]. Other related approaches are covered in [ 115]. More dis-\\ncussion on probabilistic graphical models can be found in Ch apter 7.\\n2.8 Summary\\nIn this chapter, we have reviewed three key learning framewo rks, namely\\nfrequentist, Bayesian and MDL, within a parametric probabi listic set-\\nup. The frequentist viewpoint postulates the presence of a t rue un-\\nknown distribution for the data, and aims at learning a predi ctor that\\ngeneralizes well on unseen data drawn from this distributio n. This can\\nbe done either by learning a probabilistic model to be plugge d into\\nthe expression of the optimal predictor or by directly solvi ng the ERM\\nproblem over the predictor. The Bayesian approach outputs a predic-\\ntive distribution that combines prior information with the data by solv-\\ning the inference problem of computing the posterior distri bution over'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 54, 'page_label': '49', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tive distribution that combines prior information with the data by solv-\\ning the inference problem of computing the posterior distri bution over\\nthe unseen label. Finally , the MDL method aims at selecting a model\\nthat allows the data to be described with the smallest number of bits,\\nhence doing away with the need to deﬁne the task of generalizi ng over\\nunobserved examples.\\nThe chapter has also focused extensively on the key problem o f\\noverﬁtting, demonstrating how the performance of a learnin g algorithm\\ncan be understood in terms of bias and estimation error. In pa rticular,\\nwhile choosing a hypothesis class is essential in order to en able learning,\\nchoosing the “wrong” class constitutes an irrecoverable bi as that can\\nmake learning impossible. As a real-world example, as repor ted in [\\n109],\\nincluding as independent variables in x the ZIP code of an individual\\nseeking credit at a bank may discriminate against immigrant s or minori-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 54, 'page_label': '49', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='109],\\nincluding as independent variables in x the ZIP code of an individual\\nseeking credit at a bank may discriminate against immigrant s or minori-\\nties. Another example of this phenomenon is the famous exper iment by\\nB. F. Skinner on pigeons [ 133].\\nW e conclude this chapter by emphasizing an important fact ab out\\nthe probabilistic models that are used in modern machine lea rning\\napplications. In frequentist methods, typically at least t wo (possibly\\nconditional) distributions are involved: the empirical da ta distribution\\nand the model distribution. The former amounts to the histog ram of\\nthe data which, by the law of large numbers, tends to the real d istribu-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 55, 'page_label': '50', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='50 A Gentle Introduction through Linear Regression\\ntion when the number of data points goes to inﬁnity; while the latter\\nis parametrized and is subject to optimization. F or this rea son, diver-\\ngence metrics between the two distributions play an importa nt role in\\nthe development of learning algorithms. W e will see in the re st of the\\nmonograph that other frequentist methods may involve a sing le distri-\\nbution rather than two, as discussed in Sec. 6.6, or an additional, so\\ncalled variational, distribution, as covered in Sec. 6.3 and Chapter 8.\\nIn contrast, Bayesian methods posit a single coherent distr ibution\\nover the data and the parameters, and frame the learning prob lem as\\none of inference of unobserved variables. As we will discuss in Chapter 8,\\nvariational Bayesian methods also introduce an additional variational\\ndistribution and are a building block for frequentist learn ing in the\\npresence of unobserved variables.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 55, 'page_label': '50', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='variational Bayesian methods also introduce an additional variational\\ndistribution and are a building block for frequentist learn ing in the\\npresence of unobserved variables.\\nThe running example in this chapter has been one of linear reg res-\\nsion for a Gaussian model. The next chapter provides the nece ssary\\ntools to construct and learn more general probabilistic mod els.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 56, 'page_label': '51', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3\\nProbabilistic Models for Learning\\nIn the previous chapter, we have introduced the frequentist , Bayesian,\\nand MDL learning frameworks. As we have seen, parametric pro babilis-\\ntic models play a key role for all three of them. The linear reg ression\\nexample considered in the previous chapter was limited to a s imple lin-\\near Gaussian model, which is insuﬃcient to capture the range of learn-\\ning problems that are encountered in practice. F or instance , scenarios\\nof interest may encompass discrete variables or non-negati ve quantities.\\nIn this chapter, we introduce a family of probabilistic mode ls, known as\\nthe exponential family , whose members are used as components in many\\nof the most common probabilistic models and learning algori thms. The\\ntreatment here will be leveraged in the rest of the monograph in order\\nto provide the necessary mathematical background. Through out this\\nchapter, we will speciﬁcally emphasize the common properti es of the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 56, 'page_label': '51', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to provide the necessary mathematical background. Through out this\\nchapter, we will speciﬁcally emphasize the common properti es of the\\nmodels in the exponential family , which will prove useful fo r deriving\\nlearning algorithms in the following chapters.\\n51'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 57, 'page_label': '52', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='52 Probabilistic Models for Learning\\n3.1 Preliminaries\\nW e start with a brief review of some deﬁnitions that will be us ed\\nthroughout the chapter and elsewhere in the monograph (see [ 28] for\\nmore details). Readers with a background in convex analysis and cal-\\nculus may just review the concept of suﬃcient statistic in th e last para-\\ngraph.\\nFirst, we deﬁne a convex set as a subset of RD , for some D, that\\ncontains all segments between any two points in the set. Geom etrically ,\\nconvex sets hence cannot have “indentations” . F unction f(x) is convex\\nif its domain is a convex set and if it satisﬁes the inequality f(λx+ (1 −\\nλ)y) ≤λf(x) + (1 −λ)f(y) for all x and y in its domain and for all\\n0 ≤λ≤1. Geometrically , this condition says that the function is “ ∪”-\\nshaped: the curve deﬁning the function cannot lie above the s egment\\nobtained by connecting any two points on the curve. A functio n is\\nstrictly convex if the inequality above is strict except for λ = 0 or'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 57, 'page_label': '52', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='obtained by connecting any two points on the curve. A functio n is\\nstrictly convex if the inequality above is strict except for λ = 0 or\\nλ = 1 when x ̸= y. A concave, or strictly concave, function is deﬁned\\nby reversing the inequality above – it is hence “ ∩”-shaped.\\nThe minimization of a convex (“ ∪”) function over a convex con-\\nstraint set or the maximization of a concave (“ ∩”) function over a\\nconvex constraint set are known as convex optimization problems . F or\\nthese problems, there exist powerful analytical and algori thmic tools\\nto obtain globally optimal solutions [ 28].\\nW e also introduce two useful concepts from calculus. The gradient\\nof a diﬀerentiable function f(x) with x= [ x1 ···xD ]T ∈RD is deﬁned\\nas the D×1 vector ∇f(x) = [ ∂f(x)/∂x1 ···∂f(x)/∂xD ]T containing\\nall partial derivatives. At any point x in the domain of the function,\\nthe gradient is a vector that points to the direction of local ly maximal\\nincrease of the function. The Hessian ∇2f(x) is the D×Dmatrix with'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 57, 'page_label': '52', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the gradient is a vector that points to the direction of local ly maximal\\nincrease of the function. The Hessian ∇2f(x) is the D×Dmatrix with\\n(i,j) element given by the second-order derivative ∂2 f(x)/∂xi ∂xj . It\\ncaptures the local curvature of the function.\\nFinally , we deﬁne the concept of suﬃcient statistic . Consider a rv\\nx ∼p(x|θ), whose distribution depends on some parameter θ. A func-\\ntion f(x) is a suﬃcient statistic 1 for the estimate of θ if the likelihood\\n1 A statistic is a function of the data.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 58, 'page_label': '53', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.2. The Exponential Family 53\\np(x|θ) of the parameters θdepends on xonly through the function f(x).\\nAs an example, for a rv x ∼N(0,σ2 ), the function f(x) = x2 can be\\neasily seen to be suﬃcient for the estimate of the variance σ2.\\n3.2 The Exponential Family\\nIn this section, we introduce the exponential family of para metric prob-\\nabilistic models. As it will be discussed, this family inclu des as special\\ncases most of the distributions typically assumed when solv ing machine\\nlearning problems. F or example, it includes Gaussian, Lapl ace, Gamma,\\nBeta and Dirichlet pdfs, as well as Bernoulli, Categorical, multinomial,\\nand Poisson pmfs. An extensive list can be found in [\\n156].\\n3.2.1 Basic Deﬁnitions\\nThe exponential family contains probabilistic models of th e form\\np(x|η) = 1\\nZ(η) exp\\n( K∑\\nk=1\\nηk uk (x)\\n)\\nm(x)\\n= 1\\nZ(η) exp\\n(\\nηT u(x)\\n)\\nm(x), (3.1)\\nwhere xis a discrete or continuous-valued vector; η= [ η1 ···ηK ]T is the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 58, 'page_label': '53', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x|η) = 1\\nZ(η) exp\\n( K∑\\nk=1\\nηk uk (x)\\n)\\nm(x)\\n= 1\\nZ(η) exp\\n(\\nηT u(x)\\n)\\nm(x), (3.1)\\nwhere xis a discrete or continuous-valued vector; η= [ η1 ···ηK ]T is the\\nvector of natural parameters ; u(x) = [ u1 (x) ··· uK (x)]T is the vector of\\nsuﬃcient statistics , with each suﬃcient statistic uk (x) being a function\\nof x; m(x) ≥0 is the base measure , which is a function of x that is\\nindependent of the natural parameter vector η; and Z(η) is the partition\\nfunction\\nZ(η) =\\n∫\\nexp\\n(\\nηT u(x)\\n)\\nm(x) d x (3.2)\\nfor continuous rvs and Z(η) = ∑\\nx exp\\n(\\nηT u(x)\\n)\\nm(x) for discrete rvs.\\nThe suﬃcient statistic vector u(x) can be seen to be a suﬃcient statistic\\nfor the estimation of the natural parameter vector η given x.\\nThe partition function normalizes the distribution so that it inte-\\ngrates, or sums, to one. It is also often useful to use the unnormalized\\ndistribution\\n˜p(x|η) = exp\\n(\\nηT u(x)\\n)\\nm(x), (3.3)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 59, 'page_label': '54', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='54 Probabilistic Models for Learning\\nsince the latter is generally easier to evaluate.\\nIn short, distributions belonging to the exponential famil y are such\\nthat the logarithm of the unnormalized distribution ˜ p(x|η), which is\\nalso known as the energy function , is linear 2 in the natural parameters,\\ni.e.,\\nln ˜p(x|η) = ηT u(x) + ln m(x) . (3.4)\\nF or this reason, models of the form ( 3.1) are also referred to as log-\\nlinear.3 Including the partition function, the LL of the natural para m-\\neters can be written as\\nln p(x|η) = ηT u(x) −A(η) + ln m(x), (3.5)\\nwhere\\nA(η) = ln Z(η) (3.6)\\nis the log-partition function.\\nAs per ( 3.1), a probabilistic model belonging to the exponential\\nfamily is identiﬁed by the set of suﬃcient statistics {uk (x)}K\\nk=1 , whose\\norder is irrelevant, and by the measure m(x). A speciﬁc hypothesis\\nwithin the model is selected by determining the natural para meter vec-\\ntor η. The set of feasible values for the natural parameters conta ins all,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 59, 'page_label': '54', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='within the model is selected by determining the natural para meter vec-\\ntor η. The set of feasible values for the natural parameters conta ins all,\\nand only , the vectors η for which the unnormalized distribution ˜ p(x|η)\\ncan be normalized, that is, for which the inequality A(η) < ∞holds.\\nW e will see below that this set is convex.\\nExample 3.1. (Gaussian pdf) As a ﬁrst example, consider the Gaus-\\nsian pdf\\nN(x|ν,σ2 ) = 1\\n(2πσ2 )1/2 exp\\n(\\n−x2\\n2σ2 + ν\\nσ2 x− ν2\\n2σ\\n2\\n)\\n.\\nThis can be written in the form ( 3.1) upon identiﬁcation of the base\\nmeasure m(x) = 1 and of the suﬃcient statistics u(x) = [ x x2]. Note\\nthat, in order to do this, we need to map the parameters ( ν,σ2 ) to the\\n2 Or, more precisely , aﬃne given the presence of an additive co nstant.\\n3 There exists a more general version of the exponential famil y in which the\\nnatural parameters are non-linear functions of the paramet ers that identify the dis-\\ntribution.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 60, 'page_label': '55', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.2. The Exponential Family 55\\nnatural parameters via the relationship η = [ ν/σ2 −1/(2σ2 ) ]. As a\\nresult, while the parameters ( ν,σ2 ) take all possible allowed values\\nin R ×R+, the natural parameter vector η takes values in the set\\nR ×R−. Every value η in this set corresponds to a valid pdf within\\nthe hypothesis class of N(x|ν,σ2 ) models. Finally , we can compute the\\nlog-partition function as\\nA(η) = ν2\\n2σ2 + 1\\n2 ln(2πσ2 ) = −η2\\n1\\n4η2\\n−1\\n2 ln\\n(\\n−\\n( 2η2\\n2π\\n))\\n. (3.7)\\nIn order to ensure identiﬁability of the natural parameters , the suﬃ-\\ncient statistics {uk (x)}K\\nk=1 need to be linearly independent. This means\\nthat no suﬃcient statistic uk (x) should be computable, for all x, as\\na linear combination of other suﬃcient statistics uk′ (x) with k′ ̸= k.\\nF or example, this is the case for the vector u(x) = [ x x2 ] of suﬃcient\\nstatistics for the Gaussian distribution. This condition i s referred to as\\nminimal representation [\\n151]. Unless stated otherwise, we will assume'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 60, 'page_label': '55', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='statistics for the Gaussian distribution. This condition i s referred to as\\nminimal representation [\\n151]. Unless stated otherwise, we will assume\\nin the following that the exponential family under study is m inimal.\\nF urthermore, we will assume the technical condition that th e set of fea-\\nsible values for η is also open (that is, it excludes its boundary), which\\nyields a regular exponential family .\\n3.2.2 Natural Parameters, Mean Parameters and Convexity\\nAs suggested by the example above, once the suﬃcient statist ics and\\nthe base measure are ﬁxed, a speciﬁc hypothesis – pdf or pmf – c an be\\nidentiﬁed by either specifying the vector ηof natural parameters or the\\nvector µ of mean parameters. The latter is deﬁned as the expectation\\nof the vector of suﬃcient statistics\\nµ= E x∼p(x|η)[u(x)]. (3.8)\\nF or the preceding example, we have the mean parameter vector µ =\\n[E[x] = ν, E[x2 ] = σ2 + ν2]T . W e can therefore use the notation p(x|µ)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 60, 'page_label': '55', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='µ= E x∼p(x|η)[u(x)]. (3.8)\\nF or the preceding example, we have the mean parameter vector µ =\\n[E[x] = ν, E[x2 ] = σ2 + ν2]T . W e can therefore use the notation p(x|µ)\\nas well as p(x|η) to describe a model in the exponential family . As we\\nwill see below, the availability of these two parametrizati ons implies\\nthat learning can be done on either sets of variables.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 61, 'page_label': '56', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='56 Probabilistic Models for Learning\\nA key property of the exponential family is that the mapping b e-\\ntween natural parameters and mean parameters is given by the gradi-\\nent of the log-partition function. Speciﬁcally , it can be ve riﬁed that the\\npartial derivative of the log-partition function equals th e mean of the\\ncorresponding suﬃcient statistic\\n∂A(η)\\n∂ηk\\n= E x∼p(x|η) [uk (x)] = µk , (3.9)\\nor, in vector form,\\n∇η A(η) = E x∼p(x|η) [u(x)] = µ. (3.10)\\nAlthough we will not be making use of this result here, the Hes sian\\n∇2\\nη A(η) of the log-partition function can be similarly seen to equa l the\\ncovariance matrix of the suﬃcient statistics\\n4 . It is also equal to the\\nFisher information matrix for the natural parameters [ 45].\\nThe log-partition function A(η) in ( 3.6) is strictly convex in η, as\\nit follows from the fact that it is a log-sum-exp function com posed\\nwith an aﬃne function [ 28]. This property has the following important'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 61, 'page_label': '56', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='it follows from the fact that it is a log-sum-exp function com posed\\nwith an aﬃne function [ 28]. This property has the following important\\nconsequences. First, the set of feasible values for the natu ral parameters\\nis a convex set [ 28]. Note that this is generally not the case for the\\ncorresponding set of feasible values for the mean parameter s. Second,\\nthe mapping ( 3.10) between natural parameters ηand mean parameters\\nµ is invertible (see, e.g., [ 10])5 .\\nThird, the LL function ln p(x|η) in ( 3.5) is a concave function of η.\\nAs further discussed below, the ML problem hence amounts to m axi-\\nmization of a convex optimization problem.\\n3.2.3 Bernoulli Model\\nDue to its importance for binary classiﬁcation problems, we detail here\\nthe Bernoulli model. W e also introduce the important logist ic sigmoid\\nfunction.\\n4 More generally , the log-partition function A(η) is the cumulant function for rv\\nx.\\n5 The inverse mapping between mean parameters and natural par ameters is given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 61, 'page_label': '56', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function.\\n4 More generally , the log-partition function A(η) is the cumulant function for rv\\nx.\\n5 The inverse mapping between mean parameters and natural par ameters is given\\nby the gradient ∇µ A∗ (µ) of the convex conjugate function A∗(µ) = sup η ηT µ − A(η),\\nwhere the maximization is over the feasible set of natural pa rameters.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 62, 'page_label': '57', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.2. The Exponential Family 57\\nThe Bernoulli distribution for a binary rv x ∈{0,1}is given as\\nBern(x|µ) = µx (1 −µ)1−x , (3.11)\\nwith µ = E x∼Bern(x|µ) [x] = Pr[x = 1]. Since we can write the LL\\nfunction as\\nln (Bern( x|µ)) = ln\\n( µ\\n1 −µ\\n)\\nx+ ln (1 −µ) , (3.12)\\nthe suﬃcient statistic deﬁning the Bernoulli model is u(x) = x and\\nthe measure function is m(x) = 1. The mapping between the natural\\nparameter η and the mean parameter µ is given as\\nη= ln\\n( µ\\n1 −µ\\n)\\n, (3.13)\\nthat is, the natural parameter is the LLR η= ln(Bern(1 |µ)/Bern(0|µ)).\\nF unction ( 3.13) is also known as the logit function . The corresponding\\nset of feasible values is hence R.\\nThe inverse mapping is instead given by the logistic sigmoid func-\\ntion\\nµ= σ(η) = 1\\n1 + e−η . (3.14)\\nThe sigmoid function converts a real number into the interva l [0 ,1]\\nvia an S-shape that associates values less than 0.5 to negati ve values\\nof the argument and larger values to positive numbers. Final ly , the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 62, 'page_label': '57', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='via an S-shape that associates values less than 0.5 to negati ve values\\nof the argument and larger values to positive numbers. Final ly , the\\nlog-partition function is given by the convex function of th e natural\\nparameters\\nA(η) = −ln(1 −µ) = ln(1 + eη ). (3.15)\\nNote that the relationship ( 3.10) is easily veriﬁed.\\n3.2.4 Categorical or Multinoulli Model\\nF or its role in multi-class classiﬁcation, we introduce her e in some de-\\ntail the Categorical or Multinoulli distribution, along wi th the one-hot\\nencoding of categorical variables and the soft-max functio n.\\nThe Categorical model applies to discrete variables taking C values,\\nhere labeled without loss of generality as {0,1,...,C −1}. Note that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 63, 'page_label': '58', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='58 Probabilistic Models for Learning\\nsetting C = 2 recovers the Bernoulli distribution. Pmfs in this model\\nare given as\\nCat(x|µ) =\\nC −1∏\\nk=1\\nµ1(x=k)\\nk ×µ\\n1−\\n∑ C−1\\nk=1 1(x=k)\\n0 , (3.16)\\nwhere we have deﬁned µk = Pr [x = k] for k = 1 ,...,C −1 and µ0 =\\n1 −∑ C −1\\nk=1 µk = Pr [x = 0]. The LL function is given as\\nln (Cat( x|µ)) =\\nC −1∑\\nk=1\\n1 ( x= k) ln µk\\nµ0\\n+lnµ0. (3.17)\\nThis demonstrates that the categorical model is in the expon ential fam-\\nily , with suﬃcient statistics vector u(x) = [1( x= 1) ··· 1(x= C−1)]T\\nand measure function m(x) = 1. F urthermore, the mean parameters\\nµ = [ µ1 ···µC −1]T are related to the natural parameter vector η =\\n[η1 ···ηC −1 ]T by the mapping\\nηk = ln\\n(\\nµk\\n1 −∑ C −1\\nj=1 µj\\n)\\n, (3.18)\\nwhich again takes the form of an LLR. The inverse mapping is gi ven\\nby\\nµ=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 1\\n1+\\n∑ C−1\\nk=1 eη k\\n.\\n.\\n.\\neη C−1\\n1+\\n∑ C−1\\nk=1 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n. (3.19)\\nThe parametrization given here is minimal, since the suﬃcie nt statis-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 63, 'page_label': '58', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='by\\nµ=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 1\\n1+\\n∑ C−1\\nk=1 eη k\\n.\\n.\\n.\\neη C−1\\n1+\\n∑ C−1\\nk=1 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n. (3.19)\\nThe parametrization given here is minimal, since the suﬃcie nt statis-\\ntics u(x) are linearly independent. An overcomplete representatio n would\\ninstead include in the vector of suﬃcient statistics also th e function\\n1(x= 0). In this case, the resulting vector of suﬃcient statisti cs\\nu(x) =\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\n1(x= 0)\\n.\\n.\\n.\\n1(x= C−1)\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb (3.20)\\nis known as one-hot encoding of the categorical variable, since only\\none entry equals 1 while the others are zero. F urthermore, wi th this'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 64, 'page_label': '59', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.3. Frequentist Learning 59\\nencoding, the mapping between the natural parameters and th e mean\\nparameters µ= [ µ0 ···µC −1]T can be expressed in terms of the softmax\\nfunction\\nµ= softmax( η)=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 0\\n∑ C−1\\nk=0 eη k\\n.\\n.\\n.\\neη C−1\\n∑ C−1\\nk=0 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n. (3.21)\\nThe softmax function softmax( η) converts a vector of “scores” η into\\na probability vector. F urthermore, the function has the pro perty that,\\nas c grows to inﬁnity , softmax( cη) tends to a vector with all zero en-\\ntries except for the position corresponding to the maximum v alue ηk\\n(assuming that it is unique). This justiﬁes its name.\\n3.3 Frequentist Learning\\nIn this section, we provide general results concerning ML an d MAP\\nlearning when the probabilistic model belongs to the expone ntial family .\\nAs seen in the previous chapter, with ML and MAP , one postulat es that\\nthe N available data points xD = {x1 ,...,x N }are i.i.d. realizations\\nfrom the probabilistic model p(x|η) as\\nxn ∼\\ni.i.d.\\np(x|η), n= 1 ,...,N. (3.22)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 64, 'page_label': '59', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the N available data points xD = {x1 ,...,x N }are i.i.d. realizations\\nfrom the probabilistic model p(x|η) as\\nxn ∼\\ni.i.d.\\np(x|η), n= 1 ,...,N. (3.22)\\nThis data is used to estimate the natural parameters η, or the corre-\\nsponding mean parameters µ.\\nUsing (\\n3.5), the LL of the natural parameter vector given the ob-\\nservation xD can be written as\\nlnp(xD |η) =\\nN∑\\nn=1\\nlnp(xn|η)\\n= −NA(η) + ηT\\nN∑\\nn=1\\nu(xn) +\\nN∑\\nn=1\\nlnm(xn ). (3.23)\\nTherefore, neglecting terms independent of η, we can write\\nlnp(xD |η) = −NA(η) + ηT u(xD ), (3.24)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 65, 'page_label': '60', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='60 Probabilistic Models for Learning\\nwhere we have deﬁned the cumulative suﬃcient statistics\\nuk (xD ) =\\nN∑\\nn=1\\nuk (xn), k= 1 ,...,K, (3.25)\\nand the vector u(xD ) = [ u1 (xD ) ··· uK (xD )]T .\\nA ﬁrst important observation is that the LL function only dep ends\\non the K statistics uk (xD ), k = 1 ,...,K . Therefore, the vector u(xD )\\nis a suﬃcient statistic for the estimate of η given the observation xD .\\nImportantly , vector u(xD ) is of size K, and hence it does not grow with\\nthe size N of the data set. In fact, the exponential family turns out to\\nbe unique in this respect: Informally , among all distributi ons whose\\nsupport does not depend on the parameters, only distributio ns in the\\nexponential family have suﬃcient statistics whose number d oes not\\ngrow with the number N of observations (Koopman-Pitman-Darmois\\ntheorem) [ 7].\\nGradient of the LL function. A key result that proves very\\nuseful in deriving learning algorithms is the expression of the gradient'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 65, 'page_label': '60', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='theorem) [ 7].\\nGradient of the LL function. A key result that proves very\\nuseful in deriving learning algorithms is the expression of the gradient\\nof the LL ( 3.24) with respect to the natural parameters. T o start, the\\npartial derivative with respect to ηk can be written as\\n∂lnp(xD |η)\\n∂ηk\\n= uk (xD ) −N∂A(η)\\n∂ηk\\n. (3.26)\\nUsing ( 3.9) and ( 3.10), this implies that we have\\n1\\nN\\n∂lnp(xD |η)\\n∂ηk\\n= 1\\nNuk (xD ) −µk , (3.27)\\nand for the gradient\\n1\\nN∇η lnp(xD |η) = 1\\nNu(xD ) −µ\\n= 1\\nN\\nN∑\\nn=1\\nu(xn ) −µ. (3.28)\\nThe gradient ( 3.28) is hence given by the diﬀerence between the empir-\\nical average N−1 ∑ N\\nn=1 u(xn) of the suﬃcient statistics given the data\\nxD and the ensemble average µ.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 66, 'page_label': '61', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.3. Frequentist Learning 61\\nThe following observation is instrumental in interpreting algorithms\\nbased on gradient ascent or descent for exponential familie s. The nor-\\nmalized gradient of the LL ( 3.28) has two components: ( i ) the “posi-\\ntive” component u(xD )/N points in a direction of the natural param-\\neter space that maximizes the unnormalized distribution ln ˜p(xD |η) =\\nηT u(xD ) + ∑ N\\nn=1 ln m(xn), hence maximizing the “ﬁtness” of the model\\nto the observed data xD ; while ( ii ) the “negative” component −µ =\\n−∇η A(η) points in a direction that minimizes the partition functio n,\\nthus minimizing the “ﬁtness” of the model to the unobserved d ata. The\\ntension between these two components is resolved when the em pirical\\nexpectation of the suﬃcient statistics equals that under th e model, as\\ndiscussed below.\\nML Learning. Due to concavity of the LL function, or equivalently\\nconvexity of the NLL, and assuming the regularity of the dist ribution,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 66, 'page_label': '61', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='discussed below.\\nML Learning. Due to concavity of the LL function, or equivalently\\nconvexity of the NLL, and assuming the regularity of the dist ribution,\\nthe ML estimate ηM L is obtained by imposing the optimality condition\\n∇η lnp(xD |η) = 0 , (3.29)\\nwhich gives\\nµM L = 1\\nN\\nN∑\\nn=1\\nu(xn). (3.30)\\nIn words, the ML estimate of the mean parameters is obtained b y\\nmatching the ensemble averages obtained under the model to t he em-\\npirical averages observed from the data. This procedure is k nown as\\nmoment matching. Note that, from ( 3.30), if needed, we can also com-\\npute the ML estimate ηM L using the mapping between the two sets of\\nparameters.\\nF rom ( 3.30), we can infer that the ML estimate is consistent: if\\nthe data is generated from a distribution p(x|η∗ ) within the assumed\\nfamily , the ML estimate will tend to it with probability one a s N grows\\nto inﬁnity by the strong law of large numbers [ 86]. However, for ﬁnite\\nN, ML may suﬀer from overﬁtting, as we will see next.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 66, 'page_label': '61', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='family , the ML estimate will tend to it with probability one a s N grows\\nto inﬁnity by the strong law of large numbers [ 86]. However, for ﬁnite\\nN, ML may suﬀer from overﬁtting, as we will see next.\\nExample 3.2. (Gaussian pdf). The ML estimates of the parameters'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 67, 'page_label': '62', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='62 Probabilistic Models for Learning\\n(µ, σ2 ) for the Gaussian model are given as\\nµM L = 1\\nN\\nN∑\\nn=1\\nxn (3.31)\\nσ2\\nM L = 1\\nN\\nN∑\\nn=1\\nx2\\nn −µ2\\nM L . (3.32)\\nF or the Bernoulli model, we have the ML estimate of the mean pa ram-\\neter µ= Pr [x = 1]\\nµM L = 1\\nN\\nN∑\\nn=1\\nxn = N[1]\\nN , (3.33)\\nwhere N[k] measures the number of observations equal to k, i.e.,\\nN[k] = |{n: xn = k}|.\\nNote that N[1] has a binomial distribution. F or the Categorical model,\\nwe can similarly write the ML estimate of the mean parameters µk =\\nPr [x = k] as\\nµk,M L = 1\\nN\\nN∑\\nn=1\\n1(xn = k) = N[k]\\nN . (3.34)\\nThe vector [ N[0],...,N [C −1]]T has a multinomial distribution.\\nT o illustrate the problem of overﬁtting, consider the categ orical\\nmodel. As per ( 3.34), if no instance of the data equal to some value\\nk is observed, i.e., if N[k] = 0, ML assigns a zero probability to the\\nevent x = k. In mathematical terms, if N[k] = 0 , the ML estimate of\\nthe probability of the event x = k is zero, that is, µk,M L = 0. So, ML'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 67, 'page_label': '62', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='event x = k. In mathematical terms, if N[k] = 0 , the ML estimate of\\nthe probability of the event x = k is zero, that is, µk,M L = 0. So, ML\\ngives zero probability to any previously unobserved event. The problem,\\nwhich is an instance of overﬁtting, is known as the black swan paradox\\nor zero-count problem : F or the European explorers of the 17th century\\n– or at least for those of them adhering to the ML principle – th e black\\nswans in the Americas could not exist! [ 104]\\nMAP Learning. A MAP solution can be in principle derived by\\nincluding in the optimality condition ( 3.29) the gradient of the prior\\ndistribution. W e will instead solve the MAP problem in the ne xt section\\nby computing the mode of the posterior distribution of the pa rameters.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 68, 'page_label': '63', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4. Bayesian Learning 63\\n3.4 Bayesian Learning\\nAs we discussed in the previous chapter, the Bayesian viewpo int is to\\ntreat all variables as jointly distributed, including the m odel parameters\\nµ and the new, unobserved value x . The joint distribution is given as\\np(xD ,µ,x |α) = p(µ|α)\\ued19 \\ued18\\ued17 \\ued1a\\na priori distribution\\np(xD |µ)\\ued19 \\ued18\\ued17 \\ued1a\\nlikelihood\\np(x|µ)\\ued19 \\ued18\\ued17 \\ued1a\\ndistribution of new data\\n, (3.35)\\nwhere α represents the vector of hyperparameters deﬁning the prior\\ndistribution. The problem of inferring the unobserved valu e x is solved\\nby evaluating the predictive distribution\\np(x|xD ,α) =\\n∫\\np(µ|xD ,α)p(x|µ)dµ. (3.36)\\nThis distribution accounts for the weighted average of the c ontributions\\nfrom all values of the parameter vector µaccording to the posterior dis-\\ntribution p(µ|xD ,α).Note that, for clarity , we left indicated the depen-\\ndence on the hyperparameters α. Using Bayes’ theorem, the posterior\\nof the parameter vector can be written as\\np(µ|xD ,α) = p(µ|α)p(xD |µ)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 68, 'page_label': '63', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='dence on the hyperparameters α. Using Bayes’ theorem, the posterior\\nof the parameter vector can be written as\\np(µ|xD ,α) = p(µ|α)p(xD |µ)\\np(xD |α) ∝p(µ|α)p(xD |µ). (3.37)\\nAs discussed in Chapter 2, this relationship highlights the dependence\\nof the posterior on both the prior distribution and the likel ihood p(xD |µ).\\nW e also note the the denominator in ( 3.37) is the marginal likelihood.\\nPrior distribution. The ﬁrst issue we should address is the choice\\nof the prior distribution. There are two main approaches: 1) Conjugate\\nprior : choose the prior p(µ|α), so that posterior p(µ|xD ,α) has the same\\ndistribution as the prior p(µ|α) but with generally diﬀerent parameters;\\n2) Non-informative prior : choose the prior that is the least informative\\ngiven the observed data [ 23, pp. 117-120]. Here, we will work with\\nconjugate priors, which are more commonly adopted in applic ations. In\\nfact, a key advantage of models in the exponential family is t hat they'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 68, 'page_label': '63', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='conjugate priors, which are more commonly adopted in applic ations. In\\nfact, a key advantage of models in the exponential family is t hat they\\nall admit conjugate priors, and the conjugate priors are als o members\\nof the exponential family .\\nRather than providing a general discussion, which may be of l imited\\npractical use, we proceed by means of representative exampl es. A table\\nof models with corresponding prior distributions can be fou nd in [ 155].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 69, 'page_label': '64', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='64 Probabilistic Models for Learning\\n3.4.1 Beta-Bernoulli Model\\nThe Beta-Bernoulli model is suitable to study binary data. C onditioned\\non the parameter µ = Pr [x = 1], the pmf of the N i.i.d. available\\nobservations xD with xn ∈{0,1}is given as\\np(xD |µ) =\\nN∏\\nn=1\\nBern(xn|µ) = µN [1](1 −µ)N [0]. (3.38)\\nAs seen, a conjugate prior should be such that the posterior ( 3.37) has\\nthe same distribution of the prior but with diﬀerent paramet ers. F or\\nthe likelihood ( 3.38), the conjugate prior is the Beta distribution , which\\nis deﬁned as\\np(µ|a,b) = Beta( µ|a,b) ∝µa−1 (1 −µ)b−1 , (3.39)\\nwhere a and b are hyperparameters and the normalization constant is\\nnot made explicit in order to simplify the notation. It is wor th empha-\\nsizing that ( 3.39) is a probability distribution on a probability µ. Plots\\nof the beta pdf for diﬀerent values of a,b ≥1 can be found in Fig. 3.1.\\n0 0.2 0.4 0.6 0.8 1\\n0\\n1\\n2\\n3\\n4\\n5\\nFigure 3.1: Beta distribution with diﬀerent values of the hyperparamet ers a, b ≥ 1.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 70, 'page_label': '65', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4. Bayesian Learning 65\\nA verage and mode of the Beta pdf can be evaluated as\\nEµ∼Beta(µ|a,b)[µ] = a\\na+ b (3.40)\\nmodeµ ∼Beta(µ|a,b) [µ] = a−1\\na+ b−2 , (3.41)\\nwhere the mode expression is only valid when a,b> 1 (when this condi-\\ntion is not met, the distribution is multi-modal, see Fig. 3.1). The mean\\n(3.39) suggests that the hyperparameters aand bcan be interpreted as\\nthe number of observations that are expected to equal “1” and “0”, re-\\nspectively , out of a total number of a+ bmeasurements, based on prior\\ninformation alone. More ﬁttingly , as we shall see next, we ca n think of\\nthese a priori observations as “virtual” measurements, als o known as\\npseudo-counts, that should be used alongside the actual measurements\\nxD during learning.\\nW e can now compute the posterior distribution of the paramet er\\nvector using ( 3.37) as\\np(µ|xD ,a,b) ∝Beta ( µ|a+ N[1],b + N[0] )\\n= µN [1]+a−1(1 −µ)N [0]+b−1 . (3.42)\\nThis conﬁrms that the posterior distribution is indeed a Bet a pdf, as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 70, 'page_label': '65', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='vector using ( 3.37) as\\np(µ|xD ,a,b) ∝Beta ( µ|a+ N[1],b + N[0] )\\n= µN [1]+a−1(1 −µ)N [0]+b−1 . (3.42)\\nThis conﬁrms that the posterior distribution is indeed a Bet a pdf, as\\ndictated by the choice of a Beta conjugate prior. F urthermor e, the\\nposterior Beta distribution has parameters a+ N[1] and b+ N[0]. This\\nis consistent with the interpretation given above: the tota l number of\\neﬀective observations equal to “1” and “0” are a+ N[1] and b+ N[0],\\nrespectively . As anticipated, the MAP estimate of µ can be obtained\\nby taking the mode of the posterior ( 3.37), yielding\\nµM AP = a+ N[1] −1\\na+ b+ N −2 . (3.43)\\nAs we discussed in the previous chapter, we have the limit µM AP →\\nµM L for N →∞.\\nBack to the Bayesian viewpoint, the predictive distributio n ( 3.36)\\nis given as\\np(x= 1 |xD ,a,b) =\\n∫\\np(µ|xD ,a,b)p(x= 1 |µ)dµ\\n= E µ∼p(µ|xD ,a,b)[µ] = N[1] + a\\nN + a+ b (3.44)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 71, 'page_label': '66', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='66 Probabilistic Models for Learning\\nwhere we have used the expression ( 3.40) for the mean of a Beta rv. W e\\nobserve that, if N is small, the predictive probability is approximately\\nequal to the mean of the prior, i.e., p(x= 1 |xD ,a,b) ≈a/(a+ b); while,\\nif N is large, as we have seen in the previous chapter, the predict ive\\nprobability tends to the ML solution, i.e., p(x= 1 |xD ,a,b) ≈N[1]/N.\\nAs an example of a non-conjugate prior, one could choose the d istri-\\nbution of the natural parameter η, or equivalently of the logit function\\n(3.13) of µ, as Gaussian [ 92].\\nThe following example illustrates the potential advantage s, already\\ndiscussed in Chapter 2, of the Bayesian approach in avoiding overﬁtting.\\nNote that MAP would also yield similar results in this exampl e.\\nExample 3.3. (Predicting online reviews) On an online shopping\\nplatform, there are two sellers oﬀering a product at the same price. The\\nﬁrst has 30 positive reviews and 0 negative reviews, while th e second'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 71, 'page_label': '66', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='platform, there are two sellers oﬀering a product at the same price. The\\nﬁrst has 30 positive reviews and 0 negative reviews, while th e second\\nhas 90 positive reviews and 10 negative reviews. Which one to choose?\\nT o tackle this problem, we can learn a Beta-Bernoulli model t o predict\\nwhether the next review will be positive or not. W e can comput e the\\nprobability that the next review is positive via the predict ive distribu-\\ntion ( 3.44). The result is shown in Fig. 3.2: While the ﬁrst seller has\\na 100% positive rate, as opposed to the 90% rate of the ﬁrst sel ler, we\\nprefer to choose the ﬁrst seller unless the prior distributi on is weak,\\nwhich translates here into the condition a= b≲ 3.\\n3.4.2 Dirichlet-Categorical Model\\nThe Dirichlet-Categorical model generalizes the Beta-Ber noulli model\\nto the case of discrete observations that can take any number C of\\nvalues. The treatment follows along the same lines as for the Beta-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 71, 'page_label': '66', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to the case of discrete observations that can take any number C of\\nvalues. The treatment follows along the same lines as for the Beta-\\nBernoulli model, and hence we provide only a brief discussio n. The\\nlikelihood function can be written as\\np(xD |µ) =\\nC −1∏\\nk=0\\nµN [k]\\nk . (3.45)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 72, 'page_label': '67', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.4. Bayesian Learning 67\\n2 4 6 8 10\\n0.75\\n0.8\\n0.85\\n0.9\\n0.95\\n1\\nfirst seller\\nsecond seller\\nFigure 3.2: Probability that the next review is positive using the predi ctive distri-\\nbution ( 3.44) for Example 3.3.\\nThe conjugate prior is the Dirichlet distribution, a genera lization of the\\nBeta distribution:\\np(µ|α) = Dir( µ|α) ∝\\nC −1∏\\nk=0\\nµαk −1\\nk , (3.46)\\nwhere αk is the hyperparameter representing the number of “prior”\\nobservations equal to k. Note that the Dirichlet distribution is a joint\\npdf for the entries of the mean vector µ. Mean and mode vectors for\\nthe Dirichlet distribution are given as\\nEµ∼Dir(µ|α) [µ] = α\\n∑ C −1\\nj=0 αj\\n(3.47)\\nmodeµ ∼Dir(µ|α)[µ] = α−1\\n∑ C −1\\nj=0 αj −C. (3.48)\\nThe posterior of the parameters is the Dirichlet distributi on\\np(µ|xD ,α) ∝\\nC −1∏\\nk=0\\nµN [k]+αk −1\\nk = Dir( µ|α+ N), (3.49)\\nin which we can again interpret αk + N[k] as the eﬀective number of\\nobservations equal to k. F rom this distribution, we can obtain the MAP'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 73, 'page_label': '68', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='68 Probabilistic Models for Learning\\nestimate as the mode. Finally , the Bayesian predictive dist ribution is\\np(x= k|xD ,α) = N[k] + αk\\nN + ∑ C −1\\nj=0 αj\\n. (3.50)\\nOne can check that the behavior in the two regimes of small and large\\nN is consistent with the discussion on the Beta-Bernoulli mod el.\\n3.4.3 Gaussian-Gaussian Model\\nAs a last example, we consider continuous observations that are as-\\nsumed to have a Gaussian distribution N(µ,σ2 ) with unknown mean\\nµ but known variance σ2. The likelihood function is hence p(xD |µ) =∏ N\\nn=1 N(xn|µ,σ2 ). The conjugate prior is also Gaussian, namely p(µ|µ0 ,σ2\\n0 ) =\\nN(µ|µ0,σ2\\n0 ),with hyperparameters ( µ0,σ2\\n0 ). The posterior p(µ|xD ,µ0,σ2\\n0 ) =\\nN(µ|µN ,σ2\\nN ) is hence Gaussian, with mean and variance satisfying\\nµN = σ2 /N\\nσ2\\n0 + σ2 /Nµ0 + σ2\\n0\\nσ2\\n0 + σ2 /NµM L (3.51)\\n1\\nσ2\\nN\\n= 1\\nσ2\\n0\\n+ N\\nσ2 , (3.52)\\nwhere we recall that the ML estimate is µM L = ∑ N\\nn=1 xn/N.Note that,\\nsince mean and mode are equal for the Gaussian distribution, the mean'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 73, 'page_label': '68', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='0\\nσ2\\n0 + σ2 /NµM L (3.51)\\n1\\nσ2\\nN\\n= 1\\nσ2\\n0\\n+ N\\nσ2 , (3.52)\\nwhere we recall that the ML estimate is µM L = ∑ N\\nn=1 xn/N.Note that,\\nsince mean and mode are equal for the Gaussian distribution, the mean\\nµN is also the MAP estimate µM AP of µ. Finally , the predictive distribu-\\ntion is also Gaussian and given as p(x|xD ,µ0 ,σ2\\n0 ) = N(x|µN ,σ2 + σ2\\nN ).\\nOnce again, as N grows large, the predictive distribution tends to that\\nreturned by the ML approach, namely N(x|µM L ,σ2 ).\\nFig.\\n3.3 illustrates the relationship among ML, MAP and Bayesian\\nsolutions for the Gaussian-Gaussian model. In all the panel s, the dotted\\nline represents the prior distribution, which is character ized by the pa-\\nrameters ( µ0 = 1, σ2\\n0 = 3), and the dashed line is the true distribution\\nof the data, which is assumed to be Gaussian with parameters ( µ= 0 ,\\nσ2 = 1), hence belonging to the assumed model. Each subﬁgure plo ts\\na realization of N observations (circles), along with the ML solution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 73, 'page_label': '68', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='σ2 = 1), hence belonging to the assumed model. Each subﬁgure plo ts\\na realization of N observations (circles), along with the ML solution\\n(diamond) and the MAP estimate (star). The solid lines repre sent the\\nBayesian predictive distribution.\\nAs N increases, we observe the following, already discussed, ph e-\\nnomena: ( i ) the ML estimate µM L consistently estimates the true value'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 74, 'page_label': '69', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.5. Supervised Learning via Generalized Linear Models (GL M) 69\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\n-5 0 5\\n0\\n0.2\\n0.4pdf\\nN =\\nN =\\nN =\\nN =\\n1\\n10\\n100\\n5\\nFigure 3.3: Gaussian-Gaussian model: prior distribution N (x|µ0 = 1, σ2\\n0 = 3) (dot-\\nted), true distribution N (x|µ = 0 ,σ2 = 1) (dashed), N observations (circles), ML\\nsolution (diamond), the MAP estimate (star), and Bayesian p redictive distribution\\n(solid line).\\nµ = 0; ( ii ) the MAP estimate µM AP tends to the ML estimate µM L ;\\nand ( iii ) the Bayesian predictive distribution tends to the ML predi c-\\ntive distribution, which in turn coincides with the true dis tribution due\\nto ( i ).\\n3.5 Supervised Learning via Generalized Linear Models (GLM)\\nDistributions in the exponential family are not directly su itable to serve\\nas discriminative probabilistic models to be used in superv ised learning\\ntasks. In this section, we introduce Generalized Linear Mod els (GLMs),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 74, 'page_label': '69', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as discriminative probabilistic models to be used in superv ised learning\\ntasks. In this section, we introduce Generalized Linear Mod els (GLMs),\\nwhich are popular probabilistic discriminative models tha t build on\\nmembers of the exponential family .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 75, 'page_label': '70', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='70 Probabilistic Models for Learning\\nT o elaborate, let us denote as exponential( ·|η) a probabilistic model\\nin the exponential family , that is, a model of the form ( 3.1) with natural\\nparameters η. W e also write exponential( ·|µ) for a probabilistic model\\nin the exponential family with mean parameters µ.\\nUsing the notation adopted in the previous chapter, in its mo st\\ncommon form, a GLM deﬁnes the probability of a target variabl e t as\\np(t|x,W) = exponential( t|η= Wx), (3.53)\\nwhere we recall that xis the vector of explanatory variables, and W here\\ndenotes a matrix of learnable weights of suitable dimension s. According\\nto ( 3.53), GLMs posit that the response variable t has a conditional\\ndistribution from the exponential family , with natural par ameter vector\\nη = Wx given by a linear function of the given explanatory variable s\\nx with weights W. More generally , we may have the parametrization\\np(t|x,W) = exponential( t|η= Wφ(x)) (3.54)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 75, 'page_label': '70', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='η = Wx given by a linear function of the given explanatory variable s\\nx with weights W. More generally , we may have the parametrization\\np(t|x,W) = exponential( t|η= Wφ(x)) (3.54)\\nfor some feature vector φ(·) obtained as a function of the input variables\\nx (see next chapter).\\nWhile being the most common, the deﬁnition ( 3.54) is still not the\\nmost general for GLMs. More broadly , GLMs can be interpreted as a\\ngeneralization of the linear model considered in the previo us chapter,\\nwhereby the mean parameters are deﬁned as a linear function o f a\\nfeature vector. This viewpoint, described next, may also pr ovide a more\\nintuitive understanding of the modelling assumptions made by GLMs.\\nRecall that, in the recurring example of Chapter 2, the targe t vari-\\nable was modelled as Gaussian distributed with mean given by a linear\\nfunction of the covariates x. Extending the example, GLMs posit the\\nconditional distribution\\np(t|x,W) = exponential( t|µ= g(Wφ(x))), (3.55)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 75, 'page_label': '70', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function of the covariates x. Extending the example, GLMs posit the\\nconditional distribution\\np(t|x,W) = exponential( t|µ= g(Wφ(x))), (3.55)\\nwhere the mean parameter vector is parametrized as a functio n of the\\nfeature vector φ(x) through a generally non-linear vector function g(·)\\nof suitable dimensions. In words, GLM assume that the target variable\\nis a “noisy” measure of the mean µ= g(Wφ(x)).\\nWhen the function g(·) is selected as the gradient of the partition\\nfunction of the selected model, e.g., g(·) = ∇η A(·), then, by ( 3.10), we'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 76, 'page_label': '71', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.6. Maximum Entropy Property ∗ 71\\nobtain the GLM ( 3.54). This choice for g(·) is typical, and is referred\\nto as the (inverse of the) canonical link function. F or insta nce, the\\nlinear regression model p(t|x,w) = N(t|wT φ(x),σ2 ) used in Chapter 2\\ncorresponds to a GLM with canonical link function. Througho ut this\\nmonograph, when referring to GLMs, we will consider models o f the\\nform ( 3.54), or, equivalently ( 3.55), with canonical link function. F or\\nfurther generalizations, we refer to [ 104, 15].\\nGLMs, especially in the form ( 3.54), are widely used. As we will\\nalso discuss in the next chapter, learning the parameters of GLMs can\\nbe done by means of gradient ascent on the LL using the identit y ( 3.28)\\nand the chain rule of diﬀerentiation.\\n3.6 Maximum Entropy Property ∗\\nIn this more technical section, we review the maximum entropy prop-\\nerty of the exponential family . Beside providing a compelli ng motiva-\\ntion for adopting models in this class, this property also il luminates'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 76, 'page_label': '71', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='erty of the exponential family . Beside providing a compelli ng motiva-\\ntion for adopting models in this class, this property also il luminates\\nthe relationship between natural and mean parameters.\\nThe key result is the following: The distribution p(x|η) in (\\n3.1) ob-\\ntains the maximum entropy over all distributions p(x) that satisfy the\\nconstraints E x∼p(x)[uk (x)] = µk for all k= 1 ,...,K . Recall that, as men-\\ntioned in Chapter 2 and discussed in more details in Appendix A, the\\nentropy is a measure of randomness of a random variable. Math emati-\\ncally , the distribution p(x|η) solves the optimization problem\\nmax\\np(x)\\nH(p) s.t. E x∼p(x) [uk (x)]=µk for k= 1 ,...,K. (3.56)\\nEach natural parameter ηk turns out to be the optimal Lagrange mul-\\ntiplier associated with the kth constraint (see [ 45, Ch. 6-7]).\\nT o see the practical relevance of this result, suppose that t he only\\ninformation available about some data xis given by the means of given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 76, 'page_label': '71', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='T o see the practical relevance of this result, suppose that t he only\\ninformation available about some data xis given by the means of given\\nfunctions uk (x), k= 1 ,...,K . The probabilistic model ( 3.1) can then\\nbe interpreted as encoding the least additional informatio n about the\\ndata, in the sense that it is the “most random” distribution u nder the\\ngiven constraints. This observation justiﬁes the adoption of this model\\nby the maximum entropy principle.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 77, 'page_label': '72', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='72 Probabilistic Models for Learning\\nF urthermore, the fact that the exponential distribution so lves the\\nmaximum entropy problem ( 3.56) illuminates the relationship between\\nmean parameters {µk }and natural parameters {ηk }, as the natural\\nparameter ηk is the optimal Lagrange multiplier associated with the\\nconstraint Ex∼p(x) [uk (x)] = µk .\\nAs another note on the exponential family and information-t heoretic\\nmetrics, in Appendix B we provide discussion about the compu tation\\nof the KL divergence between two distributions in the same ex ponential\\nfamily but with diﬀerent parameters.\\n3.7 Energy-based Models ∗\\nA generalization of the exponential family is given by proba bilistic mod-\\nels of the form\\np(x|η) = 1\\nZ(η) exp\\n(\\n−\\n∑\\nc\\nEc(xc|η)\\n)\\n, (3.57)\\nwhere functions Ec(xc|η) are referred to as energy functions and Z(η)\\nis the partition function. Each energy function Ec(xc|η) generally de-\\npends on a subset xc of the variables in vector x. If each energy function'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 77, 'page_label': '72', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is the partition function. Each energy function Ec(xc|η) generally de-\\npends on a subset xc of the variables in vector x. If each energy function\\ndepends linearly on the parameter vector η, we recover the exponen-\\ntial family discussed above. However, the energy functions may have a\\nmore general non-linear form. An example is the function Ec(xc|η) =\\nln\\n(\\n1 + ( ηT\\nc xc)2\\n)\\ncorresponding to a Student’s t-distribution model 6\\n[83].\\nModels in the form ( 3.57) encode information about the plausibil-\\nity of diﬀerent conﬁgurations of subsets of rvs x c using the associated\\nenergy value: a large energy entails an implausible conﬁgur ation, while\\na small energy identiﬁes likely conﬁgurations. F or example , a subset\\nof rvs x c may tend to be equal with high probability , implying that\\nconﬁgurations in which this condition is not satisﬁed shoul d have high\\nenergy . Energy-based models are typically represented via the graphi-\\ncal formalism of Markov networks, as it will be discussed in C hapter'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 77, 'page_label': '72', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='energy . Energy-based models are typically represented via the graphi-\\ncal formalism of Markov networks, as it will be discussed in C hapter\\n7.\\n6 A Student’s t-distribution can be interpreted as an inﬁnite mixture of Gaussians.\\nAs a result, it has longer tails than a Gaussian pdf [ 23, Chapter 2].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 78, 'page_label': '73', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='3.8. Some Advanced T opics ∗ 73\\nWith energy-based models, the key formula ( 3.28) of the gradient\\nof the LL with respect to the model’s parameters generalizes as\\n1\\nN∇η lnp(xD |η) = −1\\nN\\nN∑\\nn=1\\n∑\\nc\\n∇η Ec(xn|η) +\\n∑\\nc\\nEx∼p(x|η)[∇η Ec(x|η)].\\n(3.58)\\nGeneralizing the discussion around ( 3.28), the ﬁrst term in ( 3.58) is\\nthe “positive” component that points in a direction that min imizes the\\nenergy of the observations xD ; while the second term is the “negative”\\ncomponent that pushes up the energy of the unobserved conﬁgu rations.\\nIn gradient-ascent methods, the application of the ﬁrst ter m is typically\\nreferred to as the positive phase, while the second is referr ed to as the\\nnegative phase. (The negative phase is even taken by some aut hors\\nto model the working of the brain while dreaming! [ 56]) While for\\nthe exponential family the expectation in the negative phas e readily\\nyields the mean parameters, for more general models, the eva luation of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 78, 'page_label': '73', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the exponential family the expectation in the negative phas e readily\\nyields the mean parameters, for more general models, the eva luation of\\nthis term is generally prohibitive and typically requires M onte Carlo\\napproximations, which are discussed in Chapter 8.\\n3.8 Some Advanced T opics ∗\\nThe previous sections have focused on the important class of parametric\\nprobabilistic models in the exponential family . Here we bri eﬂy put the\\ncontent of this chapter in the broader context of probabilis tic models\\nfor machine learning. First, it is often useful to encode add itional infor-\\nmation about the relationships among the model variables by means of\\na graphical formalism that will be discussed in Chapter 7. Se cond, the\\nproblem of learning the distribution of given observations , which has\\nbeen studied here using parametric models, can also be tackl ed using\\na non-parametric approach. Accordingly , the distribution is inferred'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 78, 'page_label': '73', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='been studied here using parametric models, can also be tackl ed using\\na non-parametric approach. Accordingly , the distribution is inferred\\nmaking only assumptions regarding its local smoothness. Ty pical tech-\\nniques in this family include Kernel Density Estimation and Nearest\\nNeighbor Density Estimation (see, e.g., [\\n140]).\\nF urthermore, rather than learning individual probability densities,\\nin some applications, it is more useful to directly estimate ratios of\\ndensities. This is the case, for instance, when one wishes to estimate the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 79, 'page_label': '74', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='74 Probabilistic Models for Learning\\nmutual information between two observed variables, or in tw o-sample\\ntests, whereby one needs to decide whether two sets of observ ations\\nhave the same distribution or not. W e refer to [ 140] for details. Finally ,\\nthere exist important scenarios in which it is not possible t o assign an\\nexplicit probabilistic model to given observations, but on ly to specify a\\ngenerative mechanism. The resulting likelihood-free infe rence problems\\nare covered in [ 100], and will be further discussed in Chapter 6.\\n3.9 Summary\\nIn this chapter, we have reviewed an important class of proba bilistic\\nmodels that are widely used as components in learning algori thms for\\nboth supervised and unsupervised learning tasks. Among the key prop-\\nerties of members of this class, known as the exponential fam ily , are\\nthe simple form taken by the gradient of the LL, as well as the a vailabil-\\nity of conjugate priors in the same family for Bayesian infer ence. An'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 79, 'page_label': '74', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the simple form taken by the gradient of the LL, as well as the a vailabil-\\nity of conjugate priors in the same family for Bayesian infer ence. An\\nextensive list of distributions in the exponential family a long with corre-\\nsponding suﬃcient statistics, measure functions, log-par tition functions\\nand mappings between natural and mean parameters can be foun d in\\n[\\n156]. More complex examples include the Restricted Boltzmann M a-\\nchines (RBMs) to be discussed in Chapter 6 and Chapter 8. It is worth\\nmentioning that there are also distribution not in the expon ential fam-\\nily , such as the uniform distribution parametrized by its su pport. The\\nchapter also covered the important idea of applying exponen tial mod-\\nels to supervised learning via GLMs. Energy-based models we re ﬁnally\\ndiscussed as an advanced topic.\\nThe next chapter will present various applications of model s in the\\nexponential family to classiﬁcation problems.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 80, 'page_label': '75', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part II\\nSupervised Learning'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 81, 'page_label': '76', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4\\nClassiﬁcation\\nThe previous chapters have covered important background ma terial on\\nlearning and probabilistic models. In this chapter, we use t he princi-\\nples and ideas covered so far to study the supervised learnin g problem\\nof classiﬁcation. Classiﬁcation is arguably the quintesse ntial machine\\nlearning problem, with the most advanced state of the art and the most\\nextensive application to problems as varied as email spam de tection\\nand medical diagnosis. Due to space limitations, this chapt er cannot\\nprovide an exhaustive review of all existing techniques and latest devel-\\nopments, particularly in the active ﬁeld of neural network r esearch. F or\\ninstance, we do not cover decision trees here (see, e.g., [ 158]). Rather,\\nwe will provide a principled taxonomy of approaches, and oﬀe r a few\\nrepresentative techniques for each category within a uniﬁe d framework.\\nW e will speciﬁcally proceed by ﬁrst introducing as prelimin ary mate-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 81, 'page_label': '76', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='representative techniques for each category within a uniﬁe d framework.\\nW e will speciﬁcally proceed by ﬁrst introducing as prelimin ary mate-\\nrial the Stochastic Gradient Descent optimization method. Then, we\\nwill discuss deterministic and probabilistic discriminat ive models, and\\nﬁnally we will cover probabilistic generative models.\\n76'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 82, 'page_label': '77', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.1. Preliminaries: Stochastic Gradient Descent 77\\n4.1 Preliminaries: Stochastic Gradient Descent\\nIn this section, we review a technique that is extensively us ed in the\\nsolution of optimization problems that deﬁne learning prob lems such\\nas ML and MAP (see Chapter 2). The technique is known as Stocha stic\\nGradient Descent (SGD). SGD is introduced here and applied t hrough-\\nout this monograph to other learning problems, including un super-\\nvised learning and reinforcement learning. Discussions ab out conver-\\ngence and about more advanced optimization techniques, whi ch may\\nbe skipped at a ﬁrst reading, can be found in the Appendix A of t his\\nchapter.\\nSGD addresses optimization problems of the form\\nmin\\nθ\\nN∑\\nn=1\\nfn(θ), (4.1)\\nwhere θ is the vector of variables to be optimized. The cost function\\nfn(θ) typically depends on the nth example in the training set D. F ol-\\nlowing the notation set in Chapter 2, for example, in the case of dis-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 82, 'page_label': '77', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='fn(θ) typically depends on the nth example in the training set D. F ol-\\nlowing the notation set in Chapter 2, for example, in the case of dis-\\ncriminative deterministic models, the conventional form f or the cost\\nfunctions is\\nfn(θ) = ℓ(tn,ˆt(xn,θ)), (4.2)\\nwhere ℓ is a loss function; ( xn,tn) is the nth training example; and\\nˆt(x,θ) is a predictor parametrized by vector θ.\\nSGD requires the diﬀerentiability of cost functions fn(·). The idea\\nis to move at each iteration in the direction of maximum desce nt for\\nthe cost function in (\\n4.1), when the latter is evaluated as ∑\\nn∈S fn(θ)\\nover a subset, or mini-batch, Sof samples from the training set. 1 Given\\na learning rate schedule γ(i) and an initialization θ(0) of the parameters,\\nSGD repeats in each iteration until convergence the followi ng two steps:\\n•Pick a mini-batch Sof S indices from the set {1,...,N }according\\nto some predetermined order or randomly;\\n1 Strictly speaking, when the functions fn (θ) are ﬁxed and they are processed'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 82, 'page_label': '77', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•Pick a mini-batch Sof S indices from the set {1,...,N }according\\nto some predetermined order or randomly;\\n1 Strictly speaking, when the functions fn (θ) are ﬁxed and they are processed\\nfollowing a deterministic order, the approach should be ref erred to as incremental\\ngradient method [ 22]. However, the term SGD is used in machine learning, capturi ng\\nthe fact that the choice of the mini-batches may be randomize d, and that the sum\\n(4.1) is considered to be an empirical average of a target ensembl e mean (see also\\n[101]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 83, 'page_label': '78', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='78 Classiﬁcation\\n•Update the weights in the direction of steepest local descen t as\\nθ(i) ←θ(i−1) −γ(i)\\nS\\n∑\\nn∈S\\n∇θ fn(θ)|θ=θ(i−1) . (4.3)\\nThe learning rate γ(i) as a function of the iteration iis generally consid-\\nered to be part of the hyperparameters to be optimized via val idation.\\nMore discussion on this can be found in Appendix A of this chap ter.\\n4.2 Classiﬁcation as a Supervised Learning Problem\\nClassiﬁcation is a supervised learning problem in which the label tcan\\ntake a discrete ﬁnite number of values. W e refer to Sec.\\n2.1 for an in-\\ntroduction to supervised learning. In binary classiﬁcatio n, each domain\\npoint x is assigned to either one of two classes, which are denoted as\\nC0 and C1 and identiﬁed by the value of the label t as follows\\nx∈C0 if t= 0 or t= −1 (4.4a)\\nx∈C1 if t= 1 . (4.4b)\\nNote that we will ﬁnd it convenient to use either the label t = 0 or\\nt = −1 to identify class C0 . In the more general case of K classes'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 83, 'page_label': '78', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x∈C0 if t= 0 or t= −1 (4.4a)\\nx∈C1 if t= 1 . (4.4b)\\nNote that we will ﬁnd it convenient to use either the label t = 0 or\\nt = −1 to identify class C0 . In the more general case of K classes\\nC0, C1,..., CK −1, we will instead prefer to use one-hot encoding (Sec.\\n3.2) by labelling a point x∈Ck with a K×1 label t that contains all\\nzeros except for a “1” entry at position k+ 1.\\nExample 4.1. Examples of binary classiﬁcation include email spam\\ndetection and creditworthiness assessment 2 . In the former case, the\\ndomain point xmay be encoded using the bag-of-words model, so that\\neach entry represents the count of the number of times that ea ch term\\nin a given set appears in the email. In the latter application , the domain\\nvector xgenerally includes valuable information to decide on wheth er a\\ncustomer should be granted credit, such as credit score and s alary (see,\\ne.g., [ 2]). Examples of multi-class classiﬁcation include classiﬁ cation of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 83, 'page_label': '78', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='customer should be granted credit, such as credit score and s alary (see,\\ne.g., [ 2]). Examples of multi-class classiﬁcation include classiﬁ cation of\\ntext documents into categories such as sports, politics or t echnology ,\\nand labelling of images depending on the type of depicted ite m.\\n2 While less useful, the “hot dog/ not hot dog” classiﬁer desig ned in the “Silicon\\nV alley” HBO show (Season 4) is also a valid example.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 84, 'page_label': '79', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.2. Classiﬁcation as a Supervised Learning Problem 79\\nThe binary classiﬁcation problem is illustrated in Fig. 4.1. Given\\na training set Dof labeled examples xn, n = 1 ,...,N , the problem is\\nto assign a new example x to either class C0 or C1. In this particular\\nstandard data set, the two variables in each vector xn measure the\\nsepal length and sepal width of an iris ﬂower. The latter may b elong\\nto either the setosa or virginica family , as encoded by the la bel tn and\\nrepresented in the ﬁgure with diﬀerent markers. Throughout , we denote\\nas D the dimension of the domain point x (D= 2 in Fig. 4.1).\\n4 5 6 7 8 9\\n0.5\\n1\\n1.5\\n2\\n2.5\\n3\\n3.5\\n4\\n4.5\\n?\\nFigure 4.1: Illustration of the binary ( K = 2 classes) classiﬁcation problem with\\na domain space of dimension D = 2: to which class should the new example x be\\nassigned?\\nF ollowing the taxonomy introduced in Chapter 2, we can disti nguish\\nthe following modeling approaches, which will be reviewed i n the given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 84, 'page_label': '79', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='assigned?\\nF ollowing the taxonomy introduced in Chapter 2, we can disti nguish\\nthe following modeling approaches, which will be reviewed i n the given\\norder throughout the rest of this chapter.\\n• Discriminative deterministic models : Model directly the deter-\\nministic mapping between domain point and label via a parame trized\\nfunction t= ˆt(x).\\n•Discriminative probabilistic models : Model the probability of a\\npoint xbelonging to class Ck via a parametrized conditional pmf p(t|x),\\nwith the relationship between t and Ck deﬁned in ( 4.4). W e will also'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 85, 'page_label': '80', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='80 Classiﬁcation\\nwrite p(Ck |x) for the discriminative probability when more convenient.\\n•Generative probabilistic model : Model the joint distribution of\\ndomain point and class label by specifying the prior distrib ution p(t),\\nor p(Ck ), and the class-dependent probability distribution p(x|t), or\\np(x|Ck ), of the domain points within each class.\\nDiscriminative models are arguably to be considered as sett ing the\\ncurrent state of the art on classiﬁcation, including popula r methods\\nsuch as Support V ector Machine (SVM) and deep neural network s. Gen-\\nerative models are potentially more ﬂexible and powerful as they allow\\nto capture distinct class-dependent properties of the cova riates x.\\n4.3 Discriminative Deterministic Models\\nIn this section, we discuss binary classiﬁcation using disc riminative de-\\nterministic models. Owing to their practical importance an d to their\\nintuitive geometric properties, we focus on linear models, whereby the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 85, 'page_label': '80', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='terministic models. Owing to their practical importance an d to their\\nintuitive geometric properties, we focus on linear models, whereby the\\nbinary prediction ˆt(x) is obtained by applying a threshold rule on a\\ndecision variable a(x, ˜w) obtained as a linear function of the learnable\\nweights ˜w (the notation will be introduced below). Note that the deci-\\nsion variable a(x, ˜w) may not be a linear function of the covariates x.\\nAs we will discuss, this class of models underlie important a lgorithms\\nthat are extensively used in practical applications such as SVM. A\\nbrief discussion on multi-class classiﬁcation using deter ministic models\\nis provided at the end of this section. In the next two section s, we cover\\ndiscriminative probabilistic models, including GLMs and m ore general\\nmodels.\\n4.3.1 Model\\nIn their simplest form, linear discriminative determinist ic classiﬁcation\\nmodels are of the form\\nˆt(x, ˜w) = sign ( a(x, ˜w)) , (4.5)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 86, 'page_label': '81', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 81\\nwhere the activation, or decision variable, is given as\\na(x, ˜w) =\\nD∑\\nd=1\\nwdxd + w0\\n= wT x+ w0 = ˜wT ˜x, (4.6)\\nand we have deﬁned the weight vectors w = [ w1 ···wD ]T and ˜ w =\\n[w0 w1 ···wD ]T , as well as the extended domain point ˜ x = [1 xT ]T ,\\nwith x= [ x1 ···xD ]T . The sign function in decision rule ( 4.5) outputs\\n1 if its argument is positive, and 0 or −1 if the argument is negative\\ndepending on the assumed association rule in ( 4.4).\\nGeometric interpretation: classiﬁcation, geometric and f unc-\\ntional margins. The decision rule ( 4.5) deﬁnes a hyperplane that sep-\\narates the domain points classiﬁed as belonging to either of the two\\nclasses. A hyperplane is a line when D= 2; a plane when D = 3; and,\\nmore generally , a D−1-dimensional aﬃne subspace [ 28] in the domain\\nspace. The hyperplane is deﬁned by the equation a(x, ˜w) = 0, with\\npoints on either side characterized by either positive or ne gative values'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 86, 'page_label': '81', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='space. The hyperplane is deﬁned by the equation a(x, ˜w) = 0, with\\npoints on either side characterized by either positive or ne gative values\\nof the activation a(x, ˜w). The decision hyperplane can be identiﬁed as\\ndescribed in Fig. 4.2: the vector w deﬁnes the direction perpendicular\\nto the hyperplane and −w0/||w||is the bias of the decision surface in\\nthe direction w.//\\nFigure 4.2: Key deﬁnitions for a binary linear classiﬁer.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 87, 'page_label': '82', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='82 Classiﬁcation\\nGiven a point x, it is useful to measure the conﬁdence level at which\\nthe classiﬁer assigns x to the class identiﬁed through rule ( 4.5). This\\ncan be done by quantifying the Euclidean distance between x and the\\ndecision hyperplane. As illustrated in Fig. 4.2, this distance, also known\\nas classiﬁcation margin , can be computed as |a(x, ˜w) |/∥w∥.\\nA point x has a true label t, which may or may not coincide with\\nthe one assigned by rule ( 4.5). T o account for this, we augment the\\ndeﬁnition of margin by giving a positive sign to correctly cl assiﬁed\\npoints and a negative sign to incorrectly classiﬁed points. Assuming\\nthat t takes values in {−1,1}, this yields the deﬁnition of geometric\\nmargin as\\nt·a(x, ˜w)\\n∥w∥ , (4.7)\\nwhose absolute value equals the classiﬁcation margin. F or f uture refer-\\nence, we also deﬁne the functional margin as t·a(x, ˜w).\\nF eature-based model. The model described above, in which the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 87, 'page_label': '82', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='whose absolute value equals the classiﬁcation margin. F or f uture refer-\\nence, we also deﬁne the functional margin as t·a(x, ˜w).\\nF eature-based model. The model described above, in which the\\nactivation is a linear function of the input variables x, has the following\\ndrawbacks.\\n-4 -2 0 2 4\\n-4\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\nFigure 4.3: A non-linearly separable training set.\\n1) Bias: As suggested by the example in Fig. 4.3, dividing the do-\\nmain of the covariates xby means of a hyperplane may fail to capture'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 88, 'page_label': '83', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 83\\nthe geometric structure of the data. In particular, in the ex ample, the\\ntwo classes are not linearly separable in the space of the covariates – no\\nhyperplane separates exactly the domain points in the two cl asses. In\\nsuch cases, classiﬁers of the form ( 4.5) may yield large average losses\\ndue to the bias induced by the choice of the model (see Sec. 2.3.3).\\n2) Overﬁtting : When D is large and the data points N are insuﬃ-\\ncient, learning the D+ 1 weights of the classiﬁer may cause overﬁtting.\\n3) Data-dependent domain size : In some applications, the dimension\\nD may even change from data point to data point, that is, it may v ary\\nwith the index n. F or example, a text xn, e.g., represented in ASCII\\nformat, will have a diﬀerent dimension Dn depending on the number\\nof words in the text.\\nT o address these problems, a powerful approach is that of wor king\\nwith feature vectors φk (x), k = 1 ,...,D ′, rather than directly with'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 88, 'page_label': '83', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of words in the text.\\nT o address these problems, a powerful approach is that of wor king\\nwith feature vectors φk (x), k = 1 ,...,D ′, rather than directly with\\nthe covariates x, as the input to the classiﬁer. A feature φk (x) is a, gen-\\nerally non-linear, function of the vector x. It is important to emphasize\\nthat these functions are ﬁxed and not learned.\\nChoosing a number of features D′ > D, which yields an overcom-\\nplete representation of the data point x, may help against bias; while\\nopting for an undercomplete representation with D′ < D may help\\nsolve the problem of overﬁtting. F urthermore, the same numb er of fea-\\ntures D′, e.g., word counts in a bag-of-words model, may be selected\\nirrespective of the size of the data point, addressing also t he last prob-\\nlem listed above.\\nThe feature-based model can be expressed as ( 4.5) with activation\\na(x, ˜w) =\\nD′\\n∑\\nk=1\\nwk φk (x) = ˜ wT φ(x), (4.8)\\nwhere we have deﬁned the feature vector φ(x) = [ φ1 (x) ··· φD′ (x)]T .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 88, 'page_label': '83', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The feature-based model can be expressed as ( 4.5) with activation\\na(x, ˜w) =\\nD′\\n∑\\nk=1\\nwk φk (x) = ˜ wT φ(x), (4.8)\\nwhere we have deﬁned the feature vector φ(x) = [ φ1 (x) ··· φD′ (x)]T .\\nNote that model ( 4.5) is a special case of ( 4.8) with the choice φ(x) =\\n[1 xT ]T .\\n4.3.2 Learning\\nAs seen in Sec. 2.3.3, learning of deterministic discriminative models\\ncan be carried out by means of ERM for a given loss function ℓ. F ur-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 89, 'page_label': '84', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='84 Classiﬁcation\\nthermore, as discussed in Sec. 2.3.5, overﬁtting can be controlled by\\nintroducing a regularization function R( ˜w) on the weight vector ˜ w. Ac-\\ncordingly , a deterministic predictor ˆt(x, ˜w) as deﬁned in ( 4.5) can be\\nlearned by solving the regularized ERM problem\\nmin\\n˜w\\nLD ( ˜w) + λ\\nNR( ˜w), (4.9)\\nwith the empirical risk\\nLD ( ˜w) = 1\\nN\\nN∑\\nn=1\\nℓ\\n(\\ntn,ˆt(xn, ˜w)\\n)\\n. (4.10)\\nIn ( 4.9), the hyperparameter λ should be selected via validation as\\nexplained in Sec. 2.3.5.\\nExtending the examples discussed in Sec. 2.3.5, the regularization\\nterm is typically convex but possibly not diﬀerentiable, e. g., R( ˜w) =\\n∥˜w∥1 . F urthermore, a natural choice for the loss function is the 0 -1 loss,\\nwhich implies that the generalization loss Lp in ( 2.2) is the probability\\nof classiﬁcation error.\\nIn the special case of linearly separable data sets, the resu lting\\nERM problem can be converted to a Linear Program (LP) [ 133]. Since'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 89, 'page_label': '84', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of classiﬁcation error.\\nIn the special case of linearly separable data sets, the resu lting\\nERM problem can be converted to a Linear Program (LP) [ 133]. Since\\nit is in practice impossible to guarantee the separability c ondition a\\npriori, one needs generally to solve directly the ERM proble m ( 4.9).\\nThe function sign( ·) has zero derivative almost everywhere, and is not\\ndiﬀerentiable when the argument is zero. F or this reason, it is diﬃcult\\nto tackle problem ( 4.9) via standard gradient-based optimization algo-\\nrithms such as SGD. It is instead often useful to consider surrogate\\nloss functions ℓ(t,a) that depend directly on the diﬀerentiable (aﬃne)\\nactivation a(x, ˜w). The surrogate loss function should preferably be\\nconvex in a, and hence in ˜ w, ensuring that the resulting regularized\\nERM problem\\nmin\\n˜w\\nN∑\\nn=1\\nℓ(tn,a(xn , ˜w)) + λ\\nNR( ˜w) (4.11)\\nis convex. This facilitates optimization [ 28], and, under suitable addi-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 89, 'page_label': '84', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ERM problem\\nmin\\n˜w\\nN∑\\nn=1\\nℓ(tn,a(xn , ˜w)) + λ\\nNR( ˜w) (4.11)\\nis convex. This facilitates optimization [ 28], and, under suitable addi-\\ntional conditions, guarantees generalization [ 133] (see also next chap-\\nter). The surrogate loss function should also ideally be an u pper bound'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 90, 'page_label': '85', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 85\\non the original loss function. In this way , the actual averag e loss is\\nguaranteed to be smaller than the value attained under the su rrogate\\nloss function. Examples of surrogate functions that will be considered\\nin the following can be found in Fig. 4.4.\\n-2 -1 0 1 2\\n0\\n0.5\\n1\\n1.5\\n2\\n2.5\\n3\\n0-1\\nhinge\\nexponential\\nperceptron\\nlogistic\\nFigure 4.4: Some notable surrogate loss functions for binary classiﬁca tion along\\nwith the 0-1 loss.\\nPerceptron Algorithm\\nThe perceptron algorithm is one of the very ﬁrst machine lear ning and\\nAI algorithms. It was introduced by F rank Rosenblatt at the C ornell\\nAeronautical Laboratory in 1957 to much fanfare in the popul ar press –\\nit is “the embryo of an electronic computer that [the Navy] ex pects will\\nbe able to walk, talk, see, write, reproduce itself and be con scious of\\nits existence. ” reported The New Y ork Times [ 144]. The algorithm was\\nimplemented using analog electronics and demonstrated imp ressive –'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 90, 'page_label': '85', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='its existence. ” reported The New Y ork Times [ 144]. The algorithm was\\nimplemented using analog electronics and demonstrated imp ressive –\\nfor the time – classiﬁcation performance on images [ 23].\\nUsing the feature-based model for generality , the perceptr on algo-\\nrithm attempts to solve problem ( 4.11) with the surrogate perceptron'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 91, 'page_label': '86', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='86 Classiﬁcation\\nloss function deﬁned as\\nℓ(t,a(x, ˜w)) = max (0 ,−t·a(x, ˜w)) . (4.12)\\nThe perceptron loss assigns zero cost to a correctly classiﬁ ed example\\nx, whose functional margin t·a(x, ˜w) is positive, and a cost equal to\\nthe absolute value of the functional margin for a misclassiﬁ ed example,\\nwhose functional margin is negative. A comparison with the 0 -1 loss\\nis shown in Fig. 4.4. The perceptron algorithm tackles problem ( 4.11)\\nwith λ = 0 via SGD with mini-batch size S = 1. The resulting algo-\\nrithm works as follows. First, the weights ˜ w(0) are initialized. Then, for\\neach iteration i= 1 ,2,...\\n•Pick a training example ( xn,tn) uniformly with replacement from\\nD;\\n•If the example is correctly classiﬁed, i.e., if tna(xn , ˜w) ≥0, do not\\nupdate the weights: ˜ w(i) ←˜w(i−1) ;\\n•If the example is not correctly classiﬁed, i.e., if tna(xn , ˜w) < 0,\\nupdate the weights as:\\n˜w(i) ←˜w(i−1) −∇˜w ℓ(tn,a(xn, ˜w))|˜w= ˜w(i−1) = ˜w(i−1) + φ(xn)tn.\\n(4.13)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 91, 'page_label': '86', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•If the example is not correctly classiﬁed, i.e., if tna(xn , ˜w) < 0,\\nupdate the weights as:\\n˜w(i) ←˜w(i−1) −∇˜w ℓ(tn,a(xn, ˜w))|˜w= ˜w(i−1) = ˜w(i−1) + φ(xn)tn.\\n(4.13)\\nIt can be proved that, at each step, the algorithm reduces the term\\nℓ(tn,a(xn , ˜w)) in the perceptron loss related to the selected training\\nexample n if the latter is misclassiﬁed. It can also be shown that, if\\nthe training set is linearly separable, the perceptron algo rithm ﬁnds a\\nweight vector ˜wthat separates the two classes exactly in a ﬁnite number\\nof steps [ 23]. However, convergence can be slow. More importantly , the\\nperceptron fails on training sets that are not linearly sepa rable, such as\\nthe “XOR” training set D={([0,0]T ,0),([0,1]T ,1),([1,0]T ,1),([1,1]T ,0)}\\n[97]. This realization came as a disappointment and contribute d to the\\nﬁrst so-called AI winter period characterized by a reduced f unding for\\nAI and machine learning research [ 154].\\nSupport Vector Machine (SVM)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 91, 'page_label': '86', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ﬁrst so-called AI winter period characterized by a reduced f unding for\\nAI and machine learning research [ 154].\\nSupport Vector Machine (SVM)\\nSVM, introduced in its modern form by Cortes and V apnik [\\n37] in\\n1995, was among the main causes for a renewal of interest in ma chine'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 92, 'page_label': '87', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 87\\nlearning and AI. F or this section, we will write explicitly ( and with a\\nslight abuse of notation) the activation as\\na(x, ˜w) = w0 + wT φ(x), (4.14)\\nin order to emphasize the oﬀset w0 . SVM solves the regularized ERM\\nproblem ( 4.11) with the surrogate hinge loss function\\nℓ(t,a(x, ˜w)) = max(0 ,1 −t·a(x, ˜w)), (4.15)\\nand with the regularization function R( ˜w) = ∥w∥2. Note that the latter\\ninvolves only the vector wand not the bias weight w0 – we will see below\\nwhy this is a sensible choice. The hinge loss function is also shown in\\nFig. 4.4.\\nTherefore, unlike the perceptron algorithm, SVM includes a regular-\\nization term, which was shown to ensure strong theoretical g uarantees\\nin terms of generalization error [ 39]. F urthermore, rather than relying\\non SGD, SVM attempts to directly solve the regularized ERM pr oblem\\nusing powerful convex optimization techniques [ 28].\\nT o start, we need to deal with the non-diﬀerentiability of th e hinge'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 92, 'page_label': '87', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='on SGD, SVM attempts to directly solve the regularized ERM pr oblem\\nusing powerful convex optimization techniques [ 28].\\nT o start, we need to deal with the non-diﬀerentiability of th e hinge\\nloss ( 4.15). This can be done by introducing auxiliary variables zn , one\\nfor each training example n. In fact, imposing the inequality zn ≥\\nℓ(tn,a(xn , ˜w)) yields the following equivalent problem\\nmin\\n˜w,z\\nN∑\\nn=1\\nzn + λ\\nN ∥w∥2 (4.16a)\\ns.t. tn ·a(xn, ˜w) ≥1 −zn (4.16b)\\nzn ≥0 for n=1,...,N, (4.16c)\\nwhere z= [ z1 ···zN ]T . The equivalence between the original regularized\\nERM problem and problem ( 4.16) follows from the fact that any opti-\\nmal value of the variables ( ˜ w,z) must satisfy either constraint ( 4.16b) or\\n(4.16c) with equality . This can be seen by contradiction: a solutio n for\\nwhich both constraints are loose for some n could always be improved\\nby decreasing the value of the corresponding variables zn until the most'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 92, 'page_label': '87', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='which both constraints are loose for some n could always be improved\\nby decreasing the value of the corresponding variables zn until the most\\nstringent of the two constraints in ( 4.16) is met. As a consequence, at\\nan optimal solution, we have the equality zn = ℓ(tn,a(xn , ˜w)).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 93, 'page_label': '88', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='88 Classiﬁcation\\nThe advantage of formulation ( 4.16) is that the problem is convex,\\nand can hence be solved using powerful convex optimization t echniques\\n[28]. In fact, the cost function is strictly convex, and thus the optimal\\nsolution is unique [ 28]. F urthermore, the optimal solution has an in-\\nteresting interpretation in the special case in which the tr aining data\\nset is linearly separable. As we will see, this interpretati on justiﬁes the\\nname of this technique.\\nLinearly separable sets and support vectors. When the data\\nset is linearly separable, it is possible to ﬁnd a vector ˜ w such that all\\npoints are correctly classiﬁed, and hence all the functiona l margins are\\npositive, i.e., tn ·a(xn, ˜w) >0 for n= 1 ,...,N . Moreover, by scaling the\\nvector ˜w, it is always possible to ensure that the minimum functional\\nmargin equals 1 (or any other positive value). This means tha t we can\\nimpose without loss of optimality the inequalities tn ·a(xn , ˜w) ≥1 for'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 93, 'page_label': '88', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='margin equals 1 (or any other positive value). This means tha t we can\\nimpose without loss of optimality the inequalities tn ·a(xn , ˜w) ≥1 for\\nn = 1 ,...,N and hence set z = 0 in problem ( 4.16). This yields the\\noptimization problem\\nmin\\n˜w\\n∥w∥2 (4.17a)\\ns.t. tn ·a(xn, ˜w) ≥1 for n=1,...,N. (4.17b)\\nThe problem above can be interpreted as the maximization of the\\nminimum geometric margin across all training points . T o see this, note\\nthat, under the constraint ( 4.17b), the minimum geometric margin can\\nbe computed as\\nmin\\nn=1,...,N\\ntna(xn , ˜w)\\n∥w∥ = 1\\n∥w∥. (4.18)\\nF urthermore, we call the vectors that satisfy the constrain ts ( 4.17b)\\nwith equality , i.e., tn ·a(xn , ˜w) = 1, as support vectors, since they sup-\\nport the hyperplanes parallel to the decision hyperplane at the mini-\\nmum geometric margin. At an optimum value ˜ w, there are at least two\\nsupport vectors, one on either side of the separating hyperp lane (see\\n[23, Fig. 7.1]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 93, 'page_label': '88', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='mum geometric margin. At an optimum value ˜ w, there are at least two\\nsupport vectors, one on either side of the separating hyperp lane (see\\n[23, Fig. 7.1]).\\nUsing Lagrange duality , the support vectors can be easily id entiﬁed\\nby observing the optimal values {αn }of the multipliers associated with\\nthe constraints ( 4.16b). Support vectors xn correspond to positive La-\\ngrange multipliers αn > 0 (see, e.g., [ 23]), while all other points have'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 94, 'page_label': '89', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.3. Discriminative Deterministic Models 89\\nzero Lagrange multipliers. Note that the Lagrange multipli ers are re-\\nturned by standard solvers such as the ones implemented by th e CVX\\ntoolbox in MA TLAB [ 58].\\n-1 -0.5 0 0.5 1\\n-1\\n-0.5\\n0\\n0.5\\n1\\nFigure 4.5: Example of binary classiﬁcation with SVM using polynomial f eatures\\nup to degree M (λ/N = 0 .2).\\nExample 4.2. In the example in Fig. 4.5, the illustrated N = 80\\ntraining samples are fed to a SVM using the monomial feature v ec-\\ntor φ(x) = [1 x1 x2 ···xM\\n1 xM\\n2 ] and λ/N = 0 .2 for given model orders\\nM. The decision boundary is shown using dashed and solid lines . It is\\nseen that, using a suﬃciently large order (here M = 3), SVM is able to\\neﬀectively partition the two samples in the two classes. F ur thermore,\\neven with larger values of M (here M = 8), SVM appears not to suﬀer\\nfrom signiﬁcant overﬁtting thanks to the quadratic regular ization term.\\nThe optimization problem (\\n4.16) may be conveniently tackled by'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 94, 'page_label': '89', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='from signiﬁcant overﬁtting thanks to the quadratic regular ization term.\\nThe optimization problem (\\n4.16) may be conveniently tackled by\\nusing Lagrange duality techniques. This approach also allo ws one to\\nnaturally introduce the powerful tool of kernel methods. Th e interested\\nreader can ﬁnd this discussion in Appendix B of this chapter.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 95, 'page_label': '90', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='90 Classiﬁcation\\n4.3.3 Multi-Class Classiﬁcation ∗\\nHere we brieﬂy describe classiﬁcation scenarios with K >2 classes. As\\na ﬁrst observation, it is possible to build multi-class clas siﬁers based\\nsolely on multiple binary classiﬁers, such as SVM. This can b e done\\nby following one of two general strategies, namely one-versus-the-rest\\nand one-versus-one [23, Chapter 7]. The one-versus-the-rest approach\\ntrains K separate binary classiﬁers, say k = 1 ,...,K , with the kth\\nclassiﬁer operating on the examples relative to class Ck against the\\nexamples from all other classes. The one-versus-one method , instead,\\ntrains K(K−1)/2 binary classiﬁers, one for each pair of classes. Both\\napproaches can yield ambiguities in classiﬁcation [ 23, Chapter 7].\\n4.4 Discriminative Probabilistic Models: Generalized Linea r Mod-\\nels\\nDiscriminative probabilistic models are potentially more powerful than\\ndeterministic ones since they allow to model sources of unce rtainty'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 95, 'page_label': '90', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='els\\nDiscriminative probabilistic models are potentially more powerful than\\ndeterministic ones since they allow to model sources of unce rtainty\\nin the label assignment to the input variables. This randomn ess may\\nmodel noise, labelling errors, e.g., for crowdsourced labe ls, and/or the\\nresidual uncertainty in the classiﬁcation rule due to the av ailability of\\nlimited data. Probabilistic models can also more naturally accommo-\\ndate the presence of more than two classes by producing a prob ability\\ndistribution over the possible label values.\\nIn this section, we study GLMs, which were introduced in Sec. 3.5.\\nW e recall that a GLM ( 3.54) posits that the conditional pmf p(t|x),\\nor p(Ck |x), is a member of the exponential family in which the natural\\nparameter vector η is given as a linear function of a feature vector\\nφ(x), i.e., η= Wφ(x) for weight matrix W.3 It is noted that GLMs are\\nnot linear: only the unnormalized log-likelihood is linear in the weight'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 95, 'page_label': '90', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='φ(x), i.e., η= Wφ(x) for weight matrix W.3 It is noted that GLMs are\\nnot linear: only the unnormalized log-likelihood is linear in the weight\\nmatrix W (see Sec. 3.2). W e start by discussing binary classiﬁcation\\nand then cover the multi-class case in Sec. 4.4.3.\\n3 See Sec. 3.5 for a more general deﬁnition.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 96, 'page_label': '91', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.4. Discriminative Probabilistic Models: Generalized Li near Models 91\\n4.4.1 Model\\nF or classiﬁcation, the label t can take a ﬁnite number of values, and\\nit can hence be described by a Bernoulli variable in the binar y case\\nor, more generally , by a Categorial variable (see Chapter 3) . The GLM\\n(\\n3.54) for binary classiﬁcation is known as logistic regression, and it\\nassumes the predictive distribution\\np(t= 1 |x) = σ( ˜wT φ(x)). (4.19)\\nW e recall that σ(a) = (1 + exp( −a))−1 is the sigmoid function (see\\nChapter 2). W e also observe that\\nσ(−a) = 1 −σ(a), (4.20)\\nwhich implies that we can write p(t= 0 |x) = 1 −σ( ˜wT φ(x)) = σ(−˜wT φ(x)).\\nIntuitively , the sigmoid function in ( 4.19) can be thought of as a “soft”\\nversion of the threshold function sign( a) used by the deterministic mod-\\nels studied in the previous section.\\nW e emphasize that the logistic regression model ( 4.19) is a GLM\\nsince it amounts to a Bernoulli distribution, which is in the exponential'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 96, 'page_label': '91', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='els studied in the previous section.\\nW e emphasize that the logistic regression model ( 4.19) is a GLM\\nsince it amounts to a Bernoulli distribution, which is in the exponential\\nfamily , with natural parameter vector η= ˜wT φ(x) as in\\nt|x,w ∼Bern(t|η= ˜wT φ(x)). (4.21)\\nInference. Before discussing learning, we observe that inference is\\nstraightforward. In fact, once the discriminative model ( 4.19) is known,\\nthe average 0-1 loss, that is, the probability of error, is mi nimized by\\nchoosing the label according to the following rule\\np(C1 |x) = p(t= 1 |x)\\nC1\\n≷\\nC0\\n1\\n2 , (4.22)\\nor equivalently ˜ wT φ(x)\\nC1\\n≷\\nC0\\n0.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 97, 'page_label': '92', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='92 Classiﬁcation\\n4.4.2 Learning\\nConsider ﬁrst ML. The NLL function can be written as\\n−ln p(tD |xD , ˜w) = −\\nN∑\\nn=1\\nln p(tn|xn , ˜w) (4.23)\\n= −\\nN∑\\nn=1\\n{tn ln(yn) + (1 −tn) ln(1 −yn)}, (4.24)\\nwhere we have deﬁned yn = σ( ˜wT φ(xn )). The NLL (\\n4.23) is also re-\\nferred to as the cross entropy loss criterion, since the term −tln(y) −\\n(1 −t) ln(1 −y) is the cross-entropy H((t,1 −t)||(y,1 −y)) (see Sec. 2.6).\\nW e note that the cross-entropy can be used to obtain upper bou nds on\\nthe probability of error (see, e.g., [ 50]). The ML problem of minimizing\\nthe NLL is convex (see Sec. 3.1), and hence it can be solved either\\ndirectly using convex optimization tools, or by using itera tive methods\\nsuch as SGD or Newton (the latter yields the iterative reweig hed least\\nsquare algorithm [ 23, p. 207]).\\nThe development of these methods leverages the expression o f the\\ngradient of the LL function ( 3.28) (used with N = 1) for the exponential'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 97, 'page_label': '92', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='square algorithm [ 23, p. 207]).\\nThe development of these methods leverages the expression o f the\\ngradient of the LL function ( 3.28) (used with N = 1) for the exponential\\nfamily . T o elaborate, using the chain rule for diﬀerentiati on, we can\\nwrite the gradient\\n∇˜w ln p(t|x, ˜w) = ∇η ln Bern( t|η)|η= ˜wφ(x) ×∇˜w ( ˜wT φ(x)), (4.25)\\nwhich, recalling that ∇η ln(Bern(t|η)) = ( t−σ(η)) (cf. ( 3.28)), yields\\n∇˜w ln p(t|x, ˜w) = ( t−y)φ(x). (4.26)\\nEvaluating the exact posterior distribution for the Bayesi an ap-\\nproach turns out to be generally intractable due to the diﬃcu lty in\\nnormalizing the posterior\\np(w|D) ∝p(w)\\nN∏\\nn=1\\np(tn|xn, ˜w). (4.27)\\nW e refer to [ 23, p. 217-220] for an approximate solution based on\\nLaplace approximation. Other useful approximate methods w ill be dis-\\ncussed in Chapter 8.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 98, 'page_label': '93', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.4. Discriminative Probabilistic Models: Generalized Li near Models 93\\nAs a ﬁnal remark, with bipolar labels, i.e., t∈{−1,+1}, the cross-\\nentropy loss function can be written as\\n−ln p(tD |xD , ˜w) =\\nN∑\\nn=1\\nln(1 + exp( −tna(xn, ˜w)). (4.28)\\nThis formulation shows that logistic regression can be thou ght of as an\\nERM method with loss function ℓ(t,a(x, ˜w)) = ln(1 + exp( −ta(x, ˜w)),\\nwhich is seen in Fig. 4.4 to be a convex surrogate loss of the 0-1 loss.\\nMixture models. ∗ As seen, the Bayesian approach obtains the pre-\\ndictive distribution by averaging over multiple models p(t|x,w) with\\nrespect to the parameters’ posterior p(w|D) (cf. ( 2.34)). The result-\\ning model hence mixes the predictions returned by multiple discrimi-\\nnative models p(t|x,w) to obtain the predictive distribution p(t|x) =∫\\np(w|D)p(t|x,w)dw. As we brieﬂy discuss below, it is also possible to\\nlearn mixture models within a frequentist framework.\\nConsider Kprobabilistic discriminative models p(t|x,wk ), k= 1 ,...,K ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 98, 'page_label': '93', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(w|D)p(t|x,w)dw. As we brieﬂy discuss below, it is also possible to\\nlearn mixture models within a frequentist framework.\\nConsider Kprobabilistic discriminative models p(t|x,wk ), k= 1 ,...,K ,\\nsuch as logistic regression. The mixture model is deﬁned as\\np(t|x,θ) =\\nK∑\\nk=1\\nπk p(t|x,wk ). (4.29)\\nIn this model, the vector θ of learnable parameters includes the prob-\\nability vector π, which deﬁnes the relative weight of the K models,\\nand the vectors w1 ,...,wK for the K constituent models. As discussed,\\nin the Bayesian approach, the weights πk are directly obtained by us-\\ning the rules of probability , as done in ( 4.27). Within a frequentist\\napproach, instead, ML training is typically performed via a specialized\\nalgorithm, which will be described in Chapter 6, known as Exp ectation\\nMaximization (EM).\\nMixture models increase the capacity of discriminative mod els and\\nhence allow to learn more complex relationships between cov ariates'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 98, 'page_label': '93', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Maximization (EM).\\nMixture models increase the capacity of discriminative mod els and\\nhence allow to learn more complex relationships between cov ariates\\nand labels. In particular, a mixture model, such as ( 4.29), has a num-\\nber of parameters that increases proportionally with the nu mber K of\\nconstituent models. Therefore, the capacity of a mixture mo del grows\\nlarger with K. As an example, this increased capacity may be leveraged\\nby specializing each constituent model p(t|x,wk ) to a diﬀerent area of\\nthe covariate domain.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 99, 'page_label': '94', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='94 Classiﬁcation\\nGiven their larger capacity , mixture models may be prone to o ver-\\nﬁtting. A way to control overﬁtting will be discussed in Sec. 4.7.\\n4.4.3 Multi-Class Classiﬁcation\\nIn the case of K classes, the relevant exponential family distribution is\\nCategorical with natural parameters depending linearly on the feature\\nvector. This yields the following discriminative model as a generaliza-\\ntion of logistic regression\\nt|x,W ∼Cat(t|η= Wφ(x)), (4.30)\\nwhere the label vector t is deﬁned using one-hot encoding (Ch apter 3)\\nand W is a matrix of weights. W e can also equivalently write the vec tor\\nof probabilities for the K classes as\\ny= softmax( Wφ(x))=\\n\\uf8ee\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\neη 0\\n∑ K−1\\nk=0 eη k\\n.\\n.\\n.\\neη K−1\\n∑ K−1\\nk=0 eη k\\n\\uf8f9\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fb\\n, (4.31)\\nwhere y = [ y1 ···yK ]T with yk = p(Ck |x); and ηk = wT\\nk+1φ(x) with wT\\nk\\nbeing the kth row of the weight matrix W.\\nLearning follows as for logistic regression. T o brieﬂy elab orate on\\nthis point, the NLL can be written as the cross-entropy funct ion'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 99, 'page_label': '94', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='k+1φ(x) with wT\\nk\\nbeing the kth row of the weight matrix W.\\nLearning follows as for logistic regression. T o brieﬂy elab orate on\\nthis point, the NLL can be written as the cross-entropy funct ion\\n−ln p(tD |xD ,W) = −\\nN∑\\nn=1\\nln p(tn|xn,W)\\n= −\\nN∑\\nn=1\\ntT\\nn ln(yn), (4.32)\\nwhere the logarithm is applied element by element, and we hav e yn =\\nsoftmax(Wφ(xn )). Note that each term in (\\n4.32) can be expressed as\\nthe cross-entropy −tT\\nn ln(yn) = H(tn||yn). The ML problem is again\\nconvex and hence eﬃciently solvable. The gradient of the NLL can be\\nagain found using the general formula (\\n3.28) for exponential models\\nand the chain rule for derivatives. W e can write\\n∇W ln p(t|x,W)=∇η ln Cat( t|η)|η=W φ (x) ×∇W (Wφ(x)), (4.33)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 100, 'page_label': '95', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.4. Discriminative Probabilistic Models: Generalized Li near Models 95\\nwhich yields\\n∇W ln p(t|x,W) = ( t−y)φ(x)T . (4.34)\\n4.4.4 Relation to Neural Networks\\nGLM models of the form (\\n4.30), or ( 4.19) in the special case of binary\\nclassiﬁcation, can be interpreted in terms of the neural net work shown\\nin Fig. 4.6. A neural network consists of a directed graph of computing\\nelements, known as neurons. Each neuron applies a determini stic trans-\\nformation of its inputs, as deﬁned by the incoming edges, to p roduce a\\nscalar output on its outgoing edge.\\nIn Fig. 4.6, the input vector xis ﬁrst processed by a hidden layer of\\nneurons, in which each kth neuron computes the feature φk (x). Then,\\neach kth neuron in the output layer applies the kth element of the\\nsoftmax non-linearity ( 4.31) to the numbers produced by the hidden\\nneurons in order to compute the probability yk = p(Ck |x). Note that,\\nin the case of binary classiﬁcation, only one output neuron i s suﬃcient'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 100, 'page_label': '95', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='neurons in order to compute the probability yk = p(Ck |x). Note that,\\nin the case of binary classiﬁcation, only one output neuron i s suﬃcient\\nin order to compute the probability ( 4.19). It is also important to em-\\nphasize that only the weights between hidden and output laye rs are\\nlearned, while the operation of the neurons in the hidden lay er is ﬁxed.\\nFigure 4.6: GLM as a three-layer neural network with learnable weights o nly be-\\ntween hidden and output layers.\\nW e remark that one should not confuse a graph such as the one in\\nFig. 4.6 with the BN representation previously seen in Fig. 2.7, which\\nwill be further discussed in Chapter 7. In fact, while BNs rep resent\\nprobability distributions, diagrams of neural networks su ch as in Fig.\\n4.6 describe deterministic functional relations among variab les. This'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 101, 'page_label': '96', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='96 Classiﬁcation\\nis despite the fact that the output layer of the network in Fig . 4.6\\ncomputes a vector of probabilities. In other words, while th e nodes of a\\nBN are rvs, those in the graph of a neural network are computat ional\\nnodes.\\n“Extreme machine learning” . ∗ An architecture in which the\\nfeatures φ(x) are selected via random linear combinations of the input\\nvector x is sometimes studied under the rubric of “extreme machine\\nlearning” [ 67]. The advantage of this architecture as compared to deep\\nneural networks with more hidden layers and full learning of the weights\\n(Sec. 4.5) is its low complexity .\\n4.5 Discriminative Probabilistic Models: Beyond GLM\\nFigure 4.7: A multi-layer neural network.\\nAs depicted in Fig. 4.6, GLMs can be interpreted as three-layer neural\\nnetworks in which the only hidden layer computes ﬁxed featur es. The\\nﬁxed features are then processed by the output classiﬁcatio n layer. In\\nvarious applications, determining suitable features is a c omplex and'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 101, 'page_label': '96', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ﬁxed features are then processed by the output classiﬁcatio n layer. In\\nvarious applications, determining suitable features is a c omplex and\\ntime-consuming task that requires signiﬁcant domain knowl edge. Mov-\\ning beyond GLMs allows us to work with models that learn not on ly\\nthe weights used by the output layer for classiﬁcation, but a lso the vec-\\ntor of features φ(x) on which the output layer operates. This approach\\nyields a much richer set of models, which, along with suitabl e learning\\nalgorithms, has led to widely publicized breakthroughs in a pplications\\nranging from speech translation to medical diagnosis.\\nAs a prominent example of beyond-GLM classiﬁcation models, we\\ndescribe here feed-forward multi-layer neural networks, o r deep neural'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 102, 'page_label': '97', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.5. Discriminative Probabilistic Models: Beyond GLM 97\\nnetworks when the hidden layers are in large number. W e note t hat, be-\\nside yielding state-of-the-art classiﬁcation algorithms , multi-layer feed-\\nforward networks are also key components of the computation al theory\\nof mind [ 116].\\n4.5.1 Model\\nAs illustrated in Fig. 4.7, feed-forward multi-layer networks consist of\\nmultiple layers with learnable weights. F ocusing on multi- class classiﬁ-\\ncation, we have the chain of vectors x →h1 →···→ hL →y, where\\nx is the D×1 input (observed) vector; y is the K×1 vector of output\\nprobabilities for the K classes; and hl represents the vector of outputs\\nat the lth hidden layer. The number of neurons in each hidden layer\\nis a hyperparameter to be optimized via validation or Bayesi an meth-\\nods (Chapter 2). Note that the adopted numbering of the layer s is not\\nuniversally accepted, and the reverse ordering is also used .\\nReferring to Fig. 4.7, we can write the operation of the neural net-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 102, 'page_label': '97', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='universally accepted, and the reverse ordering is also used .\\nReferring to Fig. 4.7, we can write the operation of the neural net-\\nwork through the functional relations\\nh1 = h(a1 ) with a1 = W1x (4.35a)\\nhl = h(al ) with al = Wlhl−1 (4.35b)\\nfor l= 2 ,...,L (4.35c)\\ny= softmax( aL+1 ) with aL+1=WL+1hL. (4.35d)\\nThe non-linear function h(·) is applied element-wise and is typically\\nselected as a sigmoid, such as the logistic sigmoid or the hyp erbolic\\ntangent, or else, as has become increasingly common, the Rec tiﬁed\\nLinear Unit (ReLU) h(a) = max(0 ,a). In ( 4.35), we have deﬁned the\\nactivation vectors al for the hidden layers l= 1 ,...,L, and the matrices\\nof weights Wl, l= 1 ,...,L + 1, whose dimensions depend on the size of\\nthe hidden layers. W e denote the tensor 4 of all weights as W.\\nThe learnable weights of the hidden layers encode the featur e vector\\nφ(x) = hL used by the last layer for classiﬁcation. With multi-layer n et-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 102, 'page_label': '97', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The learnable weights of the hidden layers encode the featur e vector\\nφ(x) = hL used by the last layer for classiﬁcation. With multi-layer n et-\\nworks, we have then moved from having ﬁxed features deﬁned a p riori\\n4 A tensor is a generalization of a matrix in that it can have mor e than two\\ndimensions, see, e.g., [ 35].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 103, 'page_label': '98', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='98 Classiﬁcation\\nby vector φ(x) in linear models to designing optimal features that max-\\nimize the classiﬁer’s performance in non-linear models. F u rthermore,\\nin multi-layer networks, the learned features h1,...,hL tend to progress\\nfrom low-level features in the lower layers, such as edges in an image,\\nto higher-level concepts and categories, such as “cats” or “ dogs”, in the\\nhigher layers [ 56].\\n4.5.2 Learning\\nT raining deep neural networks is an art [ 56]. The basic underlying al-\\ngorithm is backpropagation, ﬁrst proposed in 1969 and then reinvented\\nin the mid-1980s [ 126, 125]. However, in practice, a number of tricks\\nare required in order to obtain state-of-the-art performan ce, including\\nmethods to combat overﬁtting, such as dropout. Covering the se solu-\\ntions would require a separate treatise, and here we refer to [64, 56] for\\nan extensive discussion.\\nBackpropagation – or backprop for short – extends the derivation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 103, 'page_label': '98', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tions would require a separate treatise, and here we refer to [64, 56] for\\nan extensive discussion.\\nBackpropagation – or backprop for short – extends the derivation\\ndone in ( 4.34) to evaluate the gradient of the LL to be used within\\nan SGD-based algorithm. Again, the main ingredients are the general\\nformula ( 3.28) for exponential models and the chain rule for derivatives.\\nT o elaborate, select a given training example ( xn ,tn) = ( x,t) to be used\\nin an iteration of SGD. Backprop computes the derivative of t he NLL,\\nor cross-entropy loss function, L(W) = −ln p(t|x,W) = −tT ln y (cf.\\n(4.32)), where the output y is obtained via the relations ( 4.35). It is\\nimportant to note that, unlike the linear models studied abo ve, the\\ncross-entropy for multi-layer is generally a non-convex fu nction of the\\nweights.\\nBackprop computes the gradients with respect to the weight m atri-\\nces by carrying out the following phases.\\n•F orward pass: Given x, apply formulas ( 4.35) to evaluate a1,h1 ,a2 ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 103, 'page_label': '98', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='weights.\\nBackprop computes the gradients with respect to the weight m atri-\\nces by carrying out the following phases.\\n•F orward pass: Given x, apply formulas ( 4.35) to evaluate a1,h1 ,a2 ,\\nh2 ,...,aL ,hL , and y.\\n•Backward pass : Given a1 ,h1 ,a2 ,h2 ,...,aL ,hL ,aL+1,y and t, com-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 104, 'page_label': '99', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.5. Discriminative Probabilistic Models: Beyond GLM 99\\npute\\nδL+1 = ( y−t) (4.36a)\\nδl = ( Wl+1)T δl+1 ·h′ (al ) for l= L,L −1,...,1 (4.36b)\\n∇W l L(W) = δl (hl−1 )T for l= 1 ,2,...,L + 1 , (4.36c)\\nwhere h′ (·) denotes the ﬁrst derivative of the function h(·); the product\\n·is taken element-wise; and we set h0 = x.\\nBackprop requires a forward pass and a backward pass for ever y con-\\nsidered training example. The forward pass uses the neural n etwork as\\ndeﬁned by equations ( 4.35). This entails multiplications by the weight\\nmatrices Wl in order to compute the activation vectors, as well as ap-\\nplications of the non-linear function h(·). In contrast, the backward\\npass requires only linear operations, which, by ( 4.36b), are based on\\nthe transpose ( Wl )T of the weight matrix Wl used in the forward pass.\\nThe derivatives ( 4.36c) computed during the backward pass are of\\nthe general form\\n∇wl\\nij\\nL(W) = hl−1\\ni ×δl\\nj , (4.37)\\nwhere wl\\nij is the ( i,j)th element of matrix Wl corresponding to the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 104, 'page_label': '99', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The derivatives ( 4.36c) computed during the backward pass are of\\nthe general form\\n∇wl\\nij\\nL(W) = hl−1\\ni ×δl\\nj , (4.37)\\nwhere wl\\nij is the ( i,j)th element of matrix Wl corresponding to the\\nweight between the pre-synaptic neuron j in layer l−1 and the post-\\nsynaptic neuron i in layer l; hl−1\\ni is the output of the pre-synaptic\\nneuron i; and δl\\nj is the back-propagated error. The back-propagated\\nerror assigns “responsibility” for the error y−t measured at the last\\nlayer (layer L+ 1) to each synaptic weight wl\\nij between neuron jin layer\\nl−1 and neuron iin layer l. The back-propagated error is obtained via\\nthe linear operations in ( 4.36b).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 105, 'page_label': '100', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='100 Classiﬁcation\\n-4 -3 -2 -1 0 1 2 3 4\\n-4\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n4\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\nFigure 4.8: Probability that the class label is the same as for the exampl es marked\\nwith circles according to the output of a feed-forward multi -layer network with one\\nhidden layer ( L = 1) and six hidden neurons (with sigmoid non-linearity). Th e\\nprobability is represented by the color map illustrated by t he bar on the right of the\\nﬁgure. F or reference, the solid line represent the decision line for logistic regression.\\nExample 4.3. In the example in Fig. 4.8, the illustrated N = 300\\ntraining examples are used to train a logistic regression, i .e., GLM,\\nmodel and a feed-forward multi-layer network with one hidde n layer\\n(L= 1) and six hidden neurons with sigmoid non-linearity h(x) = σ(x).\\nThe logistic model uses linear features φ(x) = [1 x]T . Both networks are\\ntrained using SGD. F or logistic regression, the decision li ne is illustrated'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 105, 'page_label': '100', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The logistic model uses linear features φ(x) = [1 x]T . Both networks are\\ntrained using SGD. F or logistic regression, the decision li ne is illustrated\\nas a solid line, while for the multi-layer network we plot the probability\\nthat the class label is the same as for the examples marked wit h circles\\nas color map. The GLM model with linear features is seen to be u nable\\nto capture the structure of the data, while the multi-layer n etwork can\\nlearn suitable features that improve the eﬀectiveness of cl assiﬁcation.\\n4.5.3 Some Advanced T opics ∗\\nW e conclude this section by noting a few important aspects of the\\nongoing research on deep neural networks.\\nA ﬁrst issue concerns the theoretical understanding of the g eneral-\\nization properties of deep neural networks. On the face of it , the success'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 106, 'page_label': '101', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.5. Discriminative Probabilistic Models: Beyond GLM 101\\nof deep neural networks appears to defy one of the the princip les laid\\nout in Chapter 2, which will be formalized in the next chapter : Highly\\nover-parametrized models trained via ML suﬀer from overﬁtt ing and\\nhence do not generalize well. Recent results suggest that th e use of\\nSGD, based on the gradient ( 4.37), may act a regularizer following an\\nMDL perspective. In fact, SGD favors the attainment of ﬂat lo cal max-\\nima of the likelihood function. Flat maxima require a smalle r number\\nof bits to be speciﬁed with respect to sharp maxima, since, in ﬂat max-\\nima, the parameter vector can be described with limited prec ision as\\nlong as it remain within the ﬂat region of the likelihood func tion [ 66,\\n79, 71] (see also [ 78] for a diﬀerent perspective).\\nAnother important aspect concerns the hardware implementa tion\\nof backprop. This is becoming extremely relevant given the p ractical'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 106, 'page_label': '101', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='79, 71] (see also [ 78] for a diﬀerent perspective).\\nAnother important aspect concerns the hardware implementa tion\\nof backprop. This is becoming extremely relevant given the p ractical\\napplications of deep neural networks for consumer’s device s. In fact,\\na key aspect of backprop is the need to propagate the error, wh ich\\nis measured at the last layer, to each synapse via the backwar d pass.\\nThis is needed in order to evaluate the gradient ( 4.37). While a software\\nimplementation of this rule does not present any conceptual diﬃculty ,\\nrealizing the computations in ( 4.36) in hardware, or even on a biological\\nneural system, is faced with a number of issues.\\nA ﬁrst problem is the non-locality of the update ( 4.37). An update\\nrule is local if it only uses information available at each ne uron. In\\ncontrast, as seen, rule ( 4.37) requires back-propagation through the\\nneural network. Another issue is the need for the backward pa ss to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 106, 'page_label': '101', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='contrast, as seen, rule ( 4.37) requires back-propagation through the\\nneural network. Another issue is the need for the backward pa ss to\\nuse a diﬀerent neural path with respect to the forward pass, g iven that,\\nunlike the backward pass, the forward pass includes also non -linearities.\\nA useful discussion of hardware implementation aspects can be found\\nin [ 12] (see also references therein).\\nT o obviate at least some of these practical issues, a number o f vari-\\nations of the rule ( 4.37) have been proposed [ 12]. F or instance, the\\nfeedback alignment rule modiﬁes ( 4.36b) by using ﬁxed random ma-\\ntrices in lieu of the current weight matrices Wl; while the broadcast\\nalignment rule writes the vectors δl as a linear function with ﬁxed\\nrandom coeﬃcients of the error ( y−t), hence removing the need for\\nback-propagation [ 129].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 107, 'page_label': '102', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='102 Classiﬁcation\\nF urthermore, beside ML, there exist Bayesian learning algo rithms\\n[53], including simpliﬁed approaches such as dropout [ 56, 64]. Signiﬁ-\\ncant progress has also been made on applications such as imag e recog-\\nnition by leveraging the underlying structure, or geometry , of the data\\n[30]. As an important case in point, convolutional neural networks lever-\\nage the stationarity , locality and spatial invariance of im age features\\nby limiting the receptive ﬁeld of the neurons (i.e., by setti ng to zero\\nweights that connect to “distant” pixels) and by tying the we ights of\\nneurons in the same layer.\\nAnother recent development is the design of event-driven spiking\\nneural networks that can be implemented on neuromorphic com puting\\nplatforms with extremely low energy consumption (see, e.g. , [ 84, 11]).\\n4.6 Generative Probabilistic Models\\nAs discussed in Chapter 2, discriminative models do not atte mpt to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 107, 'page_label': '102', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='platforms with extremely low energy consumption (see, e.g. , [ 84, 11]).\\n4.6 Generative Probabilistic Models\\nAs discussed in Chapter 2, discriminative models do not atte mpt to\\nmodel the distribution of the domain points x, learning only the predic-\\ntive distribution p(t|x). In contrast, generative models aim at modelling\\nthe joint distribution by specifying parametrized version s of the prior\\ndistribution p(t), or p(Ck ), and of the class-conditional probability dis-\\ntribution p(x|t), or p(x|Ck ). As a result, generative models make more\\nassumptions about the data by considering also the distribu tion of the\\ncovariates x. As such, generative models may suﬀer from bias when\\nthe model is incorrectly selected. However, the capability to capture\\nthe properties of the distribution of the explanatory varia bles x can im-\\nprove learning if the class-conditional distribution p(x|t) has signiﬁcant\\nstructure.\\n4.6.1 Model\\nGenerative models for binary classiﬁcation are typically d eﬁned as fol-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 107, 'page_label': '102', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='prove learning if the class-conditional distribution p(x|t) has signiﬁcant\\nstructure.\\n4.6.1 Model\\nGenerative models for binary classiﬁcation are typically d eﬁned as fol-\\nlows\\nt ∼Bern(π) (4.38a)\\nx|t = t∼exponential(ηt), (4.38b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 108, 'page_label': '103', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.6. Generative Probabilistic Models 103\\nwhere exponential( η) represents a distribution from the exponential\\nfamily with natural parameter vector η (see previous chapter). Accord-\\ningly , the parameters of the model are θ = ( π,η0 ,η1 ), where vectors\\nηt represent the natural parameters of the class-dependent di stribu-\\ntions. As we have seen in Chapter 2, we can also equivalently u se\\nmean parameters to deﬁne the exponential family distributi ons. As\\na result of this choice, the joint distribution for rv (x ,t) is given as\\np(x,t|π,η0 ,η1 ) = p(t|π)p(x|ηt).\\nInference. Given a new point x, in order to minimize the proba-\\nbility of error, the optimal prediction of the class under 0- 1 loss can be\\nseen to satisfy the maximum a posteriori rule\\np(C1 |x) = πp(x|η1 )\\nπp(x|η1 ) + (1 −π)p(x|η0 )\\nC1\\n≷\\nC0\\n1\\n2 . (4.39)\\n4.6.2 Learning\\nW e now focus on ML learning. The LL function can be written as\\nln p(D|π,η0 ,η1 ) =\\nN∑\\nn=1\\nln p(tn|π) +\\nN∑\\nn=1:\\ntn =0\\nln p(xn|η0) +\\nN∑\\nn=1:\\ntn =1\\nln p(xn|η1 ).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 108, 'page_label': '103', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='C1\\n≷\\nC0\\n1\\n2 . (4.39)\\n4.6.2 Learning\\nW e now focus on ML learning. The LL function can be written as\\nln p(D|π,η0 ,η1 ) =\\nN∑\\nn=1\\nln p(tn|π) +\\nN∑\\nn=1:\\ntn =0\\nln p(xn|η0) +\\nN∑\\nn=1:\\ntn =1\\nln p(xn|η1 ).\\n(4.40)\\nGiven the decomposition of the LL in ( 4.40), we can optimize over π, η0\\nand η1 separately , obtaining the respective ML estimates. Note, h ow-\\never, that, while for π we can use the entire data set, the optimization\\nover parameters η0 and η1 can leverage smaller data sets that include\\nonly the samples xn with labels tn = 0 or tn = 1, respectively . As we\\ndiscussed in Chapter 2, ML estimates of exponential familie s merely\\nrequire moment matching, making these estimates generally easy to\\nobtain. W e illustrate this point below with two important ex amples.\\nQuadratic Discriminant Analysis (QDA) . In QDA, the class-\\ndependent distributions are Gaussian with class-dependen t mean and\\ncovariance:\\nt ∼Bern(π) (4.41a)\\nx|t = k∼N(µk ,Σ k ). (4.41b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 109, 'page_label': '104', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='104 Classiﬁcation\\nBy the general rules derived in Chapter 2 for the exponential family ,\\nML selects the moment matching estimates\\nπM L = N[1]\\nN (4.42a)\\nµk,M L = 1\\nN[k]\\nN∑\\nn=1:\\ntn =k\\nxn (4.42b)\\nΣ k,M L = 1\\nN[k]\\nN∑\\nn=1:\\ntn =k\\n(xn −µk )(xn −µk )T . (4.42c)\\nThe resulting predictive distribution for the label of a new sample is\\nthen given by ( 4.39) by plugging in the estimates above as\\np(C1 |x) = πM L N(x|µ1,M L ,Σ 1,M L )\\nπM L N(x|µ1,M L ,Σ 1,M L ) + (1 −πM L )N(x|µ0,M L ,Σ 0,M L ) .\\n(4.43)\\nLinear Discriminant Analysis (LDA) . Setting Σ k = Σ for both\\nclasses k = 1 ,2 yields the Linear Discriminant Analysis (LDA) model\\n[104]. Imposing that two generally distinct parameters, such as Σ 1 and\\nΣ 2 are equal is an example of parameter tying or sharing . By reducing\\nthe number of parameters to be learned, parameter sharing ca n reduce\\noverﬁtting at the potential cost of introducing bias (see Ch apter 2).\\nUnder the assumption of conjugate priors, and of a priori ind epen-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 109, 'page_label': '104', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='overﬁtting at the potential cost of introducing bias (see Ch apter 2).\\nUnder the assumption of conjugate priors, and of a priori ind epen-\\ndence of the parameters, MAP and Bayesian approaches can be d irectly\\nobtained by following the derivations discussed in Chapter 2. W e refer\\nto [ 23, 15, 104] for details.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 110, 'page_label': '105', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.6. Generative Probabilistic Models 105\\n-4 -3 -2 -1 0 1 2 3 4\\n-4\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n4\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\nFigure 4.9: Probability that the class label is the same as for the exampl es marked\\nwith circles according to the output of the generative model QDA. The probability\\nis represented by the color map illustrated by the bar on the r ight of the ﬁgure. F or\\nthis example, it can be seen that LDA fails to separate the two classes (not shown).\\nExample 4.4. W e continue the example in Sec. 4.5 by showing in Fig.\\n4.9 the probability ( 4.43) that the class label is the same as for the\\nexamples marked with circles according to the output of QDA. Given\\nthat the covariates have a structure that is well modelled by a mixture\\nof Gaussians with diﬀerent covariance matrices, QDA is seen to perform\\nwell, arguably better than the discriminative models studi ed in Sec. 4.5.\\nIt is important to note, however, that LDA would fail in this e xample.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 110, 'page_label': '105', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='well, arguably better than the discriminative models studi ed in Sec. 4.5.\\nIt is important to note, however, that LDA would fail in this e xample.\\nThis is because a model with equal class-dependent covarian ce matrices,\\nas assumed by LDA, would entail a signiﬁcant bias for this exa mple.\\n4.6.3 Multi-Class Classiﬁcation ∗\\nAs an example of a generative probabilistic model with multi ple classes,\\nwe brieﬂy consider the generalization of QDA to K ≥2 classes. Extend-\\ning ( 4.41) to multiple classes, the model is described as\\nt ∼Cat(π) (4.44a)\\nx|t = k∼N(µk ,Σ k ), (4.44b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 111, 'page_label': '106', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='106 Classiﬁcation\\nwhere t is encoded using one-hot encoding, so that the label o f each\\nexample is given by the vector tn = [ t0n ,...,t(K −1)n ]T . F ollowing the\\ndiscussion above, moment matching yields the ML estimates\\nπk,M L = N[k]\\nN =\\n∑ N\\nn=1 tkn\\nN (4.45a)\\nµk,M L = 1\\nN[k]\\nN∑\\nn=1\\ntkn xn (4.45b)\\nΣ k,M L = 1\\nN[k]\\nN∑\\nn=1\\ntkn (xn −µk )(xn −µk )T . (4.45c)\\n4.7 Boosting ∗\\nIn this last section, we return to the mixture models of the fo rm ( 4.29)\\nand discuss a popular training approach to reduce overﬁttin g. W e focus\\non deterministic discriminative models with activations ak (x, ˜wk ), k=\\n1,...,K, in which the mixture predictor is given as\\na(x, ˜w) =\\nK∑\\nk=1\\nπk ak (x, ˜wk ) (4.46)\\nwith learnable parameters {πk }and {˜wk }. The technique, known as\\nboosting, trains one model ak (x, ˜wk ) at a time in a sequential fashion,\\nfrom k = 1 to k = K, hence adding one predictor at each training\\nstep k. As a result, boosting increases the capacity of the model in a'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 111, 'page_label': '106', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='from k = 1 to k = K, hence adding one predictor at each training\\nstep k. As a result, boosting increases the capacity of the model in a\\nsequential manner, extending the sum in ( 4.46) over a growing number\\nof predictors. In this way , one starts by training a model wit h a large\\nbias, or approximation error; and progressively decreases the bias at\\nthe cost of a potentially larger estimation error (see Chapt er 2 and the\\nnext chapter for further discussion on bias and estimation e rror). As we\\nwill discuss below, each model is trained by solving an ERM pr oblem\\nin which the contribution of a training example is weighted b y the error\\nrate of the previously trained models.\\nT o elaborate, boosting – more speciﬁcally the AdaBoost sche me –\\ncan be described as solving an ERM problem with the exponenti al loss\\nfunction ℓ(t,a(x, ˜w)) = exp( −t·a(x, ˜w)), which is plotted in Fig. 4.4.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 112, 'page_label': '107', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.8. Summary 107\\nWhen training the kth model, the outputs a1 (x, ˜w1 ),...,ak−1 (x, ˜wk−1 )\\nof the previously trained models, as well as their weights π1,...,πk−1 ,\\nare kept ﬁxed. Excluding the models k+ 1 ,...,K , the training loss can\\nbe written as\\nN∑\\nn=1\\nα(k)\\nn exp(−πk tn ·ak (xn, ˜wk )), (4.47)\\nwith the weights\\nα(k)\\nn = exp\\n\\uf8eb\\n\\uf8ed−tn ·\\nk−1∑\\nj=1\\nπj aj (xn, ˜wj )\\n\\uf8f6\\n\\uf8f8. (4.48)\\nAn important point is that the weights (\\n4.48) are larger for training\\nsamples n with smaller functional margin under the mixture model∑ k−1\\nj=1 πj aj (xn , ˜wj ). Therefore, when training the kth model, we give\\nmore importance to examples that fare worse in terms of class iﬁcation\\nmargins under the current mixture model. Note that, at each t raining\\nstep k, one trains a simple model, which has the added advantage\\nof reducing the computational complexity as compared to the direct\\nlearning of the full training model. W e refer to [ 23, Ch. 14][ 133, Ch. 10]\\nfor further details.\\n4.8 Summary'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 112, 'page_label': '107', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of reducing the computational complexity as compared to the direct\\nlearning of the full training model. W e refer to [ 23, Ch. 14][ 133, Ch. 10]\\nfor further details.\\n4.8 Summary\\nThis chapter has provided a brief review of the key supervise d learning\\nproblem of classiﬁcation. F ollowing the taxonomy put forth in Chapter\\n2, we have divided learning algorithms according to the type of models\\nused to relate explanatory variables and labels. Speciﬁcal ly , we have de-\\nscribed deterministic discriminative models, both linear and non-linear,\\ncovering the perceptron algorithm, SVM, and backprop for mu lti-layer\\nneural networks; probabilistic discriminative models, co ncentrating on\\nGLM; and probabilistic generative models, including QDA an d LDA.\\nW e have also introduced the more advanced topics of mixture m odels\\nand boosting. W e ﬁnally mention that supervised learning, i n the form\\nof classiﬁcation and regression, can also be used as a buildi ng block for'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 112, 'page_label': '107', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and boosting. W e ﬁnally mention that supervised learning, i n the form\\nof classiﬁcation and regression, can also be used as a buildi ng block for\\nthe task of sequential decision processing via imitation le arning (see,\\ne.g., [\\n88]).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 113, 'page_label': '108', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='108 Classiﬁcation\\nWhile this chapter has focused on algorithmic aspects, the n ext\\nchapter discusses a well-established theoretical framewo rk in which to\\nstudy the performance of learning for classiﬁcation.\\nAppendix A: More on SGD ∗\\nIn this appendix, we provide some discussion on the converge nce of\\nSGD and on more advanced optimization techniques.\\nConvergence\\nT o brieﬂy discuss the convergence properties of SGD, consid er ﬁrst for\\nreference the conventional gradient descent algorithms, w hich corre-\\nsponds to choosing the entire training set, i.e., S= {1,...,N }, at each\\niteration. If the function to be optimized is strictly conve x\\n5 , as for the\\nquadratic loss, the algorithm is guaranteed to converge to t he (unique)\\nminimum even with a ﬁxed learning rate γ(i) = γ, as long as the lat-\\nter is no larger than the inverse of the maximum curvature of t he loss\\nfunction L, i.e., γ ≤1/L. F or twice-diﬀerentiable loss functions, the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 113, 'page_label': '108', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ter is no larger than the inverse of the maximum curvature of t he loss\\nfunction L, i.e., γ ≤1/L. F or twice-diﬀerentiable loss functions, the\\nmaximum curvature L can be evaluated as the maximum eigenvalue\\nof the Hessian matrix. F unctions with ﬁnite curvature L are known\\nas Lipschitz smooth. F or these functions, the convergence i s geometric,\\nand hence the number of iterations needed to obtain an error o n the\\noptimal solution equal to ǫ scales as ln(1 /ǫ) (see, e.g., [ 152, Chapter\\n8][33, 72]).\\nW e turn now to the proper SGD algorithm operating with a small er\\nmini-batch size S. If the learning rate schedule is selected so as to satisfy\\nthe Robbins–Monro conditions\\n∞∑\\ni=1\\nγ(i) = ∞and\\n∞∑\\ni=1\\n(γ(i) )2 <∞, (4.49)\\nthe SGD algorithm is known to converge to the optimal solutio n of\\nproblem ( 4.9) in the case of strictly convex functions and to station-\\nary points for non-convex functions with bounded curvature (see [ 152,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 113, 'page_label': '108', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='problem ( 4.9) in the case of strictly convex functions and to station-\\nary points for non-convex functions with bounded curvature (see [ 152,\\n5 If the function is twice diﬀerentiable, strict convexity is equivalent to the re-\\nquirement that all the eigenvalues of the Hessian matrix are strictly positive.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 114, 'page_label': '109', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.8. Summary 109\\nChapter 8] for details). Learning rate schedules that satis fy ( 4.49) in-\\nclude γ(i) = 1 /i. The intuitive reason for the use of diminishing learning\\nrates is the need to limit the impact of the “noise” associate d with the\\nﬁnite-sample estimate of the gradient [ 22]. The proof of convergence\\nleverages the unbiasedness of the estimate of the gradient o btained by\\nSGD.\\nIn practice, a larger mini-batch size S decreases the variance of the\\nestimate of the gradient, hence improving the accuracy when close to a\\nstationary point. However, choosing a smaller S can improve the speed\\nof convergence when the current solution is far from the opti mum [ 152,\\nChapter 8][ 22]. A smaller mini-batch size S is also known to improve\\nthe generalization performance of learning algorithms by a voiding sharp\\nextremal points of the training loss function [ 66, 79, 71] (see also Sec.\\n4.5). F urthermore, as an alternative to decreasing the step siz e, one can'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 114, 'page_label': '109', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='extremal points of the training loss function [ 66, 79, 71] (see also Sec.\\n4.5). F urthermore, as an alternative to decreasing the step siz e, one can\\nalso increase the size of the mini-batch along the iteration s of the SGD\\nalgorithm [ 136].\\nVariations and Generalizations\\nMany variations of the discussed basic SGD algorithm have be en pro-\\nposed and are routinely used. General principles motivatin g these sched-\\nule variants include [\\n56, Chapter 8]: ( i ) momentum, or heavy-bal l, mem-\\nory: correct the direction suggested by the stochastic gradien t by consid-\\nering the “momentum” acquired during the last update; ( ii ) adaptivity:\\nuse a diﬀerent learning rate for diﬀerent parameters depend ing on an\\nestimate of the curvature of the loss function with respect t o each pa-\\nrameter; ( iii ) control variates : in order to reduce the variance of the\\nSGD updates, add control variates that do not aﬀect the unbia sed-\\nness of the stochastic gradient and are negatively correlat ed with the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 114, 'page_label': '109', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='SGD updates, add control variates that do not aﬀect the unbia sed-\\nness of the stochastic gradient and are negatively correlat ed with the\\nstochastic gradient; and ( iv) second-order updates: include information\\nabout the curvature of the cost or objective function in the p arameter\\nupdate.\\nAs detailed in [ 56, Chapter 8][ 76, 43], to which we refer for further\\ndiscussions, schemes in the ﬁrst category include Nesterov momentum;\\nin the second category , we ﬁnd AdaGrad, RMSprop and Adam; and the\\nthird encompasses SVRG and SAGA. Finally , the fourth featur es New-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 115, 'page_label': '110', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='110 Classiﬁcation\\nton methods, which require calculation of the Hessian to eva luate the\\nlocal curvature of the objective, and approximated Newton m ethods,\\nwhich leverage an estimate of the Hessian. The practical and theoret-\\nical implications of the use of these methods is still under d iscussion\\n[157].\\nRelated to second-order methods is the natural gradient approach,\\nwhich applies most naturally to probabilistic models in whi ch the func-\\ntion to be optimized is a LL [ 5]. The conventional gradient method\\nupdates the parameters by moving in the direction that minim izes the\\ncost function under a constraint on the norm of the update vec tor in\\nthe parameter space. A potentially problematic aspect of th is method is\\nthat the Euclidean distance ||θ′ −θ′′||2 between two parameter vectors\\nθ′ and θ′′,e.g., two mean parameters in a model within the exponential\\nfamily , does not provide a direct measure of the distance of t he two'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 115, 'page_label': '110', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='θ′ and θ′′,e.g., two mean parameters in a model within the exponential\\nfamily , does not provide a direct measure of the distance of t he two\\ncorresponding distributions in terms of relevant metrics s uch as the\\nKL divergence. The natural gradient method addresses this i ssue by\\nmeasuring the size of the update directly in terms of the KL di vergence\\nbetween distributions. This modiﬁes the update by pre-mult iplying the\\ngradient with the inverse of the Fisher information matrix [ 5].\\nThe discussion above focuses on the common case of diﬀerenti able\\ncost functions. ERM problems typically include possibly no n-diﬀerentiable\\nregularization terms. T o tackle these problems, technique s such as the\\nsubgradient method and proximal gradient can be used in lieu of SGD\\n[22]. Other important aspects of optimization schemes include paral-\\nlelism and non-convexity (see, e.g., [ 130, 141, 44, 161]). Alternatives\\nto gradient methods that do not require diﬀerentiability in clude evolu-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 115, 'page_label': '110', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='lelism and non-convexity (see, e.g., [ 130, 141, 44, 161]). Alternatives\\nto gradient methods that do not require diﬀerentiability in clude evolu-\\ntionary schemes [ 128].\\nAppendix B: Kernel Methods ∗\\nIn this section, we provide a brief introduction to kernel me thods. This\\nsection requires some background in Lagrange duality .\\nW e start by revisiting the problem ( 4.16) solved by SVM. Using\\nLagrange duality , the optimization ( 4.16) can be solved in the dual do-\\nmain, that is, by optimizing over the dual variables or the La grange\\nmultipliers. Referring for details to [ 23, Chapter 7], the resulting prob-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 116, 'page_label': '111', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='4.8. Summary 111\\nlem turns out to be quadratic and convex. Importantly , the re sulting\\noptimal activation can be expressed as\\na(x, ˜w) =\\nN∑\\nn=1\\nαntnk(x,xn ), (4.50)\\nwhere αn are the optimal dual variables, and we have deﬁned the kernel\\nfunction\\nk(x,y) = φ(x)T φ(y), (4.51)\\nwhere xand yare two argument vectors. The kernel function measures\\nthe correlation – informally , the similarity – between the t wo input vec-\\ntors xand y. The activation ( 4.50) has hence an intuitive interpretation:\\nThe decision about the label of an example x depends on the support\\nvectors xn, which have αn >0, that are the most similar to x. W e note\\nthat equation ( 4.50) can also be justiﬁed using the representer theorem\\nin [ 133, Chapter 16], which shows that the optimal weight vector mus t\\nbe a linear combination of the feature vectors {φ(xn)}N\\nn=1 .\\nW orking in the dual domain can have computational advantage s\\nwhen the number of the primal variables, here the size D′ of the weight'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 116, 'page_label': '111', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='be a linear combination of the feature vectors {φ(xn)}N\\nn=1 .\\nW orking in the dual domain can have computational advantage s\\nwhen the number of the primal variables, here the size D′ of the weight\\nvector ˜w, is larger than the number N of dual variables. While this\\nseems a prior unlikely to happen in practice, it turns out tha t this is\\nnot the case. The key idea is that one can use (\\n4.50) with any other\\nkernel function, not necessarily one explicitly deﬁned by a feature func-\\ntion φ(·). A kernel function is any symmetric function measuring the\\ncorrelation of two data points, possibly in an inﬁnite-dime nsional space.\\nThis is known as the kernel trick .\\nAs a ﬁrst example, the polynomial kernel\\nk(x,y) = ( γxT y+ r)L, (4.52)\\nwhere r> 0, corresponds to a correlation φ(x)T φ(y) in a high-dimensional\\nspace D′. F or instance, with L = 2 and D = 1, we have D′ = 6 and\\nthe feature vector φ(x) =\\n[\\n1,\\n√\\n2x1,\\n√\\n2x2 , x2\\n1 x2\\n2,\\n√\\n2x1x2\\n] T\\n[104]. As'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 116, 'page_label': '111', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='space D′. F or instance, with L = 2 and D = 1, we have D′ = 6 and\\nthe feature vector φ(x) =\\n[\\n1,\\n√\\n2x1,\\n√\\n2x2 , x2\\n1 x2\\n2,\\n√\\n2x1x2\\n] T\\n[104]. As\\nanother, more extreme, example, the conventional Gaussian kernel\\nk(x,y) = e−r∥ x−y∥ 2\\n(4.53)\\ncorresponds to an inner product in an inﬁnite dimensional sp ace [ 104].\\nAn extensive discussion on kernel methods can be found in [ 104].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 117, 'page_label': '112', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='112 Classiﬁcation\\nBefore leaving the subject of kernel methods, it is worth not ing that\\nan important class of methods including k−Nearest Neighbor ( k-NN),\\nuses kernels that are data-dependent. k-NN is also an example of non-\\nparametric learning rules. In contrast to the other schemes studied here,\\nit does not rely on a parametric model of the (probabilistic) relationship\\nbetween input and output. Instead, k-NN leverages the assumption that\\nthe labels of nearby points x should be similar [ 81].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 118, 'page_label': '113', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5\\nStatistical Learning Theory ∗\\nStatistical learning theory provides a well-established t heoretical frame-\\nwork in which to study the trade-oﬀ between the number N of available\\ndata points and the generalization performance of a trained machine.\\nThe approach formalizes the notions of model capacity , esti mation er-\\nror (or generalization gap), and bias that underlie many of t he design\\nchoices required by supervised learning, as we have seen in t he previous\\nchapters. This chapter is of mathematical nature, and it dep arts from\\nthe algorithmic focus of the text so far. While it may be skipp ed at a\\nﬁrst reading, the chapter sheds light on the key empirical ob servations\\nmade in the previous chapters relative to learning in a frequ entist set-\\nup. It does so by covering the theoretical underpinnings of s upervised\\nlearning within the classical framework of statistical lea rning theory .\\nT o this end, the chapter contains a number of formal statemen ts with'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 118, 'page_label': '113', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning within the classical framework of statistical lea rning theory .\\nT o this end, the chapter contains a number of formal statemen ts with\\nproofs. The proofs have been carefully selected in order to h ighlight\\nand clarify the key theoretical ideas. This chapter follows mostly the\\ntreatment in [ 133].\\n113'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 119, 'page_label': '114', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='114 Statistical Learning Theory ∗\\n5.1 A Formal Framework for Supervised Learning\\nIn this chapter, we concentrate on discriminative determin istic models\\nfor binary classiﬁcation, as it is typically done in statist ical learning\\ntheory . W e also focus on the standard 0-1 loss ℓ(t,ˆt) = 1( ˆt ̸= t), for\\nwhich the generalization loss is the probability of error. T he labels tfor\\nthe two classes take values in the set {0,1}(cf. (\\n4.4)).\\nThe learning problem is formalized as follows. Assume that a model,\\nor hypothesis class, Hhas been selected. This set contains a, possibly\\nuncountable, number of predictors ˆt that map each point x in the do-\\nmain space to a label ˆt(x) in {0,1}. W e would like to choose a speciﬁc\\nhypothesis, or predictor, ˆt∈H that minimize the generalization error\\n(cf. ( 2.2))\\nLp(ˆt) = E(x,t)∼pxt [ℓ(t,ˆt(x))]. (5.1)\\nSolving this inference problem would yield an optimal model within\\nclass Has\\nˆt∗\\nH ∈argmin\\nˆt∈H\\nLp(ˆt). (5.2)\\nThe notation in ('),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 119, 'page_label': '114', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='(cf. ( 2.2))\\nLp(ˆt) = E(x,t)∼pxt [ℓ(t,ˆt(x))]. (5.1)\\nSolving this inference problem would yield an optimal model within\\nclass Has\\nˆt∗\\nH ∈argmin\\nˆt∈H\\nLp(ˆt). (5.2)\\nThe notation in (\\n5.2) emphasizes that there may be multiple optimal\\nhypotheses returned by the minimization of the generalizat ion error\\nLp(ˆt). Nevertheless, to ﬁx the ideas, it is useful to think of the c ase in\\nwhich there is a unique optimal hypothesis. This is, for inst ance, the\\ncase when the loss function is strictly convex. Obtaining th e optimal\\npredictor ( 5.2) requires knowledge of the true distribution p(x,t), which\\nis not available.\\nExample 5.1. F or the linear (deterministic) methods studied in Chap-\\nter 4, the model is deﬁned as\\nH= {t˜w (x) = sign( wT x+ w0)} (5.3)\\nwith ˜w= [ wT w0]T , and similarly for the feature-based version. Identi-\\nfying a hypothesis within this class requires the selection of the weight\\nvector ˜w∈RD+1.\\nIn lieu of the true distribution p(x,t), what is available is an i.i.d.\\ntraining set'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 119, 'page_label': '114', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='fying a hypothesis within this class requires the selection of the weight\\nvector ˜w∈RD+1.\\nIn lieu of the true distribution p(x,t), what is available is an i.i.d.\\ntraining set\\nD= {(xn,tn )}N\\nn=1 ∼\\ni.i.d.\\np(x,t) (5.4)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 120, 'page_label': '115', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.1. A Formal Framework for Supervised Learning 115\\ndistributed according to p(x,t). A learning algorithm, such as ERM,\\ntakes the training set Das input and returns a predictor ˆtD ∈H as\\noutput. W e would like the predictive model ˆtD ∈ Hto yield a gen-\\neralization error Lp(ˆtD ) that is as close as possible to the minimum\\ngeneralization loss Lp(ˆt∗\\nH). Note that the selected model ˆtD is random\\ndue to randomness of the data set D.\\nIn this regard, we recall that the ERM learning rule chooses a hy-\\npothesis ˆtERM\\nD ∈H by following the criterion ˆtERM\\nD = argmin ˆt∈H LD (ˆt),\\nwhere the empirical risk is\\nLD (ˆt) = 1\\nN\\nN∑\\nn=1\\nℓ(tn ,ˆt(xn))). (5.5)\\nThe notation in ( 5.5) emphasizes the randomness of the training set\\nD= {(xn,tn )}N\\nn=1 .\\nSince the distribution p(x,t) is unknown, a learning rule ˆtD , such\\nas ERM, can only minimize the generalization loss Lp(ˆt) approximately\\nbased on the observation of the data D. F urthermore, this approxi-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 120, 'page_label': '115', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as ERM, can only minimize the generalization loss Lp(ˆt) approximately\\nbased on the observation of the data D. F urthermore, this approxi-\\nmation can only be guaranteed at some probability level due to the\\nrandomness of the data set D. This is illustrated in Fig.\\n5.1, in which\\nwe have represented a high-probability interval for rv Lp(ˆtD ) on the\\nhorizontal axis. W e would like the approximation to be accur ate for all\\nvalues of Lp(ˆtD ) within this interval.\\nBut there is more: the probabilistic guarantee in terms of ac curacy\\ncannot depend on the speciﬁc distribution p(x,t), but it should instead\\nbe universal with respect to all distributions p(x,t). In summary , the\\nbest one can hope for is to have a learning rule ˆtD that is Probably\\nApproximately Correct (P AC).\\nIn order to formalize this notion, we introduce the followin g deﬁni-\\ntion.\\nDeﬁnition 5.1. A learning rule ˆtD is ( N,ǫ,δ ) P AC if, when working\\non data sets Dof N examples, it satisﬁes the inequality\\nLp(ˆtD ) ≤Lp(ˆt∗'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 120, 'page_label': '115', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion.\\nDeﬁnition 5.1. A learning rule ˆtD is ( N,ǫ,δ ) P AC if, when working\\non data sets Dof N examples, it satisﬁes the inequality\\nLp(ˆtD ) ≤Lp(ˆt∗\\nH) + ǫ (5.6)\\nwith probability no smaller than 1 −δ,that is,\\nPrD ∼\\ni.i.d.\\npxt [Lp(ˆtD ) ≤Lp(ˆt∗\\nH) + ǫ] ≥1 −δ, (5.7)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 121, 'page_label': '116', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='116 Statistical Learning Theory ∗\\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n0 2 4 6 8 10\\nFigure 5.1: A learning algorithm ˆtD outputs a hypothesis that depends on the\\nrandom training set D. It hence takes values in a given interval (the box on the\\nhorizontal axis) with some large probability 1 − δ. The accuracy level ǫ is measured\\nby the diﬀerence with respect to optimal generalization los s Lp (ˆt∗\\nH) for the worst-\\ncase ˆtD in the high-probability interval.\\nfor any true distribution p(x,t).\\nIn (\\n5.6), we have deﬁned ǫ as the accuracy parameter and δ as the\\nconﬁdence parameter. The accuracy is also known as estimation error\\nor generalization gap according to the deﬁnition given in Sec. 2.3.3. In\\nwords, the ( N,ǫ,δ ) P AC condition ( 5.6) requires that the learning rule\\nˆtD operating over N data points is ǫ−accurate with probability 1 −δ\\nfor any distribution p(x,t).\\nThe key question is: Given a model H, how large should N be in\\norder to ensure the existence of an ( N,ǫ,δ) P AC learning scheme ˆtD'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 121, 'page_label': '116', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for any distribution p(x,t).\\nThe key question is: Given a model H, how large should N be in\\norder to ensure the existence of an ( N,ǫ,δ) P AC learning scheme ˆtD\\nfor given accuracy and conﬁdence levels (ǫ,δ)? At a high level, we know\\nthat a large model order implies the need for a larger N in order to\\navoid overﬁtting. More precisely , we expect to observe the b ehavior\\nillustrated in Fig. 5.2: As N increases, ( i ) the interval of values taken\\nby the generalization loss Lp(ˆtD ) with probability no smaller than 1 −δ\\nshrinks; and ( ii ) the generalization loss Lp(ˆtD ) tends to the minimum\\ngeneralization loss Lp(ˆt∗\\nH ),and hence the estimation error vanishes. As'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 122, 'page_label': '117', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.1. A Formal Framework for Supervised Learning 117\\nillustrated in the next example, this expected behavior is a consequence\\nof the law of large numbers, since a larger N allows an increasingly\\naccurate estimation of the true general loss.\\n5 10 15 20 25 30 35 40 45 50\\n0.8\\n1\\n1.2\\n1.4\\n1.6\\n1.8\\n2\\n2.2\\nFigure 5.2: High-probability interval (dashed arrow) for the generali zation error\\nLp (ˆtD ) versus the number N of data points for a model H.\\nExample 5.2. Consider the problem of binary classiﬁcation using the\\nmodel of threshold functions, namely\\nH=\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nˆtθ (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if x<θ\\n1, if x≥θ\\n= 1( x≥θ)\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe, (5.8)\\nwhere xis a real number ( D= 1). Note that the model is parametrized\\nby the threshold θ. Make the realizability assumption that the true dis-\\ntribution is within the hypothesis allowed by the model, i.e ., p(x,t) =\\np(x)1(t= ˆt0(x)) and hence the optimal hypothesis is ˆt∗\\nH = ˆt0, or, equiva-\\nlently , the optimal threshold is θ∗ = 0. Assuming a uniform distribution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 122, 'page_label': '117', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x)1(t= ˆt0(x)) and hence the optimal hypothesis is ˆt∗\\nH = ˆt0, or, equiva-\\nlently , the optimal threshold is θ∗ = 0. Assuming a uniform distribution\\np(x) = U(x|−0.5,0.5) in the interval [ −0.5,0.5] for the domain points,\\nFig.\\n5.3 shows the generalization error Pr[ ˆtθ (x) ̸= t0(x)] = |θ|, as well\\nas the training loss LD (ˆtθ ) for the training set shown on the horizontal\\naxis, for two values of N. Note that the training loss LD (ˆtθ ) is simply'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 123, 'page_label': '118', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='118 Statistical Learning Theory ∗\\nthe fraction of training examples that are correctly classi ﬁed. It is ob-\\nserved that, as N increases, the training loss, or empirical risk, becomes\\nan increasingly reliable estimate of the generalization lo ss uniformly for\\nall hypotheses, parameterized by θ, in the model.\\n-0.5 0 0.5\\n0\\n0.2\\n0.4\\n0.6\\n-0.5 0 0.5\\n0\\n0.2\\n0.4\\n0.6\\nFigure 5.3: Generalization and training losses for a scalar threshold c lassiﬁer model.\\nAs suggested by the example, if N is large enough, the empirical\\nrisk, or training loss, LD (ˆt) approximates increasingly well (with high\\nprobability) the generalization loss Lp(ˆt) for any ﬁxed hypothesis in\\nˆt∈H by the law of large numbers. It would then seem that the proble m\\nis solved: Since LD (ˆt) ≃ Lp(ˆt) for any ˆt, the ERM solution ˆtERM\\nD ,\\nwhich minimizes the training loss LD (ˆt), should also approximately\\nminimize the generalization loss Lp(ˆt), and hence we have ˆtERM\\nD ≃ˆt∗\\nH .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 123, 'page_label': '118', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='D ,\\nwhich minimizes the training loss LD (ˆt), should also approximately\\nminimize the generalization loss Lp(ˆt), and hence we have ˆtERM\\nD ≃ˆt∗\\nH .\\nHowever, this argument is incorrect. In fact, we need the tra ining loss\\nLD (ˆt) to be an accurate approximation of the generalization loss Lp(ˆt)\\nuniformly for al l hypotheses in ˆt∈H in order to ensure the condition\\nˆtERM\\nD ≃ˆt∗\\nH. As we will see in the rest of this chapter, guaranteeing\\nthis condition requires to observe a number of samples N that grows\\nwith the “capacity” of the model H, that is, roughly , with the number\\nof parameters deﬁning the hypotheses in H. Moreover, some models'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 124, 'page_label': '119', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.2. P AC Learnability and Sample Complexity 119\\nturn out to be impossible to learn – in the sense of P AC learnab ility\\nformalized below – no matter how large N is.\\n5.2 P AC Learnability and Sample Complexity\\nIn order to formally address the key question posed above reg arding\\nthe learnability of a model H, we make the following deﬁnitions. As\\nmentioned, for simplicity , we consider binary classiﬁcati on under the 0-1\\nloss, although the analysis can be generalized under suitab le conditions\\n[\\n133].\\nDeﬁnition 5.2. A hypothesis class His P AC learnable if, for any ǫ,δ ∈\\n(0,1), there exist an ( N,ǫ,δ ) P AC learning rule as long as the inequality\\nN ≥NH(ǫ,δ) is satisﬁed for some function NH (ǫ,δ) <∞.\\nIn words, a hypothesis class is P AC learnable if, as long as en ough\\ndata is collected, a learning algorithm can be found that obt ains any\\ndesired level of accuracy and conﬁdence. An illustration of the threshold\\nNH(ǫ,δ) can be found in Fig. 5.2. A less strong deﬁnition of P AC'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 124, 'page_label': '119', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='desired level of accuracy and conﬁdence. An illustration of the threshold\\nNH(ǫ,δ) can be found in Fig. 5.2. A less strong deﬁnition of P AC\\nlearnability requires ( 5.7) to hold only for all true distributions p(x,t)\\nthat can be written as\\np(x,t) = p(x)1(t= ˆt(x)) (5.9)\\nfor some marginal distribution p(x) and for some hypothesis ˆt(x) ∈H.\\nThe condition ( 5.9) is known as the realizability assumption, which im-\\nplies that the data is generated from some mechanism that is i ncluded\\nin the hypothesis class. Note that realizability implies th e linear sepa-\\nrability of any data set drawn from the true distribution for the class\\nof linear predictors (see Chapter 4).\\nA ﬁrst important, and perhaps surprising, observation is th at not all\\nmodels are P AC learnable. As an extreme example of this pheno menon,\\nconsider the class Hof all functions from RD to {0,1}. By the no\\nfree lunch theorem , this class is not P AC learnable. In fact, given any'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 124, 'page_label': '119', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='consider the class Hof all functions from RD to {0,1}. By the no\\nfree lunch theorem , this class is not P AC learnable. In fact, given any\\namount of data, we can always ﬁnd a distribution p(x,t) under which\\nthe P AC condition is not satisﬁed. Intuitively , even in the r ealizable\\ncase, knowing the correct predictor ˆt(x) in ( 5.9) for any number of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 125, 'page_label': '120', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='120 Statistical Learning Theory ∗\\nx∈RD yields no information on the value of ˆt(x) for other values of x.\\nAs another, less obvious, example the class\\nH= {hw (x) = 1(sin( wx) >0)} (5.10)\\nis not P AC learnable despite being parameterized by a single scalar\\n[133].\\nDeﬁnition 5.3. The sample complexity N∗\\nH(ǫ,δ) of model His the min-\\nimal value of NH (ǫ,δ) that satisﬁes the requirements of P AC learning\\nfor H.\\nW e will see next that the sample complexity depends on the ca-\\npacity of the model H. Note that the sample complexity of the two\\nexamples above is inﬁnite since they are not P AC learnable. W e also\\nremark that P AC learnability may be alternatively deﬁned un der the\\nadditional conditions on the scaling of N∗\\nH(ǫ,δ) as a function of ǫ and\\nδ, as well as on the computational complexity of the learning r ule. W e\\nwill not consider these more reﬁned deﬁnitions here, and we r efer the\\nreader to [ 51, 133] for discussion.\\n5.3 P AC Learnability for Finite Hypothesis Classes'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 125, 'page_label': '120', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='will not consider these more reﬁned deﬁnitions here, and we r efer the\\nreader to [ 51, 133] for discussion.\\n5.3 P AC Learnability for Finite Hypothesis Classes\\nIn this section, we consider models with a ﬁnite number of hyp othe-\\nses. The main result is summarized in the following theorem, which is\\nproved below in Sec.\\n5.3.1.\\nTheorem 5.1. A ﬁnite hypothesis class His P AC learnable with sample\\ncomplexity satisfying the inequality\\nN∗\\nH(ǫ,δ) ≤\\n⌈\\n2 ln |H|+ 2 ln(2 /δ)\\nǫ2\\n⌉\\n≜ NERM\\nH (ǫ,δ). (5.11)\\nMoreover, the ERM algorithm achieves the upper bound NERM\\nH (ǫ,δ).\\nThe previous theorem shows that all ﬁnite classes are P AC lea rnable.\\nF urthermore, for all ﬁnite classes, ERM is a P AC learning rul e for any\\ndesired levels of accuracy and conﬁdence ( ǫ,δ), as long as N is larger\\nthan the threshold NERM\\nH (ǫ,δ). This threshold, which we will refer to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 126, 'page_label': '121', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.3. P AC Learnability for Finite Hypothesis Classes 121\\nas the ERM sample complexity for class H, depends on the capacity\\nof the hypothesis class, deﬁned as ln |H|(nats) or log 2 |H|(bits). This\\nis the number of bits required to index the hypotheses in H. It is also\\ninteresting to note that increasing the accuracy , i.e., dec reasing ǫ is\\nmore demanding than increasing the conﬁdence, that is, decr easing δ,\\nin terms of sample complexity .\\nAnother way to understand the result ( 5.11) is that, with N data\\npoints, we can achieve the estimation error\\nǫ=\\n√\\n2 ln(2 |H|/δ)\\nN , (5.12)\\nwith probability 1 −δ, by using ERM. As a result, with N data points,\\nwe can upper bound the generalization loss of ERM as\\nLp(ˆtERM\\nD ) ≤Lp(ˆt∗\\nH) +\\n√\\n2 ln |H|/δ\\nN (5.13)\\nwith probability 1 −δ. In words, ERM achieves the optimal generaliza-\\ntion loss with an estimation error that scales with square ro ot of the\\nmodel capacity and with the inverse square root of N.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 126, 'page_label': '121', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='with probability 1 −δ. In words, ERM achieves the optimal generaliza-\\ntion loss with an estimation error that scales with square ro ot of the\\nmodel capacity and with the inverse square root of N.\\nAs another important note, under the realizability assumpt ion, the\\ntheorem can be modiﬁed to yield the smaller upper bound [ 133]\\nN∗\\nH(ǫ,δ) ≤\\n⌈\\nln |H|+ ln(1/ δ)\\nǫ\\n⌉\\n≜ NERM\\nH (ǫ,δ), (5.14)\\nwhich is also achievable by ERM.\\nWhat does the theorem say about inﬁnite models such as the lin ear\\nclassiﬁer ( 5.3)? One approach is to learn a “quantized” version of H,\\nsay Hb , in which each weight is represented by bbits or, equivalently , as\\none of 2 b pre-determined quantization levels. As a result, the numbe r\\nof hypotheses in the hypothesis class His |H| = (2 b )D+1 , and the\\ncapacity of the hypothesis class is log |H|= ( D+ 1) b (bits) or ln |H|=\\nb(D+ 1) ln 2 (nats). It follows that, using ( 5.3), we obtain the ERM\\nsample complexity\\nNERM\\nH (ǫ,δ) =\\n⌈\\n2b(D+ 1) ln 2 + 2 ln(2 /δ)\\nǫ2\\n⌉\\n. (5.15)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 127, 'page_label': '122', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='122 Statistical Learning Theory ∗\\nIt is observed that the ERM sample complexity scales proport ionally\\nto the number of parameters D+ 1 and to the resolution b. Therefore,\\nobtaining an arbitrary precision by selecting larger value s of b yields\\na sample complexity that grows unbounded. W e will see below h ow to\\ncorrect this result by introducing a more advanced theory of general-\\nization through the concept of V apnik–Chervonenkis (VC) di mension.\\n5.3.1 Proof of Theorem 5.1\\nThe proof of Theorem 5.1 reveals the role played by the training loss\\nLD (ˆt) in approximating the generalization loss Lp(ˆt) uniformly for all\\nhypotheses ˆt∈H. W e start with the following key lemma.\\nLemma 5.2. F or any N ≥NERM\\nH (ǫ,δ), we have\\nPrD ∼\\ni.i.d.\\np(x,t)\\n[\\n|Lp(ˆt) −LD (ˆt)|≤ ǫ\\n2 for all ˆt∈H\\n]\\n≥1 −δ. (5.16)\\nReﬂecting the observation made above around Fig. 5.3, the lemma\\nsays that the training loss LD (ˆt) is a uniformly accurate approximation,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 127, 'page_label': '122', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x,t)\\n[\\n|Lp(ˆt) −LD (ˆt)|≤ ǫ\\n2 for all ˆt∈H\\n]\\n≥1 −δ. (5.16)\\nReﬂecting the observation made above around Fig. 5.3, the lemma\\nsays that the training loss LD (ˆt) is a uniformly accurate approximation,\\nwith accuracy level ǫ/2, of the generalization loss, as long as N ≥\\nNERM\\nH (ǫ,δ).\\nAssume now that the lemma is true – a proof will be given below.\\nUsing the lemma, Theorem 5.1 follows immediately from the inequali-\\nties\\nLp(ˆtERM\\nD ) ≤LD (ˆtERM\\nD ) + ǫ\\n2 ≤LD (ˆt∗ ) + ǫ\\n2 (5.17)\\n≤Lp(ˆt∗ ) + ǫ\\n2 + ǫ\\n2 = Lp(ˆt∗ ) + ǫ, (5.18)\\nwhere the ﬁrst inequality follows from the lemma; the second from the\\ndeﬁnition of ERM; and the third by another application of the lemma.\\nW e hence only need to prove the Lemma in order to conclude the\\nproof. T o proceed, we will use Hoeﬀding’s inequality , which says the\\nfollowing (see, e.g., [ 133]). F or i.i.d. rvs u 1,u2,··· ,uM ∼p(u) such\\nthat E [u i] = µ and Pr[ a ≤ui ≤b] = 1, we have the large deviation\\ninequality\\nPr\\n[⏐\\n⏐\\n⏐\\n⏐\\n⏐\\n1\\nM\\nM∑\\nm=1\\num −µ\\n⏐\\n⏐\\n⏐\\n⏐\\n⏐>ǫ\\n]'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 127, 'page_label': '122', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='following (see, e.g., [ 133]). F or i.i.d. rvs u 1,u2,··· ,uM ∼p(u) such\\nthat E [u i] = µ and Pr[ a ≤ui ≤b] = 1, we have the large deviation\\ninequality\\nPr\\n[⏐\\n⏐\\n⏐\\n⏐\\n⏐\\n1\\nM\\nM∑\\nm=1\\num −µ\\n⏐\\n⏐\\n⏐\\n⏐\\n⏐>ǫ\\n]\\n≤2 exp\\n(\\n− 2Mǫ2\\n(b−a)2\\n)\\n. (5.19)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 128, 'page_label': '123', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.3. P AC Learnability for Finite Hypothesis Classes 123\\nW e can now write the following sequence of equalities and ine qualities,\\nwhich prove the lemma and hence conclude the proof:\\nPrD ∼\\ni.i.d.\\np(x,t)\\n[\\n∃ˆt∈H : |Lp(ˆt) −LD (ˆt)|> ǫ\\n2\\n]\\n=PrD ∼\\ni.i.d.\\np(x,t)\\n\\uf8ee\\n\\uf8f0⋃\\nˆt∈H\\n{\\n|Lp(ˆt) −LD (ˆt)|> ǫ\\n2\\n}\\uf8f9\\n\\uf8fb\\n≤\\n∑\\nˆt∈H\\nPrD ∼\\ni.i.d.\\np(x,t)\\n[\\n|Lp(ˆt) −LD (ˆt)|> ǫ\\n2\\n]\\n≤2\\n∑\\nˆt∈H\\nexp\\n(\\n−Nǫ2\\n2\\n)\\n=2|H|exp\\n(\\n−Nǫ2\\n2\\n)\\n≤δ,\\nwhere the ﬁrst inequality follows by the union bound; the sec ond by\\nHoeﬀding’s inequality; and the third can be veriﬁed to be tru e as long\\nas the inequality N ≥NERM\\nH (ǫ,δ) is satisﬁed.\\n5.3.2 Structural Risk Minimization ∗\\nThe result proved above is useful also to introduce the Struc tural Risk\\nMinimization (SRM) learning approach. SRM is a method for jo int\\nmodel selection and hypothesis learning that is based on the minimiza-\\ntion of an upper bound on the generalization loss. In princip le, the ap-\\nproach avoids the use of validation, and has deep theoretica l properties'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 128, 'page_label': '123', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion of an upper bound on the generalization loss. In princip le, the ap-\\nproach avoids the use of validation, and has deep theoretica l properties\\nin terms of generalization [ 133]. In practical applications, the approach\\nis rarely used, and validation is often preferable. It is nev ertheless con-\\nceptually and theoretically a cornerstone of statistical l earning theory .\\nT o elaborate, assume that we have a nested set of hypothesis c lasses\\nH1 ⊆H2 ⊆... ⊆HMmax . F or instance, the nested model may corre-\\nspond to linear classiﬁers with increasing orders M ∈{1,2,...,Mmax }.\\nF rom Lemma 5.2, we can obtain the following bound\\nLp(ˆt) ≤LD (ˆt) +\\n√\\nln(2|HM |/δ)\\n2N (5.20)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 129, 'page_label': '124', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='124 Statistical Learning Theory ∗\\nfor all ˆt ∈ HM , with probability 1 −δ. SRM minimizes this upper\\nbound, which is a pessimistic estimate of the generalizatio n loss, over\\nboth the choice of the model M and the hypothesis ˆt∈HM . W e note\\nthe similarity of this approach with the simpliﬁed MDL crite rion based\\non two-part codes covered in Chapter 2.\\n5.4 VC Dimension and Fundamental Theorem of P AC Learning\\nW e have seen that ﬁnite classes are P AC learnable with sample com-\\nplexity proportional to the model capacity ln |H|by using ERM. In this\\nsection, we address the following questions: Is NERM\\nH (ǫ,δ) the smallest\\nsample complexity? How can we deﬁne the capacity of inﬁnite h ypoth-\\nesis classes? W e have discussed at the end of Sec.\\n5.3 that the answer\\nto the latter question cannot be found by extrapolating from results\\nobtained when considering ﬁnite hypothesis classes. In con trast, will\\nsee here that the answers to both of these questions rely on th e con-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 129, 'page_label': '124', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='obtained when considering ﬁnite hypothesis classes. In con trast, will\\nsee here that the answers to both of these questions rely on th e con-\\ncept of VC dimension, which serves as a more fundamental deﬁn ition\\nof capacity of a model. The VC dimension is deﬁned next.\\nDeﬁnition 5.4. A hypothesis class His said to shatter a set of domain\\npoints X= {xn}V\\nn=1 if, no matter how the corresponding labels {tn ∈\\n{0,1}}V\\nn=1 are selected, there exists a hypothesis ˆt ∈H that ensures\\nˆt(xn) = tn for all n= 1 ,...,V .\\nDeﬁnition 5.5. The VC dimension VCdim( H) of the model His the\\nsize of the largest set Xthat is shattered by H.\\nBased on the deﬁnitions above, to prove that a model has VCdim (H) =\\nV, we need to carry out the following two steps:\\nStep 1 ) Demonstrate the existence of a set X with |X|= V that\\nis shattered by H; and\\nStep 2 ) Prove that no set X of dimension V + 1 exists that is\\nshattered by H.\\nThe second step is typically seen to be more diﬃcult, as illus trated'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 129, 'page_label': '124', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is shattered by H; and\\nStep 2 ) Prove that no set X of dimension V + 1 exists that is\\nshattered by H.\\nThe second step is typically seen to be more diﬃcult, as illus trated\\nby the following examples.\\nExample 5.3. The threshold function model (\\n5.8) has VCdim( H)= 1,\\nsince there is clearly a set Xof one sample ( V = 1) that can be shat-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 130, 'page_label': '125', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.4. VC Dimension and Fundamental Theorem of P AC Learning 125\\ntered (Step 1); but there are no sets of V = 2 that can be shattered\\n(Step 2). In fact, for any set X= ( x1 ,x2 ) of two points with x1 ≤x2 ,\\nthe label assignment ( t1 ,t2) = (1 ,0) cannot be realized by any choice\\nof the threshold θ, which is the only parameter in the model.\\nExample 5.4. The model H= {ˆta,b(x) = 1 ( a≤x≤b)}, which assigns\\nthe label t = 1 within an interval [ a,b] and the label t = 0 outside it,\\nhas VCdim( H)= 2. In fact, any set of V = 2 points can be shattered\\n– and hence there also exists one such set (Step 1); while ther e are no\\nsets Xof V = 3 points that can be shattered (Step 2). F or Step 2, note\\nthat, for any set X= ( x1 ,x2 ,x3) of three points with x1 ≤x2 ≤x3, the\\nlabel assignment ( t1 ,t2 ,t3) = (1 ,0,1) cannot be realized by any choice\\nof the two free parameters ( a,b).\\nExample 5.5. The model H= {ˆta1 ,a2 ,b1 ,b2 (x) = 1( a1 ≤x1 ≤a2 and b1 ≤'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 130, 'page_label': '125', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='label assignment ( t1 ,t2 ,t3) = (1 ,0,1) cannot be realized by any choice\\nof the two free parameters ( a,b).\\nExample 5.5. The model H= {ˆta1 ,a2 ,b1 ,b2 (x) = 1( a1 ≤x1 ≤a2 and b1 ≤\\nx2 ≤b2)}, which assigns the label t= 1 within an axis-aligned rectan-\\ngle deﬁned by parameters a1,a2 ,b1 and b2 has VCdim( H)= 4, as it can\\nbe proved by using arguments similar to the previous example s.\\nExample 5.6. The linear classiﬁer ( 5.3) has VCdim( H)= D+ 1 [ 133].\\nThe example above suggests that the VC dimension of a set ofte n\\ncoincides with the number of degrees of freedom, or free para meters, in\\nthe model. However, this is not necessarily the case.\\nExample 5.7. Model (\\n5.10), while having a single parameter, has an\\ninﬁnite VC dimension [ 133].\\nW e also note that, for ﬁnite classes, we have the inequality V Cdim(H) ≤\\nlog |H|, since |H|hypotheses can create at most |H|diﬀerent label con-\\nﬁgurations. The next theorem, whose importance is attested by its title'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 130, 'page_label': '125', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='log |H|, since |H|hypotheses can create at most |H|diﬀerent label con-\\nﬁgurations. The next theorem, whose importance is attested by its title\\nof fundamental theorem of P AC learning, provides an answer to the two\\nquestions posed at the beginning of this section.\\nTheorem 5.3. A model Hwith ﬁnite VCdim( H)= d < ∞is P AC\\nlearnable with sample complexity\\nC1\\nd+ ln(1 /δ)\\nǫ2 ≤N∗\\nH(ǫ,δ) ≤C2\\nd+ ln(1 /δ)\\nǫ2 (5.21)\\nfor some constants C1 and C2 . Moreover, the ERM learning rule achieves\\nthe upper bound.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 131, 'page_label': '126', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='126 Statistical Learning Theory ∗\\nThe theorem shows that the sample complexity is proportiona l to\\n(VCdim(H) + ln(1 /δ))/ǫ2 . This reveals that VCdim( H) can be consid-\\nered as the correct deﬁnition of capacity for a hypothesis cl ass H, irre-\\nspective of whether the class is ﬁnite or not: As VCdim( H) increases,\\nthe number of required data points for P AC learning increase s propor-\\ntionally to it. F urthermore, the theorem demonstrates that , if learning\\nis possible for a given model H, then ERM allows us to learn with\\nclose-to-optimal sample complexity .\\nF or a proof of this result and for extensions, we refer to the e xtensive\\ntreatment in [ 133]. W e mention here the important extension of the\\ntheory of generalization to convex learning problems – i.e. , to problems\\nwith convex parameter set and a convex loss function. Rather than\\ndepending on the model complexity as the theory developed so far,\\ngeneralization in this class of problems hinges on the stabi lity of the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 131, 'page_label': '126', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='depending on the model complexity as the theory developed so far,\\ngeneralization in this class of problems hinges on the stabi lity of the\\nlearning algorithms. Stability is the property that small c hanges in the\\ninput do not aﬀect much the output of the learning algorithm – a notion\\nrelated to that of diﬀerential privacy [ 119]. W e also point to the related\\nnotion of capacity of a perceptron introduced in [ 94].\\n5.5 Summary\\nThis chapter has described the classical P AC framework for t he anal-\\nysis of the generalization performance of supervised learn ing for clas-\\nsiﬁcation. W e have seen that the concept of VC dimension deﬁn es the\\ncapacity of the model, and, through it, the number of samples needed\\nto learn the model with a given accuracy and conﬁdence, or sam ple\\ncomplexity . In the next chapter, we move from supervised lea rning to\\nunsupervised learning problems.\\nAppendix: Minimax Redundancy and Model Capacity ∗'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 131, 'page_label': '126', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='complexity . In the next chapter, we move from supervised lea rning to\\nunsupervised learning problems.\\nAppendix: Minimax Redundancy and Model Capacity ∗\\nIn this appendix, we describe an alternative deﬁnition of mo del capacity\\nthat is directly related to the conventional notion of Shann on’s capacity\\nof a noisy channel [\\n38]. As for Sec. 2.5, some background in information\\ntheory may be needed to fully appreciate the content of this a ppendix.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 132, 'page_label': '127', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5.5. Summary 127\\nT o elaborate, consider a probabilistic model Hdeﬁned as the set\\nof all pmfs p(x|θ) parametrized by θ in a given set. With some abuse\\nof notation, we take Hto be also the domain of parameter θ. T o ﬁx\\nthe ideas, assume that x takes values over a ﬁnite alphabet. W e know\\nfrom Sec. 2.5, that a distribution q(x) is associated with a lossless\\ncompression scheme that requires around −log q(x) bits to describe a\\nvalue x. F urthermore, if we were informed about the true parameter θ,\\nthe minimum average coding length would be the entropy H(p(x|θ)),\\nwhich requires setting q(x) = p(x|θ) (see Appendix A).\\nAssume now that we only know that the parameter θ lies in set\\nH, and hence the true distribution p(x|θ) is not known. In this case,\\nwe cannot select the true parameter distribution, and we nee d instead\\nto choose a generally diﬀerent distribution q(x) to deﬁne a compres-\\nsion scheme. With a given distribution q(x), the average coding length\\nis given by −∑'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 132, 'page_label': '127', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to choose a generally diﬀerent distribution q(x) to deﬁne a compres-\\nsion scheme. With a given distribution q(x), the average coding length\\nis given by −∑\\nx p(x|θ) log q(x). Therefore, the choice of a generally\\nincorrect distribution q(x) entails a redundancy of\\n∆ R(q(x),θ) = −\\n∑\\nx\\np(x|θ) log q(x) −H(p(x|θ)) ≥0 (5.22)\\nbits.\\nThe redundancy ∆ R(q(x),θ) in ( 5.22) depends on the true value of\\nθ. Since the latter is not known, this quantity cannot be compu ted. W e\\ncan instead obtain a computable metric by maximizing over al l values\\nof θ∈H, which yields the worst-case redundancy\\n∆ R(q(x),H) = max\\nθ∈H\\n∆ R(q(x),θ). (5.23)\\nThis quantity can be minimized over q(x) yielding the so-called mini-\\nmax redundancy:\\n∆ R(H) = min\\nq(x)\\n∆ R(q(x),H) (5.24)\\n= min\\nq(x)\\nmax\\nθ\\n−\\n∑\\nx\\np(x|θ) log q(x) −H(p(x|θ)) (5.25)\\n= min\\nq(x)\\nmax\\nθ\\n∑\\nx\\np(x|θ) log p(x|θ)\\nq(x) . (5.26)\\nThe minimax redundancy can be taken as a measure of the capaci ty\\nof model H,since a richer model tends to yield a larger ∆ R(H).In fact,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 133, 'page_label': '128', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='128 Statistical Learning Theory ∗\\nfor a richer model, it is more diﬃcult to ﬁnd a representative distribu-\\ntion q(x) that yields an average coding length close to the minimum\\nH(p(x|θ)) for all values of θ.\\nIt turns out that the minimax redundancy equals the capacity\\nC(p(x|θ)) of the channel p(x|θ), which is deﬁned as C(p(x|θ)) = max p(θ) I(x; θ)\\n[38]. This is shown by the following sequence of equalities:\\n∆ R(H) =min\\nq(x)\\nmax\\np(θ)\\n∑\\nx\\n∑\\nθ\\np(θ)p(x|θ) log p(x|θ)\\nq(x) (5.27a)\\n=max\\np(θ)\\nmin\\nq(x)\\n∑\\nx\\n∑\\nθ\\np(θ)p(x|θ) log p(x|θ)\\nq(x) (5.27b)\\n=max\\np(θ)\\n∑\\nx\\n∑\\nθ\\np(θ)p(x|θ) log p(x|θ)\\np(x) (5.27c)\\n=C(p(x|θ)), (5.27d)\\nwhere the ﬁrst equality follows since the average of a set of n umbers is\\nno larger than any of the numbers; the second is a consequence of the\\nminimax theorem since the term ∑\\nx\\n∑\\nθ p(θ)p(x|θ) log( p(x|θ)/q(x)) is\\nconvex in q(x) and concave in p(θ); and the third equality follows by\\nGibbs’ inequality (see Sec. 2.6 and ( A.5) in Appendix A). As a ﬁnal'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 133, 'page_label': '128', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='x\\n∑\\nθ p(θ)p(x|θ) log( p(x|θ)/q(x)) is\\nconvex in q(x) and concave in p(θ); and the third equality follows by\\nGibbs’ inequality (see Sec. 2.6 and ( A.5) in Appendix A). As a ﬁnal\\nnote, the mutual information I(x; θ) between model parameter and\\ndata also plays a central role in obtaining bounds on the perf ormance\\nof estimation [ 91].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 134, 'page_label': '129', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part III\\nUnsupervised Learning'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 135, 'page_label': '130', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6\\nUnsupervised Learning\\nUnlike supervised learning, unsupervised learning tasks o perate over\\nunlabelled data sets. Apart from this general statement, un supervised\\nlearning is more loosely deﬁned than supervised learning, a nd it also\\nlacks a strong theoretical framework to mirror the P AC learn ing the-\\nory covered in the previous chapter. Nevertheless, it is wid ely expected\\nthat future breakthroughs in machine learning will come mai nly from\\nadvances in the theory and design of unsupervised learning a lgorithms.\\nThis is due to the availability of huge repositories of unlab elled data,\\nas well as to the broader applicability of learning tasks whe reby the\\nmachine learns, as it were, without supervision or feedback . Unsuper-\\nvised learning is also considered by some as the key to the dev elopment\\nof general, as opposed to task, speciﬁc AI [ 137] (see also [ 142, 87] for\\nmore on general AI).\\nGenerally speaking, unsupervised learning algorithms aim at learn-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 135, 'page_label': '130', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of general, as opposed to task, speciﬁc AI [ 137] (see also [ 142, 87] for\\nmore on general AI).\\nGenerally speaking, unsupervised learning algorithms aim at learn-\\ning some properties of interest of the mechanism underlying the gen-\\neration of the data. In this sense, unsupervised learning co ncerns the\\nstudy of generative models, although, as we will see, this st atement\\ncomes with some caveats. A common aspect of many models used f or\\nunsupervised learning is the presence of hidden, or latent, variables\\n130'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 136, 'page_label': '131', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.1. Unsupervised Learning 131\\nthat help explain the structure of the data.\\nThis chapter starts by discussing applications of unsuperv ised learn-\\ning, and by providing a description of the well-known K-means algo-\\nrithm. It then covers directed and undirected generative pr obabilistic\\nmodels for unsupervised learning. As we will detail, these m odels posit\\ndiﬀerent types of statistical dependence relations betwee n hidden and\\nmeasured variables. Discriminative models, which capture the depen-\\ndence of hidden variables on observed variables, as well as a utoencoders,\\nwhich combine discriminative and generative models, are al so intro-\\nduced. The chapter is concluded with a discussion of a diﬀere nt type\\nof learning algorithm that may be considered as unsupervise d, namely\\nPageRank, which is included due to its practical relevance.\\n6.1 Unsupervised Learning\\nDeﬁning unsupervised learning. A general, and rather imprecise,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 136, 'page_label': '131', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='PageRank, which is included due to its practical relevance.\\n6.1 Unsupervised Learning\\nDeﬁning unsupervised learning. A general, and rather imprecise,\\ndeﬁnition of unsupervised learning tasks is the following. T aking a fre-\\nquentist viewpoint, we are given a data set D consisting of N i.i.d.\\nunlabelled observations x n ∈RD . These are assumed to be drawn i.i.d.\\nfrom an unknown true distribution as\\nD= {xn }N\\nn=1 ∼\\ni.i.d.\\np(x). (6.1)\\nThe goal is to learn some useful properties of the distributi on p(x),\\nwhere the properties of interest depend on the speciﬁc appli cation.\\nWhile this deﬁnition is general enough to include also the es timation\\nproblems studied in Chapter 3, as mentioned, unsupervised l earning\\nproblems are typically characterized by the presence of hidden or la-\\ntent variables. Notable examples include the following.\\n•Density estimation : Density estimation aims at learning directly\\na good approximation of the distribution p(x), e.g., for use in plug-in\\nestimators ['),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 136, 'page_label': '131', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='•Density estimation : Density estimation aims at learning directly\\na good approximation of the distribution p(x), e.g., for use in plug-in\\nestimators [\\n86], to design compression algorithms (see Sec. 2.5), or to\\ndetect outliers [ 139].\\n• Clustering: Clustering assumes the presence of an unobserved\\nlabel zn associated to each data point xn, and the goal is that of recov-\\nering the labels zn for all points in the data set D. F or example, one'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 137, 'page_label': '132', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='132 Unsupervised Learning\\nmay wish to cluster a set Dof text documents according to their topics,\\nby modelling the latter as an unobserved label zn. Broadly speaking,\\nthis requires to group together documents that are similar a ccording\\nto some metric. It is important at this point to emphasize the distinc-\\ntion between classiﬁcation and clustering: While the forme r assumes\\nthe availability of a labelled set of training examples and e valuates its\\n(generalization) performance on a separate set of unlabell ed examples,\\nthe latter works with a single, unlabelled, set of examples. The diﬀerent\\nnotation used for the labels – zn in lieu of tn – is meant to provide a\\nreminder of this key diﬀerence.\\n•Dimensionality reduction and representation : Given the set D, we\\nwould like to represent the data points xn ∈D in a space of lower dimen-\\nsionality . This makes it possible to highlight independent explanatory\\nfactors, and/or to ease visualization and interpretation [ 93], e.g., for'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 137, 'page_label': '132', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='sionality . This makes it possible to highlight independent explanatory\\nfactors, and/or to ease visualization and interpretation [ 93], e.g., for\\ntext analysis via vector embedding (see, e.g., [ 124]).\\n•F eature extraction: F eature extraction is the task of deriving func-\\ntions of the data points xn that provide useful lower-dimensional inputs\\nfor tasks such as supervised learning. The extracted featur es are unob-\\nserved, and hence latent, variables. As an example, the hidd en layer of\\na deep neural network extract features from the data for use b y the\\noutput layer (see Sec. 4.5).\\n•Generation of new samples : The goal here is to learn a machine\\nthat is able to produce samples that are approximately distr ibuted ac-\\ncording to the true distribution p(x). F or example, in computer graphics\\nfor ﬁlmmaking or gaming, one may want to train a software that is able\\nto produce artiﬁcial scenes based on a given description.\\nThe variety of tasks and the diﬃculty in providing formal deﬁ ni-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 137, 'page_label': '132', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for ﬁlmmaking or gaming, one may want to train a software that is able\\nto produce artiﬁcial scenes based on a given description.\\nThe variety of tasks and the diﬃculty in providing formal deﬁ ni-\\ntions, e.g., on the realism of an artiﬁcially generated imag e, make unsu-\\npervised learning, at least in its current state, a less form al ﬁeld than\\nsupervised learning. Often, loss criteria in unsupervised learning mea-\\nsure the divergence between the learned model and the empiri cal data\\ndistribution, but there are important exceptions, as we wil l see.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 138, 'page_label': '133', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.1. Unsupervised Learning 133\\nFigure 6.1: (a) Directed generative models; (b) Undirected generative models; (c)\\nDiscriminative models; (d) Autoencoders.\\nModels. W e now review the type of models that can be used to\\ntackle unsupervised learning problems. The models will be f urther dis-\\ncussed in the subsequent sections of this chapter.\\n•Directed generative models: Directed generative models are mix-\\nture models in which the distribution p(x|θ) of the data is deﬁned by a\\nparametrized prior p(z|θ) of the latent variables z and by a parametrized\\nconditional distribution p(x|z,θ) that deﬁnes the relationship between\\nlatent and observed variables. Accordingly , the distribut ion can be ex-\\npressed, for discrete latent variables z, as\\np(x|θ) =\\n∑\\nz\\np(z|θ)p(x|z,θ). (6.2)\\nA similar expression applies to continuous hidden variable s with an in-\\ntegral in lieu of the sum. Directed models are suitable to cap ture the\\ncause-eﬀect relationships between z and x. A BN describing d irected'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 138, 'page_label': '133', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tegral in lieu of the sum. Directed models are suitable to cap ture the\\ncause-eﬀect relationships between z and x. A BN describing d irected\\ngenerative models is shown in Fig. 6.1(a). Graphical models, including\\nBNs, will be covered in detail in the next chapter. Examples o f di-\\nrected generative models include the mixture of Gaussians m odel, and\\nthe so-called likelihood-free models , in which the conditional distribu-\\ntion p(x|z,θ) is implemented by a deterministic transformation, most\\ntypically a multi-layer network.\\n•Undirected generative models: Undirected models parametrize di-\\nrectly the joint distribution of the observed variables x an d the hidden\\nvariables z as p(x,z|θ), and accordingly write the distribution of the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 139, 'page_label': '134', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='134 Unsupervised Learning\\ndata as\\np(x|θ) =\\n∑\\nz\\np(x,z|θ). (6.3)\\nUnlike directed models, undirected models capture the aﬃni ty , or com-\\npatibility , of given conﬁgurations of values for z and x. An M arkov Ran-\\ndom Field (MRF) describing undirected generative models is shown in\\nFig. 6.1(b) (see next chapter). A prominent example is given by RBMs.\\n•Discriminative models : Discriminative models attempt to directly\\nlearn an encoding probabilistic mapping p(z|x,θ) between the data\\npoint x and a representation z . This is represented by the BN in Fig.\\n6.1(c).\\n•Autoencoders: As seen in Fig. 6.1(d), autoencoders compose a\\nparametrized discriminative model p(z|x,θ), which produces the hid-\\nden variables z from the data x, with a parametrized generati ve model\\np(x|z,θ). The former is known as encoder, while the latter as decoder.\\nAccordingly , the latent variables are also referred to as th e code. The\\nmost typical implementations use parameterized determini stic func-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 139, 'page_label': '134', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Accordingly , the latent variables are also referred to as th e code. The\\nmost typical implementations use parameterized determini stic func-\\ntions z= Fθ (x) and x= Gθ (z) in lieu of the more general probabilistic\\nmodels p(z|x,θ) and p(x|z,θ), respectively . As we will see, autoencoders\\nare trained to reproduce the data x at the output, turning the unsu-\\npervised problem into a supervised one with “labels” given b y the data\\npoint x itself.\\n6.2 K-Means Clustering\\nW e start by reviewing the well-known K-means clustering algorithm.\\nThe purpose here is to emphasize an algorithmic structure, n amely the\\nExpectation Maximization (EM) algorithm, that is conceptu ally at the\\ncore of many unsupervised learning algorithms.\\nThe problem is one of multi-cluster clustering: Given a data set\\nD= {xn}N\\nn=1 , we would like to assign every vector xn ∈RD to one\\nof K clusters. Cluster indices are encoded by categorical varia bles zn\\nvia one-hot encoding (see Chapter 3). Accordingly , we write the kth'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 139, 'page_label': '134', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='n=1 , we would like to assign every vector xn ∈RD to one\\nof K clusters. Cluster indices are encoded by categorical varia bles zn\\nvia one-hot encoding (see Chapter 3). Accordingly , we write the kth\\ncomponent of vector zn as zkn = 1 if xn is assigned to cluster k, while\\nwe write zkn = 0 otherwise. It is emphasized that the labels are not\\ngiven for any of the examples in D. Therefore, the algorithm should'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 140, 'page_label': '135', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.2. K-Means Clustering 135\\ndiscern some regularity in the data in order to divide the dat a set into\\nK classes.\\nK-means is a heuristic method that attempts to cluster togeth er\\npoints that are mutually close in Euclidean distance. T o thi s end, K-\\nmeans assigns all points in the same cluster a given “prototy pe” repre-\\nsentative vector µk . This vector can be thought of in terms of quantiza-\\ntion: all points within a given cluster can be quantized to th e prototype\\nµk with minimal quadratic loss. This is formalized by the follo wing op-\\ntimization problem over the cluster assignment variables zn and the\\ncluster representatives µk :\\nmin\\n{zn },{µk }\\nN∑\\nn=1\\nK∑\\nk=1\\nzkn d(xn,µk ), (6.4)\\nwhere d(x,µ) = ∥x−µ∥2 is the squared Euclidean distance. When us-\\ning a general distance metric, the approach to be described i s instead\\nknown as the K-medoids algorithm. In this regard, we note, for in-\\nstance, that it is possible to apply clustering also to discr ete data as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 140, 'page_label': '135', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='known as the K-medoids algorithm. In this regard, we note, for in-\\nstance, that it is possible to apply clustering also to discr ete data as\\nlong as the distance d is properly deﬁned – typically by a matrix of\\npairwise dissimilarities.\\nThe K-means algorithm performs alternatively optimization of t he\\ncluster assignment variables zn and of the cluster representatives µk as\\nfollows:\\n•Initialize cluster representatives {µold\\nk }.\\n•Expectation step, or E step : F or ﬁxed vectors {µold\\nk },solve problem\\n(\\n6.4) over the cluster assignment {zn }:\\nznew\\nkn =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 for k= argmin j d(xn,µold\\nj )\\n0 otherwise\\n. (6.5)\\nAccordingly , each training point is assigned to the cluster with the clos-\\nest prototype. Note that this step generally requires the co mputation\\nof K distances for each data point xn.\\n•Maximization step, or M step : F or ﬁxed vectors {zn }, solve prob-\\nlem (\\n6.4) over the cluster representatives {µk }. Imposing the optimality'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 140, 'page_label': '135', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of K distances for each data point xn.\\n•Maximization step, or M step : F or ﬁxed vectors {zn }, solve prob-\\nlem (\\n6.4) over the cluster representatives {µk }. Imposing the optimality\\ncondition that the gradient of the objective function in ( 6.4) be zero,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 141, 'page_label': '136', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='136 Unsupervised Learning\\nwe obtain\\nµnew\\nk =\\n∑ N\\nn=1 znew\\nkn xn\\n∑ N\\nn=1 znew\\nkn\\n. (6.6)\\nThe new cluster representative µnew\\nk for each cluster k is the mean of\\nthe data points assigned to cluster k.\\n•If a convergence criterion is not satisﬁed, set { µold\\nk }←{ µnew\\nk }\\nand return to the E step.\\nSince both E step and M step minimize the objective function i n\\n(\\n6.4), respectively over the cluster assignment variables zn and the\\ncluster representatives µk , the value of the objective function is non-\\ndecreasing across the iterations. This ensures convergenc e. Illustrations\\nof convergence and examples can be found in [ 23, Chapter 9]. As a note,\\nthe algorithm is also known as Lloyd-Max quantization [ 54].\\nAt a high level, K-means alternates between: ( i ) making inferences\\nabout the hidden variables { zn} based on the current model deﬁned\\nby the representatives { µk } in the E step; and ( ii ) updating the model\\n{µk } to match the data { xn } and the inferred variables { zn } in the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 141, 'page_label': '136', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='by the representatives { µk } in the E step; and ( ii ) updating the model\\n{µk } to match the data { xn } and the inferred variables { zn } in the\\nM step. W e will see that a similar algorithmic structure is ap plied by\\nmany unsupervised learning algorithms.\\nBefore we move on to discussing more general solutions, it is worth\\nspending a few words on the problem of selecting the number K of\\nclusters. A ﬁrst possibility is to add or remove clusters unt il certain\\nheuristic criteria are satisﬁed, such as the “purity” of clu sters. A second\\napproach is hierarchical clustering, whereby one builds a t ree, known\\nas dendrogram, that includes clustering solutions with an i ncreasing\\nnumber of clusters as one moves away from the root (see, e.g., [51]).\\nY et another solution is to let K be selected automatically by adopting\\na non-parametric Bayesian approach via a Dirichlet process prior [ 104].\\n6.3 ML, ELBO and EM\\nIn this section, we discuss two key technical tools that are e xtensively'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 141, 'page_label': '136', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a non-parametric Bayesian approach via a Dirichlet process prior [ 104].\\n6.3 ML, ELBO and EM\\nIn this section, we discuss two key technical tools that are e xtensively\\nused in tackling unsupervised learning problems, namely th e Evidence\\nLower BOund (ELBO) and the EM algorithm. The starting point i s the\\nfundamental problem of learning a probabilistic, directed or undirected,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 142, 'page_label': '137', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 137\\nmodel p(x|θ) from the data using ML. W e will discuss later how to learn\\ndiscriminative models and autoencoders.\\n6.3.1 ML Learning\\nF rom Sec.\\n2.6, we know that ML, asymptotically in N, tends to min-\\nimize a KL divergence between the true distribution p(x) and the se-\\nlected hypothesis in the model. This is a criterion that is we ll suited\\nfor many of the unsupervised learning tasks mentioned above , such as\\ndensity estimation or generation of new samples, and it is he nce useful\\nto start the discussion with ML learning.\\nBefore we do that, a few remarks are in order. First, it is ofte n useful\\nto choose divergences other than KL, which are tailored to th e speciﬁc\\napplication of interest [ 8]. W e will further discuss this aspect in Sec.\\n6.4.3. Second, when the goal is representation learning, the mach ine\\naims at obtaining useful features z. Hence, minimizing the KL diver-\\ngence to match the true distribution p(x) does not directly address the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 142, 'page_label': '137', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='aims at obtaining useful features z. Hence, minimizing the KL diver-\\ngence to match the true distribution p(x) does not directly address the\\nobjective of representation learning, unless appropriate restrictions are\\nimposed on the model p(x|z,θ).In fact, if the generative model p(x|z,θ)\\nis too powerful, then it can disregard the features z and stil l obtain a\\nhigh likelihood for the data (see, e.g., [ 69]). W e will get back to this\\npoint in Sec. 6.6. Finally , obtaining ML solutions is often impractical,\\nparticularly in large models. Nevertheless, understandin g the ML prob-\\nlem allows one to better gauge the impact of the approximatio ns and\\nsimpliﬁcations made to obtain eﬃcient algorithms.\\nT o proceed, we consider probabilistic, directed or undirec ted, model,\\nand focus, for the purpose of simplifying the notation, on a d ata set\\nwith a single data point ( N = 1). The extension to a data set with an\\narbitrary number N of points only requires adding an outer sum over'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 142, 'page_label': '137', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='with a single data point ( N = 1). The extension to a data set with an\\narbitrary number N of points only requires adding an outer sum over\\nthe sample index to the LL function. W e also concentrate on di screte\\nhidden rvs, and the generalization to continuous rvs is obta ined by sub-\\nstituting sums with suitable integrals. The ML problem can b e written\\nas the maximization of the LL function as\\nmax\\nθ\\nln p(x|θ) = ln\\n( ∑\\nz\\np(x,z|θ)\\n)\\n, (6.7)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 143, 'page_label': '138', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='138 Unsupervised Learning\\nwhere x denotes the data and z the hidden or latent variables. Note\\nthe marginalization with respect to the hidden variables in (6.7). This\\nproblem should be contrasted with the supervised learning M L problem\\nobtained when both x and z are observed, namely\\nmax\\nθ\\nln p(x,z|θ). (6.8)\\nExample 6.1. Consider a directed generative Bernoulli-Gaussian model\\ncharacterized as\\nz ∼Bern(0.5) (6.9a)\\nx|z = 0 ∼N(2,1) (6.9b)\\nx|z = 1 ∼N(θ,1). (6.9c)\\nThis corresponds to a mixture of Gaussians model, in which th e only\\nparameter θ is the mean of one of the two Gaussian components. As-\\nsume that we observe x = 0. Consider ﬁrst the supervised learning\\ncase, where we assume that we also measure z = 1. In this case, the\\nLL function in ( 6.8) is ln p(x = 0 ,z = 1 |θ) = ln N(x|θ,1) + ln(0 .5).\\nIn contrast, with unsupervised learning, the LL function in (6.7) is\\nln p(x= 0 |θ) = ln(0 .5N(0|2,1) + 0 .5N(0|θ,1)).\\nThe LL functions are shown in Fig. 6.2. Unlike supervised learning,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 143, 'page_label': '138', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='In contrast, with unsupervised learning, the LL function in (6.7) is\\nln p(x= 0 |θ) = ln(0 .5N(0|2,1) + 0 .5N(0|θ,1)).\\nThe LL functions are shown in Fig. 6.2. Unlike supervised learning,\\nthe LL for unsupervised learning is seen to be non-concave. In this\\nexample, this is a consequence of the fact that, when θ is suﬃciently\\nlarge in absolute value, the probability of the data xresulting from the\\nﬁxed Gaussian distribution centered at x = 2 makes the contribution\\nof the Gaussian centered θ increasingly irrelevant.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 144, 'page_label': '139', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 139\\n-4 -3 -2 -1 0 1 2 3 4\\n-5\\n-4.5\\n-4\\n-3.5\\n-3\\n-2.5\\n-2\\n-1.5\\n-1\\n-0.5Log-likelihood\\nsupervised\\nunsupervised\\nFigure 6.2: Illustration of LL functions for supervised and unsupervis ed learning\\nin a mixture of Gaussians model (Example 6.1).\\nSolving problem ( 6.7) has two additional complications as compared\\nto the supervised learning counterpart ( 6.8). The ﬁrst issue was high-\\nlighted in the previous example: Even for models in which the ML\\nsupervised learning problem is convex, the LL is generally n on-concave\\nwhen the variables z are hidden, which precludes the use of co nvex\\noptimization algorithms. Barring the use of often impracti cal global\\noptimization algorithms, in general, non-convex problems cannot be\\nsolved exactly . Rather, the best one can hope for with standa rd local\\noptimization schemes, such as SGD, is obtaining stationary points or\\nlocally optimal points [ 28]. In practice, this problem may not be critical'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 144, 'page_label': '139', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='optimization schemes, such as SGD, is obtaining stationary points or\\nlocally optimal points [ 28]. In practice, this problem may not be critical\\nsince non-convexity is not by itself a cause of poor learning performance.\\nF or instance, as seen in Chapter 4, beyond-GLM supervised le arning\\nmethods, including deep neural networks, solve non-convex problems.\\nThe second complication is the need to sum – or integrate – ove r the\\nhidden variables in order to evaluate the LL. This step is com plicated\\nby the fact that the distribution of the hidden variables nee ds to be\\nlearned and is hence unknown. This is a signiﬁcant obstacle t o the\\ndevelopment of eﬃcient learning algorithms, and it general ly needs to\\nbe addressed in order to make learning feasible. In the rest o f this\\nsection, we describe two technical tools that are useful to t ackle these'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 145, 'page_label': '140', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='140 Unsupervised Learning\\nproblems. Chapter 8 will develop more complex solutions for issues\\narising in the presence of large latent spaces in which margi nalization\\nis not viable.\\n6.3.2 ELBO\\nMany methods to tackle the ML problem (\\n6.7) are based on the maxi-\\nmization of the ELBO. These techniques include the EM algori thm and\\nsome of the variational inference algorithms to be discusse d in Chapter\\n8. The key element in the development of the ELBO is the introd uction\\nof an auxiliary distribution q(z) on the latent variables. This is referred\\nto as the variational distribution or the variational posterior for rea-\\nsons that will be made clear later. As we will see, computatio n of the\\nELBO requires an average over distribution q(z), which can be ﬁxed\\nindependently of the model parameters. This solves the key p roblem\\nidentiﬁed above of averaging over the parameter-dependent marginal\\nof the hidden variables.\\nDeﬁnition 6.1. F or any ﬁxed value x and any distribution q(z) on'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 145, 'page_label': '140', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='identiﬁed above of averaging over the parameter-dependent marginal\\nof the hidden variables.\\nDeﬁnition 6.1. F or any ﬁxed value x and any distribution q(z) on\\nthe latent variables z (possibly dependent on x), the ELBO L(q,θ) is\\ndeﬁned in one of the following equivalent forms\\nL(q,θ) =E z∼q(z)[ln p(x,z|θ) −ln q(z)\\ued19\\n\\ued18\\ued17 \\ued1a\\nlearning signal\\n] (6.10)\\n= E z∼q(z)[ln p(x,z|θ)]\\n\\ued19 \\ued18\\ued17 \\ued1a\\nnegative energy\\n+ H(q)\\ued19 \\ued18\\ued17 \\ued1a\\nentropy\\n(6.11)\\n= E z∼q(z)[ln p(x|z,θ)]\\n\\ued19 \\ued18\\ued17 \\ued1a\\ncross-entropy\\n− KL ( q(z)||p(z|θ))\\ued19 \\ued18\\ued17 \\ued1a\\nvariational regularization\\n(6.12)\\n= −KL ( q(z)||p(x,z|θ)) (6.13)\\n= ln p(x|θ) −KL ( q(z)||p(z|x,θ)) , (6.14)\\nwhere we have identiﬁed some terms using common terminology that\\nwill be clariﬁed in the following, and, in ( 6.13), we have used the con-\\nvention of deﬁning KL( p||q) even when q is not normalized (see Sec.\\n2.6).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 146, 'page_label': '141', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 141\\nThe equivalence between the three forms of the ELBO can be eas -\\nily checked. The form ( 6.11) justiﬁes the deﬁnition of the negative of\\nthe ELBO as variational free energy or Gibbs free energy , which is the\\ndiﬀerence of energy and entropy . This form is particularly u seful for\\nundirected models in which one speciﬁes directly the joint d istribution\\np(x,z|θ), such as energy-based models, while the form ( 6.12) is espe-\\ncially well suited for directed models that account for the d iscriminative\\ndistribution p(x|z,θ), such as for deep neural networks [ 27]. F or both\\nforms the ﬁrst term can be interpreted as a cross-entropy los s. The\\nform ( 6.13) is more compact, and suggests that, as we will formalize\\nbelow, the ELBO is maximized when q(z) is selected to match the\\nmodel distribution. The last form yields terms that are gene rally not\\neasily computable, but it illuminates the relationship bet ween the LL\\nfunction and the ELBO, as we discuss next.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 146, 'page_label': '141', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='model distribution. The last form yields terms that are gene rally not\\neasily computable, but it illuminates the relationship bet ween the LL\\nfunction and the ELBO, as we discuss next.\\nThe following theorem describes the deﬁning property of the ELBO\\nas well as another important property . T aken together, thes e features\\nmake the ELBO uniquely suited for the development of algorit hmic\\nsolutions for problem ( 6.7).\\nTheorem 6.1. The ELBO is a global lower bound on the LL function,\\nthat is,\\nln p(x|θ) ≥L(q,θ), (6.15)\\nwhere equality holds at a value θ0 if and only if the distribution q(z)\\nsatisﬁes q(z) = p(z|x,θ0 ). F urthermore, the ELBO is concave in q(z)\\nfor a ﬁxed θ; and, if ln p(x,z|θ) is concave in θ, it is also concave in θ\\nfor a ﬁxed q(z).\\nProof. The ﬁrst part of the theorem follows immediately from the for m\\n(6.14), which we can rewrite as\\nln p(x|θ) = L(q,θ)+KL ( q(z)||p(z|x,θ)) , (6.16)\\nand from Gibbs’ inequality . In fact, the latter implies that the KL di-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 146, 'page_label': '141', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='(6.14), which we can rewrite as\\nln p(x|θ) = L(q,θ)+KL ( q(z)||p(z|x,θ)) , (6.16)\\nand from Gibbs’ inequality . In fact, the latter implies that the KL di-\\nvergence KL ( q(z)||p(z|x,θ)) is non-negative and equal to zero if and\\nonly if the two distributions in the argument are equal. The c oncavity\\nof the ELBO can be easily checked using standard properties o f con-\\nvex functions [ 28]. As a note, an alternative proof of the ﬁrst part of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 147, 'page_label': '142', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='142 Unsupervised Learning\\nthe theorem can be provided via the importance sampling tric k and\\nJensen’s inequality . In fact, we can write\\nln p(x|θ) = ln\\n( ∑\\nz\\np(x,z|θ)\\n)\\n(6.17a)\\n= ln\\n( ∑\\nz\\nq(z) p(x,z|θ)\\nq(z)\\n)\\n(6.17b)\\n≥\\n∑\\nz\\nq(z) ln\\n( p(x,z|θ)\\nq(z)\\n)\\n= L(q,θ), (6.17c)\\nwhere the ﬁrst equality is just obtained by multiplying and d ividing\\nby q(z) – the importance sampling trick – and the last step is a conse -\\nquence of Jensen’s inequality . W e recall that Jensen’s ineq uality says\\nthat for any concave function f(x) – here f(x) = ln( x) – we have the\\ninequality E[ f(x)] ≤f(E[x]).\\nW e illustrate the just described properties of the ELBO via t he\\nfollowing example.\\nExample 6.2. Consider again the directed generative Bernoulli-Gaussia n\\nmodel (\\n6.9). The posterior distribution of the latent variable given a n\\nobservation x is given as\\np(z= 1 |x= 0 ,θ) = N(0|θ,1)\\nN(0|2,1) + N(0|θ,1) . (6.18)\\nFix a parametrized variational distribution q(z|ϕ) = Bern( z|ϕ). Using'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 147, 'page_label': '142', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='observation x is given as\\np(z= 1 |x= 0 ,θ) = N(0|θ,1)\\nN(0|2,1) + N(0|θ,1) . (6.18)\\nFix a parametrized variational distribution q(z|ϕ) = Bern( z|ϕ). Using\\n(6.11), the ELBO is then given as\\nL(q,θ) = ϕ(ln(N(0|θ,1)+ln(0.5))+(1−ϕ)(ln(N(0|2,1)+ln(0.5))+H(q).\\n(6.19)\\nThe theorem above says that, given any value of ϕ, the ELBO is a lower\\nbound on the LL function, uniformly for all values of θ. F urthermore,\\nthis bound is tight. i.e., it equals the LL function, at all va lues θ0 for\\nwhich the selected variational distribution q(z|ϕ) equals the posterior of\\nthe hidden variables, that is, for which we have ϕ= p(z= 1 |x= 0 ,θ0 ).\\nThis is shown in Fig. 6.3, where we plot the LL and the ELBO. W e see\\nthat indeed the ELBO is a uniform lower bound on the LL, which i s'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 148, 'page_label': '143', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 143\\ntight for speciﬁc values θ0 of the parameter θ. Reﬂecting the concavity\\nproperty of the ELBO in the theorem, the ELBO is also seen to be a\\nconcave function of the parameter θ.\\n-4 -3 -2 -1 0 1 2 3 4\\n-5\\n-4.5\\n-4\\n-3.5\\n-3\\n-2.5\\n-2\\n-1.5Log-likelihood\\nNLL\\nELBO ( 0=  3)\\nELBO ( 0 =  2)\\nFigure 6.3: Illustration of the ELBO for two diﬀerent choices of the vari ational\\ndistribution that are tight at diﬀerent values θ0 of the parameter.\\nThe lower bound property of the ELBO makes it useful not only\\nfor the purpose of ML optimization but also as an estimate of L L, and\\nhence of how well the model ﬁts the data, for the goal of model s election.\\nF urthermore, the ELBO can be computed analytically in speci al cases\\nfor exponential models [ 151, 159].\\nThe ELBO can be generalized as the multi-sample ELBO [32]:\\nln p(x|θ) ≥Ez1 ,...,zK ∼\\ni.i.d.\\nq(z)\\n[\\nln\\n(\\n1\\nK\\nK∑\\nk=1\\np(x,zk |θ)\\nq(zk )\\n)]\\n. (6.20)\\nThe proof of this inequality follows in the same way as for the ELBO.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 148, 'page_label': '143', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ln p(x|θ) ≥Ez1 ,...,zK ∼\\ni.i.d.\\nq(z)\\n[\\nln\\n(\\n1\\nK\\nK∑\\nk=1\\np(x,zk |θ)\\nq(zk )\\n)]\\n. (6.20)\\nThe proof of this inequality follows in the same way as for the ELBO.\\nThis bound has the advantage that, as K grows large, it tends to be-\\ncome increasingly accurate. In fact, as K →∞, by the law of large\\nnumbers, we have the limit K−1 ∑ K\\nk=1 p(x,zk |θ)/q(zk ) →∑\\nz p(x,z|θ)\\nwith probability one.\\nELBO and Bayesian inference. In summary , for a given vari-\\national distribution q(z), the ELBO provides an upper bound on the\\nLL function, or equivalently a lower bound on the NLL functio n. This'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 149, 'page_label': '144', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='144 Unsupervised Learning\\nbound is tight for values of the parameter vectors θ at which we have\\nthe equality q(z) = p(z|x,θ). As such, given a certain value θ of the\\nparameter vector, the variational distribution q(z) that provides the\\ntightest bound is the posterior distribution q(z) = p(z|x,θ), at which\\nthe KL divergence in ( 6.16) vanishes. That is, in order to obtain the\\ntightest ELBO, one needs to solve the Bayesian inference pro blem of\\ncomputing the posterior p(z|x,θ) of the hidden variables for the given\\nvalue θ. This property can be stated for reference as follows\\nargmax\\nq(z)\\nL(q,θ) = p(z|x,θ). (6.21)\\nGradients of the LL and of the ELBO over the model\\nparameters.∗ Under suitable diﬀerentiability assumptions, the gradi-\\nent of the ELBO at the value θ0 in which the ELBO is tight coincides\\nwith the gradient of the LL, i.e.,\\n∇θ ln p(x|θ)|θ=θ0 = ∇θ L(p(z|x,θ0 ),θ) |θ=θ0\\n= E z∼p(z|x,θ0) [∇θ ln p(x,z|θ)|θ=θ0 ] . (6.22)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 149, 'page_label': '144', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ent of the ELBO at the value θ0 in which the ELBO is tight coincides\\nwith the gradient of the LL, i.e.,\\n∇θ ln p(x|θ)|θ=θ0 = ∇θ L(p(z|x,θ0 ),θ) |θ=θ0\\n= E z∼p(z|x,θ0) [∇θ ln p(x,z|θ)|θ=θ0 ] . (6.22)\\nThis is also suggested by the curves in Fig. 6.3. W e will see with an\\nexample in Sec. 6.5.1 that this formula is extremely useful when the\\ngradient for the complete log-likelihood ∇θ ln p(x,z|θ)|θ=θ0 can be easily\\ncomputed, such as for exponential family models.\\nOther global lower bounds on the likelihood. ∗ Revisiting the\\nproof of Theorem 6.1, it can be concluded that the following general\\nfamily of lower bounds\\nf(p(x|θ)) ≥Ez∼q(z)\\n[\\nf\\n( p(x,z|θ)\\nq(z)\\n)]\\n, (6.23)\\nfor any concave function f. While the ELBO equals the negative of a KL\\ndivergence between variational distribution and the true d istribution,\\nas seen in ( 6.13), this representation yields more general divergence\\nmeasures, such as the α-divergence to be discussed in Chapter 8 [ 90,\\n13, 159].\\n6.3.3 EM Algorithm'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 149, 'page_label': '144', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as seen in ( 6.13), this representation yields more general divergence\\nmeasures, such as the α-divergence to be discussed in Chapter 8 [ 90,\\n13, 159].\\n6.3.3 EM Algorithm\\nAs mentioned, a large number of practical schemes for unsupe rvised\\nlearning using directed and undirected generative models a re based on'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 150, 'page_label': '145', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 145\\n•Initialize parameter vector θold.\\n•E step: F or ﬁxed parameter vector θold, maximize the ELBO over\\nthe variational distribution q, i.e., solve problem maxq L(q,θold), which,\\nby ( 6.21), yields the new distribution\\nqnew(z) = p(z|x,θold). (6.24)\\n•M step: F or ﬁxed variational distribution qnew(z), maximize the\\nELBO over the parameter vector θ, i.e., solve problem max\\nθ\\nL(qnew,θ).\\nThis convex problem can be equivalently written as the maxim ization\\nof the negative energy\\nmax\\nθ\\nQ(θ,θold) =E z∼p(z|x,θold) [ln p(x,z|θ)] . (6.25)\\n•If a convergence criterion is not satisﬁed, set θnew ←θoldand return\\nto the E step.\\nT able 6.1: EM algorithm.\\nthe maximization of ELBO L(q,θ) in lieu of the LL function. As seen,\\nthis maximization has the key advantage that the ELBO is a con cave\\nfunction of the parameters θ. F urthermore, the lower bound property\\n(6.15) ensures that, if the ELBO is tight at a value θ0, the result of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 150, 'page_label': '145', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function of the parameters θ. F urthermore, the lower bound property\\n(6.15) ensures that, if the ELBO is tight at a value θ0, the result of\\nthe optimization of the ELBO must necessarily yield a LL valu e that\\nis no smaller than ln p(x|θ0 ). This observation is leveraged by the EM\\nalgorithm to obtain a procedure that is guaranteed to conver ge to a\\nstationary point of the original ML problem ( 6.7).\\nThe EM algorithm is described in T able 6.1.\\nIn many problems of interest, the model p(x,z|θ) can be taken to be\\neither the product of a prior and a likelihood from the expone ntial fam-\\nily for directed models, or directly a member of the exponent ial family\\nfor undirected models. In these cases, the problem (\\n6.25) solved in the\\nM step will be seen below via an example to reduce to the corres pond-\\ning supervised learning problem, with the caveat that the su ﬃcient\\nstatistics are averaged over the posterior distribution p(z|x,θold).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 150, 'page_label': '145', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ing supervised learning problem, with the caveat that the su ﬃcient\\nstatistics are averaged over the posterior distribution p(z|x,θold).\\nThe EM algorithm is an instance of the more general Majorizat ion'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 151, 'page_label': '146', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='146 Unsupervised Learning\\nMinimization (MM) algorithm [ 141]. In this class of algorithms, at each\\niteration, one constructs a tight lower bound of the objecti ve function\\nat the current iterate θold. This bound, which should be easy to max-\\nimize, is then optimized, yielding the new iterate θnew. The process is\\nillustrated in Fig. 6.4. As it can be seen, at each iteration one is guar-\\nanteed that the objective function is not decreased, which e nsures con-\\nvergence to a local optimum of the original problem. In EM, th e tight\\nlower bound is the ELBO L(qnew,θ), which is obtained by computing\\nthe posterior distribution of the latent variables qnew(z) = p(z|x,θold )\\nat the current iterate θold.\\n...\\nLL\\nnewold\\nFigure 6.4: Illustration of the EM algorithm. The dashed line is the LL fu nction.\\nThe solid lines represent the ELBOs corresponding to the ﬁrs t two steps of the\\nalgorithm, while the dashed-dotted line is the ELBO after a n umber of iterations.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 151, 'page_label': '146', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The solid lines represent the ELBOs corresponding to the ﬁrs t two steps of the\\nalgorithm, while the dashed-dotted line is the ELBO after a n umber of iterations.\\nAt each step, EM maximizes the ELBO, which is a lower bound on t he LL function.\\nEM is an instance of the more general MM approach [ 141].\\nGeneralizing the K-means algorithm, the EM algorithm alternates\\nbetween: ( i ) making inferences about the hidden variables z based on\\nthe model deﬁned by the current iterate of the model paramete r θ\\nin the E step; and ( ii ) updating the model θ to match the data x\\nand the inferred variables z in the M step. It is useful to emph asize'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 152, 'page_label': '147', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.3. ML, ELBO and EM 147\\nthat unsupervised learning, even in the assumed frequentis t approach,\\nentails the Bayesian inference problem of evaluating the po sterior of\\nthe hidden variables.\\nGeneralization to N observ ations. W e conclude this section by\\nmaking explicit the generalization of the EM algorithm to th e case in\\nwhich we have N i.i.d. observations. T o elaborate, assume that we have\\npairs of observed/ unobserved i.i.d. variables (x n ,zn), whose assumed\\njoint distribution can be written as p(xN ,zN |θ) = ∏ N\\nn=1 p(xn,zn |θ).\\nE step : The E step requires the computation of the posterior p(zN |xN ,θ).\\nThis can be seen to factorize across the examples, since we ha ve\\np(zN |xN ,θ) = p(xN ,zN |θ)\\np(xN |θ) =\\nn∏\\nn=1\\np(xn,zn |θ)\\np(xn|θ)\\n=\\nn∏\\nn=1\\np(zn |xn,θ). (6.26)\\nTherefore, in order to compute the posterior, we can operate separately\\nfor each example in the data set by evaluating p(zn|xn ,θ) for all n =\\n1,...,N .\\nM step : In a similar manner, the negative energy function Q(θ,θold)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 152, 'page_label': '147', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for each example in the data set by evaluating p(zn|xn ,θ) for all n =\\n1,...,N .\\nM step : In a similar manner, the negative energy function Q(θ,θold)\\nto be used in the M step can be computed separately for each example\\nas\\nQ(θ,θold) = E zN ∼p(zN |xN ,θold)\\n[\\nln p(xN ,zN |θ)\\n]\\n=\\nN∑\\nn=1\\nEzn ∼p(zn |xn ,θold) [ln p(xn,zn |θ)] , (6.27)\\nand hence separately for each example. Note that the optimiz ation in\\nthe M step should instead be done jointly on ( 6.27).\\nExtensions.∗ The EM algorithm solves the non-convexity prob-\\nlem identiﬁed at the beginning of this section by optimizing ELBOs\\niteratively according to the outlined MM mechanism. Nevert heless, im-\\nplementing the EM algorithm may be too computationally dema nding\\nin practice. In fact, the E step requires to compute the poste rior dis-\\ntribution of the latent variables, which may be intractable when the\\nlatent space is large; and the M step entails an average over t he poste-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 152, 'page_label': '147', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tribution of the latent variables, which may be intractable when the\\nlatent space is large; and the M step entails an average over t he poste-\\nrior distribution, which can also be intractable. In Chapte r 8, we will'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 153, 'page_label': '148', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='148 Unsupervised Learning\\nsee approaches to overcome these problems via approximate i nference\\nand learning techniques. F or extensions of EM algorithm, we refer to\\n[15, pp. 247-248]. In this regard, it is observed here that the EM al-\\ngorithm applies also to scenarios in which diﬀerent data poi nts have\\ngenerally diﬀerent subsets of unobserved variables.\\n6.4 Directed Generative Models\\nIn this section, we discuss directed generative models, in w hich, as seen\\nin Fig.\\n6.1(a), one posits a parametrized prior p(z|θ) of the latent vari-\\nables z and a parametrized conditional decoding distributi on p(x|z,θ).\\nAs discussed, the goal can be that of learning the distributi on p(x) of\\nthe true data or to extract useful features z. In the latter ca se, the use\\nof directed generative model is referred to as performing analysis by\\nsynthesis. W e ﬁrst discuss two prototypical applications of EM to per-\\nform ML learning. W e then outline an alternative approach, k nown as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 153, 'page_label': '148', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='synthesis. W e ﬁrst discuss two prototypical applications of EM to per-\\nform ML learning. W e then outline an alternative approach, k nown as\\nGAN, which can be thought of as a generalization of ML. Accord ingly ,\\nrather than selecting a priori the KL divergence as a perform ance met-\\nric, as done implicitly by ML, GANs learn at the same time dive rgence\\nand generative model.\\nMulti-layer extensions of generative directed models disc ussed here\\nfall in the category of Helmholtz machines. W e refer to, e.g. , [ 42], for a\\ndiscussion about the task of training these networks via an a pproxima-\\ntion of the EM algorithm, which uses tools covered in Chapter 8.\\n6.4.1 Mixture of Gaussians Model\\nThe mixture of Gaussians model can be described by the follow ing\\ndirected generative model\\nzn ∼Cat(π) (6.28a)\\nxn|zn = k∼N(µk ,Σ k ), (6.28b)\\nwith parameter vector θ = [ π,µ0 ,...,µK −1,Σ 0,...,Σ K −1 ]. W e use one-\\nhot encoding for the categorical variables zn = [ z0n ,...,z(K −1)n ]T .Note'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 153, 'page_label': '148', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='xn|zn = k∼N(µk ,Σ k ), (6.28b)\\nwith parameter vector θ = [ π,µ0 ,...,µK −1,Σ 0,...,Σ K −1 ]. W e use one-\\nhot encoding for the categorical variables zn = [ z0n ,...,z(K −1)n ]T .Note\\nthat this model can be thought as an unsupervised version of t he QDA\\nmodel for the fully observed, or supervised, case studied in Sec. 4.6'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 154, 'page_label': '149', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.4. Directed Generative Models 149\\n(cf. ( 4.44)). W e will see below that the EM algorithm leverages this\\nobservation in the M step. F urthermore, it will be observed t hat EM\\nfor mixture of Gaussians generalizes the K-means algorithm.\\nE step . In the E step, as per ( 6.26), we need to solve the inference\\nproblem of computing the posterior p(zkn |xn,θold) for every example n\\nand cluster index k= 0 ,...,K −1. In this case, this can be done directly\\nvia Bayes’ theorem since the normalization requires to sum o nly over\\nthe K possible values taken by z n, yielding\\np(zkn = 1 |xn ,θold) = πold\\nk N(xn |µold\\nk ,Σ old\\nk )\\n∑ K −1\\nj=0 πold\\nj N(xn|µold\\nj ,Σ old\\nj )\\n. (6.29)\\nM step . In the M step, we need to maximize the negative energy\\nfunction Q(θ,θold) in (\\n6.27). Each term in the sum can be computed\\ndirectly as\\nEzn ∼p(zn |xn ,θold) [ln p(xn,zn |θ)] =\\nK −1∑\\nk=0\\n¯zkn {ln πk + ln N(xn|µk ,Σ k )}\\n(6.30)\\nwith\\n¯zkn = Ezn ∼p(zn |xn ,θold) [zkn ] = p(zkn = 1 |xn,θold). (6.31)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 154, 'page_label': '149', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='directly as\\nEzn ∼p(zn |xn ,θold) [ln p(xn,zn |θ)] =\\nK −1∑\\nk=0\\n¯zkn {ln πk + ln N(xn|µk ,Σ k )}\\n(6.30)\\nwith\\n¯zkn = Ezn ∼p(zn |xn ,θold) [zkn ] = p(zkn = 1 |xn,θold). (6.31)\\nAs it can be easily checked, the function Q(θ,θold) equals the LL func-\\ntion of the QDA supervised problem, in which the variables zn are\\nobserved, with the following caveat: the suﬃcient statisti cs zkn are\\nreplaced by their posterior averages ¯zkn . As a result, as opposed to su-\\npervised learning, EM describes each example xn as being part of all\\nclusters, with the “responsibility” of cluster k being given by ¯zkn . Hav-\\ning made this observation, we can now easily optimize the Q(θ,θold)\\nfunction by using the ML solutions ( 4.45) for QDA by substituting ¯zkn\\nfor the observed variable tkn .\\nSetting Σ k = ǫI as a known parameter and letting ǫ →0 recovers\\nthe K-means algorithm [ 23, p. 443].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 155, 'page_label': '150', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='150 Unsupervised Learning\\n-5 0 5\\n0\\n0.05\\n0.1\\n0.15\\n0.2\\n0.25\\n0.3\\n0.35\\nFigure 6.5: T rue distribution (dashed line) and mixture of Gaussians mo del learned\\nvia EM (solid line).\\nExample 6.3. Consider data generated from the multi-modal distribu-\\ntion shown in Fig. 6.5 as a dashed line, which obtained as a mixture\\nof two Gaussians and an exponential distribution. When M = 1 , the\\nmixture of Gaussians distribution learned via EM correspon ds to the\\nconventional ML estimate, and is hence obtained via moment m atching\\n(see Chapter 3). This is plotted in the ﬁgure for a given data r ealiza-\\ntion with N = 100 . Running EM with the larger values M = 2 and\\nM = 3 also returns the same distribution. This distribution is se en to\\nbe inclusive of the entire support of the true distribution a nd to smooth\\nout the edges of the original distribution. As we will furthe r discuss in\\nSec. 6.4.3, this is a consequence of the fact that ML minimizes the KL\\ndivergence over the second argument.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 155, 'page_label': '150', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='out the edges of the original distribution. As we will furthe r discuss in\\nSec. 6.4.3, this is a consequence of the fact that ML minimizes the KL\\ndivergence over the second argument.\\nA similar model that applies to binary data, rather than cont inu-\\nous data, such as black-and-white images, is the mixture of B ernoullis\\nmodel. The EM algorithm can be derived by following the same s teps\\ndetailed here [ 23].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 156, 'page_label': '151', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.4. Directed Generative Models 151\\n6.4.2 Probabilistic Principal Component Analysis\\nProbabilistic Principal Component Analysis (PPCA) is a pop ular gen-\\nerative model that describes the data in terms of M <D features that\\nare linearly related to the data vector. Speciﬁcally , PPCA u ses a linear\\nfactor generative model with M <D features described as\\nzn ∼N(0,I) (6.32a)\\nxn|zn = z∼N(Wz + µ,σ2I), (6.32b)\\nwith parameter vector θ= ( W µ σ). Equivalently , according to PPCA,\\nthe data vector can be written as\\nxn = Wzn + µ+ q n, (6.33)\\nwith the latent variables zn ∼ N(0,I) and the additive noise qn ∼\\nN(0,σ2 I). According to (\\n6.33), the columns {wk }of the matrix W =\\n[w1 w2 ···wM ] can be interpreted as linear features of the data. This is\\nin the sense that each data point is written as a linear combin ation of\\nthe feature vectors as\\nxn =\\nM∑\\nm=1\\nwmzmn + µ+ q n, (6.34)\\nwhere zmn is the mth component of the latent vector zn .\\nIn the models studied above, the latent variable was a catego rical'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 156, 'page_label': '151', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the feature vectors as\\nxn =\\nM∑\\nm=1\\nwmzmn + µ+ q n, (6.34)\\nwhere zmn is the mth component of the latent vector zn .\\nIn the models studied above, the latent variable was a catego rical\\nidentiﬁer of the class of the observation. As such, In PPCA, i nstead,\\nthe representation of an observation xn in the hidden variable space\\nis distributed across all the variables in vector zn. This yields a more\\neﬃcient encoding of the hidden representation. This is part icularly clear\\nin the case discrete hidden rv, which will be further discuss ed in Sec.\\n6.5.1 (see also [ 20]).\\nAn EM algorithm can be devised to learn the parameter vector a s\\ndescribed in [ 23, p. 577]. The E step leverages the known result that\\nthe posterior of the latent variables can be written as\\nzn|xn = xn,θ ∼N(zn |J−1 WT (xn −µ),J−1 ), (6.35)\\nwith matrix J = σ−2WT W + I.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 157, 'page_label': '152', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='152 Unsupervised Learning\\nW e note that, if we model the latent variables zkn , k = 1 ,...,M ,\\nare independent but not Gaussian, we obtain a type of Indepen dent\\nComponent Analysis (ICA) (see [ 23, p. 591]). It is also possible to\\nimpose structure on the latent vector by selecting suitable marginal\\ndistributions p(z). F or instance, choosing Student’s t-distribution or a\\nLaplace distribution tends to impose sparsity on the learne d model. A\\ngeneral discussion on linear factor models can be found in [ 104] (see\\nalso [ 36] for a generalization of PPCA to any model in the exponential\\nfamily).\\n6.4.3 GAN\\nIn Sec.\\n2.6, we have seen that ML can be interpreted, in the asymptotic\\nregime of a large data set N, as minimizing the KL divergence between\\nthe true distribution of the data and the model. W e start this section by\\nrevisiting this argument for unsupervised learning in orde r to highlight\\na similar interpretation that holds for ﬁnite values of N. This viewpoint'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 157, 'page_label': '152', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='revisiting this argument for unsupervised learning in orde r to highlight\\na similar interpretation that holds for ﬁnite values of N. This viewpoint\\nwill lead us to generalize the ML learning approach to techni ques in\\nwhich the choice of the divergence measure is adapted to the d ata. As an\\nimportant by-product, the resulting technique, known as GA N, will be\\nseen to accommodate easily likelihood-free models. GANs ar e currently\\nconsidered to yield state-of-the-art results for image gen eration [ 57].\\nT o simplify the discussion, assume that variables xn are categorical\\nand take a ﬁnite number of values. T o start, let us observe tha t the\\nNLL function ( 6.1) for i.i.d. data can be written as\\n−1\\nN\\nN∑\\nn=1\\nlnp(xn|θ) = −\\n∑\\nx\\nN[x]\\nN lnp(x|θ), (6.36)\\nwhere we recall that N[x] = |{n : xn = x}|. W e now note that the\\nML problem of minimizing the NLL ( 6.36) over θ is equivalent to the\\nminimization of the KL divergence\\nmin\\nθ\\n−\\n∑\\nx\\npD (x)lnp(x|θ) +\\n∑\\nx\\npD (x)lnpD (x)\\n=min\\nθ'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 157, 'page_label': '152', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ML problem of minimizing the NLL ( 6.36) over θ is equivalent to the\\nminimization of the KL divergence\\nmin\\nθ\\n−\\n∑\\nx\\npD (x)lnp(x|θ) +\\n∑\\nx\\npD (x)lnpD (x)\\n=min\\nθ\\nKL(pD (x)||p(x|θ)), (6.37)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 158, 'page_label': '153', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.4. Directed Generative Models 153\\nwhere we have deﬁned the empirical distribution\\npD (x) = N[x]\\nN . (6.38)\\nW e hence conclude the ML attempts to minimize the KL divergen ce\\nbetween the empirical distribution pD (x) of the data and the model\\ndistribution p(x|θ). The ML problem min θ KL(pD (x)||p(x|θ)) is also\\nknown as the M-projection of the data distribution pD (x) into the\\nmodel {p(x|θ)}[40] (see Chapter 8 for further discussion).\\nThe KL divergence ( 6.37) is a measure of the diﬀerence between\\ntwo distribution with speciﬁc properties that may not be tai lored to\\nthe particular application of interest. F or instance, dist ributions ob-\\ntained by minimizing ( 6.37) tend to provide “blurry” estimates of the\\ndistribution of the data distribution, as we have seen in Fig . 6.5. As\\na result, learning image distributions using M-projection s is known to\\ncause the learned model to produce unfocused images [ 57].\\nThe KL divergence is not, however, the only measure of the diﬀ er-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 158, 'page_label': '153', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a result, learning image distributions using M-projection s is known to\\ncause the learned model to produce unfocused images [ 57].\\nThe KL divergence is not, however, the only measure of the diﬀ er-\\nence between two distributions. As discussed in more detail in Appendix\\nA, the KL divergence is in fact part of the larger class of f-divergences\\nbetween two distributions p(x) and q(x). This class includes divergence\\nmeasures deﬁned by the variational expression 1\\nDf (p||q) = max\\nT (x)\\nEx∼p[T(x)] −Ex∼q [g(T(x))], (6.39)\\nfor some concave increasing function g(·) (the meaning of the f sub-\\nscript is discussed in Appendix A). The key new element in ( 6.39) is\\nthe decision rule T(x), which is also known as discriminator or critic.\\nThis function takes as input a sample x and ideally outputs a large\\nvalue when xis generated from distribution p, and a small value when\\nit is instead generated from q. Optimizing over T(x) hence ensures that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 158, 'page_label': '153', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='value when xis generated from distribution p, and a small value when\\nit is instead generated from q. Optimizing over T(x) hence ensures that\\nthe right-hand side of ( 6.39) is large when the two distributions are dif-\\nferent and hence can be distinguished based on the observati on of x.\\nWhen the domain over which the discriminator T(x) is optimized is left\\nunconstrained, solving problem ( 6.39) recovers the KL divergence and\\n1 The term variational refers to the fact that the deﬁnition in volves an optimiza-\\ntion.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 159, 'page_label': '154', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='154 Unsupervised Learning\\nthe Jensen-Shannon divergence, among others, with speciﬁc choices of\\nfunction g (see Appendix A). 2\\nGeneralizing the ML problem ( 6.37), GANs attempt to solve the\\nproblem\\nmin\\nθ\\nDf (pD (x)||p(x|θ)). (6.40)\\nMore precisely , GANs parametrize the discriminator T(x) by choosing a\\ndiﬀerentiable function Tϕ(x) of the parameter vector ϕ. This eﬀectively\\nreduces the search space for the discriminator, and deﬁnes a diﬀerent\\ntype of divergence for each value of ϕ. A typical choice for Tϕ (x) is the\\noutput of a multi-layer neural network with weights ϕ or a function\\nthereof (see Sec. 4.5). With this in mind, using ( 6.39) in ( 6.40), we\\nobtain the minimax problem solved by GANs 3\\nmin\\nθ\\nmaxϕ Ex∼pD [Tϕ (x)] −Ex∼p(x|θ)[g(Tϕ (x))]. (6.41)\\nAccording to ( 6.41), GANs select the divergence measure adaptively\\nthrough the optimization of the discriminator Tϕ(x). Problem ( 6.41)\\ncan also be interpreted in terms of a strategic game played by generator\\nand discriminator [ 57].4'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 159, 'page_label': '154', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='through the optimization of the discriminator Tϕ(x). Problem ( 6.41)\\ncan also be interpreted in terms of a strategic game played by generator\\nand discriminator [ 57].4\\nThe original GAN method [ 57] operates by setting Tϕ(x) = ln Dϕ (x),\\nwhere Dϕ(x) is the output of a multi-layer perceptron, and g(t) =\\n−log(1 −exp(t)). A variation that is shown to be more useful in prac-\\ntice is also discussed in the ﬁrst GAN paper (see [ 49]). As another\\npopular example, W asserstein GAN simply sets Tϕ(x) to be the output\\nof a multi-layer perceptron and chooses g(t) = −(1 −t).\\nApplication to likelihood-free models. ∗ GANs are typically\\nused with likelihood-free models. Accordingly , the model d istribution\\np(x|θ) is written as\\np(x|θ) =\\n∫\\nδ(x−Gθ (z))N(z|0,I)dz. (6.42)\\n2 F or a given function T (x), the right-hand side of ( 6.39), excluding the maxi-\\nmization, provides a lower bound on the divergence Df (p||q). Another useful related'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 159, 'page_label': '154', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='∫\\nδ(x−Gθ (z))N(z|0,I)dz. (6.42)\\n2 F or a given function T (x), the right-hand side of ( 6.39), excluding the maxi-\\nmization, provides a lower bound on the divergence Df (p||q). Another useful related\\nbound for the KL divergence is the so-called Donsker-V aradh an representation (see,\\ne.g., [ 18]).\\n3 The version of GAN given here is known as f -GANs [ 107], which is a general-\\nization of the original GAN.\\n4 It is noted that the GAN set-up is reminiscent of the adversar ial model used\\nto deﬁne semantic security in cryptography .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 160, 'page_label': '155', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.5. Undirected Generative Models 155\\nThe samples x are hence modelled as the output of a generator function\\nGθ (z), whose input z is given by i.i.d. Gaussian variables. This gener-\\native model can hence be interpreted as a generalization of P PCA to\\nnon-linear encoders Gθ (z). The latter is conventionally modelled again\\nas a multi-layer neural network.\\nProblem ( 6.41) is typically tackled using SGD (Chapter 4) by iterat-\\ning between the optimization of the generator parameters θ and of the\\ndiscriminator parameters ϕ (see [ 8, Algorithm 1]). Learning requires\\nempirical approximations for the evaluation of the gradien ts that will\\nbe discussed in Chapter 8.\\nLikelihood ratio estimation viewpoint. ∗ When no constraints\\nare imposed over the discriminator T(x) in ( 6.39) and the function g\\nis selected as g(t) = exp( t−1), the optimal solution is given as T(x) =\\n1 + ln( pD (x)/p(x|θ)) and the corresponding divergence measure ( 6.39)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 160, 'page_label': '155', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is selected as g(t) = exp( t−1), the optimal solution is given as T(x) =\\n1 + ln( pD (x)/p(x|θ)) and the corresponding divergence measure ( 6.39)\\nis the KL divergence KL (pD (x)||p(x|θ)). Therefore, solving problem\\n(6.39) over a suﬃciently general family of functions Tϕ(x) allows one\\nto obtain an estimate of the log-likelihood ratio ln(pD (x)/p(x|θ)). As\\na result, GANs can be interpreted as carrying out the estimat ion of\\nlikelihood ratios between the data and the model distributi ons as a\\nstep in the learning process. The idea of estimating likelih ood ratios in\\norder to estimate KL divergences is useful in other learning problems\\nbased on variational inference, to be discussed in Chapter 8 (see [ 70]).\\nSome research topics. ∗ Among topics of current research, we\\nmention here the problem of regularization of GANs [ 123]. W e also note\\nthat GANs can also be extended to supervised learning proble ms [ 108].\\nThe GAN approach of formulating the divergence as an optimiz ation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 160, 'page_label': '155', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='that GANs can also be extended to supervised learning proble ms [ 108].\\nThe GAN approach of formulating the divergence as an optimiz ation\\nover a discriminator function was also recently found to be u seful for\\nICA [ 29].\\n6.5 Undirected Generative Models\\nUnlike directed generative models, undirected generative models posit\\na joint distribution for the hidden and the observed variabl es that cap-\\ntures aﬃnity , rather than causality , relationships betwee n the two sets\\nof variables, as seen in Fig.\\n6.1(b). In this section, we discuss a repre-\\nsentative example of undirected generative models that is c onsidered'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 161, 'page_label': '156', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='156 Unsupervised Learning\\nto be a powerful tool for a number of applications, including feature se-\\nlection, generation of new samples, and even recommendatio n systems\\n[127]. The model, known as RBM, also ﬁnds application as a compo-\\nnents of larger multi-layer structures, also for supervise d learning [ 64].\\n6.5.1 Restricted Boltzmann Machines (RBM)\\nRBMs are typically characterized by an M-dimensional binary hidden\\nvector z ∈{0,1}M , while the observed variables may be discrete or\\ncontinuous. Here we consider the case of binary observed var iables,\\nwhich is suitable to model, e.g., black-and-white images or positive/\\nnegative recommendations. The RBM model is deﬁned as (\\n6.3), where\\nthe joint distribution of visible and latent variables is a l og-linear model,\\nand hence part of the exponential family . Mathematically , w e have\\np(x,z|θ) = 1\\nZ(θ) exp(−E(x,z|θ)), (6.43)\\nwith the energy function given as\\nE(x,z|θ) = −aT z−bT x−xT Wz, (6.44)\\nand the partition function as Z(θ) = ∑'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 161, 'page_label': '156', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='p(x,z|θ) = 1\\nZ(θ) exp(−E(x,z|θ)), (6.43)\\nwith the energy function given as\\nE(x,z|θ) = −aT z−bT x−xT Wz, (6.44)\\nand the partition function as Z(θ) = ∑\\nx,z exp(−E(x,z|θ)).The param-\\neter vector θ includes the M ×1 vector a, the D×1 vector b and the\\nD×M matrix W.\\nThe qualiﬁer “restricted” captures the fact that the energy func-\\ntion ( 6.44) only features cross-terms that include one variable from x\\nand one from z, and not two variables from x or two from z. In other\\nwords, the model accounts for the aﬃnities between variable s in x and\\nz, but not directly between variables in either x or z [20]. F or instance,\\nif ( i,j)th entry wij of matrix W is a large positive number, variables\\nxi and zj will tend to have equal signs in order to minimize the energy\\nand hence maximize the probability; and the opposite is true when wij\\nis negative. As we will seen in the next chapter, this type of p robabilis-\\ntic relationship can be represented by the undirected graph ical model'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 161, 'page_label': '156', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is negative. As we will seen in the next chapter, this type of p robabilis-\\ntic relationship can be represented by the undirected graph ical model\\nknown as MRF shown in Fig. 6.6.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 162, 'page_label': '157', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.5. Undirected Generative Models 157\\nFigure 6.6: An undirected graph (MRF) describing the joint distributio n prescribed\\nby the RBM model ( 6.43)-(6.44).\\nF rom the model, it is easy to compute the distribution of each\\nhidden or observed variable when conditioning on all the obs erved or\\nhidden variables, respectively . In particular, we have tha t the variables\\nin z are mutually independent when conditioned on x, and, similarly ,\\nthe variables in x are independent given z. F urthermore, the conditional\\ndistributions are given as:\\np(zj = 1 |x,θ) = σ(wT\\nj x+ aj ) (6.45a)\\np(xi = 1 |z,θ) = σ( ˜wT\\ni z+ bi), (6.45b)\\nwhere wj is the jth column of W and ˜wi is the ith row of matrix W re-\\narranged into a column vector via transposition. These rela tionships\\nreveal the signiﬁcance of the binary hidden variables z in terms of fea-\\ntures.\\nIn fact, as for PPCA, we can consider each column of matrix W\\nas a feature vector that contributes in explaining the obser vations. T o'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 162, 'page_label': '157', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tures.\\nIn fact, as for PPCA, we can consider each column of matrix W\\nas a feature vector that contributes in explaining the obser vations. T o\\nsee this, note that ( 6.45a) suggests that the jth hidden variable zj\\nequals 1 when the feature wj is well correlated with the data point x.\\nProbability ( 6.45b) also conﬁrms this interpretation, as each variable zj\\nmultiplies the ith element of the feature vector wj in deﬁning the LLR\\n˜wT\\ni z+ bi (see Sec. 3.2). F urthermore, the distributed representation of\\nthe data in terms of the binary hidden vector z is more eﬃcient than\\nthat provided by models with categorical variables such as t he mixture\\nof Gaussian model. This is in the following sense. While cate gorical\\nmodels require to learn a number of parameters that increase s linearly\\nwith the number of classes, the distributed representation with a binary\\nvector z can distinguish 2D combinations of features with a number of\\nparameters that increases only linearly with D [20].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 163, 'page_label': '158', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='158 Unsupervised Learning\\nLearning is typically done by means of an approximate SGD met hod\\nthat leverages MC techniques. Recalling the general formul a ( 3.28) for\\nthe exponential family , the gradient at the current iterati on θ = θold\\ncan be computed using ( 6.22) as\\n∇wij ln p(x|θ)|θ=θold = Ezj ∼p(zj |x,θold)[xi zj ] −Exi , zj ∼p(x, z j |θold)[xi zj ],\\n(6.46)\\nwhich can be further simpliﬁed using ( 6.45). The gradient presents the\\nstructure, noted in Chapter 3, given by the diﬀerence betwee n a positive\\ncomponent, which depends on the data x, and a negative component,\\nwhich instead requires an ensemble average over all other po ssible sam-\\nples x ∼p(x|θold). Similar relations can be written for the gradients\\nwith respect to a and b, namely\\n∇aj ln p(x|θ)|θ=θold = Ezj ∼p(zj |x,θold)[zj ] −Ezj ∼p(zj |θold)[zj ] (6.47)\\nand\\n∇bi ln p(x|θ)|θ=θold = xi −Exi ∼p(xi |θold )[xi ]. (6.48)\\nIn order to evaluate the expectations in the negative compon ents of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 163, 'page_label': '158', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and\\n∇bi ln p(x|θ)|θ=θold = xi −Exi ∼p(xi |θold )[xi ]. (6.48)\\nIn order to evaluate the expectations in the negative compon ents of\\nthe gradients, one typically uses a an MC technique known as M arkov\\nChain MC (MCMC) to be discussed in Chapter 8. More speciﬁcall y , a\\nsimpliﬁed approach known as Contrastive Divergence (CD) ha s been\\nfound to be an eﬀective approximation. Accordingly , one “cl amps” the\\nvisible variables to the observed variables x = x, and generates the\\nsequence x →z(0) →x(1) →z(1) , using the conditional probability\\n(6.45a) to generate z from x and ( 6.45b) to generate x from z. The\\nresulting samples are used to approximate the expectations as\\n∇wij ln p(x|θ)|θ=θold ≃xi z(0)\\nj −x(1)\\ni z(1)\\nj , (6.49)\\nand similar expressions apply for the other gradients. The C D scheme\\ncan also be generalized to CD- k by increasing the Markov chain se-\\nquence to k steps, and the using the resulting samples x(k) and z(k) in\\nlieu of x(1) and z(1) .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 163, 'page_label': '158', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='can also be generalized to CD- k by increasing the Markov chain se-\\nquence to k steps, and the using the resulting samples x(k) and z(k) in\\nlieu of x(1) and z(1) .\\nExtensions and application of the RBM are discussed in [\\n20, 153].\\nGeneralizations of RBMs with multiple layers of hidden vari ables are\\nreferred to as Deep Boltzmann Machines. W e refer to [ 64] for discussion\\nabout training and applications.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 164, 'page_label': '159', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.6. Discriminative Models 159\\n6.6 Discriminative Models\\nWhen the goal is learning a representation z of data x, one can try to di-\\nrectly learn a parametrized encoder, or discriminative mod el, p(z|x,θ),\\nas illustrated in Fig. 6.1(c). With an encoder p(z|x,θ), we can deﬁne\\nthe joint distribution as p(x,z|θ) = p(x)p(z|x,θ), where p(x) is the\\ntrue distribution of the data. The latter is in practice appr oximated\\nusing the empirical distribution pD (x) of the data. This yields the joint\\ndistribution\\np(x,z|θ) = pD (x)p(z|x,θ). (6.50)\\nF rom (6.50), it is observed that, unlike the frequentist methods con-\\nsidered up to now, discriminative models for unsupervised l earning are\\nbased on the deﬁnition of a single distribution over observe d and un-\\nobserved variables. As such, divergence measures, which in volve two\\ndistributions, are not relevant performance metrics. In co ntrast, a suit-\\nable metric is the mutual information between the jointly di stributed'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 164, 'page_label': '159', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='distributions, are not relevant performance metrics. In co ntrast, a suit-\\nable metric is the mutual information between the jointly di stributed\\nvariables ( x,z). The mutual information is a measure of the statistical\\ndependence between the two rvs and is introduced in Appendix A.\\nT o elaborate, a typical learning criterion is the maximizat ion of the\\nmutual information Ip(x,z|θ)(x; z) between the representation z and the\\ndata x under the joint distribution p(x,z|θ). Note that, for clarity , we\\nexplicitly indicated the joint distribution used to evalua te the mutual\\ninformation as a subscript. It can be related to the KL diverg ence as\\nIp(x,z|θ)(x; z) = KL(p(x,z|θ)||p(x)p(z)). This relationship indicates that\\nthe mutual information quantiﬁes the degree of statistical dependence,\\nor the distance from independence, for the two rvs.\\nThe resulting Information Maximization problem is given as\\nmax\\nθ\\nIpD (x)p(z|x,θ)(x; z) . (6.51)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 164, 'page_label': '159', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='or the distance from independence, for the two rvs.\\nThe resulting Information Maximization problem is given as\\nmax\\nθ\\nIpD (x)p(z|x,θ)(x; z) . (6.51)\\nAs seen, in order to avoid learning the trivial identity mapp ing, one\\nneeds to impose suitable constraints on the encoder p(z|x,θ) in order to\\nrestrict its capacity . In order to tackle problem ( 6.51), a typical solution\\nis to resort to an MM approach that is akin to the EM algorithm f or\\nML learning described above (see Fig. 6.4).\\nT o this end, as for EM, we introduce a variational distributi on\\nq(x|z), and observe that we have the following lower bound on the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 165, 'page_label': '160', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='160 Unsupervised Learning\\nmutual information 5\\nIpD (x)p(z|x,θ)(x; z) ≥H(pD (x)) + Ex,z∼pD (x)p(z|x,θ)[ln q(x|z)]. (6.52)\\nThis result follows using the same steps as for the ELBO. The b ound is\\ntight when the variational distribution q(x|z) equals the exact posterior\\np(x|z,θ) = pD (x)p(z|x,θ)/(∑\\nx pD (x)p(z|x,θ)). Based on this inequal-\\nity , one can design an iterative optimization algorithm ove r the model\\nparameters and the variational distribution q(x|z) (see, e.g., [ 3, 150]).\\nWhen the latter is constrained to lie in a parametrized famil y , the opti-\\nmization over the decoder q(x|z) is an example of variational inference,\\nwhich will be discussed in Chapter 8. The optimization over t he model\\nparameters can be simpliﬁed when the model has additional st ructure,\\nsuch as in the InfoMax ICA method [ 85].\\nInference-based interpretation. ∗ The mutual information can\\nbe related to the error probability of inferring x given the representa-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 165, 'page_label': '160', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='such as in the InfoMax ICA method [ 85].\\nInference-based interpretation. ∗ The mutual information can\\nbe related to the error probability of inferring x given the representa-\\ntion z. This can be seen, e.g., by using F ano’s inequality [ 38, 3]. More\\nconcretely , criterion ( 6.52) can be interpreted in terms of inference of x\\ngiven z by noting that its right-hand side can be written as the diﬀer -\\nence H(pD (x))−(Ex,z∼pD (x)p(z|x,θ)[−ln q(x|z)]).In fact, the second term\\nis the cross-entropy measure for the prediction of x given z by means\\nof the variational distribution q(x|z). Therefore, by maximizing ( 6.52)\\nover θ, the model p(z|x,θ) obtains a representation z such that the\\npredictor q(x|z) ensures, on average, a good reconstruction of x given\\nz. This point is further elaborated on in [ 4]. W e speciﬁcally point to [ 4,\\nFig. 2], where a comparison with methods based on ML is provid ed.\\nInformation bottleneck method. ∗ An important variation of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 165, 'page_label': '160', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Fig. 2], where a comparison with methods based on ML is provid ed.\\nInformation bottleneck method. ∗ An important variation of\\nthe InfoMax principle yields the information bottleneck method. In the\\nlatter, one assumes the presence of an additional variable y, jointly\\ndistributed with x, which represents the desired information, but is\\nunobserved. The goal is, as above, to learn an encoder p(z|x,θ) be-\\ntween the observed x and the representation z. However, here, this is\\ndone by maximizing the mutual information I(y; z) between the tar-\\nget unobserved variable y and the representation z, in the presence of\\na regularization term that aims at minimizing the complexit y of the\\n5 The bound is also used by the Blahut-Arimoto algorithm [ 38].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 166, 'page_label': '161', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.7. Autoencoders 161\\nrepresentation. This penalty term is given by the mutual inf ormation\\nI(x; z) , which ﬁnds justiﬁcation in rate-distortion arguments [ 145].\\n6.7 Autoencoders\\nAs seen in Fig. 6.1, autoencoders include parametric models for both\\nencoder and decoder. W e focus here for brevity on determinis tic autoen-\\ncoders, in which the encoder is deﬁned by a function z = Fθ (x) and the\\ndecoder by a function x = Gθ (z). Note that the parameters deﬁning\\nthe two functions may be tied or may instead be distinct, and t hat\\nthe notation is general enough to capture both cases. W e will mention\\nat the end of this section probabilistic autoencoders, in wh ich encoder\\nand decoder are deﬁned by conditional probability distribu tions.\\nAutoencoders transform the unsupervised learning problem of ob-\\ntaining a representation z = Fθ (x) of the input xbased solely on unla-\\nbelled examples {xn }N\\nn=1 into an instance of supervised learning. They'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 166, 'page_label': '161', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='taining a representation z = Fθ (x) of the input xbased solely on unla-\\nbelled examples {xn }N\\nn=1 into an instance of supervised learning. They\\ndo so by concatenating the encoder z = Fθ (x) with a decoder x= Gθ (z),\\nso as to obtain the input-output relationship t = Gθ (Fθ (x)). The key\\nidea is to train this function by setting the target t to be equal to\\nthe input x. As such, the machine learns to obtain an intermediate\\nrepresentation z = Fθ (x) that makes it possible to recover a suitable\\nestimate t= Gθ (z) ≃x of x.\\nT o formalize the approach, learning is typically formulate d in terms\\nof the ERM problem\\nmin\\nθ\\nN∑\\nn=1\\nℓ(xn,Gθ (Fθ (xn))), (6.53)\\nin which, as explained, the encoder-decoder mapping Gθ (Fθ (·)) is trained\\nto reproduce the input at its output.\\nIn the absence of constraints on encoder and decoder, the pro blem\\nabove trivially returns an identify mapping, i.e., Gθ (Fθ (x)) = x. In\\norder to potentially learn a useful model, one should hence i mpose'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 166, 'page_label': '161', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='above trivially returns an identify mapping, i.e., Gθ (Fθ (x)) = x. In\\norder to potentially learn a useful model, one should hence i mpose\\nconstraints, such as dimensionality or sparsity , on the lat ent vector z.\\nSome notable examples are discussed next.\\nPCA. PCA assumes linear encoder and decoder, and ties their\\nweight matrices via a transposition. Speciﬁcally , PCA sets the encoder'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 167, 'page_label': '162', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='162 Unsupervised Learning\\nas Fθ (x) = WT x and the decoder as Gθ (z) = Wz. The parameters θ\\nare hence given by the D×M matrix W. By these deﬁnitions, the M\\ncolumns of W have the interpretation of linear features as for PPCA.\\nWith a quadratic loss function, the learning problem ( 6.53) is given\\nas\\nmin\\nW\\nN∑\\nn=1\\n∥xn −WWT xn∥2 . (6.54)\\nThis problem can be solved in closed form. The solution is in f act\\ngiven by the M principal eigenvectors of the sample covariance matrix\\nN−1 ∑ N\\nn=1 xnxT\\nn .Extensions of PCA that use the kernel trick (Chapter\\n4) can be also devised (see, e.g., [\\n104]). F urthermore, PCA can be seen\\nto be a special case of PPCA by setting in the latter µ = 0 and by\\ntaking the limit σ2 →0.\\nDictionary learning. In dictionary learning, the decoder is linear,\\ni.e., Gθ (z) = Wz, as for PCA. However, the encoder is limited only\\nby constraints on the set of feasible latent variables z. A typical such\\nconstraint is sparsity: the latent vector should have a smal l number of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 167, 'page_label': '162', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='by constraints on the set of feasible latent variables z. A typical such\\nconstraint is sparsity: the latent vector should have a smal l number of\\nnon-zero elements. Deﬁning as Cthe set of feasible values for z, the\\ndictionary learning problem can be formulated as\\nmin\\nW,{zn }∈C\\n1\\nN\\nN∑\\nn=1\\n∥xn −Wzn∥2 . (6.55)\\nThe name of the method accounts for the fact that matrix W can be\\nthought of as the dictionary of M features – its columns – that are\\nused to describe the data. The problem above is typically sol ved using\\nalternate optimization. Accordingly , one optimizes over W for a ﬁxed\\nset of latent vectors {zn }, which is a standard least squares problem;\\nand the optimizes over each latent vector zn for a ﬁxed W. The second\\nproblem can be tackled by using standard sparsity-based met hods, such\\nas LASSO (Chapter 2).\\nMulti-layer autoencoders. ∗ One can also represent both encoder\\nand decoder as multi-layer neural networks. In this case, th e weights'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 167, 'page_label': '162', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='as LASSO (Chapter 2).\\nMulti-layer autoencoders. ∗ One can also represent both encoder\\nand decoder as multi-layer neural networks. In this case, th e weights\\nof encoder and decoders are typically tied to be the transpos e of one\\nanother, in a manner similar to PCA. T raining is often done ﬁr st layer-\\nby-layer, e.g., using RBM training, and then via backpropag ation across\\nthe entire network [ 64].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 168, 'page_label': '163', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.8. Ranking ∗ 163\\nDenoising autoencoders. ∗ An alternative approach to facilitate\\nthe learning of useful features is that taken by denoising autoencoders\\n[150]. Denoising autoencoders add noise to each input xn, obtaining\\na noisy version ˜xn, and to then train the machine with the aim of\\nrecovering the input xn from its noisy version ˜xn. F ormally , this can be\\ndone by minimizing the empirical risk ∑ N\\nn=1 ℓ(xn,Gθ (Fθ (˜xn))).\\nProbabilistic autoencoders. ∗ Instead of using deterministic en-\\ncoder and decoder, it is possible to work with probabilistic encoders\\nand decoders, namely p(z|x,θ) and p(x|z,θ), respectively . T reating the\\ndecoder as a variational distribution, learning can then be done by a\\nvariant of the EM algorithm. The resulting algorithm, known as V ari-\\national AutoEncoder (V AE), will be mentioned in Chapter 8.\\n6.8 Ranking ∗\\nW e conclude this chapter by brieﬂy discussing the problem of ranking.\\nWhen one has available ranked examples, ranking can be formu lated'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 168, 'page_label': '163', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='6.8 Ranking ∗\\nW e conclude this chapter by brieﬂy discussing the problem of ranking.\\nWhen one has available ranked examples, ranking can be formu lated\\nas a supervised learning problem [\\n133]. Here, we focus instead on the\\nproblem of ranking a set of webpages based only on the knowled ge of\\ntheir underlying graph of mutual hyperlinks. This set-up ma y be con-\\nsidered as a special instance of unsupervised learning. W e s peciﬁcally\\ndescribe a representative, popular, scheme known as PageRa nk [ 110],\\nwhich uses solely the web of hyperlinks as a form of supervisi on signal\\nto guide the ranking.\\nT o elaborate, we deﬁne the connectivity graph by including a vertex\\nfor each webpage and writing the adjacent matrix as\\nLij =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if page j links to page i\\n0 otherwise\\n. (6.56)\\nThe outgoing degree of a webpage is hence given as\\nCj =\\n∑\\ni\\nLij . (6.57)\\nPageRank computes the rank pi of a webpage i as\\npi = (1 −d) + d\\n∑\\nj̸=i\\nLij\\nCj\\npj , (6.58)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 169, 'page_label': '164', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='164 Unsupervised Learning\\nwhere 0 <d< 1 is a parameter. Hence, the rank of a page is a weighted\\nsum of a generic rank of equal to 1, which enables the choice of new\\npages, and of an aggregate “vote” from other pages. The latte r term\\nis such that any other page j votes for page i if it links to page i and\\nits vote equals its own rank divided by the total number of out going\\nlinks, that is, pj /Cj . In essence, a page iis highly ranked if it is linked\\nby pages with high rank. The equation ( 6.58) can be solved recursively\\nto obtain the ranks of all pages. A variation of PageRank that tailors\\nranking to an individual’s preferences can be obtained as de scribed in\\n[63].\\n6.9 Summary\\nIn this chapter, we have reviewed the basics of unsupervised learning. A\\ncommon aspect of all considered approaches is the presence o f hidden,\\nor latent, variables that help explain the structure of the d ata. W e have\\nﬁrst reviewed ML learning via EM, and variations thereof, fo r directed'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 169, 'page_label': '164', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='or latent, variables that help explain the structure of the d ata. W e have\\nﬁrst reviewed ML learning via EM, and variations thereof, fo r directed\\nand undirected models. W e have then introduced the GAN metho d\\nas a generalization of ML in which the KL divergence is replac ed by\\na divergence measure that is learned from the data. W e have th en\\nreviewed discriminative models, which may be trained via th e InfoMax\\nprinciple, and autoencoders.\\nIn the next section, we broaden the expressive power of the pr oba-\\nbilistic models considered so far by discussing the powerfu l framework\\nof probabilistic graphical models.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 170, 'page_label': '165', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part IV\\nAdvanced Modelling and\\nInference'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 171, 'page_label': '166', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7\\nProbabilistic Graphical Models\\nAs we have seen in the previous chapters, probabilistic mode ls are\\nwidely used in machine learning. Using Fig. 6.1 as an example, we\\nhave encountered both directed and undirected models, whic h have\\nbeen used to carry out supervised and unsupervised learning tasks.\\nGraphical models encode structural information about the r vs of inter-\\nest, both observed and latent. They hence provide a principl ed way to\\ndeﬁne parametric probabilistic models with desired featur es.\\nThe selection of a probabilistic graphical model hence foll ows the\\nsame general rules that have been discussed so far: A more spe cialized,\\nor structured, model may help reduce overﬁtting, and hence t he gener-\\nalization gap. This is done, as we will see, by reducing the nu mber of\\nparameters to be learned. On the ﬂip side, specialization ma y come at\\nthe cost of an irrecoverable bias.\\nIn this chapter, we provide an introduction to the vast ﬁeld p rob-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 171, 'page_label': '166', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='parameters to be learned. On the ﬂip side, specialization ma y come at\\nthe cost of an irrecoverable bias.\\nIn this chapter, we provide an introduction to the vast ﬁeld p rob-\\nabilistic graphical models, which is a powerful framework t hat allows\\nus to represent and learn structured probabilistic models. The goal\\nhere is to introduce the main concepts and tools, while refer ring to the\\nextensive treatments in [ 81, 15, 104, 151] for additional information.\\n166'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 172, 'page_label': '167', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.1. Introduction 167\\n7.1 Introduction\\nIn this section, we start by discussing two examples that ill ustrate\\nthe type of structural information that can be encoded by mea ns of\\nprobabilistic graphical models. W e then provide an overvie w of this\\nchapter.\\nAs illustrated by the two examples below, structured probab ilistic\\nmodels can be used to set up parametric models for both superv ised\\nand unsupervised learning. In the former case, all variable s are observed\\nin the training set, with some rvs being inputs, i.e., covari ates ( x), and\\nothers being considered as outputs, or targets ( t). In contrast, in the\\nlatter case, some variables are unobserved and play the role of latent\\nvariables ( z) that help explain or generate the observed variables ( x).\\n1\\nExample 7.1. Consider the tasks of text classiﬁcation via supervised\\nlearning or text clustering via unsupervised learning. In t he supervised\\nlearning case, the problem is to classify documents dependi ng on their'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 172, 'page_label': '167', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning or text clustering via unsupervised learning. In t he supervised\\nlearning case, the problem is to classify documents dependi ng on their\\ntopic, e.g., sport, politics or entertainment, based on set of labelled\\ndocuments. With unsupervised learning, the problem is to cl uster doc-\\numents according to the similarity of their contents based o n the sole\\nobservation of the documents themselves.\\nA minimal model for this problem should include a variable t repre-\\nsenting the topic and a variable x for the document. The topic can\\nbe represented by a categorical variable taking T values, i.e.., t ∈\\n{1,...,T },which is observed for supervised learning and latent for uns u-\\npervised learning. As for the document, with “bag-of-words ” encoding,\\na set of W words of interest is selected, and a document is encoded as\\na W ×1 binary vector x= [ x1 ,...,xW ]T , in which xw = 1 if word w is\\ncontained in the document. 2\\nT o start, we could try to use an unstructured directed model d eﬁned\\nas'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 172, 'page_label': '167', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='a W ×1 binary vector x= [ x1 ,...,xW ]T , in which xw = 1 if word w is\\ncontained in the document. 2\\nT o start, we could try to use an unstructured directed model d eﬁned\\nas\\nt ∼Cat(π) (7.1a)\\nx|t = t∼Cat(πt), (7.1b)\\n1 Strictly speaking, this distinction applies to the frequen tist approach, since in\\nthe Bayesian approach the model parameters are always treat ed as unobserved rvs.\\n2 Note that W here does not represent a matrix of weights!'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 173, 'page_label': '168', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='168 Probabilistic Graphical Models\\nwhere the parameter vector includes the T×1 probability vector πand\\nthe T probability vectors πt, one for each class, each of dimension 2W .\\nNote, in fact, that the vector x can take 2W possible values. As such,\\nthis model would require to learn (T−1)+ T(2W −1) parameters, which\\nquickly becomes impractical when the number W of words of interest\\nis large enough. F urthermore, as we have seen, a learned mode l with\\na large number of parameters is bound to suﬀer from overﬁttin g if the\\navailable data is relatively limited.\\nInstead of using this unstructured model, we can adopt a mode l that\\nencodes some additional assumptions that can be reasonably made on\\nthe data. Here is one possible such assumption: once the topi c is ﬁxed,\\nthe presence of a word is independent on the presence of other words.\\nThe resulting model is known as Bernoulli naive Bayes , and can be\\ndescribed as follows\\nt ∼Cat(π) (7.2a)\\nx|t = t∼\\nW∏\\nw=1\\nBern(xw |πw|t), (7.2b)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 173, 'page_label': '168', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='The resulting model is known as Bernoulli naive Bayes , and can be\\ndescribed as follows\\nt ∼Cat(π) (7.2a)\\nx|t = t∼\\nW∏\\nw=1\\nBern(xw |πw|t), (7.2b)\\nwith parameter vector including the T ×1 probability vector π and T\\nsets of W probabilities πw|t, w = 1 ,...,W , for each topic t. Parameter\\nπw|t represents the probability of word w occurring in a document of\\ntopic t. The mentioned independence assumption hence allowed us to\\nbring the number of parameters down to (T −1) + TW, which corre-\\nsponds to an exponential reduction.\\nFigure 7.1: BN for the naive Bayes model using the plate notation. Learna ble\\nparameters are represented as dots.\\nThe naive Bayes model can be represented graphically by the B N'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 174, 'page_label': '169', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.1. Introduction 169\\nillustrated in Fig. 7.1, where we have considered N i.i.d. documents.\\nNote that the graph is directed: in this problem, it is sensib le to model\\nthe document as being caused by the topic, entailing a directed causal-\\nity relationship. Learnable parameters are represented as dots. BNs are\\ncovered in Sec. 7.2.\\nFigure 7.2: MRF for the image denoising example. Only one image is shown a nd\\nthe learnable parameters are not indicated in order to simpl ify the illustration.\\nExample 7.2. The second example concerns image denoising using su-\\npervised learning. F or this task, we wish to learn a joint dis tribution\\np(x,z|θ) of the noisy image x and of the corresponding desired noise-\\nless image z. W e encode the images using a matrix representing the\\nnumerical values of the pixels. A structured model in this pr oblem can\\naccount for the following reasonable assumptions: ( i ) neighboring pixels\\nof the noiseless image are correlated, while pixels further apart are not'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 174, 'page_label': '169', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='account for the following reasonable assumptions: ( i ) neighboring pixels\\nof the noiseless image are correlated, while pixels further apart are not\\ndirectly dependent on one another; and ( ii ) noise acts independently\\non each pixel of the noiseless image to generate the noisy ima ge. These\\nassumptions are encoded by the MRF shown in Fig. 7.2. Note that this\\nis an undirected model. This choice is justiﬁed by the need to capture\\nthe mutual correlation among neighboring pixels, which can not be de-\\nscribed as a directed causality relationship. W e will study MRF s in Sec.\\n7.3.\\nAs suggested by the examples above, structure in probabilis tic mod-\\nels can be conveniently represented in the form of graphs. At a fun-\\ndamental level, structural properties in a probabilistic m odel amount'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 175, 'page_label': '170', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='170 Probabilistic Graphical Models\\nto conditional independence assumptions. F or instance, in the naive\\nBayes model, the word indicators are conditionally indepen dent given\\nthe topic. As we will see in the rest of this chapter, conditio nal in-\\ndependence assumptions translate into factorizations of t he joint dis-\\ntributions of the variables under study . F actorizations, a nd associated\\nconditional independence properties, can be represented b y three diﬀer-\\nent graphical frameworks, namely BNs, MRF s and factor graph s. F or\\nbrevity , this chapter will only focus on the ﬁrst two.\\n7.2 Bayesian Networks\\nThis section provides a brief introduction to BNs by focusin g on key\\ndeﬁnitions and on the problem of ML learning with some note on MAP\\nand Bayesian viewpoints.\\n7.2.1 Deﬁnitions and Basics\\nBNs encode a probability factorization or, equivalently , a set of condi-\\ntional independence relationships through a directed grap h. The start-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 175, 'page_label': '170', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and Bayesian viewpoints.\\n7.2.1 Deﬁnitions and Basics\\nBNs encode a probability factorization or, equivalently , a set of condi-\\ntional independence relationships through a directed grap h. The start-\\ning point is the chain rule for probabilities for a generic se t of K rvs\\n{x1 ,...,xK }:\\np(x1,...,xk ) = p(x1)p(x2 |x1 )...p(xK |x1 ,...,xK −1 ),\\n=\\nK∏\\nk=1\\np(xk |x1 ,...,xk−1 ), (7.3)\\nwhere the order of the variables is arbitrary . The factoriza tion (\\n7.3)\\napplies for a generic joint distribution, and it does not enc ode any\\nadditional structural information. Note that the notation here is general\\nand not meant to indicate that the variables are necessary ob served.\\nExample 7.3. Consider again the naive Bayes model for text classiﬁ-\\ncation/ clustering. There, we imposed the structural const raint that\\nword indicator variables {xw }W\\nw=1 be conditionally independent given\\nthe topic t. This conditional independence assumption can be expresse d\\nusing the “perp” notation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 175, 'page_label': '170', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='word indicator variables {xw }W\\nw=1 be conditionally independent given\\nthe topic t. This conditional independence assumption can be expresse d\\nusing the “perp” notation\\nxw ⊥{xw′ }w′ ̸=w |t, (7.4)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 176, 'page_label': '171', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 171\\nor the Markov chain notation\\nxw −t −{xw′ }w′ ̸=w . (7.5)\\nMathematically , this condition means that we have p(xw |t,{xw′ }) =\\np(xw |t), where {xw′ }is any subset of the variables {xw′ }w′ ̸=w . Applying\\nthe chain rule to the rvs ({xw }W\\nw=1 ,t) using order t,x1 ,...,xW (or any\\nother order on the {xw }W\\nw=1 variables), we can hence write\\np(x,t) = p(t)\\nW∏\\nw=1\\np(xw |t). (7.6)\\nThis factorization is represented by the BN in Fig.\\n7.1. In the di-\\nrected graph shown in the ﬁgure, each vertex corresponds to a rv, and\\na directed edge is included from t to each variable xw . This edge cap-\\ntures the fact that the conditional probability of the varia ble xw in ( 7.6)\\nis conditioned on rv t. Informally , t “causes” all variables in vector x.\\nThe graph accounts for multiple i.i.d. realization (xD ,tD ) = {xn,tn }N\\nn=1 ,\\nwhere we denote the nth sample as xn = [x 1n ···xW n ]T . The joint dis-\\ntribution factorizes as\\np(xD ,tD ) =\\nN∏\\nn=1\\np(tn)\\nW∏\\nw=1\\np(xwn |tn). (7.7)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 176, 'page_label': '171', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='n=1 ,\\nwhere we denote the nth sample as xn = [x 1n ···xW n ]T . The joint dis-\\ntribution factorizes as\\np(xD ,tD ) =\\nN∏\\nn=1\\np(tn)\\nW∏\\nw=1\\np(xwn |tn). (7.7)\\nThe BN uses the tile notation that will be formalized below to indicate\\nmultiple independent realizations of rvs with the same dist ribution.\\nGeneralizing the example above, we deﬁne BNs as follows.\\nDeﬁnition 7.1. A BN is a directed acyclic graph (DAG)\\n3 , whose ver-\\ntices represent rvs {x1 ,....,xK }with an associated joint distribution\\nthat factorizes as\\np(x1,...,xK ) =\\nK∏\\nk=1\\np(xk |xP (k)) (7.8)\\nwhere P(k) denotes the set of parents of node k in the DAG. In a BN,\\nrvs are represented by full circles, while learnable parame ters deﬁning\\nthe conditional distributions are represented by dots.\\n3 In a DAG, there are no directed cycles, that is, no closed path s following the\\ndirection of the arrows.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 177, 'page_label': '172', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='172 Probabilistic Graphical Models\\nAs per the deﬁnition, the parents xP (k) of a rv xk in the DAG\\naccount for the statistical dependence of xk with all the preceding vari-\\nables x1,...,xk−1 according to the selected order. That is, the BN en-\\ncodes the local conditional independence relationships\\nxk ⊥{x1 ,...,xk−1 }|xP (k) (7.9)\\nusing the “perp” notation, or equivalently xk −xP (k) −{x1,...,xk−1 }\\nusing the Markov chain notation, for k = 1 ,...,K . As seen in Fig. 7.1,\\nplates are used to represent independent replicas of a part of the gr aph.\\nWhen to use BNs. BNs are suitable models when one can identify\\ncausality relationships among the variables. In such cases , there exists\\na natural order on the variables, such that rvs that appear la ter in the\\norder are caused by a subset of the preceding variables. The c ausing\\nrvs for each rv xk are included in the parent set P(k), and are such\\nthat, when conditioning on rvs xP (k), rv xk is independent on all other'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 177, 'page_label': '172', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='rvs for each rv xk are included in the parent set P(k), and are such\\nthat, when conditioning on rvs xP (k), rv xk is independent on all other\\npreceding rvs {x1 ,...,xk−1 }. BNs also underlie the framework of inter-\\nventions that allows the assessment of causality , as oppose d to mere\\ncorrelation, among observed variables, as brieﬂy discusse d in Sec. 2.7\\n[113].\\nSampling from a BN. The causality relationship among the or-\\ndered variables {x1 ,...,xK }encoded by a BN makes it easy , at least\\nin principle, to draw samples from a BN. This can be done by usi ng\\nancestral sampling : Generate rv x1 ∼p(x1); then, x2 ∼p(x2 |xP (2)); and\\nso on, with rv xk being generated as xk ∼p(xk |xP (k)).\\nExample 7.4. Hidden Markov Models (HMMs) are used to study time\\nseries, or more generally sequential data, measured throug h a memo-\\nryless transformation, such as an additive noise channel. M athemati-\\ncally , HMMs can be represented by two sets of variables: the u nderly-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 177, 'page_label': '172', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ryless transformation, such as an additive noise channel. M athemati-\\ncally , HMMs can be represented by two sets of variables: the u nderly-\\ning sequence z1 ,z2 ,...,zD ,and the measured “noisy” data x1,x2 ,...,xD .\\nHMMs encode two assumptions: ( i ) each sample zi depends on the past\\nsamples only through the previous sample zi−1; and ( ii ) each measured\\ndata xi depends only on zi. Assumption ( i ) makes process z1 ,z2 ,... a\\nMarkov chain.\\nUsing the order z1,x1 ,z2 ,x2 ,..., we can write the joint distribution'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 178, 'page_label': '173', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 173\\nas\\np(x,z) = p(z1 )p(x1 |z1 )\\nD∏\\ni=1\\np(zi|zi−1 )p(xi |zi ) (7.10)\\nby enforcing the local independencies zi −zi−1 −{z1 ,...,zi−2 ,x1 ,...,xi−2 }\\nand xi −zi −{z1 ,...,zi−1 ,x1 ,...,xi−1 }.This factorization is represented\\nby the BN in Fig. 7.3. While not indicated in the ﬁgure for clarity , an\\nimportant aspect of HMMs is that the learnable parameters de ﬁning\\nthe transitions probabilities p(zi|zi−1 ) and the transformations p(xi|zi )\\nare respectively imposed to be equal, or tied, for all i, hence reducing\\nthe number of parameters to be leaned.\\nAmong the many relevant examples of applications of HMMs (se e\\n[81, 104, 15, 117]), we mention here text autocorrection, in which the\\nunderlying sequential data z1 ,z2 ,... amount to the correct text while\\nthe measured data x1,x2 ,... to the typed text; and speech recognition,\\nin which the underlying time series z1 ,z2 ,... is a sequence of words and\\nthe transformation to the measured recorded speech x1,x2 ,... translates'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 178, 'page_label': '173', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in which the underlying time series z1 ,z2 ,... is a sequence of words and\\nthe transformation to the measured recorded speech x1,x2 ,... translates\\nwords into sounds.\\nFigure 7.3: BN representing an HMM. The lernable parameters are not expl icitly\\nindicated.\\nIn supervised learning applications, both sequences are ob served in\\nthe training data, with the goal of learning to predict the se quence\\nz1 ,z2 ,..., for new measured data points x1,x2 ,... via to the trained\\nmodel. This task, in this context, is also known as denoising, since\\nx1 ,x2 ,... can be thought of as a noisy version of z1 ,z2 ,... With unsu-\\npervised learning, only the sequence x1,x2 ,... is observed.\\nExample 7.5. This example demonstrates how easily Bayesian mod-\\nelling can be incorporated in a BN. T o this end, consider agai n the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 179, 'page_label': '174', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='174 Probabilistic Graphical Models\\nBernoulli naive Bayes model ( 7.2) for text classiﬁcation. T aking a Bayesian\\nviewpoint, parameters πand {πw|t}are to be considered as rvs. W e fur-\\nther assume them to be a priori independent, which is known as the\\nglobal independence assumption . As a result, the joint probability dis-\\ntribution for each document factorizes as\\np(x,t,π,π w|t|α,a,b) = Dir(π|α)\\nT∏\\nt=1\\nW∏\\nw=1\\nBeta(πw|t|a,b)\\n×Cat(t|π)\\nW∏\\nw=1\\nBern(xw |πw|t). (7.11)\\nIn the factorization above, we have made the standard assump tion\\nof a Dirichlet prior for the probability vector π and a Beta prior for\\nparameters {πw|t}, as discussed in Chapter 3. The quantities α,a,b\\nare hyperparameters. Note that the hyperparameters (a,b) are shared\\nfor all variables πw|t in this example. The corresponding BN is shown\\nin Fig. 7.4, which can be compared to Fig. 7.1 for the corresponding\\nfrequentist model.\\nFigure 7.4: BN for the Bayesian version of the naive Bayes model ( 7.11). Hyper-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 179, 'page_label': '174', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in Fig. 7.4, which can be compared to Fig. 7.1 for the corresponding\\nfrequentist model.\\nFigure 7.4: BN for the Bayesian version of the naive Bayes model ( 7.11). Hyper-\\nparameters are not indicated and tiles indices are marked wi thout their ranges for\\nclarity .\\nW e invite the reader to consider also the Latent Dirichlet Al loca-\\ntion (LDA) model and the other examples available in the ment ioned\\ntextbooks.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 180, 'page_label': '175', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 175\\n7.2.2 Global Conditional Independence\\nAs we have discussed, BNs are deﬁned by local conditional ind epen-\\ndence properties that are encoded in the factorization of a j oint dis-\\ntribution and in the supporting DAG. BNs can also be used to as sess\\ngeneric global conditional independence queries of the typ e: Is a given\\nsubset of variables Aindependent of another set Bconditioned on a\\nthird subset Cof variables? The d-separation algorithm outputs either\\na positive response or a “maybe” answer to this question. It i s brieﬂy\\ndescribed as follows:\\n•Build a subgraph G′ from the original DAG by keeping all ver-\\ntices in the subsets A, B and C, as well as all the edges and vertices\\nencountered by moving backwards on the DAG one or more edges f rom\\nthe vertices in A, B and C;\\n•Build a subgraph G′′ from G′ by deleting all edges coming out of\\nthe vertices in C;\\n•If there no path, neglecting the directionality of the edges , between'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 180, 'page_label': '175', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the vertices in A, B and C;\\n•Build a subgraph G′′ from G′ by deleting all edges coming out of\\nthe vertices in C;\\n•If there no path, neglecting the directionality of the edges , between\\na node in Aand a node in B, then the conditional independence relation\\nA⊥B|C holds. Else, if one such path exists, then there is at least on e\\njoint distribution that factorizes as for the given DAG for w hich the\\ncondition A⊥B|C does not hold.\\nExample 7.6. Consider the so-called V-structure x →y ←z. Using d-\\nseparation, it can be seen that the conditional independenc e x−y−z\\ndoes not hold in general.\\n7.2.3 Learning\\nAssume that the DAG of a BN is given. Structure learning, that is,\\nthe decision of which edges should be included in the graph ba sed\\non available training data, is also an important problem tha t will not\\nbe considered here. Making explicit the dependence of the pr obability\\nfactors on learnable parameters µ, the joint distribution encoded by a\\nBN can be written as\\np(x1,...,xK ) =\\nK∏\\nk=1'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 180, 'page_label': '175', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='be considered here. Making explicit the dependence of the pr obability\\nfactors on learnable parameters µ, the joint distribution encoded by a\\nBN can be written as\\np(x1,...,xK ) =\\nK∏\\nk=1\\np(xk |xP (k),µk|xP (k) ), (7.12)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 181, 'page_label': '176', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='176 Probabilistic Graphical Models\\nwhere µk|xP (k) are the parameters deﬁning the conditional distribu-\\ntion p(xk |xP (k)). Note that the parameters µk|xP (k) are generally dif-\\nferent for diﬀerent values of k and of the parents’ variables xP (k) (see,\\ne.g., ( 7.11)). In most cases of interest, the probability distribution\\np(xk |xP (k),µk|xP (k) ) is in the exponential family or is a GLM (see Chap-\\nter 3).\\nAs we have already seen in previous examples, the parameters\\nµk|xP (k) can either be separate, that is, distinct for each k and each\\nvalue of xP (k), or they can be tied. In the latter case, some of the pa-\\nrameters µk|xP (k) are constrained to be equal across diﬀerent values of\\nxP (k) and/or across diﬀerent values of k. As a special case of tied pa-\\nrameters, the value of µk|xP (k) may also be independent of xP (k), such\\nas in the case for GLMs.\\nAs for the data, we have seen that the rvs x1,...,xK can be either'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 181, 'page_label': '176', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='rameters, the value of µk|xP (k) may also be independent of xP (k), such\\nas in the case for GLMs.\\nAs for the data, we have seen that the rvs x1,...,xK can be either\\nfully observed in the training set, as in supervised learnin g, or they can\\nbe partially observed as in unsupervised learning.\\nF or the sake of brevity , here we describe learning only for th e case of\\nfully observed data with separate parameters, and we brieﬂy mention\\nextensions to the other cases.\\nFully Observed Data with Separate Parameters\\nW e are given a fully observed data set D= {xn}N\\nn=1 , with each data\\npoint written as xn = [ x1n ,...,xK n ]T . F or concreteness, assume that\\nall variables are categorical. Denoting as xP (k)n the parents of variable\\nxkn , the LL function can be factorized as:\\nln p(D|µ) =\\nN∑\\nn=1\\nK∑\\nk=1\\nln p(xkn |xP (k)n ,µk|xP (k)n ) (7.13a)\\n=\\nK∑\\nk=1\\nN∑\\nn=1\\nln p(xkn |xP (k)n ,µk|xP (k)n ) (7.13b)\\n=\\nK∑\\nk=1\\n∑\\nxP (k)\\n∑\\nn∈NxP (k)\\nln p(xkn |xP (k),µk|xP (k) ), (7.13c)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 182, 'page_label': '177', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.2. Bayesian Networks 177\\nwhere we have deﬁned the set of indices\\nNxP (k) = {n: xP (k)n = xP (k)}. (7.14)\\nThis set includes the indices n for which the parents xP (k)n of node k\\ntake a speciﬁc vector of values xP (k). In ( 7.13c), the inner sum depends\\nonly on the parameters µk|xP (k) corresponding to the given value xP (k)\\nof the rvs xP (k)n for n = 1 ,...,N . Therefore, in the case of separate\\nparameters, the ML estimate for each parameter µk|xP (k) can be carried\\nout independently . While this simpliﬁes the problem, it may also cause\\noverﬁtting issues owing to the problem of data fragmentatio n, as each\\nparameter is estimated based only on a fraction of the data se t.\\nAs an even more concrete example, consider binary variables mod-\\nelled as xk ∼Bern(µk|xP (k) ). Accordingly , the probability of each rv\\ndepends on the value xP (k) of the parents. F or this case, we can write\\nthe ML estimate as\\nˆµk|xP (k),M L =\\n∑\\nn∈NxP (k)\\nxkn\\n⏐\\n⏐\\n⏐NxP (k)\\n⏐\\n⏐\\n⏐\\n. (7.15)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 182, 'page_label': '177', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='depends on the value xP (k) of the parents. F or this case, we can write\\nthe ML estimate as\\nˆµk|xP (k),M L =\\n∑\\nn∈NxP (k)\\nxkn\\n⏐\\n⏐\\n⏐NxP (k)\\n⏐\\n⏐\\n⏐\\n. (7.15)\\nFigure 7.5: BN for Example 7.7.\\nExample 7.7. Consider the BN shown in Fig. 7.5 with binary rvs in'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 183, 'page_label': '178', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='178 Probabilistic Graphical Models\\nthe alphabet {0,1}. The observed data Dis given as\\n\\uf8f1\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f3\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n0\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n10\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n1\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n14\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n1\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n8\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n0\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n12\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n0\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n1\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n1\\n0\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n2\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n1\\n1\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n1\\n,\\n\\uf8eb\\n\\uf8ec\\n\\uf8ed\\n0\\n0\\n1\\n\\uf8f6\\n\\uf8f7\\n\\uf8f8\\n\\ued19\\n\\ued18\\ued17 \\ued1a\\n2\\n\\uf8fc\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8fd\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8fe\\n,\\nwhere the bottom row indicates the number of observations eq ual to the\\nvector above it. The ML estimates are: µ1,M L = 10+8+1+1\\n50 = 20\\n50 = 2\\n5 ,\\nµ2,M L = 14+8+2+1\\n50 = 1\\n2 , ˆµ3|00 = 2\\n12+2 = 1\\n7 , ˆµ3|11 = 1\\n8+1 = 1\\n9 , ˆµ3|01 =\\n14\\n14+2 = 7\\n8 and ˆµ3|10 = 10\\n10+1 = 10\\n11 .\\nMAP estimates can be seen to decompose in a similar way un-\\nder global independence assumptions on the parameters, and the same\\nholds for Bayesian approach [ 81].\\nNotes on the General Case\\nWith shared parameters, obtaining ML and MAP estimates requ ire\\naggregating statistics across all variables that share the same parame-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 183, 'page_label': '178', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='holds for Bayesian approach [ 81].\\nNotes on the General Case\\nWith shared parameters, obtaining ML and MAP estimates requ ire\\naggregating statistics across all variables that share the same parame-\\nters. The Bayesian approach is more complex, and we refer to [ 81] for\\ndiscussion. An alternative approach with “soft sharing” is the hierar-\\nchical Bayes model (see [ 81, Fig. 17.11]). In the presence of missing\\ndata, learning typically involves the EM algorithm describ ed in Chap-\\nter 6 or approximate learning counterparts to be introduced in the next\\nchapter.\\n7.3 Markov Random Fields\\nIn this section, we turn to MRF by following the same approach as for\\nBNs in the previous section.\\n7.3.1 Deﬁnitions and Basics\\nAs BNs, MRF s encode a probability factorization or, equival ently , a\\nset of conditional independence relationships. They do so, however,\\nthrough an undirected graph.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 184, 'page_label': '179', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.3. Markov Random Fields 179\\nDeﬁnition 7.2. A MRF is an undirected graph, whose vertices repre-\\nsent rvs with associated joint distribution that factorize s as\\np(x) = 1\\nZ\\n∏\\nc\\nψc(xc), (7.16)\\nwhere c is the index of a clique 4 in the graph; xc is the set of rvs\\nassociated with the vertices in clique c; ψc(xc) ≥0 is the factor or\\npotential for clique c; and Z = ∑\\nx\\n∏\\nc\\nψc(xc) is the partition function.\\nWith no loss of generality , the sum can be limited to maximal c liques\\n(i.e., cliques that are not fully included in a larger clique ). In a MRF,\\nrvs are represented by full circles, while learnable parame ters deﬁning\\nthe conditional distributions are represented by dots.\\nEach factor ψc(xc) in ( 7.16) encodes the compatibility of the values\\nxc in each clique, with larger values of ψc(xc) corresponding to con-\\nﬁgurations xc that are more likely to occur. F actors are generally not\\nprobability distributions, i.e., they are not normalized t o sum or inte-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 184, 'page_label': '179', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ﬁgurations xc that are more likely to occur. F actors are generally not\\nprobability distributions, i.e., they are not normalized t o sum or inte-\\ngrate to one. F urthermore, unlike BNs, each factor does not d istinguish\\nbetween conditioning and conditioned rvs. Rather, all vari ables in the\\nclique xc can play the same role in deﬁning the value of the potential\\nψc(xc).\\nWhen to use MRF s. This discussion points to the fact that MRF s\\nare especially well suited to model mutual relationships of compatibility ,\\nor lack thereof, among variables, rather than causality eﬀe cts.\\nEv aluating Probabilities and Sampling from an MRF . This\\ndistinguishing feature of MRF, which brings potential mode lling advan-\\ntages in some applications, comes with the added diﬃculty of evaluating\\nthe joint probability distribution and sampling from the joint distribu-\\ntion. In fact, the computation of the probability ( 7.16) requires the\\ncalculation of the partition function Z, which is generally intractable'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 184, 'page_label': '179', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tion. In fact, the computation of the probability ( 7.16) requires the\\ncalculation of the partition function Z, which is generally intractable\\nwhen the alphabet of the vector x is large enough. This is typically not\\nthe case for BNs, in which each conditional probability is co nventionally\\nselected from a known (normalized) distribution. F urtherm ore, unlike\\nBNs, MRF s do not allow ancestral sampling, as all the conditi onal dis-\\n4 A clique is a fully connected subgraph.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 185, 'page_label': '180', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='180 Probabilistic Graphical Models\\ntributions of the individual rvs in x are generally tied together via the\\npartition function.\\nExample 7.8. The image denoising example described at the beginning\\nof this chapter leverages the MRF in Fig.\\n7.2. In it, the maximal cliques\\nare given by the pairs of rvs { zi ,zj } and {xi ,zi }that are connected by\\nan edge. Associating a factor or potential to each clique yie lds the\\nfactorized joint distribution\\np(x,z) = 1\\nZ\\n∏\\n{i,j }\\nψi,j (zi,zj ) ·\\n∏\\ni\\nψi(zi ,xi), (7.17)\\nwhere {i,j}represents an edge of the undirected graph. As a notable\\nexample, in the Ising model , the variables are bipolar, i.e., zi,xi ∈\\n{−1,+1}, and the potentials are deﬁned as ψij (zi,zj |η1) = exp(−E(zi ,zj |η1 ))\\nand ψi(zi ,xi|η2 ) = exp(−E(zi ,xi|η2 )), with energy functions\\nE(zi ,zj |η1 ) = −η1 zizj and E(zi ,xi |η) = −η2zi xi. (7.18)\\nF rom this deﬁnition, a large natural parameter η1 > 0 yields a large\\nprobability – or a low energy – when zi and zj are equal; and, similarly ,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 185, 'page_label': '180', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='F rom this deﬁnition, a large natural parameter η1 > 0 yields a large\\nprobability – or a low energy – when zi and zj are equal; and, similarly ,\\na large η2 >0 favors conﬁgurations in which zi = xi, that is, with low\\nnoise.\\nExample 7.9. Another related example is given by the RBMs studied\\nin Sec.\\n6.5.1, whose undirected graph is shown in Fig. 6.6.\\nAs illustrated by the previous examples, potentials are typ ically\\nparameterized using the energy-based form\\nψc(xc) = exp(−Ec(xc|ηc)), (7.19)\\nwith parameter vector ηc.This form ensures that the factors are strictly\\npositive as long as the energy is upper bounded. A special cla ss of such\\nmodels is given by log-linear models, such as the Ising model , in which,\\nas seen in Chapter 3, the energy is a linear function of the par ameters.\\n7.3.2 Global Conditional Independence\\nMRF, in a manner similar to BNs, enable the assessment of cond itional\\nindependence properties globally in the graph. The procedu re is, in'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 186, 'page_label': '181', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.3. Markov Random Fields 181\\nfact, easier with MRF s thanks to the Hammersley–Cliﬀord the orem.\\nThe latter says that, if the potentials ψc(xc) are strictly positive for\\nall cliques c, as for the energy-based potentials ( 7.19), the conditional\\nindependence relationship A ⊥ B|Ccan be tested via the following\\nsimple algorithm.\\n•Eliminate all variables in Cand all the connected edges;\\n•If there is no path between rvs in Aand B, then the relationship\\nA⊥B|C holds; if, instead, there is a path, then there exists at leas t one\\njoint distribution that factorizes as for the undirected gr aph at hand\\nfor which the relationship A⊥B|C does not hold.\\n7.3.3 Learning\\nLearning in MRF s is made complicated by the partition functi on. In\\nfact, the partition function couples together all the param eters. This\\nmakes it impossible to carry out separately the estimate of t he param-\\neters ηc associated with each clique even in the fully observed case'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 186, 'page_label': '181', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='makes it impossible to carry out separately the estimate of t he param-\\neters ηc associated with each clique even in the fully observed case\\nwith separate parameters. Nevertheless, MRF s with energy- based po-\\ntentials (\\n7.19) fall either in the exponential family , when the factors\\nare log-normal, or in the more general class of energy-based models. In\\nboth cases, gradient-based algorithms can be devised by usi ng methods\\nsimilar to those used in Sec. 6.5.1 for RBMs.\\n7.3.4 Converting BNs to MRFs\\nAs suggested by the discussion above, BNs and MRF s are suitab le to\\nencode diﬀerent types of statistical dependencies, with th e former cap-\\nturing causality while the latter accounting for mutual com patibility .\\nThere are in fact conditional independence properties that can be ex-\\npressed by BN or MRF but not by both. An example is the V-struct ure\\nx →y ←z discussed in Example 7.6, whose independencies cannot be\\ncaptured by an MRF.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 186, 'page_label': '181', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='pressed by BN or MRF but not by both. An example is the V-struct ure\\nx →y ←z discussed in Example 7.6, whose independencies cannot be\\ncaptured by an MRF.\\nThat said, given a BN with factorization ( 7.8), we can deﬁne poten-\\ntial functions\\nψk (xk ,xP (k)) = p(xk |xP (k)) (7.20)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 187, 'page_label': '182', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='182 Probabilistic Graphical Models\\nto obtain the factorization\\np(x) =\\nK∏\\nk=1\\nψk (xk ,xP (k)) (7.21)\\nwith partition function Z = 1 . This factorization deﬁnes an MRF in\\nwhich each maximal clique contains a rv xk and its parents xP (k). The\\ncorresponding undirected graph can be directly obtained fr om the DAG\\nthat deﬁnes the BN via the following two steps:\\n•Connect all pairs of parents by an undirected edge – this step is\\nknown as “moralization”;\\n•Make all edges undirected.\\nAs per the discussion above, the resulting MRF may not accoun t\\nfor all the independencies encoded in the original graph. Th is can be\\neasily seen by applying the procedure to the V-structure.\\n7.4 Bayesian Inference in Probabilistic Graphical Models\\nBayesian inference amounts to the computation of the poster ior prob-\\nability of unobserved, or latent, variables given observed variables. In\\nthis regard, it is useful to diﬀerentiate between intensive and extensive'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 187, 'page_label': '182', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ability of unobserved, or latent, variables given observed variables. In\\nthis regard, it is useful to diﬀerentiate between intensive and extensive\\nlatent variables. Intensive latent variables are model par ameters whose\\nnumber does not increase with the number N of data points, such as\\nthe probability vectors (π,{πw|t}) in the Bernoulli naive Bayes model.\\nExtensive latent variables are instead rvs indexed by the ex ample index\\nn, whose number grows with the sample size N. These correspond to\\nthe latent variables zn introduced in the previous chapter.\\nBayesian inference is a fundamental task that lies at the hea rt of\\nboth inference and learning problems. As seen in Chapter 2, i t un-\\nderlies supervised learning for generative probabilistic models, which\\nrequires the computation of the predictive probability p(t|x,θ) for the\\nnew sample ( x,t) from the learned model p(x,t|θ). It is also at the core\\nof Bayesian supervised learning, which evaluates the poste rior p(θ|D)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 187, 'page_label': '182', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='new sample ( x,t) from the learned model p(x,t|θ). It is also at the core\\nof Bayesian supervised learning, which evaluates the poste rior p(θ|D)\\nof the parameter vector θ (an intensive variable) in order to obtain the\\npredictive posterior p(t|x,D) =\\n∫\\np(θ|D)p(t|x,θ)dθ for the new sam-\\nple ( x,t). As studied in Chapter 6, Bayesian inference is a key step\\nin unsupervised learning even under a frequentist viewpoin t, since the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 188, 'page_label': '183', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.4. Bayesian Inference in Probabilistic Graphical Models 183\\nEM algorithm requires the evaluation of the posterior p(zn|xn,θ) of the\\nlatent (extensive) variables {zn}given the current iterate θ.\\nAs discussed, when performing Bayesian inference, we can di stin-\\nguish between observed variables, say x, and latent variables z. In gen-\\neral, only a subset of latent variables may be of interest, sa y zi , with the\\nrest of the rvs in z being denoted as z−i.The quantity to be computed\\nis the posterior distribution\\np(zi|x) = p(x,zi )\\np(x) , (7.22)\\nwhere\\np(x,zi ) =\\n∑\\nz−i\\np(x,z) (7.23)\\nand\\np(x) =\\n∑\\nzi\\np(x,zi ), (7.24)\\nwith the sum being replaced by an integral for continuous var iables.\\nThe key complication in evaluating these expressions is the need to\\nsum over potentially large sets, namely the domains of varia bles z−i\\nand zi . Note that the sum in ( 7.23), which appears at the numerator of\\n(7.22), is over all hidden variables that are of no interest. In con trast,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 188, 'page_label': '183', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and zi . Note that the sum in ( 7.23), which appears at the numerator of\\n(7.22), is over all hidden variables that are of no interest. In con trast,\\nthe sum in ( 7.24), which is at the denominator of ( 7.22), is over the\\nvariables whose posterior probability ( 7.22) is the ﬁnal objective of the\\ncalculation.\\nThe complexity of the steps ( 7.23) and ( 7.24) is exponential in the\\nrespective numbers of latent variables over which the sums a re com-\\nputed, and hence it can be prohibitive.\\nExample 7.10. Consider an HMM, whose BN is shown in Fig.\\n7.3. Hav-\\ning learned the probabilistic model, a typical problem is th at of infer-\\nring a given hidden variable zi given the observed variables x = {x1,....,xD }.\\nComputing the posterior p(zi |x) requires the evaluation of the sums in\\n(7.23) and ( 7.24). When the hidden variables z1 ,...,zD are discrete with\\nalphabet size Z, the complexity of step ( 7.23) is of the order |Z|D−1 ,\\nsince one needs to sum over the |Z|D−1 possible values of the hidden'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 188, 'page_label': '183', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='alphabet size Z, the complexity of step ( 7.23) is of the order |Z|D−1 ,\\nsince one needs to sum over the |Z|D−1 possible values of the hidden\\nvariables.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 189, 'page_label': '184', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='184 Probabilistic Graphical Models\\nThe structure encoded by probabilistic graphic models can h elp\\nreduce the discussed complexity of Bayesian inference. The refore, prob-\\nabilistic graphical models can not only enhance learning by controlling\\nthe capacity of the model, but also enable Bayesian inferenc e. T o elab-\\norate, consider a joint distributions deﬁned by an MRF as in ( 7.16).\\nNote that, as we have seen in Sec. 7.3.4, one can easily convert BNs into\\nMRF s, although possibly at the cost of not preserving some li near in-\\ndependence relationship. With this factorization, the mar ginalizations\\n(7.23)-(7.24) require solving the so-called sum-product inference task\\n∑\\nz\\n∏\\nc\\nψc(xc), (7.25)\\nwhere the variables z are a subset of the variables in x.\\nAs an important observation, formulation ( 7.25) highlights the fact\\nthat the problem of computing the partition function Z for MRF s is\\na special case of the sum-product inference task. In fact, in order to'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 189, 'page_label': '184', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='that the problem of computing the partition function Z for MRF s is\\na special case of the sum-product inference task. In fact, in order to\\ncompute Z, the sum in ( 7.25) is carried out over all variables in x.\\nWhen the undirected graph describing the joint distributio n is a\\ntree5 , the complexity of sum-product inference becomes exponent ial\\nonly in the maximum number of variables in each factor, also k nown as\\ntreewidth of the graph. In this case, the sum-product inference proble m\\ncan be exactly solved via message passing belief propagation over the\\nfactor graph associated to the MRF. W e refer to the textbooks [81, 15,\\n104] for details on factor graphs and belief propagation.\\nExample 7.11. The MRF associated with an HMM is obtained from\\nthe BN in Fig. 7.3 by simply substituting directed for undirected edges,\\nand the distribution ( 7.10) factorizes as\\np(x,z) = ψ(z1 )ψ(x1 ,z1 )\\nD∏\\ni=1\\nψ(zi ,zi−1 )ψ(xi ,zi ). (7.26)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 189, 'page_label': '184', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the BN in Fig. 7.3 by simply substituting directed for undirected edges,\\nand the distribution ( 7.10) factorizes as\\np(x,z) = ψ(z1 )ψ(x1 ,z1 )\\nD∏\\ni=1\\nψ(zi ,zi−1 )ψ(xi ,zi ). (7.26)\\nThe undirected graph is a tree with treewidth equal to 2, sinc e, as per\\n(7.26), there are at most two variables in each clique. Therefore, belief\\npropagation allows to evaluate the posteriors p(zi|x) with a complexity\\nof the order |Z|2 , which does not scale exponentially with the number\\nD of time samples.\\n5 In a tree, there is only one path between any pairs of nodes (no loops).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 190, 'page_label': '185', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='7.5. Summary 185\\nWhen the undirected graph is not a tree, one can use the junction\\ntree algorithm for exact Bayesian inference. The idea is to group subsets\\nof variables together in cliques, in such a way that the resul ting graph is\\na tree. The complexity depends on the treewidth of the result ing graph.\\nWhen this complexity is too high for the given application, a pproximate\\ninference methods are necessary . This is the subject of the n ext chapter.\\n7.5 Summary\\nProbabilistic graphical models encode a priori informatio n about the\\nstructure of the data in the form of causality relationships – via di-\\nrected graphs and BNs – or mutual aﬃnities – via undirected gr aphs\\nand MRF s. This structure translates into conditional indep endence con-\\nditions. The structural properties encoded by probabilist ic graphical\\nmodels have the potential advantage of controlling the capa city of a\\nmodel, hence contributing to the reduction of overﬁtting at the expense'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 190, 'page_label': '185', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='models have the potential advantage of controlling the capa city of a\\nmodel, hence contributing to the reduction of overﬁtting at the expense\\nof possible bias eﬀects (see Chapter 5). They also facilitat e Bayesian\\ninference (Chapters 2-4), at least in graphs with tree-like structures.\\nProbabilistic graphical models can be used as the underlyin g proba-\\nbilistic framework for supervised, unsupervised, and semi -supervised\\nlearning problems, depending on which subsets of rvs are obs erved or\\nlatent.\\nWhile graphical models can reduce the complexity of Bayesia n infer-\\nence, this generally remains computationally infeasible f or most models\\nof interest. T o address this problem, the next chapter discu sses ap-\\nproximate Bayesian inference, as well as associated learni ng problems\\n(Chapter 6).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 191, 'page_label': '186', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8\\nApproximate Inference and Learning\\nIn Chapters 6 and 7, we have seen that learning and inference t asks are\\noften made diﬃcult by the need to compute the posterior distr ibution\\np(z|x) of an unobserved variables z given an observed variables x. This\\ntask requires the computation of the normalizing marginal\\np(x) =\\n∑\\nz\\np(x,z), (8.1)\\nwhere the sum is replaced by an integral for continuous varia bles.1 This\\ncomputation is intractable when the alphabet of the hidden v ariable z\\nis large enough. Chapter 7 has shown that the complexity of co mput-\\ning ( 8.1) can be alleviated in the special case in which the factorize d\\njoint distribution p(x,z) is deﬁned by speciﬁc classes of probabilistic\\ngraphical models.\\nWhat to do when the complexity of computing ( 8.1) is excessive?\\nIn this chapter, we provide a brief introduction to two popul ar ap-\\nproximate inference approaches, namely MC methods and V ari ational\\nInference (VI). W e also discuss their application to learni ng. As for the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 191, 'page_label': '186', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='proximate inference approaches, namely MC methods and V ari ational\\nInference (VI). W e also discuss their application to learni ng. As for the\\n1 Note that this task subsumes ( 7.23) after appropriate redeﬁnitions of the vari-\\nables.\\n186'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 192, 'page_label': '187', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.1. Monte Carlo Methods 187\\nprevious chapter, the reader is referred to [ 81, 15, 104, 151] for details\\nand generalizations (see also [ 114]).\\n8.1 Monte Carlo Methods\\nT o introduce MC methods, we start by observing that the expre ssion\\n(8.1) can be rewritten as the ensemble average\\np(x) =\\n∑\\nz\\np(z)p(x|z) = Ez∼p(z)[p(x|z)] (8.2)\\nover the latent rvs z∼p(z). The general idea behind MC methods is re-\\nplacing ensemble averages with empirical averages over ran domly gen-\\nerated samples. In the most basic incarnation of MC, M i.i.d. samples\\nzm ∼p(z), m = 1 ,...,M, are generated from the marginal distribu-\\ntion p(z) of the latent variables, and then the ensemble average ( 8.2)\\nis approximated by the empirical average\\np(x) ≃ 1\\nM\\nM∑\\nm=1\\np(x|zm). (8.3)\\nBy the law of large numbers, we know that this estimate is cons istent,\\nin the sense that it tends with probability one to the ensembl e average\\n(8.2) when M is large. F urthermore, the error of the approximation\\nscales as 1/\\n√\\nM.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 192, 'page_label': '187', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='in the sense that it tends with probability one to the ensembl e average\\n(8.2) when M is large. F urthermore, the error of the approximation\\nscales as 1/\\n√\\nM.\\nExample 8.1. Consider the Ising model for image denoising introduced\\nin Example 7.8. W e recall that the joint distribution can be factorized\\nas\\np(x,z) = 1\\nZ\\n∏\\n{i,j }\\nψi,j (zi,zj ) ·\\n∏\\ni\\nψi(zi ,xi), (8.4)\\nwhere {i,j}represents an edge of the undirected graph, with energy-\\nbased potentials ψij (zi,zj ) = exp(η1 zizj ) and ψi(zi ,xi ) = exp(η2 zixi ).\\nW e have removed the dependence of the potentials on the (natu ral)\\nparameters η1 and η2 for simplicity of notation. In order to compute\\nthe posterior p(z|x), which may be used for image denoising, the MC\\napproach ( 8.3) requires to sample from the marginal p(z). This is, how-\\never, not easy given the impossibility to perform ancestral sampling\\nover MRF s as discussed in Sec. 7.3.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 193, 'page_label': '188', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='188 Approximate Inference and Learning\\nImportance Sampling. As seen in the previous example, the MC\\nprocedure explained above is not always feasible in practic e, since draw-\\ning samples from the marginal p(z) may not be tractable. F or instance,\\nthe marginal p(z) may not be known or it may be diﬃcult to draw\\nsamples from it. In such common cases, one can instead resort to a sim-\\npliﬁed distribution q(z) from which sampling is easy . This distribution\\ntypically has convenient factorization properties that en able ancestral\\nsampling.\\nThe starting observation is that the marginal distribution (8.1) can\\nbe expressed as an ensemble average over a rv z ∼q(z) as\\np(x) =\\n∑\\nz\\np(z)p(x|z) q(z)\\nq(z)\\n=\\n∑\\nz\\nq(z) p(z)\\nq(z) p(x|z)\\n= Ez∼q(z)\\n[p(z)\\nq(z) p(x|z)\\n]\\n,\\n(8.5)\\nas long as the support of distribution q(z) contains that of p(z). This\\nexpression suggests the following empirical estimate, whi ch goes by the\\nname of Importance Sampling: Generate M i.i.d. samples zm ∼q(z),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 193, 'page_label': '188', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='expression suggests the following empirical estimate, whi ch goes by the\\nname of Importance Sampling: Generate M i.i.d. samples zm ∼q(z),\\nm= 1 ,...,M, and then compute the empirical approximation\\np(x) ≃ 1\\nM\\nM∑\\nm=1\\np(zm)\\nq(zm) p(x|zm). (8.6)\\nThis estimate is again consistent, but its variance depends on how well\\nq(z) approximates p(z). Note this approach requires knowledge of the\\nmarginal p(z) but not the ability to sample from it.\\nMarkov Chain Monte Carlo (MCMC) via Gibbs Sampling.\\nRather than drawing samples from a distribution that mimics p(z) in or-\\nder to compute an approximation of the posterior p(z|x) = p(x,z)/p(x),\\nMCMC methods aim at obtaining samples {zm } directly from the poste-\\nrior p(z|x). With such samples, one can compute empirical approxima-\\ntions of any ensemble average with respect to p(z|x). This is suﬃcient\\nto carry out most tasks of interest, including the expectati on needed\\nto evaluate the predictive posterior in Bayesian methods fo r supervised'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 193, 'page_label': '188', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='to carry out most tasks of interest, including the expectati on needed\\nto evaluate the predictive posterior in Bayesian methods fo r supervised\\nlearning or the average energy in the EM algorithm.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 194, 'page_label': '189', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 189\\nMCMC methods generate a sequence of correlated samples z1 ,z2 ,...\\nfrom an easy-to-sample Markov chain z1 −z2 −...that has the key prop-\\nerty of having the desired distribution p(z|x) as the stationary distri-\\nbution. Such a Markov chain can be designed automatically on ce a BN\\nor MRF factorization of the joint distribution is available . T o this end,\\nGibbs sampling samples sequentially subsets of rvs. F or eac h subset,\\nthe sampling distribution is obtained by normalizing the pr oduct of all\\nfactors including the rv being sampled (see, e.g., [ 81]).\\nThe mechanical nature of this procedure makes it a universal, or\\nblack-box, inference method, in the sense that it can be applied to\\nany typical probabilistic graphical model in an automatic f ashion. This\\nhas led to the recent emergence of probabilistic programming, whereby\\nBayesian inference is automatically performed by software libraries that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 194, 'page_label': '189', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='has led to the recent emergence of probabilistic programming, whereby\\nBayesian inference is automatically performed by software libraries that\\nare given as input a probabilistic graphical model for the jo int distri-\\nbution (see, e.g., [ 41, 148]).\\nMC methods are often used in combination with VI, as discusse d\\nin Sec. 8.3.\\n8.2 Variational Inference\\nThe general idea behind VI is to replace the ensemble average in ( 8.2)\\nwith a suitable optimization that returns an approximation of the pos-\\nterior distribution p(z|x). Speciﬁcally , VI methods introduce an addi-\\ntional distribution on the hidden variables z that is optimized in order\\nto approximate the desired posterior p(z|x).\\nI-projection. W e start with the observation that the solution to\\nthe optimization problem\\nmin\\nq(z)\\nKL(q(z)||p(z|x)) (8.7)\\nfor a ﬁxed value x, yields the unique solution q(z) = p(z|x) if no con-\\nstraints are imposed on q(z). This is due to Gibbs’ inequality ( 2.44).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 194, 'page_label': '189', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='min\\nq(z)\\nKL(q(z)||p(z|x)) (8.7)\\nfor a ﬁxed value x, yields the unique solution q(z) = p(z|x) if no con-\\nstraints are imposed on q(z). This is due to Gibbs’ inequality ( 2.44).\\nThis result is, by itself, not useful, since evaluating the K L divergence\\nKL(q(z)||p(z|x)) requires knowledge of p(z|x), which is exactly what\\nwe are after.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 195, 'page_label': '190', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='190 Approximate Inference and Learning\\nHowever, the equality between ( 6.13) and ( 6.14), namely\\nKL(q(z)||p(x,z)) = KL(q(z)||p(z|x)) −ln p(x), (8.8)\\ndemonstrates that problem ( 8.7) is equivalent to solving\\nmin\\nq(z)\\nKL(q(z)||p(x,z)), (8.9)\\nwhere, by ( 6.11), we can write\\nKL(q(z)||p(x,z)) = −Ez∼q(z)[ln p(x,z)] −H(q). (8.10)\\nIn words, solving problem ( 8.7) is equivalent to minimizing the varia-\\ntional free energy or Gibbs free energy (8.10) – or the negative of the\\nELBO. A key feature of this alternative formulation is that i t does not\\nrequire knowledge of the unavailable posterior p(z|x).\\nF rom the derivation above, solving problem ( 8.9) exactly without\\nimposing any constraint on q(z) would yield the desired posterior p(z|x)\\nas the output. The key idea of VI is to choose a parametric form q(z|ϕ)\\nfor the variational posterior that enables the solution of p roblem\\nminϕ KL(q(z|ϕ)||p(x,z)). (8.11)\\nBy the discussion above, this is equivalent to minimizing KL (q(z|ϕ)||p(z|x)),'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 195, 'page_label': '190', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for the variational posterior that enables the solution of p roblem\\nminϕ KL(q(z|ϕ)||p(x,z)). (8.11)\\nBy the discussion above, this is equivalent to minimizing KL (q(z|ϕ)||p(z|x)),\\ndespite the fact that p(z|x) is not known.\\nThe solution q(z|ϕ∗ ) to problem ( 8.11) is known as I-projection of\\nthe distribution p(z|x) in the set of distributions {q(z|ϕ)}deﬁned by\\nthe given parametrization. The I-projection can be taken as an estimate\\nof the posterior p(z|x). In fact, if the parametrized family {q(z|ϕ)}is\\nrich enough to contain distributions close to the true poste rior p(z|x),\\nthe minimization ( 8.11) guarantees the approximate equality q(z|ϕ∗ ) ≃\\np(z|x).\\nIn order to ensure the feasibility of the optimization ( 8.11), the\\nparametrized distribution q(z|ϕ) is typically selected to have a conve-\\nnient factorization and to have factors with tractable anal ytical forms,\\nsuch as members of the exponential family or GLMs [ 16].\\nAmortized VI. ∗ The variational posterior q(z|ϕ) obtained from'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 195, 'page_label': '190', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='nient factorization and to have factors with tractable anal ytical forms,\\nsuch as members of the exponential family or GLMs [ 16].\\nAmortized VI. ∗ The variational posterior q(z|ϕ) obtained from\\nthe I-projection ( 8.11) depends on the speciﬁc value of the observed\\nvariables x = x. Problem ( 8.11) is, in fact, solved separately for each'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 196, 'page_label': '191', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 191\\nvalue x = x. A potentially more eﬃcient solution is to deﬁne an in-\\nference variational distribution q(z|x,ϕ), which models the posterior\\ndistribution of z for any value of x = x. The inference distribution is\\nparametrized by a vector ϕ, and is typically implemented using a multi-\\nlayer neural network. In this case, it is typically referred to as inference\\nnetwork. This approach is referred to as amortized VI.\\nAmortized VI has the key advantage that, once the inference d is-\\ntribution is learned, one does not need to carry out I-projec tions for\\npreviously unobserved values of x = x. Instead, one can directly apply\\nq(z|x,ϕ) for the learned values of parameter ϕ [80].\\nThe inference distribution q(z|x,ϕ) can be obtained by solving the\\namortized I-projection problem\\nminϕ Ex∼p(x)[KL(q(z|x,ϕ)||p(x,z))], (8.12)\\nwhere the ensemble average is, in practice, replaced by an em pirical\\naverage over available data points {xn}. The solution of the VI problem'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 196, 'page_label': '191', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='minϕ Ex∼p(x)[KL(q(z|x,ϕ)||p(x,z))], (8.12)\\nwhere the ensemble average is, in practice, replaced by an em pirical\\naverage over available data points {xn}. The solution of the VI problem\\n(8.12) is hence “amortized” across multiple values of x.\\nM-projection.∗ By Theorem 6.1, the I-projection maximizes a\\nlower bound – the ELBO – on the log-distribution of the observ ed data\\nx. This gives I-projections a strong theoretical justiﬁcati on grounded\\nin the ML learning principle. Recalling that the KL divergen ce is not\\nsymmetric (see Sec. 2.6 and Appendix A), one could also deﬁne the\\nalternative problem\\nminϕ KL(p(z|x)||q(z|ϕ)). (8.13)\\nThe solution q(z|ϕ∗ ) to this problem is known as M-projection of the\\ndistribution p(z|x) in the set of distributions {q(z|ϕ)}deﬁned by the\\ngiven parametrization.\\nAs for the counterpart ( 8.7), this problem does not appear to be\\nsolvable since it requires knowledge of the desired posteri or p(z|x). How-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 196, 'page_label': '191', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='given parametrization.\\nAs for the counterpart ( 8.7), this problem does not appear to be\\nsolvable since it requires knowledge of the desired posteri or p(z|x). How-\\never, the problem turns out to have an easy solution if q(z|ϕ) belongs to\\nthe exponential family . In fact, the gradient with respect t o the natural\\nparameters ϕof the KL divergence in ( 8.7) can be computed by follow-\\ning the same steps detailed for ML learning in Sec. 3.3. The upshot of\\nthis computation and of the enforcement of the optimality co ndition'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 197, 'page_label': '192', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='192 Approximate Inference and Learning\\nis that the M-projection is obtained by moment matching. Speciﬁcally ,\\none needs to ﬁnd a value of parameter ϕ such that the expectations\\nof the suﬃcient statistics of the model q(z|ϕ) under distribution q(z|ϕ)\\nmatch with the same expectations under the true distributio n p(z|x).\\nIn mathematical terms, the M-projection in the exponential fam-\\nily model q(z|ϕ) ∝exp(ϕT u(z)), with suﬃcient statistics u(z), yields\\nnatural parameters ϕ∗ that satisfy the moment matching condition\\nEz∼p(z|x)[u(z)] = Ez∼q(z|ϕ ∗) [u(z)]. (8.14)\\nThis derivation is detailed in the Appendix of this chapter. Amortized\\ninference can be deﬁned in a similar way as for I-projection.\\n-3 -2 -1 0 1 2 3\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\nI-projection\\nM-projection\\nFigure 8.1: Example of I- and M-projections of a mixture of Gaussians dis tribution\\n(dashed line).\\nExample 8.2. This simple example is meant to provide an intuitive'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 197, 'page_label': '192', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='1.2\\n1.4\\nI-projection\\nM-projection\\nFigure 8.1: Example of I- and M-projections of a mixture of Gaussians dis tribution\\n(dashed line).\\nExample 8.2. This simple example is meant to provide an intuitive\\ncomparison between the approximations produced by I- and M- projections.\\nT o this end, consider a mixture of Gaussians distribution\\np(z|x) = 0 .3N(z|µ1 = −1,σ2\\n1 = 0 .3) + 0 .7N(z|µ2 = 1 ,σ2\\n2 = 0 .3),\\n(8.15)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 198, 'page_label': '193', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 193\\nas shown in Fig. 8.1. Note that this example is clearly idealized, since\\nin practice the conditional distribution p(z|x) is not known. Assume\\nthe variational distribution q(z|ϕ) = N(z|m,γ2 ) with variational pa-\\nrameters ϕ= ( m,γ2 ). The M-projection returns the moment matching\\nestimates m = Ez∼p(z|x)[z] = 0 .4 and γ2 = varz∼p(z|x)[z] = 0 .3((µ1 −\\nm)2 + σ2\\n1 ) + 0 .7((µ2 −m)2 + σ2\\n2 ) = 1 .93 for i = 1 ,2. Instead, the I-\\nprojection can be computed numerically , yielding m= 1 and γ2 = 0 .3.\\nThe I- and M-projections are also plotted in Fig. 8.1.\\nThe previous example illustrates a few important facts abou t I-\\nand M-projections. First, the I-projection tends to be mode-seeking\\nand exclusive. Mathematically , this is because the variational posterio r\\nq(z|ϕ) determines the support over which the distributions p(z|x) and\\nq(z|ϕ) are compared by the KL divergence. Therefore, I-projection s\\ntend to underestimate the variance of a distribution 2. F urthermore,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 198, 'page_label': '193', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='q(z|ϕ) are compared by the KL divergence. Therefore, I-projection s\\ntend to underestimate the variance of a distribution 2. F urthermore,\\nthe I-projection is generally more accurate where p(z|x) is larger. In\\ncontrast, the M-projection tends to be inclusive and to span the entire\\nsupport of p(z|x). This is because the M-projection prefers to avoid zero\\nvalues for q(z|ϕ) at values of z such that p(z|x) ̸= 0 in order to avoid\\nan inﬁnite KL divergence. W e refer to Fig. 6.5 for a related example.\\nα−Divergence.∗ As already discussed in Sec. 6.4.3, the KL diver-\\ngence is only one among many possible ways to deﬁne a measure o f\\ndistance between two distributions. A metric that has found useful ap-\\nplications in the context of VI is the α-divergence introduced in [ 96].\\nThe α-divergence between two distributions p(x) and q(x) is deﬁned as\\nDα (p||q) =\\n∑\\nx αp(x) + (1 −α)q(x) −p(x)α q(x)1−α\\nα(1 −α) , (8.16)\\nwhere p and q need not be normalized, and α is a parameter. It can'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 198, 'page_label': '193', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Dα (p||q) =\\n∑\\nx αp(x) + (1 −α)q(x) −p(x)α q(x)1−α\\nα(1 −α) , (8.16)\\nwhere p and q need not be normalized, and α is a parameter. It can\\nbe proved that, as α →0, we obtain Dα (p||q) = KL(q||p), and, when\\nα →1, we have Dα(p||q) = KL(p||q). Consistently with the discus-\\nsion about I- and M-projections in the previous example, per form-\\ning projections of the type min ϕDα (p(x|z)||q(z|ϕ)) with α ≤0 and\\ndecreasing values of α yields an increasingly mode-seeking, or exclu-\\nsive, solution; while increasing values of α ≥ 1 yield progressively\\n2 See [ 147] for an example that demonstrates the limitations of this ge neral state-\\nment.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 199, 'page_label': '194', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='194 Approximate Inference and Learning\\nmore inclusive and zero-avoiding solutions (see [ 96, Fig. 1]). Finally ,\\nfor all α ̸= 0 , it can be proved that the stationary points of the pro-\\njection min ϕDα(p(x|z)||q(z|ϕ)) coincide with those of the projection\\nminϕKL(p(x|z)||p(x|z)α q(z|ϕ)1−α ). The α-divergence can be further\\ngeneralized as discussed in Appendix A.\\n8.2.1 Mean Field Variational Inference\\nMean Field VI (MFVI) is a VI method that leads to a universal, o r\\nblack-box, Bayesian inference technique, such as Gibbs sam pling for\\nMC techniques. MFVI assumes the factorization q(z) = ∏\\nj q(zj ), and\\nperforms an I-projection iteratively for one hidden variab le zi at a time,\\nwhile ﬁxing the factors qj (zj ) for the other latent variables zj with j ̸= i.\\nNo constraints are imposed on each factor qj (zj ). This corresponds to\\ntackling the I-projection problem using block coordinate d escent within\\nthe given factorized family of distributions.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 199, 'page_label': '194', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='No constraints are imposed on each factor qj (zj ). This corresponds to\\ntackling the I-projection problem using block coordinate d escent within\\nthe given factorized family of distributions.\\nF or each factor qi(zi ), the I-projection problem minimizes the vari-\\national free energy\\n−Ezi ∼qi(zi ) [Ej̸=i[lnp(x,z)]] −\\n∑\\nj\\nH(qj (zj )), (8.17)\\nwhere we have deﬁned for brevity the expectation\\nEj̸=i[lnp(x,z)] = E{zj }j̸=i ∼\\n∏\\nj̸=i qj (zj )[lnp(x,zi ,{zj }j̸=i)]. (8.18)\\nNeglecting constants independent of qi(zi ), this problem is equivalent\\nto the minimization\\nminqi\\nKL(qi(zi )||exp(Ej̸=i[lnp(x,z)])). (8.19)\\nThe solution to this problem can be easily seen to be obtained by\\nnormalizing the right-hand argument of the divergence as\\nqi(zi) = exp(Ej̸=i[lnp(x,z)])\\n∑\\nzi exp(Ej̸=i[lnp(x,z)]) . (8.20)\\nMFVI solves the system of equations ( 8.20) for all i by cycling\\nthrough the factors qi(zi ) or by choosing them randomly . Note that, as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 200, 'page_label': '195', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.2. Variational Inference 195\\ndiscussed more generally above, this procedure does not req uire knowl-\\nedge of the desired posterior p(z|x) but only of the joint distribution\\np(x,z). The MFVI iterations are guaranteed to converge to a station ary\\npoint of the KL minimization problem.\\nIt remains to discuss how to evaluate the expectations in ( 8.20). T o\\nthis end, let us assume that the joint distribution p(x,z) factorizes as\\np(x,z) = Z−1 ∏\\nc ψc(xc,zc) as for MRF s or BNs – recall that in the\\nlatter case, we have Z = 1 . The MFVI equation ( 8.20) can be written\\nas\\nqi(zi ) ∝exp\\n(\\nEj̸=i\\n[∑\\nc\\nlnψc(xc,zc)\\n])\\n= exp\\n(\\nEj̸=i\\n[ ∑\\nc: zi ∈ zc\\nlnψc(xc,zc)\\n])\\n.\\n(8.21)\\nIn the second line we have used the fact that it is suﬃcient to c onsider\\nonly the factors corresponding to cliques that include zi. This enables\\nimplementations by means of local message passing (see, e.g ., [ 81]).\\nF urthermore, additional simpliﬁcations are possible when the factors'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 200, 'page_label': '195', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='implementations by means of local message passing (see, e.g ., [ 81]).\\nF urthermore, additional simpliﬁcations are possible when the factors\\nψc(xc,zc) are log-linear, as illustrated by the next example.\\n0 1 2 3 4\\nnumber of iterations\\n10-4\\n10-2\\n100\\nKL divergence\\nFigure 8.2: KL divergence between actual posterior and mean-ﬁeld appro ximation\\nas a function of the number of iterations of MFVI ( η1 = 0 .15).\\nExample 8.3. Consider again the Ising model ( 8.4). The MFVI equa-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 201, 'page_label': '196', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='196 Approximate Inference and Learning\\ntions ( 8.21) for approximating the posterior p(z|x) are given as\\nqi(zi ) ∝exp\\n(\\nη1\\n∑\\n{i,j }\\nEzj ∼q(zj )[zi zj ] + η2 xizi\\n)\\n= exp\\n(\\nzi\\n(\\nη1\\n∑\\n{i,j }\\nEzj ∼q(zj )[zj ] + η2xi\\n))\\n,\\n(8.22)\\nand hence, upon normalization, we have\\nqi(zi = 1) = 1\\n1 + exp( −2(η1\\n∑\\n{i,j } µj + η2 xi)) , (8.23)\\n= σ\\n\\uf8eb\\n\\uf8ed2\\n\\uf8eb\\n\\uf8edη1\\n∑\\n{i,j }\\nµj + η2xi\\n\\uf8f6\\n\\uf8f8\\n\\uf8f6\\n\\uf8f8,\\nwhere µi = qi(zi = 1) −qi(zi = −1) = 2 qi(zi = 1) −1.\\nF or a numerical example, consider a 4 ×4 binary image z observed\\nas matrix x, where the joint distribution of x and z is given by the\\nIsing model. Note that, according to this model, the observe d matrix x\\nis such that each pixel of the original matrix z is ﬂipped independently\\nwith probability σ(−2η2 ). In this small example, it is easy to generate\\nan image x distributed according to the model, as well as to compute\\nthe exact posterior p(z|x) by enumeration of all possible images z. The\\nKL divergence KL (p(x|z)||∏\\ni qi(zi)) obtained at the end of each iter-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 201, 'page_label': '196', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the exact posterior p(z|x) by enumeration of all possible images z. The\\nKL divergence KL (p(x|z)||∏\\ni qi(zi)) obtained at the end of each iter-\\nation of MFVI – with one iteration applying (\\n8.23) one by one to all\\nvariables – is shown in Fig. 8.2 for η1 = 0 .15 and various values of η2 .\\nAs η2 increases, the posterior distribution tends to become dete rminis-\\ntic, since x is an increasingly accurate measurement of z. As a result,\\nthe ﬁnal mean-ﬁeld approximation is more faithful to the rea l poste-\\nrior, since a product distribution can capture a determinis tic pmf. F or\\nsmaller values of η2 ,however, the bias due to the mean-ﬁeld assumption\\nyields a signiﬁcant ﬂoor on the achievable KL divergence.\\nBeyond MFVI. ∗ MFVI assumes a fully factorized variational dis-\\ntribution q(z). It is also possible to develop methods that are based on\\nthe same factorization as the joint distribution p(x,z). This is known\\nas the Bethe approach , and yields Loopy Belief Propagation (LBP) as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 201, 'page_label': '196', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the same factorization as the joint distribution p(x,z). This is known\\nas the Bethe approach , and yields Loopy Belief Propagation (LBP) as\\na speciﬁc solution technique. LBP can also be interpreted as the ap-\\nplication of message passing belief propagation, which was described'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 202, 'page_label': '197', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.3. Monte Carlo-Based Variational Inference ∗ 197\\nin Sec. 7.4, to factor graphs with loops. Simpliﬁcations of loopy belie f\\npropagation include Approximate Message Passing (AMP). Wh en ap-\\nplied to M-projections with factors restricted to lie in the exponential\\nfamily , the approach yields the Expectation Propagation method. W e\\nrefer to [ 81, 114] for details.\\n8.3 Monte Carlo-Based Variational Inference ∗\\nThe VI methods described in the previous section require the evalua-\\ntion of expectations with respect to the variational poster ior (see, e.g.,\\n(8.20)). The feasibility of this operation relies on speciﬁc assu mptions\\nabout the variational posterior, such as its factorization properties and\\nmembership of the exponential family . It is hence desirable to devise\\nmethods that do not require the exact computation of the ense mble\\naverages with respect to the variational posterior q(z|ϕ). As we will\\nsee below, this is possible by combining VI methods with MC ap proxi-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 202, 'page_label': '197', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='averages with respect to the variational posterior q(z|ϕ). As we will\\nsee below, this is possible by combining VI methods with MC ap proxi-\\nmations. The resulting methods can leverage SGD, scale to la rge data\\nsets, and have found a large number of recent applications [ 24, 25, 7].\\nThe key idea of MC-based VI is to approximate the KL divergenc e\\n(8.10) via MC by drawing one or more samples zm ∼q(z), with m =\\n1,...,M , and by computing the empirical average\\nKL(q(z)||p(x,z)) ≃ 1\\nM\\nM∑\\nm=1\\n(lnq(zm) −ln p(x,zm)). (8.24)\\nIn order to optimize over the parameters ϕof the variational posterior\\nq(z|ϕ), it is in fact more useful to approximate the gradient of the K L\\ndivergence, as discussed next.\\nREINFORCE approach. T o proceed, assume the following two\\nrather mild conditions on the parametrized variational pos terior: ( i ) it\\nis easy to draw samples z ∼q(z|ϕ); and ( ii ) it is possible to compute\\nthe gradient ∇ϕlnq(z|ϕ). W e can now develop an SGD-based scheme as'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 202, 'page_label': '197', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is easy to draw samples z ∼q(z|ϕ); and ( ii ) it is possible to compute\\nthe gradient ∇ϕlnq(z|ϕ). W e can now develop an SGD-based scheme as\\nfollows. The main result is that the gradient of the KL diverg ence in the\\nI-projection problem ( 8.11) with respect to the variational parameters\\nϕ can be written as\\n∇ϕKL(q(z|ϕ)||p(x,z)) = Ez∼q(z|ϕ) [∇ϕlnq(z|ϕ)lϕ (x,z)] , (8.25)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 203, 'page_label': '198', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='198 Approximate Inference and Learning\\nwhere we have deﬁned the learning signal\\nlϕ (x,z) = lnq(z|ϕ) −lnp(x,z). (8.26)\\nT o obtain ( 8.25), we have used the identity ∇ϕlnq(z|ϕ) = ∇ϕq(z|ϕ)/q(z|ϕ),\\nwhich follows from the chain rule for diﬀerentiation, as wel l as the equal-\\nity E z∼q(z|ϕ) [∇ϕlnq(z|ϕ)] = 0 (see [ 25] for details).\\nMC-based VI methods evaluate an MC approximation of the grad i-\\nent ( 8.25) at a given value ϕby drawing one or more samples zm ∼q(z|ϕ),\\nwith m= 1 ,...,M , and then computing\\n∇ϕKL(q(z|ϕ)||p(x,z)) ≃ 1\\nM\\nM∑\\nm=1\\n[∇ϕlnq(zm|ϕ)lϕ (x,zm)] . (8.27)\\nThis estimate is also known as likelihood ratio or REINFORCE gradi-\\nent, and it can be used to update the value of ϕ using SGD (see Sec.\\n4.1). The name reﬂects the origin and the importance of the appro ach\\nin the reinforcement learning literature, as we brieﬂy disc uss in Chapter\\n93\\nIn practice, these gradients have high variance. This is int uitively\\ndue to the fact that this estimator does not use any informati on about'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 203, 'page_label': '198', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='93\\nIn practice, these gradients have high variance. This is int uitively\\ndue to the fact that this estimator does not use any informati on about\\nhow a change in z aﬀects the learning signal lϕ (x,z), since it only\\ndepends on the value of this signal. Therefore, techniques s uch as Rao-\\nBlackwellization or control variates need to be introduced in order to\\nreduce its variance (see [ 89] for a review). Simpliﬁcations are possible\\nwhen the variational posterior is assumed to factorize, e.g ., according to\\nthe mean-ﬁeld full factorization. This approach is used in t he black-box\\ninference method of [ 120].\\nReparametrization trick. In order to mitigate the problem of\\nthe high variance of the REINFORCE estimator, the reparamet riza-\\ntion trick leverage additional information about the depen dence of the\\nvariational distribution q(z|ϕ),and hence of the learning signal lϕ(x,z),\\non the variable z. This approach is applicable if: ( i ) the latent variable'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 203, 'page_label': '198', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='variational distribution q(z|ϕ),and hence of the learning signal lϕ(x,z),\\non the variable z. This approach is applicable if: ( i ) the latent variable\\nz ∼q(z|ϕ) can be written as z = Gϕ (w) for some diﬀerentiable function\\n3 In reinforcement learning, it is useful to compute the gradi ent of the average\\nreward E t∼q(t|x,ϕ ) [R(t, x )] with respect to the parameters ϕ deﬁning the distribution\\nq(t|x, ϕ ) of the action t given the current state x of the environment. The reward\\nR(t, x ) is a function, possibly stochastic, of the action and of the state.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 204, 'page_label': '199', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.4. Approximate Learning ∗ 199\\nGϕ(·) and for some rv w ∼s(z) whose distribution does not depend on\\nϕ; and ( ii ) the variational regularization term KL (q(z|ϕ)||p(z)) in ( 6.12)\\ncan be computed and diﬀerentiated with respect to ϕ. Assumption ( ii )\\nis satisﬁed by members of the exponential family (see Append ix B). A\\ntypical choice that satisﬁes these conditions is to set p(z) to be an i.i.d.\\nGaussian distribution; w as i.i.d. Gaussian rvs; and function Gϕ(w) as\\nGϕ(w) = Aϕw+ bϕ, where matrix Aϕ and vector bϕ are parametrized\\nby a multi-layer neural networks. Note that, with this choic e, we have\\nq(z|ϕ) = N(z|bϕ ,AϕAT\\nϕ ). W e refer to [\\n73, 95] for other examples.\\nT o see why these assumptions are useful, let us ﬁrst rewrite t he\\nobjective of the I-projection problem using ( 6.12) as\\nKL(q(z|ϕ)||p(x,z)) = −Ew∼s(z) [lnp(x|Gϕ (w))] + KL(q(z|ϕ)||p(z)).\\n(8.28)\\nW e can now approximate the expectation in the ﬁrst term via an em-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 204, 'page_label': '199', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='objective of the I-projection problem using ( 6.12) as\\nKL(q(z|ϕ)||p(x,z)) = −Ew∼s(z) [lnp(x|Gϕ (w))] + KL(q(z|ϕ)||p(z)).\\n(8.28)\\nW e can now approximate the expectation in the ﬁrst term via an em-\\npirical average by generating i.i.d. samples wm ∼s(w), m= 1 ,...,M 4 .\\nNote that this distribution does not depend on the current it erate ϕ.\\nW e can then estimate the gradient by writing\\n∇ϕKL(q(z|ϕ)||p(x,z)) ≃− 1\\nM\\nM∑\\nm=1\\n[∇ϕlnp(x|Gϕ (wm))]+∇ϕKL(q(z|ϕ)||p(z)).\\n(8.29)\\nThis approach tends to provide estimate with lower variance than the\\nREINFORCE gradient, since it exploits the structure of the d istribu-\\ntion q(z|ϕ).\\nBoth REINFORCE and reparametrization trick can be naturall y\\ncombined with amortized inference. W e also refer to [ 59] for a proposed\\ncombination of both methods.\\n8.4 Approximate Learning ∗\\nAs we have discussed, Bayesian inference plays a key role in l earning\\nproblems. In this section, we brieﬂy discuss representativ e schemes that'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 204, 'page_label': '199', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.4 Approximate Learning ∗\\nAs we have discussed, Bayesian inference plays a key role in l earning\\nproblems. In this section, we brieﬂy discuss representativ e schemes that\\nincorporate approximate inference for learning. Since Bay esian learning\\n4 This can be seen as an application of the Law of the Unconsciou s Statistician.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 205, 'page_label': '200', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='200 Approximate Inference and Learning\\ncan directly beneﬁt from approximate inference in evaluati ng the pos-\\nterior of the parameters and the variational posterior, we f ocus here on\\nthe frequentist viewpoint.\\nML learning in the presence of hidden variables can be approx i-\\nmated by maximizing the ELBO with respect to both the model pa -\\nrameters θ that deﬁne the forward model p(x|z,θ) and the parameters\\nϕ of the variational (amortized) model q(z|x,ϕ). T o understand what\\nis accomplished with this optimization, it is useful to writ e the ELBO\\nover a data set D={xn}N\\nn=1 using (\\n6.14) as\\nN∑\\nn=1\\nln p(xn|θ) −KL (q(z|xn ,ϕ)||p(z|xn ,θ)) . (8.30)\\nAs such, for any ﬁxed ϕ, optimizing the ELBO over θ maximizes the\\nlikelihood function in the ﬁrst term under a variational reg ularization\\nterm that penalizes posteriors p(z|x,θ) that are signiﬁcantly diﬀerent\\nfrom the selected variational posteriors q(z|x,ϕ). The choice of a given'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 205, 'page_label': '200', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='term that penalizes posteriors p(z|x,θ) that are signiﬁcantly diﬀerent\\nfrom the selected variational posteriors q(z|x,ϕ). The choice of a given\\nmodel for the variational posterior hence drives learning, and should\\nbe treated as model or hyperparameter selection [ 68].\\nThe maximization of the ELBO over both model and variational\\nparameters can be carried out in diﬀerent ways. As a ﬁrst appr oach,\\none can use EM by performing the E step via approximate infere nce\\nto evaluate the posterior of the latent variables. When VI is used for\\nthis purpose, the resulting scheme is known as variational EM . Alterna-\\ntively , one can use SGD with respect to both parameter vector s θand ϕ\\nby leveraging the REINFORCE method or the reparametrizatio n trick.\\nThe reparametrization trick approach is for instance used i n the V AE\\nmethod for generative modelling [ 80], also known as Deep Gaussian\\nLatent Models [ 122], as well as in the black-box learning approach of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 205, 'page_label': '200', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='method for generative modelling [ 80], also known as Deep Gaussian\\nLatent Models [ 122], as well as in the black-box learning approach of\\n[121] (see also [ 98]). The KL divergence can also be substituted by an\\nadversarially learned divergence as in the GAN approach [ 47] (see Sec.\\n6.4.3).\\nWhen the variational parameters are updated using an M-proj ection,\\nrather than the I-projection that results from the maximiza tion of the\\nELBO, the approach of jointly optimizing model and variatio nal pa-\\nrameters yields the wake-sleep algorithm [65].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 206, 'page_label': '201', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='8.5. Summary 201\\n8.5 Summary\\nHaving observed in previous chapters that learning in proba bilistic mod-\\nels is often held back by the complexity of exact Bayesian inf erence for\\nhidden variables, this chapter has provided an overview of a pproximate,\\nlower-complexity , inference techniques. W e have focused o n MC and VI\\nmethods, which are most commonly used. The treatment stress ed the\\nimpact of design choices in the selection of diﬀerent types o f approxi-\\nmation criteria, such as M- and I-projection. It also covere d the use of\\napproximate inference in learning problems. T echniques th at improve\\nover the state of the art discussed in this chapter are being a ctively\\ninvestigated. Some additional topics for future research a re covered in\\nthe next chapter.\\nAppendix: M-Projection with the Exponential Family\\nIn this appendix, we consider the problem of obtaining the M- projection\\nof a distribution p(z) into a model q(z|ϕ) = Z(ϕ)−1 exp(ϕT u(z)) from'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 206, 'page_label': '201', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Appendix: M-Projection with the Exponential Family\\nIn this appendix, we consider the problem of obtaining the M- projection\\nof a distribution p(z) into a model q(z|ϕ) = Z(ϕ)−1 exp(ϕT u(z)) from\\nthe exponential family with suﬃcient statistics u(z). W e will prove\\nthat, if there exists a value of ϕ∗ of the natural parameter vector that\\nsatisﬁes the moment matching condition (\\n8.14), then q(z|ϕ∗ ) is the\\nM-projection.\\nW e ﬁrst write the KL divergence as\\nKL(p(z)||q(z|ϕ)) = lnZ(ϕ) −ϕT Ez∼p(z)[u(z)] −H(p). (8.31)\\nThe diﬀerence between the KL divergence for a generic parame ter vec-\\ntor ϕand for the vector ϕ∗ satisfying ( 8.14) can be written as\\nKL(p(z)||q(z|ϕ)) −KL(p(z)||q(z|ϕ∗ ))\\n=ln\\n( Z(ϕ)\\nZ(ϕ∗ )\\n)\\n−(ϕ−ϕ∗ )T Ez∼p(z)[u(z)]\\n=Ez∼q(z|ϕ∗)\\n[\\nln\\n( q(z|ϕ∗ )\\nq(z|ϕ)\\n) ]\\n=KL(q(z|ϕ∗ )||q(z|ϕ)). (8.32)\\nSince the latter inequality is non-negative and equal to zer o when ϕ=\\nϕ∗ ,this choice of the natural parameters minimizes the KL diver gence.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 207, 'page_label': '202', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Part V\\nConclusions'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 208, 'page_label': '203', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='9\\nConcluding Remarks\\nThis monograph has provided a brief introduction to machine learn-\\ning by focusing on parametric probabilistic models for supe rvised and\\nunsupervised learning problems. It has endeavored to descr ibe funda-\\nmental concepts within a uniﬁed treatment starting from ﬁrs t princi-\\nples. Throughout the text, we have also provided pointers to advanced\\ntopics that we have only been able only to mention or shortly t ouch\\nupon. Here, we oﬀer a brief list of additional important aspe cts and\\nopen problems that have not been covered in the preceding cha pters.\\n•Privacy: In many applications, data sets used to train machine\\nlearning algorithms contain sensitive private informatio n, such as per-\\nsonal preferences for recommendation systems. It is hence i mportant to\\nensure that the learned model does not reveal any informatio n about\\nthe individual entries of the training set. This constraint can be for-\\nmulated using the concept of diﬀerential privacy . Typical t echniques'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 208, 'page_label': '203', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the individual entries of the training set. This constraint can be for-\\nmulated using the concept of diﬀerential privacy . Typical t echniques\\nto guarantee privacy of individual data points include addi ng noise to\\ngradients when training via SGD and relying on mixture of exp erts\\ntrained with diﬀerent subsets of the data [ 1].\\n•Robustness: It has been reported that various machine learning\\nmodels, including neural networks, are sensitive to small v ariations in\\n203'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 209, 'page_label': '204', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='204 Concluding Remarks\\nthe data, producing the wrong response upon minor, properly chosen,\\nchanges in the explanatory variables. Note that such advers arially cho-\\nsen examples, which cause a speciﬁc machine to fail, are conc eptually\\ndiﬀerent from the randomly selected examples that are assum ed when\\ndeﬁning the generalization properties of a network. There i s evidence\\nthat ﬁnding such examples is possible even without knowing t he inter-\\nnal structure of a machine, but solely based on black-box obs ervations\\n[111]. Modifying the training procedure in order to ensure robus tness\\nto adversarial examples is an active area of research with im portant\\npractical implications [ 55].\\n•Computing platforms and programming frameworks : In order to\\nscale up machine learning applications, it is necessary to l everage dis-\\ntributed computing architectures and related standard pro gramming\\nframeworks [ 17, 7]. As a complementary and more futuristic approach,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 209, 'page_label': '204', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tributed computing architectures and related standard pro gramming\\nframeworks [ 17, 7]. As a complementary and more futuristic approach,\\nrecent work has even proposed to leverage the capabilities o f annealing-\\nbased quantum computers as samplers [ 82] or discrete optimizers [ 103].\\n•T ransfer learning : Machines trained for a certain task currently\\nneed to be re-trained in order to be re-purposed for a diﬀeren t task.\\nF or instance, a machine that learned how to drive a car would n eed to\\nbe retrained in order to learn how to drive a truck. The ﬁeld of transfer\\nlearning covers scenarios in which one wishes to transfer th e expertise\\nacquired from some tasks to others. T ransfer learning inclu des diﬀerent\\nrelated paradigms, such as multitask learning, lifelong le arning, zero-\\nshot learning, and domain adaptation [ 149]. In multitask learning , sev-\\neral tasks are learned simultaneously . Typical solutions f or multitask'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 209, 'page_label': '204', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='shot learning, and domain adaptation [ 149]. In multitask learning , sev-\\neral tasks are learned simultaneously . Typical solutions f or multitask\\nlearning based on neural networks prescribe the presence of common\\nhidden layers among neural networks trained for diﬀerent ta sks [ 19].\\nLifelong learning updates a machine trained on a number of tasks to\\ncarry out a new task by leveraging the knowledge accumulated during\\nthe previous training phases [ 143]. Zero-shot learning refers to models\\ncapable of recognizing unseen classes with training exampl es available\\nonly for related, but diﬀerent, classes. This often entails the task of\\nlearning representation of classes, such as prototype vect ors, that gen-\\nerate data in the class through a ﬁxed probabilistic mechani sm [ 52].\\nDomain adaptation will be discussed separately in the next p oint.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 210, 'page_label': '205', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='205\\n• Domain adaptation : In many learning problems, the available\\ndata has a diﬀerent distribution from the data on which the al gorithm\\nwill be tested. F or instance, in speech recognition, one has available\\ndata for a given user at learning time, but it may be desirable , after\\nlearning, to use the same machine for another user. F or super vised\\nlearning, this is typically modeled by assuming that the dis tribution of\\nthe covariates x is diﬀerent during training and test, while the discrim-\\ninative conditional distribution p(t|x) is the same for both phases [ 149].\\nA generalization of P AC theory analyses domain adaptation, obtaining\\nbounds on the generalization error under the desired test di stribution\\nas a function of the diﬀerence between the training and test d istribu-\\ntions [ 26].\\n•Communication-eﬃcient learning : In distributed computing plat-\\nforms, data is typically partitioned among the processors a nd commu-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 210, 'page_label': '205', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tions [ 26].\\n•Communication-eﬃcient learning : In distributed computing plat-\\nforms, data is typically partitioned among the processors a nd commu-\\nnication among the processor entails latency and energy con sumption.\\nAn important research problem is that of characterizing the best trade-\\noﬀ between learning performance and communication overhea d [ 160].\\n•Reinforcement learning : Reinforcement learning is at the heart\\nof recent successes of machine learning methods in acquirin g the skills\\nnecessary to play video games or games against human opponen ts (see,\\ne.g., [ 99]). In reinforcement learning, one wishes to learn the optim al\\nmapping, say q(t|x,θ), between the observed state xof the world and an\\naction t. Unlike supervised learning, the optimal action tis not known,\\nbut the machine observes a reward/ punishment signal depend ing on\\nthe eﬀect of the action. A popular approach, referred to as de ep rein-\\nforcement learning, models the mapping q(t|x,θ) using a deep neural'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 210, 'page_label': '205', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the eﬀect of the action. A popular approach, referred to as de ep rein-\\nforcement learning, models the mapping q(t|x,θ) using a deep neural\\nnetwork. This is trained to maximize the average reward via S GD by\\nusing the REINFORCE method (Chapter 8) to estimate the gradi ent\\n[135, 88, 77, 9].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 211, 'page_label': '206', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Appendices'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 212, 'page_label': '207', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A\\nAppendix A: Information Measures\\nIn this appendix, we describe a principled and intuitive int roduction to\\ninformation measures that builds on inference, namely esti mation and\\nhypothesis testing. W e focus on entropy , mutual informatio n and diver-\\ngence measures. W e also concentrate on discrete rvs. In the m onograph,\\nwe have taken the pragmatic approach of extending the deﬁnit ions to\\ncontinuous variables by substituting sums with integrals. It is worth\\nnoting that this approach does not come with any practical co mplica-\\ntions when dealing with mutual information and divergence. Instead,\\nthe continuous version of the entropy , known as diﬀerential entropy ,\\nshould be treated with care, as it does not satisfy some key pr operties\\nof the entropy such as non-negativity .\\nA.1 Entropy\\nAs proposed by Claude Shannon, the amount of information rec eived\\nfrom the observation of a discrete random variable x ∼p(x) deﬁned over'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 212, 'page_label': '207', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of the entropy such as non-negativity .\\nA.1 Entropy\\nAs proposed by Claude Shannon, the amount of information rec eived\\nfrom the observation of a discrete random variable x ∼p(x) deﬁned over\\na ﬁnite alphabet Xshould be measured by the amount of uncertainty\\nabout its value prior to its measurement [\\n134]. T o this end, we consider\\nthe problem of estimating the value of x when one only knows the\\n207'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 213, 'page_label': '208', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='208 Appendix A: Information Measures\\nprobabilistic model p(x). The key idea is that the observation of a\\nrandom variable x is more informative if its value is more diﬃcult to\\npredict a priori, that is, based only on the knowledge of p(x).\\nT o formalize this notion, we need to specify: ( i ) the type of estimates\\nthat one is allowed to make on the value of x; and ( ii ) the loss function\\nℓthat is used to measure the accuracy of the estimate. W e will p roceed\\nby considering two types of estimates, namely point estimates , whereby\\none needs to commit to a speciﬁc value ˆx as the estimate of x; and\\ndistributional estimates , in which instead we are allowed to produce a\\npmf ˆp(x) over alphabet X, hence deﬁning a proﬁle of \"beliefs\" over the\\npossible values of rv x. W e will see below that the second approach\\nyields Shannon entropy , ﬁrst encountered in this monograph in ( 2.45).\\nPoint Estimates. Given a point estimate ˆxand an observed value'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 213, 'page_label': '208', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='yields Shannon entropy , ﬁrst encountered in this monograph in ( 2.45).\\nPoint Estimates. Given a point estimate ˆxand an observed value\\nx∈X, as we have seen, the estimation error can be measured by a non -\\nnegative loss function ℓ(x,ˆx), such the quadratic loss function and the\\n0-1 loss function. F or any given loss function ℓ, based on the discussion\\nabove, we can measure the information accrued by the observa tion\\nof x ∼px by evaluating the average loss that is incurred by the best\\npossible a priori estimate of x. This leads to the deﬁnition of generalized\\nentropy [ 61]\\nHℓ(px ) = min\\nˆx\\nEx∼px [ℓ(x,ˆx)], (A.1)\\nwhere the estimate ˆx is not necessarily constrained to lie in the alpha-\\nbet X. As highlighted by the notation Hℓ(px ), the generalized entropy\\ndepends on the pmf px and on the loss function ℓ. The notion of gen-\\neralized entropy ( A.1) coincides with that of minimum Bayes risk for\\nthe given loss function ℓ.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 213, 'page_label': '208', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='depends on the pmf px and on the loss function ℓ. The notion of gen-\\neralized entropy ( A.1) coincides with that of minimum Bayes risk for\\nthe given loss function ℓ.\\nF or the quadratic loss function, the generalized entropy is the vari-\\nance of the distribution Hℓ2 (px ) = var(px ). T o see this, impose the\\noptimality condition dE[(x −ˆx)2 ]/dˆx = 0 to conclude that the opti-\\nmal point estimate is the mean ˆx = Ex∼px [x]. As for the 0-1 loss, the\\ngeneralized entropy equals the minimum probability of erro r for the\\ndetection of x, that is,\\nHℓ0 (px ) = min\\nˆx\\n∑\\nx̸=ˆx\\np(x) = 1 −max\\nˆx\\np(ˆx). (A.2)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 214, 'page_label': '209', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A.1. Entropy 209\\nThis is because the optimal estimate is the mode, i.e., the va lue ˆxwith\\nthe largest probability p(ˆx).\\nDistributional Estimate. W e now consider a diﬀerent type of\\nestimation problem in which we are permitted to choose a pmf ˆp(x)\\non the alphabet X as the estimate for the outcome of variable x. T o\\nfacilitate intuition, we can imagine ˆp(x) to represent the fraction of\\none’s wager that is invested on the outcome of x being a speciﬁc value\\nx. Note that it may not be necessarily optimal to put all of one’ s money\\non one value x! In fact, this depends on how we measure the reward,\\nor conversely the cost, obtained when a value x = x is realized.\\nT o this end, we deﬁne a non-negative loss function ℓ(x,ˆpx ) repre-\\nsenting the loss, or the “negative gain”, suﬀered when the va lue x = x\\nis observed. This loss should sensibly be a decreasing funct ion of ˆp(x)\\n– we register a smaller loss, or conversely a larger gain, whe n we have'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 214, 'page_label': '209', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is observed. This loss should sensibly be a decreasing funct ion of ˆp(x)\\n– we register a smaller loss, or conversely a larger gain, whe n we have\\nwagered more on the actual outcome x. As a fairly general class of loss\\nfunctions, we can hence deﬁne\\nℓ(x,ˆpx ) = f( ˆp(x)), (A.3)\\nwhere f is a decreasing function. More general classes of loss funct ions\\nare considered in [ 46].\\nDenote as ∆( X) the simplex of pmfs deﬁned over alphabet X. The\\ngeneralized entropy can now be deﬁned in a way that is formall y equiv-\\nalent to ( A.1), with the only diﬀerence being the optimization over pmf\\nˆpx rather than over point estimate ˆx:\\nHℓ(px ) = min\\nˆpx∈∆( X )\\nEx∼px [ℓ(x,ˆpx )]. (A.4)\\nA key e xample of loss function ℓ(x,ˆpx ) in class ( A.3) is the log-loss\\nℓ(x,ˆpx ) = −log ˆp(x). The log-loss has a strong motivation in terms of\\nlossless compression. In fact, as discussed in Sec. 2.5, by Kraft’s inequal-\\nity , it is possible to design a preﬁx-free – and hence decodab le without'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 214, 'page_label': '209', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='lossless compression. In fact, as discussed in Sec. 2.5, by Kraft’s inequal-\\nity , it is possible to design a preﬁx-free – and hence decodab le without\\ndelay – lossless compression scheme that uses ⌈−log ˆp(x)⌉bits to repre-\\nsent value x. As a result, the choice of a pmf ˆpx is akin to the selection\\nof a preﬁx-free lossless compression scheme that requires a description\\nof around −ln ˆp(x) bits to represent value x. The expectation in ( A.4)\\nmeasures the corresponding average number of bits required for lossless\\ncompression by the given scheme.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 215, 'page_label': '210', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='210 Appendix A: Information Measures\\nUsing the log-loss in ( A.1), we obtain the Shannon entropy\\nmin\\nˆpx∈∆( X )\\nEx∼px [−ln ˆp(x)], (A.5)\\n= Ex∼px [−lnp(x)] = H(px ). (A.6)\\nIn fact, imposing the optimality condition yields the optim al pmf ˆp(x)\\nas ˆp(x) = p(x). Equation ( A.5) reveals that the entropy H(px ) is the\\nminimum average log-loss when optimizing over all possible pmfs ˆpx.\\nIt may seem at ﬁrst glance that the choice ˆp(x) = p(x) should be\\noptimal for most reasonable loss functions in class ( A.3), but this is not\\nthe case. In fact, when the alphabet Xhas more than two elements, it\\ncan be proved that the log-loss – more generally deﬁned as ℓ(x,ˆpx ) =\\nblog ˆp(x) + c with b ≤0 and any c – is the only loss function of the\\nform ( A.3) for which ˆp(x) = p(x) is optimal [ 74].\\nAs a ﬁnal note, the generalized entropy Hℓ(px ) is a concave function\\nof px , which means that we have the inequality Hℓ(λpx + (1 −λ)qx ) ≥\\nλHℓ(px ) + (1 −λ)Hℓ(qx ) for any two distributions px and qx and any'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 215, 'page_label': '210', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='of px , which means that we have the inequality Hℓ(λpx + (1 −λ)qx ) ≥\\nλHℓ(px ) + (1 −λ)Hℓ(qx ) for any two distributions px and qx and any\\n0 ≤λ≤1. This follows from the fact that the entropy is the minimum\\nover a family of linear functionals of px [28]. The concavity of Hℓ(px )\\nimplies that a variable x ∼λpx + (1 −λ)qx distributed according to the\\nmixture of two distributions is more “random”, i.e., it is mo re diﬃcult\\nto estimate, than both variables x ∼px and x ∼qx .\\nA.2 Conditional Entropy and Mutual Information\\nGiven two random variables x and y jointly distributed according to\\na known probabilistic model p(x,y), i.e., (x,y) ∼pxy, we now discuss\\nhow to quantify the information that the observation of one v ariable,\\nsay y, brings about the other, namely x. F ollowing the same approach\\nadopted above, we can distinguish two inferential scenario s for this\\npurpose: in the ﬁrst, a point estimate ˆx(y) of x needs to be produced'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 215, 'page_label': '210', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='adopted above, we can distinguish two inferential scenario s for this\\npurpose: in the ﬁrst, a point estimate ˆx(y) of x needs to be produced\\nbased on the observation of a value y = y and the knowledge of the\\njoint pmf pxy; while, in the second, we are allowed to choose a pmf\\nˆpx|y=y as the estimate of x given the observation y = y.\\nPoint Estimate : Assuming point estimates and given a loss function\\nℓ(x,ˆx), the generalized conditional entropy for an observation y = y is'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 216, 'page_label': '211', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A.2. Conditional Entropy and Mutual Information 211\\ndeﬁned as the minimum average loss\\nHℓ(px|y=y ) = min\\nˆx(y)\\nEx∼px|y=y [ℓ(x,ˆx(y))|y = y]. (A.7)\\nNote that this deﬁnition is consistent with ( A.1) as applied to the con-\\nditional pmf px|y=y . A veraging over the distribution of the observation\\ny yields the generalized conditional entropy\\nHℓ(x|y) = Ey∼py [Hℓ(px|y )]. (A.8)\\nIt is emphasized that the generalized conditional entropy d epends on\\nthe joint distribution pxy, while ( A.7) depends only on the conditional\\npmf px|y=y .\\nF or the squared error, the generalized conditional entropy can be\\neasily seen to be the average conditional variance Hℓ2 (x|y) = Ey∼py [var(px|y)],\\nsince the a posteriori mean ˆx(y) = Ex∼px|y=y [x|y = y] is the optimal\\nestimate. F or the 0-1 loss, the generalized conditional ent ropy Hℓ0 (x|y)\\nis instead equal to the minimum probability of error for the d etection\\nof x given y and the MAP estimate ˆx(y) = argmaxˆx∈x p(ˆx|y) is optimal.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 216, 'page_label': '211', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='is instead equal to the minimum probability of error for the d etection\\nof x given y and the MAP estimate ˆx(y) = argmaxˆx∈x p(ˆx|y) is optimal.\\nDistributional Estimate : Assume now that we are allowed to choose\\na pmf ˆpx|y=y as the estimate of x given the observation y = y, and that\\nwe measure the estimation loss via a function ℓ(x,ˆpx ) as in ( A.3). The\\ndeﬁnition of generalized conditional entropy for a given va lue of y = y\\nfollows directly from the arguments above and is given as Hℓ(px|y=y ),\\nwhile the generalized conditional entropy is ( A.8). With the log-loss\\nfunction, the deﬁnition above can be again seen to coincide w ith Shan-\\nnon conditional entropy H(x|y) = Ex,y∼px, y [ −ln p(x|y)].\\nIf x and y are independent, we have the equality Hℓ(x|y) = Hℓ(x).\\nF urthermore, since in ( A.7) we can always choose estimates that are\\nindependent of y, we generally have the inequality Hℓ(x|y) ≤Hℓ(x):\\nobserving y, on average, can only decrease the entropy . Note, however,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 216, 'page_label': '211', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='independent of y, we generally have the inequality Hℓ(x|y) ≤Hℓ(x):\\nobserving y, on average, can only decrease the entropy . Note, however,\\nthat it is not true that Hℓ(px|y=y ) is necessarily smaller than Hℓ(x) [38].\\nMutual Information : The inequality Hℓ(x|y) ≤Hℓ(x) justiﬁes the\\ndeﬁnition of generalized mutual information with respect t o the given\\nloss function ℓ as\\nIℓ(x; y) = Hℓ(x) −Hℓ(x|y). (A.9)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 217, 'page_label': '212', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='212 Appendix A: Information Measures\\nThe mutual information measures the decrease in average los s that is\\nobtained by observing y as compared to having only prior informa-\\ntion about px . This notion of mutual information is in line with the\\nconcept of statistical information proposed by DeGroot (se e [ 46] for\\na recent treatment). With the log-loss, the generalized mut ual infor-\\nmation ( A.9) reduces to Shannon’s mutual information. As shown in\\n[75], the log-loss is in fact the only loss function, up to multip licative\\nfactors, under which the generalized mutual information ( A.9) satisﬁes\\nthe data processing inequality , as long as the alphabet of x has more\\nthan two elements.\\nA.3 Divergence Measures\\nW e now discuss a way to quantify the “diﬀerence” between two g iven\\nprobabilistic models px and qx deﬁned over the same alphabet X. W e\\nconsider here the viewpoint of binary hypothesis testing as a theoret-\\nical framework in which to tackle the issue. Other related ap proaches'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 217, 'page_label': '212', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='consider here the viewpoint of binary hypothesis testing as a theoret-\\nical framework in which to tackle the issue. Other related ap proaches\\nhave also found applications in machine learning, includin g optimal\\ntransport theory and kernel methods [\\n8].\\nW e consider the following standard binary hypothesis testi ng prob-\\nlem. Given an observation x, decide whether x was generated from pmf\\npx or from pmf qx . T o proceed, we deﬁne a decision rule T(x), which\\nshould have the property that it is increasing with the certa inty that\\na value x = x is generated from px rather than qx. F or e xample, in\\npractice, one may impose a threshold on the rule T(x) so that, when\\nT(x) is larger than the threshold, a decision is made that x = x was\\ngenerated from px .\\nIn order to design the decision rule T(x), we again minimize a loss\\nfunction or, equivalently , maximize a merit function. F or c onvenience,\\nhere we take the latter approach, and deﬁne the problem of max imizing\\nthe merit function'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 217, 'page_label': '212', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='function or, equivalently , maximize a merit function. F or c onvenience,\\nhere we take the latter approach, and deﬁne the problem of max imizing\\nthe merit function\\nEx∼px [T(x)] −Ex∼qx [g(T(x))] (A.10)\\nover the rule T(x), where g is a concave increasing function. This cri-\\nterion can be motivated as follows: ( i ) It increases if T(x) is large, on\\naverage, for values of x generated from px ; and ( ii ) it decreases if, upon'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 218, 'page_label': '213', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='A.3. Divergence Measures 213\\nexpectation, T(x) is large for values of x generated from qx . The func-\\ntion g can be used to deﬁne the relative importance of errors made in\\nfavor of one distribution or the other. F rom this discussion , the optimal\\nvalue of ( A.10) can be taken to be a measure of the distance between\\nthe two pmfs. This yields the following deﬁnition of diverge nce between\\ntwo pmfs\\nDf (px ||qx ) = max\\nT (x)\\nEx∼px [T(x)] −Ex∼qx [g(T(x))], (A.11)\\nwhere the subscript f will be justiﬁed below.\\nUnder suitable diﬀerentiability assumptions on function g(see [ 107]\\nfor generalizations), taking the derivative with respect t o T(x) for all\\nx ∈x yields the optimality condition g′ (T(x)) = p(x)/q(x). This rela-\\ntionship reveals the connection between the optimal detect or T(x) and\\nthe LLR p(x)/q(x). Plugging this result into ( A.11), it can be directly\\nchecked that the following equality holds [ 105]\\nDf (px ||qx ) = Ex∼qx\\n[\\nf\\n( px (x)\\nqx (x)\\n)]\\n, (A.12)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 218, 'page_label': '213', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='the LLR p(x)/q(x). Plugging this result into ( A.11), it can be directly\\nchecked that the following equality holds [ 105]\\nDf (px ||qx ) = Ex∼qx\\n[\\nf\\n( px (x)\\nqx (x)\\n)]\\n, (A.12)\\nwhere the function f(x) = g∗ (x) is the convex dual function of g(t),\\nwhich is deﬁned as g∗ (x) = sup t (xt−g(t)). Note that dual function f\\nis always convex [ 28].\\nUnder the additional constraint f(1) = 0 , deﬁnition ( A.12) de-\\nscribes a large class of divergence measures parametrized b y the con-\\nvex function f, which are known as f-divergences or Ali-Silvey distance\\nmeasures [ 45]. Note that the constraint f(1) = 0 ensures that the diver-\\ngence is zero when the pmfs px and qx are identical. Among their key\\nproperties, f-divergences satisfy the data processing inequality [ 45].\\nF or e xample, the choice g(t) = exp( t−1), which gives the dual con-\\nvex f(x) = xln x, yields the optimal detector T(x) = 1 + ln( p(x)/q(x))\\nand the corresponding divergence measure ( A.12) is the standard KL'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 218, 'page_label': '213', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='vex f(x) = xln x, yields the optimal detector T(x) = 1 + ln( p(x)/q(x))\\nand the corresponding divergence measure ( A.12) is the standard KL\\ndivergence KL (px ||qx ). As another instance of f-divergence, with g(t) =\\n−ln(2−exp(t)) we obtain the optimal detector T(x) = ln(2 px (x)/px (x)+\\nqx (x)), and Df (px ||qx ) becomes the Jensen-Shannon divergence 1 . F or\\n1 The Jensen-Shannon divergence can also be interpreted as th e mutual informa-\\ntion I (s; x)'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 219, 'page_label': '214', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='214 Appendix A: Information Measures\\nreference, the latter can be written as\\nJS(px ||qx ) = KL(px ∥ mx )+KL(qx ∥ mx ), (A.13)\\nwhere mx (x) = ( px (x) + qx (x))/2.2 Another special case, which general-\\nizes the KL divergence and other metrics, is the α-divergence discussed\\nin Chapter 8 (see ( 8.16)), which is obtained with f(x) = ( α(x−1) −\\n(xα −1))/(α(1 −α)) for some real-valued parameter α. W e refer to [ 107,\\n45] for other examples.\\nThe discussion above justiﬁed the adoption of the loss funct ion\\n(A.11) in a heuristic fashion. It is, however, possible to derive f ormal\\nrelationships between the error probability of binary hypo thesis testing\\nand f -divergences [ 21]. W e also refer to the classical Sanov lemma and\\nStein lemma as fundamental applications of KL divergence to large\\ndeviation and hypothesis testing [ 38].\\n2 The Jensen-Shannon divergence, as deﬁned above, is proport ional to the mutual'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 219, 'page_label': '214', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Stein lemma as fundamental applications of KL divergence to large\\ndeviation and hypothesis testing [ 38].\\n2 The Jensen-Shannon divergence, as deﬁned above, is proport ional to the mutual\\ninformation I (s; x) for the joint distribution ps, x (s, x ) = 1 /2 · px|s (x|s) with binary\\ns, and conditional pmf deﬁned as px|s (x|0) = px (x) and px|s (x|s)(x|1) = qx (x).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 220, 'page_label': '215', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='B\\nAppendix B: KL Divergence and Exponential\\nFamily\\nIn this appendix, we provide a general expression for the KL d ivergence\\nbetween two distributions p(x|η1 ) and p(x|η2 ) from the same regular\\nexponential family with log-partition function A(·), suﬃcient statistics\\nu(x), and moment parameters µ1 and µ2, respectively . W e recall from\\nChapter 3 that the log-partition function is convex and that we have\\nthe identity ∇A(η) = µ.\\nThe KL divergence between the two distributions can be trans lated\\ninto a divergence on the space of natural parameters. In part icular, the\\nfollowing relationship holds [ 6]\\nKL(p(x|η1 )||p(x|η2 )) = DA(η2 ,η1 ), (B.1)\\nwhere DA(η2 ,η1 ) represents the Bregman divergence with generator\\nfunction given by the log-partition function A(·), that is\\nDA (η2 ,η1 ) = A(η2 ) −A(η1 ) −(η2 −η1 )T ∇A(η1 )\\n= A(η2 ) −A(η1 ) −(η2 −η1 )T µ1 . (B.2)\\nThe ﬁrst line of ( B.2) is the general deﬁnition of the Bregman diver-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 220, 'page_label': '215', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='DA (η2 ,η1 ) = A(η2 ) −A(η1 ) −(η2 −η1 )T ∇A(η1 )\\n= A(η2 ) −A(η1 ) −(η2 −η1 )T µ1 . (B.2)\\nThe ﬁrst line of ( B.2) is the general deﬁnition of the Bregman diver-\\ngence DA(·,·) with a generator function A(·), while the second follows\\nfrom the relationship ( 3.10). Note that the Bregman divergence can be\\n215'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 221, 'page_label': '216', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='216 Appendix B: KL Divergence and Exponential Family\\nproved to be non-negative, and convex in its ﬁrst argument, b ut not\\nnecessarily in the second argument. The equality ( B.1)-(B.2) can be\\nproved by using the deﬁnition of exponential family via the f ollowing\\nequality\\nKL(p(x|η1 )||p(x|η2 )) = Ex∼p(x|η1 )\\n[\\nlog p(x|η1 )\\np(x|η2 )\\n]\\n= Ex∼p(x|η1 )[(η1 −η2)T u(x)] −A(η1 ) + A(η2 ).\\n(B.3)\\nRecalling again that we have the equality ∇A(η1 ) = µ1, the rela-\\ntionship ( B.1)-(B.2) can be approximated as\\nKL(p(x|η1 )||p(x|η2 )) = 1\\nN(η1 −η2)T Jη1 (η1 −η2 ) + O(||η1 −η2||3 ),\\n(B.4)\\nwhere Jη = −E\\n[\\n∇2\\nη lnp(x|η)\\n]\\nis the Fisher information matrix. This\\nexpansion holds given the relationship ∇2\\nη A(η) = Jη [\\n45].\\nIt is also possible to write a relationship analogous to ( B.1)-(B.2) in\\nterms of mean parameters. This is done by using the convex con jugate\\nfunction\\nA∗ (µ) = sup\\nη\\nηT µ−A(η), (B.5)\\nwhere the maximization is over the feasible set of natural pa rameters.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 221, 'page_label': '216', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='terms of mean parameters. This is done by using the convex con jugate\\nfunction\\nA∗ (µ) = sup\\nη\\nηT µ−A(η), (B.5)\\nwhere the maximization is over the feasible set of natural pa rameters.\\nIn fact, the optimization over η yields the natural parameter η corre-\\nsponding to the mean parameter µ, i.e., ∇A(η) = µ. It hence follows\\nfrom ( B.2) that we have\\nKL(p(x|µ1)||p(x|µ2 )) = A∗(µ1 ) −A∗ (µ2 ) −(µ1 −µ2)T η2\\n= DA∗ (µ1 ,µ2), (B.6)\\nwhere in the second line we have used the inverse mapping ∇A∗(µ) = η\\nbetween mean and natural parameters (which holds for minima l fami-\\nlies).\\nChernoﬀ divergence measures, including the Bhattacharyya distance,\\ncan also be written in closed form for exponential families [ 106].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 222, 'page_label': '217', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Acknowledgements\\nOsvaldo Simeone has received funding from the European Rese arch\\nCouncil (ERC) under the European Union’s Horizon 2020 resea rch and\\ninnovation programme (grant agreement No 725731).\\n217'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 223, 'page_label': '218', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Abadi, M., Ú. Erlingsson, I. Goodfellow, H. Brendan McMa -\\nhan, I. Mironov, N. Papernot, K. T alwar, and L. Zhang. 2017.\\n“On the Protection of Private Information in Machine Learni ng\\nSystems: T wo Recent Approaches”. ArXiv e-prints . Aug. arXiv:\\n1708.08022 [stat.ML].\\n[2] Abu-Mostafa, Y. S., M. Magdon-Ismail, and H.-T. Lin. 201 2.\\nLearning from data . V ol. 4. AMLBook New Y ork, NY, USA.\\n[3] Agakov, F. 2005. V ariational Information Maximization in Stochas-\\ntic Environments (PhD thesis) . University of Edinburgh.\\n[4] Alemi, A. A., B. Poole, and E. a. Fischer. 2017. “An Inform ation-\\nTheoretic Analysis of Deep Latent-V ariable Models”. ArXiv e-\\nprints. Nov. arXiv: 1711.00464v1.\\n[5] Amari, S.-I. 1998. “Natural gradient works eﬃciently in learn-\\ning”. Neural computation . 10(2): 251–276.\\n[6] Amari, S.-i. 2016. Information geometry and its applications .\\nSpringer.\\n[7] Angelino, E., M. J. Johnson, R. P . Adams, et al. 2016. “Patterns'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 223, 'page_label': '218', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ing”. Neural computation . 10(2): 251–276.\\n[6] Amari, S.-i. 2016. Information geometry and its applications .\\nSpringer.\\n[7] Angelino, E., M. J. Johnson, R. P . Adams, et al. 2016. “Patterns\\nof scalable Bayesian inference”. F oundations and T rends R⃝ in\\nMachine Learning . 9(2-3): 119–247.\\n[8] Arjovsky , M., S. Chintala, and L. Bottou. 2017. “W assers tein\\nGAN”. arXiv preprint arXiv:1701.07875 .\\n218'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 224, 'page_label': '219', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 219\\n[9] Arulkumaran, K., M. P . Deisenroth, M. Brundage, and A. A.\\nBharath. 2017. “Deep Reinforcement Learning: A Brief Surve y”.\\nIEEE Signal Processing Magazine . 34(6): 26–38. issn: 1053-5888.\\ndoi: 10.1109/MSP .2017.2743240.\\n[10] Azoury , K. S. and M. K. W armuth. 2001. “Relative loss bou nds\\nfor on-line density estimation with the exponential family of\\ndistributions”. Machine Learning . 43(3): 211–246.\\n[11] Bagheri, A., O. Simeone, and B. Rajendran. 2017. “T rain ing\\nProbabilistic Spiking Neural Networks with First-to-spik e De-\\ncoding”. ArXiv e-prints . Oct. arXiv: 1710.10704 [stat.ML].\\n[12] Baldi, P ., P . Sadowski, and Z. Lu. 2016. “Learning in the ma-\\nchine: Random backpropagation and the learning channel”. arXiv\\npreprint arXiv:1612.02734 .\\n[13] Bamler, R., C. Zhang, M. Opper, and S. Mandt. 2017. “Pert ur-\\nbative Black Box V ariational Inference”. ArXiv e-prints . Sept.\\narXiv: 1709.07433 [stat.ML].\\n[14] Baraniuk, R. G. 2007. “Compressive sensing [lecture no tes]”.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 224, 'page_label': '219', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='bative Black Box V ariational Inference”. ArXiv e-prints . Sept.\\narXiv: 1709.07433 [stat.ML].\\n[14] Baraniuk, R. G. 2007. “Compressive sensing [lecture no tes]”.\\nIEEE signal processing magazine . 24(4): 118–121.\\n[15] Barber, D. 2012. Bayesian reasoning and machine learning . Cam-\\nbridge University Press.\\n[16] Beal, M. J. 2003. V ariational algorithms for approximate Bayesian\\ninference. University of London London.\\n[17] Bekkerman, R., M. Bilenko, and J. Langford. 2011. Scaling up\\nmachine learning: Paral lel and distributed approaches . Cambridge\\nUniversity Press.\\n[18] Belghazi, I., S. Rajeswar, A. Baratin, R. D. Hjelm, and A . Courville.\\n2018. “MINE: Mutual Information Neural Estimation”. arXiv\\npreprint arXiv:1801.04062 .\\n[19] Bengio, Y. 2012. “Deep learning of representations for unsuper-\\nvised and transfer learning”. In: Proceedings of ICML W orkshop\\non Unsupervised and T ransfer Learning . 17–36.\\n[20] Bengio, Y., A. Courville, and P . Vincent. 2013. “Repres entation'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 224, 'page_label': '219', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='vised and transfer learning”. In: Proceedings of ICML W orkshop\\non Unsupervised and T ransfer Learning . 17–36.\\n[20] Bengio, Y., A. Courville, and P . Vincent. 2013. “Repres entation\\nlearning: A review and new perspectives”. IEEE transactions on\\npattern analysis and machine intel ligence . 35(8): 1798–1828.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 225, 'page_label': '220', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='220 References\\n[21] Berisha, V., A. Wisler, A. O. Hero, and A. Spanias. 2016. “Em-\\npirically estimable classiﬁcation bounds based on a nonpar amet-\\nric divergence measure”. IEEE T ransactions on Signal Process-\\ning. 64(3): 580–591.\\n[22] Bertsekas, D. P . 2011. “Incremental gradient, subgrad ient, and\\nproximal methods for convex optimization: A survey”. Optimiza-\\ntion for Machine Learning . 2010(1-38): 3.\\n[23] Bishop, C. M. 2006. Pattern recognition and machine learning .\\nSpringer.\\n[24] Blei, D. M., A. Kucukelbir, and J. D. McAuliﬀe. 2017. “V a ria-\\ntional inference: A review for statisticians”. Journal of the Amer-\\nican Statistical Association . (just-accepted).\\n[25] Blei, D., R. Ranganath, and S. Mohamed. “V ariational In ference:\\nF oundations and Modern Methods”.\\n[26] Blitzer, J., K. Crammer, A. Kulesza, F. Pereira, and J. W ortman.\\n2008. “Learning bounds for domain adaptation”. In: Advances\\nin neural information processing systems . 129–136.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 225, 'page_label': '220', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[26] Blitzer, J., K. Crammer, A. Kulesza, F. Pereira, and J. W ortman.\\n2008. “Learning bounds for domain adaptation”. In: Advances\\nin neural information processing systems . 129–136.\\n[27] Blundell, C., J. Cornebise, K. Kavukcuoglu, and D. Wier stra.\\n2015. “W eight uncertainty in neural networks”. arXiv preprint\\narXiv:1505.05424.\\n[28] Boyd, S. and L. V andenberghe. 2004. Convex optimization . Cam-\\nbridge university press.\\n[29] Brakel, P . and Y. Bengio. 2017. “Learning Independent F eatures\\nwith Adversarial Nets for Non-linear ICA”. ArXiv e-prints . Oct.\\narXiv: 1710.05050 [stat.ML].\\n[30] Bronstein, M. M., J. Bruna, Y. LeCun, A. Szlam, and P . V an -\\ndergheynst. 2017. “Geometric deep learning: going beyond e u-\\nclidean data”. IEEE Signal Processing Magazine . 34(4): 18–42.\\n[31] Brynjolfsson, E. and T. Mitchell. 2017. “What can machi ne\\nlearning do? W orkforce implications”. Science. 358(6370): 1530–\\n1534.\\n[32] Burda, Y., R. Grosse, and R. Salakhutdinov. 2015. “Impo rtance'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 225, 'page_label': '220', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='learning do? W orkforce implications”. Science. 358(6370): 1530–\\n1534.\\n[32] Burda, Y., R. Grosse, and R. Salakhutdinov. 2015. “Impo rtance\\nweighted autoencoders”. arXiv preprint arXiv:1509.00519 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 226, 'page_label': '221', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 221\\n[33] Cevher, V., S. Becker, and M. Schmidt. 2014. “Convex opt imiza-\\ntion for big data: Scalable, randomized, and parallel algor ithms\\nfor big data analytics”. IEEE Signal Processing Magazine . 31(5):\\n32–43.\\n[34] Cheeseman, P . C. 1985. “In Defense of Probability .” In: IJCAI.\\nV ol. 85. 1002–1009.\\n[35] Cichocki, A., D. Mandic, L. De Lathauwer, G. Zhou, Q. Zha o, C.\\nCaiafa, and H. A. Phan. 2015. “T ensor decompositions for sig nal\\nprocessing applications: F rom two-way to multiway compone nt\\nanalysis”. IEEE Signal Processing Magazine . 32(2): 145–163.\\n[36] Collins, M., S. Dasgupta, and R. E. Schapire. 2002. “A ge ner-\\nalization of principal components analysis to the exponent ial\\nfamily”. In: Advances in neural information processing systems .\\n617–624.\\n[37] Cortes, C. and V. V apnik. 1995. “Support-vector networ ks”. Ma-\\nchine learning . 20(3): 273–297.\\n[38] Cover, T. M. and J. A. Thomas. 2012. Elements of information\\ntheory. John Wiley & Sons.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 226, 'page_label': '221', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[37] Cortes, C. and V. V apnik. 1995. “Support-vector networ ks”. Ma-\\nchine learning . 20(3): 273–297.\\n[38] Cover, T. M. and J. A. Thomas. 2012. Elements of information\\ntheory. John Wiley & Sons.\\n[39] Cristianini, N. and J. Shawe-T aylor. 2000. An introduction to\\nsupport vector machines and other kernel-based learning me th-\\nods. Cambridge university press.\\n[40] Csiszár, I. and P . C. Shields. 2004. “Information theor y and\\nstatistics: A tutorial”. F oundations and T rends R⃝ in Communi-\\ncations and Information Theory . 1(4): 417–528.\\n[41] Davidson-Pilon, C. 2015. “Probabilistic Programming & Bayesian\\nMethods for Hackers”.\\n[42] Dayan, P ., G. E. Hinton, R. M. Neal, and R. S. Zemel. 1995.\\n“The helmholtz machine”. Neural computation . 7(5): 889–904.\\n[43] De, S., G. T aylor, and T. Goldstein. 2015. “V ariance Red uction\\nfor Distributed Stochastic Gradient Descent”. arXiv preprint\\narXiv:1512.01708.\\n[44] Di Lorenzo, P . and G. Scutari. 2016. “Next: In-network n oncon-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 226, 'page_label': '221', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='for Distributed Stochastic Gradient Descent”. arXiv preprint\\narXiv:1512.01708.\\n[44] Di Lorenzo, P . and G. Scutari. 2016. “Next: In-network n oncon-\\nvex optimization”. IEEE T ransactions on Signal and Informa-\\ntion Processing over Networks . 2(2): 120–136.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 227, 'page_label': '222', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='222 References\\n[45] Duchi, J. 2016. “Lecture Notes for Statistics 311/Elec trical En-\\ngineering 377”.\\n[46] Duchi, J. C., K. Khosravi, and F. Ruan. 2016. “Informati on\\nMeasures, Experiments, Multi-category Hypothesis T ests, and\\nSurrogate Losses”. arXiv preprint arXiv:1603.00126 .\\n[47] Dumoulin, V., I. Belghazi, B. Poole, O. Mastropietro, A . Lamb,\\nM. Arjovsky , and A. Courville. 2016. “Adversarially learne d in-\\nference”. arXiv preprint arXiv:1606.00704 .\\n[48] Efron, B. and T. Hastie. 2016. Computer Age Statistical Infer-\\nence. V ol. 5. Cambridge University Press.\\n[49] F edus, W., M. Rosca, B. Lakshminarayanan, A. M. Dai, S. M o-\\nhamed, and I. Goodfellow. 2017. “Many Paths to Equilibrium:\\nGANs Do Not Need to Decrease a Divergence At Every Step”.\\nArXiv e-prints . Oct. arXiv:\\n1710.08446 [stat.ML].\\n[50] F eutry , C., P . Piantanida, Y. Bengio, and P . Duhamel. 20 18.\\n“Learning Anonymized Representations with Adversarial Ne ural'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 227, 'page_label': '222', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ArXiv e-prints . Oct. arXiv:\\n1710.08446 [stat.ML].\\n[50] F eutry , C., P . Piantanida, Y. Bengio, and P . Duhamel. 20 18.\\n“Learning Anonymized Representations with Adversarial Ne ural\\nNetworks”. ArXiv e-prints . F eb. arXiv: 1802.09386 [stat.ML].\\n[51] F riedman, J., T. Hastie, and R. Tibshirani. 2001. The elements\\nof statistical learning . V ol. 1. Springer series in statistics New\\nY ork.\\n[52] F u, Y., T. Xiang, Y.-G. Jiang, X. Xue, L. Sigal, and S. Gon g.\\n2017. “Recent advances in zero-shot recognition”. arXiv preprint\\narXiv:1710.04837.\\n[53] Gal, Y. 2016. “Uncertainty in Deep Learning”. PhD thesis . Uni-\\nversity of Cambridge.\\n[54] Gersho, A. and R. M. Gray. 2012. V ector quantization and signal\\ncompression. V ol. 159. Springer Science & Business Media.\\n[55] Goodfellow, I. J., J. Shlens, and C. Szegedy. 2014a. “Ex plaining\\nand harnessing adversarial examples”. arXiv preprint arXiv:1412.6572 .\\n[56] Goodfellow, I., Y. Bengio, and A. Courville. 2016. Deep learning .\\nMIT press.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 227, 'page_label': '222', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='and harnessing adversarial examples”. arXiv preprint arXiv:1412.6572 .\\n[56] Goodfellow, I., Y. Bengio, and A. Courville. 2016. Deep learning .\\nMIT press.\\n[57] Goodfellow, I., J. Pouget-Abadie, M. Mirza, B. Xu, D. W a rde-\\nF arley, S. Ozair, A. Courville, and Y. Bengio. 2014b. “Gener a-\\ntive adversarial nets”. In: Advances in neural information pro-\\ncessing systems . 2672–2680.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 228, 'page_label': '223', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 223\\n[58] Grant, M., and Y. Y e. arti. “cvx users’ guide”.\\n[59] Grathwohl, W., D. Choi, Y. W u, G. Roeder, and D. Duvenaud .\\n2017. “Backpropagation through the V oid: Optimizing contr ol\\nvariates for black-box gradient estimation”. ArXiv e-prints . Oct.\\narXiv:\\n1711.00123 [cs.LG].\\n[60] Grunwald, P . D. 2007. The minimum description length princi-\\nple. MIT press.\\n[61] Grünwald, P . D., A. P . Dawid, et al. 2004. “Game theory , max-\\nimum entropy , minimum discrepancy and robust Bayesian deci -\\nsion theory”. the Annals of Statistics . 32(4): 1367–1433.\\n[62] Guardian), S. L. ( 2016. A beauty contest was judged by AI and\\nthe robots didn ’t like dark skin . url: http://www.nytimes.com/1958/07/08/archives/new-navy-device-learns-by-doing-psychologist-shows-embryo-o f.html.\\n[63] Haveliwala, T. H. 2003. “T opic-sensitive pagerank: A c ontext-\\nsensitive ranking algorithm for web search”. IEEE transactions\\non knowledge and data engineering . 15(4): 784–796.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 228, 'page_label': '223', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[63] Haveliwala, T. H. 2003. “T opic-sensitive pagerank: A c ontext-\\nsensitive ranking algorithm for web search”. IEEE transactions\\non knowledge and data engineering . 15(4): 784–796.\\n[64] Hinton, G. 2016. “Neural Networks for Machine Learning (online\\ncourse)”.\\n[65] Hinton, G. E., P . Dayan, B. J. F rey, and R. M. Neal. 1995.\\n“The\" wake-sleep\" algorithm for unsupervised neural netwo rks”.\\nScience. 268(5214): 1158.\\n[66] Hochreiter, S. and J. Schmidhuber. 1997. “Flat minima” . Neural\\nComputation. 9(1): 1–42.\\n[67] Huang, G.-B., Q.-Y. Zhu, and C.-K. Siew. 2006. “Extreme learn-\\ning machine: theory and applications”. Neurocomputing. 70(1):\\n489–501.\\n[68] Huszár, F. 2017a. “Choice of Recognition Models in V AEs : a\\nregularisation view”.\\n[69] Huszár, F. 2017b. “Is Maximum Likelihood Useful for Rep resen-\\ntation Learning?”\\n[70] Huszár, F. 2017c. “V ariational Inference using Implic it Distribu-\\ntions”. arXiv preprint arXiv:1702.08235 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 228, 'page_label': '223', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='tation Learning?”\\n[70] Huszár, F. 2017c. “V ariational Inference using Implic it Distribu-\\ntions”. arXiv preprint arXiv:1702.08235 .\\n[71] Huszár, F. “Everything that W orks W orks Because it’s Ba yesian:\\nWhy Deep Nets Generalize?”'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 229, 'page_label': '224', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='224 References\\n[72] Jain, P . and P . Kar. 2017. “Non-convex Optimization for Ma-\\nchine Learning”. F oundations and T rends R⃝ in Machine Learn-\\ning. 10(3-4): 142–336. issn: 1935-8237. url: http://dx.doi.org/10.1561/2200000058.\\n[73] Jang, E., S. Gu, and B. Poole. 2016. “Categorical repara meteri-\\nzation with gumbel-softmax”. arXiv preprint arXiv:1611.01144 .\\n[74] Jiao, J., T. A. Courtade, A. No, K. V enkat, and T. W eissma n.\\n2014. “Information measures: the curious case of the binary\\nalphabet”. IEEE T ransactions on Information Theory . 60(12):\\n7616–7626.\\n[75] Jiao, J., T. A. Courtade, K. V enkat, and T. W eissman. 201 5.\\n“Justiﬁcation of logarithmic loss via the beneﬁt of side inf orma-\\ntion”. IEEE T ransactions on Information Theory . 61(10): 5357–\\n5365.\\n[76] Johnson, R. and T. Zhang. 2013. “Accelerating stochast ic gra-\\ndient descent using predictive variance reduction”. In: Advances\\nin neural information processing systems . 315–323.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 229, 'page_label': '224', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='5365.\\n[76] Johnson, R. and T. Zhang. 2013. “Accelerating stochast ic gra-\\ndient descent using predictive variance reduction”. In: Advances\\nin neural information processing systems . 315–323.\\n[77] Karpathy , A. “Deep Reinforcement Learning: Pong from P ixels”.\\nurl: http://karpathy .github.io/2016/05/31/rl/.\\n[78] Kawaguchi, K., L. Pack Kaelbling, and Y. Bengio. 2017. “ Gener-\\nalization in Deep Learning”. ArXiv e-prints . Oct. arXiv: 1710.05468 [stat.ML].\\n[79] Keskar, N. S., D. Mudigere, J. Nocedal, M. Smelyanskiy , and\\nP . T. P . T ang. 2016. “On large-batch training for deep learni ng:\\nGeneralization gap and sharp minima”. arXiv preprint arXiv:1609.04836 .\\n[80] Kingma, D. P . and M. W elling. 2013. “Auto-encoding vari ational\\nbayes”. arXiv preprint arXiv:1312.6114 .\\n[81] Koller, D. and N. F riedman. 2009. Probabilistic graphical models:\\nprinciples and techniques . MIT press.\\n[82] Korenkevych, D., Y. Xue, Z. Bian, F. Chudak, W. G. Macrea dy,'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 229, 'page_label': '224', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[81] Koller, D. and N. F riedman. 2009. Probabilistic graphical models:\\nprinciples and techniques . MIT press.\\n[82] Korenkevych, D., Y. Xue, Z. Bian, F. Chudak, W. G. Macrea dy,\\nJ. Rolfe, and E. Andriyash. 2016. “Benchmarking quantum har d-\\nware for training of fully visible boltzmann machines”. arXiv\\npreprint arXiv:1611.04528 .\\n[83] LeCun, Y., S. Chopra, R. Hadsell, M. Ranzato, and F. Huan g.\\n2006. “A tutorial on energy-based learning”. Predicting struc-\\ntured data . 1.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 230, 'page_label': '225', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 225\\n[84] Lee, J. H., T. Delbruck, and M. Pfeiﬀer. 2016. “T raining deep\\nspiking neural networks using backpropagation”. F rontiers in\\nneuroscience. 10.\\n[85] Lee, T.-W., M. Girolami, and T. J. Sejnowski. 1999. “Ind epen-\\ndent component analysis using an extended infomax algorith m\\nfor mixed subgaussian and supergaussian sources”. Neural com-\\nputation. 11(2): 417–441.\\n[86] Lehmann, E. L. and G. Casella. 2006. Theory of point estimation .\\nSpringer Science & Business Media.\\n[87] Levesque, H. J. 2017. Common Sense, the T uring T est, and the\\nQuest for Real AI . MIT University Press.\\n[88] Levine, S. 2017. Deep Reinforcement Learning. url: http://rll.berkeley .edu/deeprlcourse/#lecture-videos.\\n[89] Li, Y. “T opics in Approximate Inference”. url: http://yingzhenli.net/home/pdf/topics_approx_infer.pdf .\\n[90] Li, Y. and R. E. T urner. 2016. “Rényi divergence variati onal\\ninference”. In: Advances in Neural Information Processing Sys-\\ntems. 1073–1081.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 230, 'page_label': '225', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[90] Li, Y. and R. E. T urner. 2016. “Rényi divergence variati onal\\ninference”. In: Advances in Neural Information Processing Sys-\\ntems. 1073–1081.\\n[91] Loh, P .-L. 2017. “On Lower Bounds for Statistical Learn ing The-\\nory”. Entropy. 19(11): 617.\\n[92] Lunn, D., C. Jackson, N. Best, A. Thomas, and D. Spiegelh al-\\nter. 2012. The BUGS book: A practical introduction to Bayesian\\nanalysis. CRC press.\\n[93] Maaten, L. v. d. and G. Hinton. 2008. “Visualizing data u sing\\nt-SNE”. Journal of Machine Learning Research . 9(Nov): 2579–\\n2605.\\n[94] MacKay , D. J. 2003. Information theory, inference and learning\\nalgorithms. Cambridge university press.\\n[95] Maddison, C. J., A. Mnih, and Y. W. T eh. 2016. “The concre te\\ndistribution: A continuous relaxation of discrete random v ari-\\nables”. arXiv preprint arXiv:1611.00712 .\\n[96] Minka, T. 2005. “Divergence measures and message passi ng”.\\nT ech. rep. T echnical report, Microsoft Research.\\n[97] Minsky , M. and S. Papert. 1969. “Perceptrons.”'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 230, 'page_label': '225', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[96] Minka, T. 2005. “Divergence measures and message passi ng”.\\nT ech. rep. T echnical report, Microsoft Research.\\n[97] Minsky , M. and S. Papert. 1969. “Perceptrons.”\\n[98] Mnih, A. and K. Gregor. 2014. “Neural variational infer ence and\\nlearning in belief networks”. arXiv preprint arXiv:1402.0030 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 231, 'page_label': '226', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='226 References\\n[99] Mnih, V., K. Kavukcuoglu, D. Silver, A. Graves, I. Anton oglou,\\nD. Wierstra, and M. Riedmiller. 2013. “Playing atari with de ep\\nreinforcement learning”. arXiv preprint arXiv:1312.5602 .\\n[100] Mohamed, S. and B. Lakshminarayanan. 2016. “Learning in im-\\nplicit generative models”. arXiv preprint arXiv:1610.03483 .\\n[101] Mokhtari, A. and A. Ribeiro. 2017. “First-Order Adapt ive Sam-\\nple Size Methods to Reduce Complexity of Empirical Risk Min-\\nimization”. ArXiv e-prints . Sept. arXiv:\\n1709.00599 [cs.LG].\\n[102] Montavon, G., W. Samek, and K.-R. Müller. 2017. “Metho ds for\\ninterpreting and understanding deep neural networks”. arXiv\\npreprint arXiv:1706.07979 .\\n[103] Mott, A., J. Job, J.-R. Vlimant, D. Lidar, and M. Spirop ulu.\\n2017. “Solving a Higgs optimization problem with quantum an -\\nnealing for machine learning”. Nature. 550(7676): 375.\\n[104] Murphy , K. P . 2012. Machine learning: a probabilistic perspec-\\ntive. MIT press.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 231, 'page_label': '226', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='nealing for machine learning”. Nature. 550(7676): 375.\\n[104] Murphy , K. P . 2012. Machine learning: a probabilistic perspec-\\ntive. MIT press.\\n[105] Nguyen, X., M. J. W ainwright, and M. I. Jordan. 2010. “E sti-\\nmating divergence functionals and the likelihood ratio by c onvex\\nrisk minimization”. IEEE T ransactions on Information Theory .\\n56(11): 5847–5861.\\n[106] Nielsen, F. 2011. “Chernoﬀ information of exponentia l families”.\\narXiv preprint arXiv:1102.2684 .\\n[107] Nowozin, S., B. Cseke, and R. T omioka. 2016. “f-GAN: T r ain-\\ning generative neural samplers using variational divergen ce min-\\nimization”. In: Advances in Neural Information Processing Sys-\\ntems. 271–279.\\n[108] Odena, A., C. Olah, and J. Shlens. 2016. “Conditional i mage syn-\\nthesis with auxiliary classiﬁer gans”. arXiv preprint arXiv:1610.09585 .\\n[109] O’Neil, K. 2016. W eapons of Math Destruction . Penguin Books.\\n[110] Page, L., S. Brin, R. Motwani, and T. Winograd. 1999. “T he'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 231, 'page_label': '226', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[109] O’Neil, K. 2016. W eapons of Math Destruction . Penguin Books.\\n[110] Page, L., S. Brin, R. Motwani, and T. Winograd. 1999. “T he\\nPageRank citation ranking: Bringing order to the web.” T ech.\\nrep. Stanford InfoLab.\\n[111] Papernot, N., P . McDaniel, I. Goodfellow, S. Jha, Z. Be rkay Ce-\\nlik, and A. Swami. 2016. “Practical Black-Box Attacks again st\\nMachine Learning”. ArXiv e-prints . F eb. arXiv: 1602.02697 [cs.CR].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 232, 'page_label': '227', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 227\\n[112] Pearl, J. 2018. “Theoretical Impediments to Machine L earning\\nWith Seven Sparks from the Causal Revolution”. ArXiv e-prints .\\nJan. arXiv: 1801.04016 [cs.LG].\\n[113] Pearl, J., M. Glymour, and N. P . Jewell. 2016. Causal inference\\nin statistics: a primer . John Wiley & Sons.\\n[114] Pereyra, M., P . Schniter, E. Chouzenoux, J.-C. Pesque t, J.-Y.\\nT ourneret, A. O. Hero, and S. McLaughlin. 2016. “A survey of\\nstochastic simulation and optimization methods in signal p ro-\\ncessing”. IEEE Journal of Selected T opics in Signal Processing .\\n10(2): 224–241.\\n[115] Peters, J., D. Janzing, and B. Scholkopf. 2017. Elements of\\nCausal Inference: F oundations and Learning Algorithms . MIT\\nPress (available on-line).\\n[116] Pinker, S. 1997. How the Mind W orks . Penguin Press Science.\\n[117] Rabiner, L. and B. Juang. 1986. “An introduction to hid den\\nMarkov models”. IEEE ASSP magazine . 3(1): 4–16.\\n[118] Raginsky , M. 2011. “Directed information and Pearl’s causal cal-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 232, 'page_label': '227', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[117] Rabiner, L. and B. Juang. 1986. “An introduction to hid den\\nMarkov models”. IEEE ASSP magazine . 3(1): 4–16.\\n[118] Raginsky , M. 2011. “Directed information and Pearl’s causal cal-\\nculus”. In: Communication, Control, and Computing (Al lerton),\\n2011 49th Annual Al lerton Conference on . IEEE. 958–965.\\n[119] Raginsky , M., A. Rakhlin, M. T sao, Y. W u, and A. Xu. 2016 .\\n“Information-theoretic analysis of stability and bias of l earn-\\ning algorithms”. In: Information Theory W orkshop (ITW), 2016\\nIEEE. IEEE. 26–30.\\n[120] Ranganath, R., S. Gerrish, and D. Blei. 2014. “Black bo x vari-\\national inference”. In: Artiﬁcial Intel ligence and Statistics . 814–\\n822.\\n[121] Ranganath, R., L. T ang, L. Charlin, and D. Blei. 2015. “ Deep\\nexponential families”. In: Artiﬁcial Intel ligence and Statistics .\\n762–771.\\n[122] Rezende, D. J., S. Mohamed, and D. Wierstra. 2014. “Sto chastic\\nbackpropagation and approximate inference in deep generat ive\\nmodels”. arXiv preprint arXiv:1401.4082 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 232, 'page_label': '227', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='762–771.\\n[122] Rezende, D. J., S. Mohamed, and D. Wierstra. 2014. “Sto chastic\\nbackpropagation and approximate inference in deep generat ive\\nmodels”. arXiv preprint arXiv:1401.4082 .\\n[123] Roth, K., A. Lucchi, S. Nowozin, and T. Hofmann. 2017. “ Sta-\\nbilizing T raining of Generative Adversarial Networks thro ugh\\nRegularization”. arXiv preprint arXiv:1705.09367 .'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 233, 'page_label': '228', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='228 References\\n[124] Rudolph, M., F. Ruiz, S. Athey, and D. Blei. 2017. “Stru ctured\\nEmbedding Models for Grouped Data”. ArXiv e-prints . Sept.\\narXiv: 1709.10367 [stat.ML].\\n[125] Rumelhart, D. E., G. E. Hinton, and R. J. Williams. 1988 . “Learn-\\ning representations by back-propagating errors”. Cognitive mod-\\neling. 5(3): 1.\\n[126] Russel, S. and P . Norvig. 2009. Artiﬁcial Intel ligence: A Modern\\nApproach. Pearson.\\n[127] Salakhutdinov, R., A. Mnih, and G. Hinton. 2007. “Rest ricted\\nBoltzmann machines for collaborative ﬁltering”. In: Proceedings\\nof the 24th international conference on Machine learning . ACM.\\n791–798.\\n[128] Salimans, T., J. Ho, X. Chen, and I. Sutskever. 2017. “E volution\\nstrategies as a scalable alternative to reinforcement lear ning”.\\narXiv preprint arXiv:1703.03864 .\\n[129] Samadi, A., T. P . Lillicrap, and D. B. T weed. 2017. “Dee p\\nLearning with Dynamic Spiking Neurons and Fixed F eedback\\nW eights”. Neural Computation . 29(3): 578–602.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 233, 'page_label': '228', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='[129] Samadi, A., T. P . Lillicrap, and D. B. T weed. 2017. “Dee p\\nLearning with Dynamic Spiking Neurons and Fixed F eedback\\nW eights”. Neural Computation . 29(3): 578–602.\\n[130] Scutari, G., F. F acchinei, L. Lampariello, and P . Song . 2014.\\n“Distributed methods for constrained nonconvex multi-age nt optimization-\\npart I: theory”. arXiv preprint arXiv:1410.4754 .\\n[131] Scutari, M. 2017. “Bayesian Dirichlet Bayesian Netwo rk Scores\\nand the Maximum Entropy Principle”. arXiv preprint arXiv:1708.00689 .\\n[132] Shahriari, B., K. Swersky, Z. W ang, R. P . Adams, and N. d e\\nF reitas. 2016. “T aking the human out of the loop: A review of\\nbayesian optimization”. Proceedings of the IEEE . 104(1): 148–\\n175.\\n[133] Shalev-Shwartz, S. and S. Ben-David. 2014. Understanding ma-\\nchine learning: F rom theory to algorithms . Cambridge university\\npress.\\n[134] Shannon, C. E. 1948. “A mathematical theory of communi ca-\\ntion”. The Bel l System T echnical Journal . 27(3): 379–423.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 233, 'page_label': '228', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='chine learning: F rom theory to algorithms . Cambridge university\\npress.\\n[134] Shannon, C. E. 1948. “A mathematical theory of communi ca-\\ntion”. The Bel l System T echnical Journal . 27(3): 379–423.\\n[135] Silver, D. 2015. Course on reinforcement learning . url:\\nhttp://www0.cs.ucl.ac.uk/staﬀ/d.silver/web/T eaching.html.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 234, 'page_label': '229', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 229\\n[136] Smith, S. L., P .-J. Kindermans, and Q. V. Le. 2017. “Don ’t\\nDecay the Learning Rate, Increase the Batch Size”. ArXiv e-\\nprints. Nov. arXiv: 1711.00489 [cs.LG].\\n[137] Spectrum, I. Wil l the F uture of AI Learning Depend More on\\nNature or Nurture? url: https://spectrum.ieee.org/tech-talk/robotics/artiﬁc ial-intelligence/ai-and-psychology-researchers-deba te-the-future-of-deep-learning .\\n[138] Stigler, S. M. 2016. The seven pil lars of statistical wisdom . Har-\\nvard University Press.\\n[139] Subramaniam, S., T. Palpanas, D. Papadopoulos, V. Kal oger-\\naki, and D. Gunopulos. 2006. “Online outlier detection in se n-\\nsor data using non-parametric models”. In: Proceedings of the\\n32nd international conference on V ery large data bases . VLDB\\nEndowment. 187–198.\\n[140] Sugiyama, M., T. Suzuki, and T. Kanamori. 2012. Density ratio\\nestimation in machine learning . Cambridge University Press.\\n[141] Sun, Y., P . Babu, and D. P . Palomar. 2017. “Majorizatio n-minimization'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 234, 'page_label': '229', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='estimation in machine learning . Cambridge University Press.\\n[141] Sun, Y., P . Babu, and D. P . Palomar. 2017. “Majorizatio n-minimization\\nalgorithms in signal processing, communications, and mach ine\\nlearning”. IEEE T ransactions on Signal Processing . 65(3): 794–\\n816.\\n[142] T egmark, M. 2017. Life 3.0: Being Human in the Age of Artiﬁ-\\ncial Intel ligence . Allen Lane.\\n[143] Thrun, S. 1996. “Is learning the n-th thing any easier t han learn-\\ning the ﬁrst?” In: Advances in neural information processing\\nsystems. 640–646.\\n[144] Times, T. N. Y. 1958. NEW NA VY DEVICE LEARNS BY DO-\\nING; Psychologist Shows Embryo of Computer Designed to Read\\nand Grow Wiser . url: http://www.nytimes.com/1958/07/08/archives/new-navy-device-learns-by-doing-psychologist-shows-embryo-o f.html.\\n[145] Tishby , N., F. C. Pereira, and W. Bialek. 2000. “The inf ormation\\nbottleneck method”. arXiv preprint physics/0004057 .\\n[146] T sybakov, A. B. 2009. “Introduction to nonparametric estima-\\ntion”.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 234, 'page_label': '229', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='bottleneck method”. arXiv preprint physics/0004057 .\\n[146] T sybakov, A. B. 2009. “Introduction to nonparametric estima-\\ntion”.\\n[147] T urner, R. E. and M. Sahani. 2011. “T wo problems with va ria-\\ntional expectation maximisation for time-series models”. Bayesian\\nTime series models : 115–138.\\n[148] Uber. Pyro: Deep universal probabilistic programming . url: http://pyro.ai/.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 235, 'page_label': '230', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='230 References\\n[149] V enkateswara, H., S. Chakraborty, and S. Panchanatha n. 2017.\\n“Deep-Learning Systems for Domain Adaptation in Computer\\nVision: Learning T ransferable F eature Representations”. IEEE\\nSignal Processing Magazine . 34(6): 117–129. issn: 1053-5888.\\ndoi: 10.1109/MSP .2017.2740460.\\n[150] Vincent, P ., H. Larochelle, I. Lajoie, Y. Bengio, and P .-A. Man-\\nzagol. 2010. “Stacked denoising autoencoders: Learning us eful\\nrepresentations in a deep network with a local denoising cri te-\\nrion”. Journal of Machine Learning Research . 11(Dec): 3371–\\n3408.\\n[151] W ainwright, M. J. and M. I. Jordan. 2008. “Graphical mo d-\\nels, exponential families, and variational inference”. F oundations\\nand T rends R⃝ in Machine Learning . 1(1–2): 1–305.\\n[152] W att, J., R. Borhani, and A. Katsaggelos. 2016. Machine Learn-\\ning Reﬁned: F oundations, Algorithms, and Applications . Cam-\\nbridge University Press.\\n[153] W elling, M., M. Rosen-Zvi, and G. E. Hinton. 2005. “Exp onen-'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 235, 'page_label': '230', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='ing Reﬁned: F oundations, Algorithms, and Applications . Cam-\\nbridge University Press.\\n[153] W elling, M., M. Rosen-Zvi, and G. E. Hinton. 2005. “Exp onen-\\ntial family harmoniums with an application to information r e-\\ntrieval”. In: Advances in neural information processing systems .\\n1481–1488.\\n[154] Wikipedia. AI Winter . url: https://en.wikipedia.org/wiki/AI_winter.\\n[155] Wikipedia. Conjugate priors . url: https://en.wikipedia.org/wiki/Conjugate_prior.\\n[156] Wikipedia. Exponential family . url: https://en.wikipedia.org/wiki/Exponential_family.\\n[157] Wilson, A. C., R. Roelofs, M. Stern, N. Srebro, and B. Re cht.\\n2017. “The Marginal V alue of Adaptive Gradient Methods in\\nMachine Learning”. arXiv preprint arXiv:1705.08292 .\\n[158] Witten, I. H., E. F rank, M. A. Hall, and C. J. Pal. 2016. Data\\nMining: Practical machine learning tools and techniques . Mor-\\ngan Kaufmann.\\n[159] Zhang, C., J. Butepage, H. Kjellstrom, and S. Mandt. 20 17.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 235, 'page_label': '230', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='Mining: Practical machine learning tools and techniques . Mor-\\ngan Kaufmann.\\n[159] Zhang, C., J. Butepage, H. Kjellstrom, and S. Mandt. 20 17.\\n“Advances in V ariational Inference”. ArXiv e-prints . Nov. arXiv:\\n1711.05597 [cs.LG].'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-20T20:15:18-04:00', 'moddate': '2018-05-20T20:15:18-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '..\\\\data\\\\pdf\\\\ML intro new one.pdf', 'total_pages': 237, 'page': 236, 'page_label': '231', 'source_file': 'ML intro new one.pdf', 'file_type': 'pdf'}, page_content='References 231\\n[160] Zhang, Y., J. Duchi, M. I. Jordan, and M. J. W ainwright. 2013.\\n“Information-theoretic lower bounds for distributed stat istical\\nestimation with communication constraints”. In: Advances in\\nNeural Information Processing Systems . 2328–2336.\\n[161] Zhao, X. and A. H. Sayed. 2015. “Asynchronous adaptati on and\\nlearning over networks—Part I: Modeling and stability anal ysis”.\\nIEEE T ransactions on Signal Processing . 63(4): 811–826.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='A Very Brief Introduction to Machine Learning\\nWith Applications to Communication Systems\\nOsvaldo Simeone, Fellow, IEEE\\nAbstract—Given the unprecedented availability of data\\nand computing resources, there is widespread renewed\\ninterest in applying data-driven machine learning methods\\nto problems for which the development of conventional\\nengineering solutions is challenged by modelling or al-\\ngorithmic deﬁciencies. This tutorial-style paper starts by\\naddressing the questions of why and when such techniques\\ncan be useful. It then provides a high-level introduction\\nto the basics of supervised and unsupervised learning. For\\nboth supervised and unsupervised learning, exemplifying\\napplications to communication networks are discussed by\\ndistinguishing tasks carried out at the edge and at the\\ncloud segments of the network at different layers of the\\nprotocol stack, with an emphasis on the physical layer.\\nI. I NTRODUCTION\\nAfter the “AI winter” of the 80s and the 90s, interest in'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='cloud segments of the network at different layers of the\\nprotocol stack, with an emphasis on the physical layer.\\nI. I NTRODUCTION\\nAfter the “AI winter” of the 80s and the 90s, interest in\\nthe application of data-driven Artiﬁcial Intelligence (AI)\\ntechniques has been steadily increasing in a number of\\nengineering ﬁelds, including speech and image analysis\\n[1] and communications [2]. Unlike the logic-based\\nexpert systems that were dominant in the earlier work\\non AI (see, e.g., [3]), the renewed conﬁdence in data-\\ndriven methods is motivated by the successes of pattern\\nrecognition tools based on machine learning. These tools\\nrely on decades-old algorithms, such as backpropagation\\n[4], the Expectation Maximization (EM) algorithm [5],\\nand Q-learning [6], with a number of modern algorithmic\\nadvances, including novel regularization techniques and\\nadaptive learning rate schedules (see review in [7]). Their\\nsuccess is built on the unprecedented availability of data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='advances, including novel regularization techniques and\\nadaptive learning rate schedules (see review in [7]). Their\\nsuccess is built on the unprecedented availability of data\\nand computing resources in many engineering domains.\\nWhile the new wave of promises and breakthroughs\\naround machine learning arguably falls short, at least for\\nnow, of the requirements that drove early AI research\\n[3], [8], learning algorithms have proven to be useful\\nin a number of important applications – and more is\\ncertainly on the way.\\nKing’s College London, United Kingdom (email:\\nosvaldo.simeone@kcl.ac.uk). This work has received funding\\nfrom the European Research Council (ERC) under the European\\nUnion Horizon 2020 research and innovation program (grant\\nagreement 725731).\\nThis paper provides a very brief introduction to key\\nconcepts in machine learning and to the literature on\\nmachine learning for communication systems. Unlike\\nother review papers such as [9]–[11], the presentation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='concepts in machine learning and to the literature on\\nmachine learning for communication systems. Unlike\\nother review papers such as [9]–[11], the presentation\\naims at highlighting conditions under which the use of\\nmachine learning is justiﬁed in engineering problems, as\\nwell as speciﬁc classes of learning algorithms that are\\nsuitable for their solution. The presentation is organized\\naround the description of general technical concepts, for\\nwhich an overview of applications to communication\\nnetworks is subsequently provided. These applications\\nare chosen to exemplify general design criteria and tools\\nand not to offer a comprehensive review of the state of\\nthe art and of the historical progression of advances on\\nthe topic.\\nWe proceed in this section by addressing the question\\n“What is machine learning?”, by providing a taxonomy\\nof machine learning methods, and by ﬁnally considering\\nthe question “When to use machine learning?”.\\nA. What is Machine Learning?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='“What is machine learning?”, by providing a taxonomy\\nof machine learning methods, and by ﬁnally considering\\nthe question “When to use machine learning?”.\\nA. What is Machine Learning?\\nIn order to ﬁx the ideas, it is useful to introduce\\nthe machine learning methodology as an alternative to\\nthe conventional engineering approach for the design of\\nan algorithmic solution. As illustrated in Fig. 1(a), the\\nconventional engineering design ﬂow starts with the ac-\\nquisition of domain knowledge : The problem of interest\\nis studied in detail, producing a mathematical model that\\ncapture the physics of the set-up under study. Based on\\nthe model, an optimized algorithm is produced that offers\\nperformance guarantees under the assumption that the\\ngiven physics-based model is an accurate representation\\nof reality.\\nAs an example, designing a decoding algorithm for\\na wireless fading channel under the conventional engi-\\nneering approach would require the development, or the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of reality.\\nAs an example, designing a decoding algorithm for\\na wireless fading channel under the conventional engi-\\nneering approach would require the development, or the\\nselection, of a physical model for the channel connecting\\ntransmitter and receiver. The solution would be obtained\\nby tackling an optimization problem, and it would yield\\noptimality guarantees under the given channel model.\\nTypical example of channel models include Gaussian and\\nfading channels (see, e.g., [12]).\\n1\\narXiv:1808.02342v4  [cs.IT]  5 Nov 2018'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='acquisition \\nof domain \\nknowledge\\nalgorithm \\ndevelopment\\nphysics-based \\nmathematical model\\nalgorithm with \\nperformance \\nguarantees\\nacquisition \\nof data\\nlearning\\ntraining set\\nblack-box\\nmachine\\nhypothesis \\nclass\\n(a)\\n(b)\\nFig. 1. (a) Conventional engineering design ﬂow; and (b) baseline\\nmachine learning methodology.\\nIn contrast, in its most basic form, the machine\\nlearning approach substitutes the step of acquiring do-\\nmain knowledge with the potentially easier task of\\ncollecting a sufﬁciently large number of examples of\\ndesired behaviour for the algorithm of interest. These\\nexamples constitute the training set. As seen in Fig. 1(b),\\nthe examples in the training set are fed to a learning\\nalgorithm to produce a trained “machine” that carries\\nout the desired task. Learning is made possible by the\\nchoice of a set of possible “machines”, also known as\\nthe hypothesis class, from which the learning algorithm\\nmakes a selection during training. An example of an'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='choice of a set of possible “machines”, also known as\\nthe hypothesis class, from which the learning algorithm\\nmakes a selection during training. An example of an\\nhypothesis class is given by a neural network architecture\\nwith learnable synaptic weights. Learning algorithms are\\ngenerally based on the optimization of a performance\\ncriterion that measures how well the selected “machine”\\nmatches the available data.\\nFor the problem of designing a channel decoder, a\\nmachine learning approach can hence operate even in the\\nabsence of a well-established channel model. It is in fact\\nenough to have a sufﬁciently large number of examples\\nof received signals – the inputs to the decoding machine\\n– and transmitted messages – the desired outputs of the\\ndecoding machine – to be used for the training of a given\\nclass of decoding functions [13].\\nacquisition \\nof domain \\nknowledge\\nacquisition \\nof data\\nlearning\\ntraining set\\n machine\\nhypothesis \\nclass'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='decoding machine – to be used for the training of a given\\nclass of decoding functions [13].\\nacquisition \\nof domain \\nknowledge\\nacquisition \\nof data\\nlearning\\ntraining set\\n machine\\nhypothesis \\nclass\\nFig. 2. Machine learning methodology that integrates domain knowl-\\nedge during model selection.\\nMoving beyond the basic formulation described above,\\nmachine learning tools can integrate available domain\\nknowledge in the learning process. This is indeed the\\nkey to the success of machine learning tools in a number\\nof applications. A notable example is image processing,\\nwhereby knowledge of the translational invariance of vi-\\nsual features is reﬂected in the adoption of convolutional\\nneural networks as the hypothesis class to be trained.\\nMore generally, as illustrated in Fig. 2, domain knowl-\\nedge can dictate the choice of a speciﬁc hypothesis class\\nfor use in the training process. Examples of applications\\nof this idea to communication systems, including to the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='edge can dictate the choice of a speciﬁc hypothesis class\\nfor use in the training process. Examples of applications\\nof this idea to communication systems, including to the\\nproblem of decoding, will be discussed later in the paper.\\nB. Taxonomy of Machine Learning Methods\\nThere are three main classes of machine learning\\ntechniques, as discussed next.\\n• Supervised learning : In supervised learning, the\\ntraining set consists of pairs of input and desired\\noutput, and the goal is that of learning a mapping\\nbetween input and output spaces. As an illustration,\\nin Fig. 3(a), the inputs are points in the two-\\ndimensional plane, the outputs are the labels as-\\nsigned to each input (circles or crosses), and the\\ngoal is to learn a binary classiﬁer. Applications\\ninclude the channel decoder discussed above, as\\nwell as email spam classiﬁcation on the basis of\\nexamples of spam/ non-spam emails.\\n• Unsupervised learning : In unsupervised learning,\\nthe training set consists of unlabelled inputs, that is,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='well as email spam classiﬁcation on the basis of\\nexamples of spam/ non-spam emails.\\n• Unsupervised learning : In unsupervised learning,\\nthe training set consists of unlabelled inputs, that is,\\nof inputs without any assigned desired output. For\\ninstance, in Fig. 3(b), the inputs are again points\\nin the two-dimensional plane, but no indication is\\nprovided by the data about the corresponding de-\\nsired output. Unsupervised learning generally aims\\nat discovering properties of the mechanism gen-\\nerating the data. In the example of Fig. 3(b), the\\ngoal of unsupervised learning is to cluster together\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='input points that are close to each other, hence\\nassigning a label – the cluster index – to each\\ninput point (clusters are delimited by dashed lines).\\nApplications include clustering of documents with\\nsimilar topics. It is emphasized that clustering is\\nonly one of the learning tasks that fall under the\\ncategory of unsupervised learning (see Sec. V).\\n• Reinforcement learning : Reinforcement learning\\nlies, in a sense, between supervised and unsuper-\\nvised learning. Unlike unsupervised learning, some\\nform of supervision exists, but this does not come\\nin the form of the speciﬁcation of a desired output\\nfor every input in the data. Instead, a reinforcement\\nlearning algorithm receives feedback from the envi-\\nronment only after selecting an output for a given\\ninput or observation. The feedback indicates the\\ndegree to which the output, known as action in re-\\ninforcement learning, fulﬁls the goals of the learner.\\nReinforcement learning applies to sequential deci-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='degree to which the output, known as action in re-\\ninforcement learning, fulﬁls the goals of the learner.\\nReinforcement learning applies to sequential deci-\\nsion making problems in which the learner interacts\\nwith an environment by sequentially taking actions\\n– the outputs – on the basis of its observations –\\nits inputs – while receiving feedback regarding each\\nselected action.\\nMost current machine learning applications fall in\\nthe supervised learning category, and hence aim at\\nlearning an existing pattern between inputs and outputs.\\nSupervised learning is relatively well-understood at a\\ntheoretical level [14], [15], and it beneﬁts from well-\\nestablished algorithmic tools. Unsupervised learning has\\nso far deﬁed a uniﬁed theoretical treatment [16]. Never-\\ntheless, it arguably poses a more fundamental practical\\nproblem in that it directly tackles the challenge of learn-\\ning by direct observation without any form of explicit\\nfeedback. Reinforcement learning has found extensive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='problem in that it directly tackles the challenge of learn-\\ning by direct observation without any form of explicit\\nfeedback. Reinforcement learning has found extensive\\napplications in problems that are characterized by clear\\nfeedback signals, such as win/lose outcomes in games,\\nand that entail searches over large trees of possible\\naction-observation histories [17], [18].\\nThis paper only covers supervised and unsupervised\\nlearning. Reinforcement learning requires a different\\nanalytical framework grounded in Markov Decision Pro-\\ncesses and will not be discussed here (see [17]). For a\\nbroader discussion on the technical aspects of supervised\\nand unsupervised learning, we point to [19] and refer-\\nences therein.\\nC. When to Use Machine Learning?\\nBased on the discussion in Sec. I-A, the use of a\\nmachine learning approach in lieu of a more conventional\\nengineering design should be justiﬁed on a case-by-\\ncase basis on the basis of its suitability and potential'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='machine learning approach in lieu of a more conventional\\nengineering design should be justiﬁed on a case-by-\\ncase basis on the basis of its suitability and potential\\nadvantages. The following criteria, inspired by [20], offer\\nuseful guidelines on the type of engineering tasks that\\ncan beneﬁt from the use of machine learning tools.\\n1. The traditional engineering ﬂow is not applicable or\\nis undesirable due to a model deﬁcit or to an algorithm\\ndeﬁcit [21].\\n• With a model deﬁcit, no physics-based mathematical\\nmodels exist for the problem due to insufﬁcient\\ndomain knowledge. As a result, a conventional\\nmodel-based design is inapplicable.\\n• With an algorithm deﬁcit, a well-established math-\\nematical model is available, but existing algorithms\\noptimized on the basis of such model are too com-\\nplex to be implemented for the given application.\\nIn this case, the use of hypothesis classes including\\nefﬁcient “machines”, such as neural network of lim-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='plex to be implemented for the given application.\\nIn this case, the use of hypothesis classes including\\nefﬁcient “machines”, such as neural network of lim-\\nited size or with tailored hardware implementations\\n(see, e.g., [22], [23] and references therein), can\\nyield lower-complexity solutions.\\n2. A sufﬁciently large training data sets exist or can be\\ncreated.\\n3. The task does not require the application of logic,\\ncommon sense, or explicit reasoning based on back-\\nground knowledge.\\n4. The task does not require detailed explanations for\\nhow the decision was made . The trained machine is by\\nand large a black box that maps inputs to outputs. As\\nsuch, it does not provide direct means to ascertain why a\\ngiven output has been produced in response to an input,\\nalthough recent research has made some progress on\\nthis front [24]. This contrasts with engineered optimal\\nsolutions, which can be typically interpreted on the\\nbasis of physical performance criteria. For instance, a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='this front [24]. This contrasts with engineered optimal\\nsolutions, which can be typically interpreted on the\\nbasis of physical performance criteria. For instance, a\\nmaximum likelihood decoder chooses a given output\\nbecause it minimizes the probability of error under the\\nassumed model.\\n5. The phenomenon or function being learned is station-\\nary for a sufﬁciently long period of time. This is in order\\nto enable data collection and learning.\\n6. The task has either loose requirement constraints,\\nor, in the case of an algorithm deﬁcit, the required\\nperformance guarantees can be provided via numeri-\\ncal simulations . With the conventional engineering ap-\\nproach, theoretical performance guarantees can be ob-\\ntained that are backed by a physics-based mathematical\\nmodel. These guarantees can be relied upon insofar as\\nthe model is trusted to be an accurate representation\\nof reality. If a machine learning approach is used to\\naddress an algorithm deﬁcit and a physics-based model'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='the model is trusted to be an accurate representation\\nof reality. If a machine learning approach is used to\\naddress an algorithm deﬁcit and a physics-based model\\nis available, then numerical results may be sufﬁcient in\\norder to compute satisfactory performance measures. In\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='4 5 6 7 8 90\\n1\\n2\\n3\\n4\\n5\\n4 5 6 7 80\\n1\\n2\\n3\\n4\\n5\\n(a)\\n(b)\\nFig. 3. Illustration of (a) supervised learning and (b) unsupervised\\nlearning.\\ncontrast, weaker guarantees can be offered by machine\\nlearning in the absence of a physics-based model. In this\\ncase, one can provide performance bounds only under\\nthe assumptions that the hypothesis class is sufﬁciently\\ngeneral to include “machines” that can perform well on\\nthe problem and that the data is representative of the\\nactual data distribution to be encountered at runtime (see,\\ne.g., [19][Ch. 5]). The selection of a biased hypothesis\\nclass or the use of an unrepresentative data set may hence\\nyield strongly suboptimal performance.\\nWe will return to these criteria when discussing ap-\\nplications to communication systems.\\nII. M ACHINE LEARNING FOR COMMUNICATION\\nNETWORKS\\nIn order to exemplify applications of supervised and\\nunsupervised learning, we will offer annotated pointers\\nto the literature on machine learning for communication'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='NETWORKS\\nIn order to exemplify applications of supervised and\\nunsupervised learning, we will offer annotated pointers\\nto the literature on machine learning for communication\\nsystems. Rather than striving for a comprehensive, and\\nhistorically minded, review, the applications and refer-\\nences have been selected with the goal of illustrating\\nkey aspects regarding the use of machine learning in\\nengineering problems.\\nCore \\nNetwork\\nEdge \\nCloud\\nWireless \\nEdge\\nAccess \\nNetwork\\nCore \\nCloud\\nCloud\\nEdge\\nFig. 4. A generic cellular wireless network architecture that dis-\\ntinguishes between edge segment, with base stations, access points,\\nand associated computing resources, and cloud segment, consisting\\nof core network and associated cloud computing platforms.\\nThroughout, we focus on tasks carried out at the\\nnetwork side, rather than at the users, and organize the\\napplications along two axes. On one, with reference to\\nFig. 4, we distinguish tasks that are carried out at the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='network side, rather than at the users, and organize the\\napplications along two axes. On one, with reference to\\nFig. 4, we distinguish tasks that are carried out at the\\nedge of the network, that is, at the base stations or\\naccess points and at the associated computing platforms,\\nfrom tasks that are instead responsibility of a centralized\\ncloud processor connected to the core network (see, e.g.,\\n[25]). The edge operates on the basis of timely local\\ninformation collected at different layers of the protocol\\nstack, which may include all layers from the physical up\\nto the application layer. In contrast, the centralized cloud\\nprocesses longer-term and global information collected\\nfrom multiple nodes in the edge network, which typically\\nencompasses only the higher layers of the protocol stack,\\nnamely networking and application layers. Examples of\\ndata that may be available at the cloud and at the edge\\ncan be found in Table I and Table II, respectively.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='namely networking and application layers. Examples of\\ndata that may be available at the cloud and at the edge\\ncan be found in Table I and Table II, respectively.\\nAs a preliminary discussion, it is useful to ask which\\ntasks of a communication network, if any, may beneﬁt\\nfrom machine learning through the lens of the criteria re-\\nviewed in Sec. I-C. First, as seen, there should be either a\\nmodel deﬁcit or an algorithm deﬁcit that prevents the use\\nof a conventional model-based engineering design. As an\\nexample of model deﬁcit, proactive resource allocation\\nthat is based on predictions of human behaviour, e.g., for\\ncaching popular contents, may not beneﬁt from well-\\nestablished and reliable models, making a data-driven\\napproach desirable (see, e.g., [26], [27]). For an instance\\nof algorithm deﬁcit, consider the problem of channel\\ndecoding for channels with known and accurate models\\nbased on which the maximum likelihood decoder entails\\nan excessive complexity.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of algorithm deﬁcit, consider the problem of channel\\ndecoding for channels with known and accurate models\\nbased on which the maximum likelihood decoder entails\\nan excessive complexity.\\nAssuming that the problem at hand is characterized\\nby model or algorithm deﬁcits, one should then consider\\nthe rest of the criteria discussed in Sec. I-C. Most are\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='TABLE I\\nEXAMPLES OF DATA AVAILABLE AT THE EDGE SEGMENT OF A COMMUNICATION NETWORK\\nLayer Data\\nPhysical Baseband signals, channel state information\\nMedium Access Control/ Link Throughput, FER, random access load and latency\\nNetwork Location, trafﬁc loads across services, users’ device types, battery levels\\nApplication Users’ preferences, content demands, computing loads, QoS metrics\\nTABLE II\\nEXAMPLES OF DATA AVAILABLE AT THE CLOUD SEGMENT OF A COMMUNICATION NETWORK\\nLayer Data\\nNetwork Mobility patterns, network-wide trafﬁc statistics, outage rates\\nApplication User’s behaviour patterns, subscription information, service usage statistics, TCP/IP trafﬁc statistics\\ntypically satisﬁed by communication problems. Indeed,\\nfor most tasks in communication networks, it is possible\\nto collect or generate training data sets and there is\\nno need to apply common sense or to provide detailed\\nexplanations for how a decision was made.\\nThe remaining two criteria need to be checked on a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='no need to apply common sense or to provide detailed\\nexplanations for how a decision was made.\\nThe remaining two criteria need to be checked on a\\ncase-by-case basis. First, the phenomenon or function\\nbeing learned should not change too rapidly over time.\\nFor example, designing a channel decoder based on\\nsamples obtained from a limited number of realizations\\nof a given propagation channel requires the channel is\\nstationary over a sufﬁciently long period of time (see\\n[28]).\\nSecond, in the case of a model deﬁcit, the task should\\nhave some tolerance for error in the sense of not requir-\\ning provable performance guarantees. For instance, the\\nperformance of a decoder trained on a channel lacking\\na well-established channel model, such as a biological\\ncommunication link, can only be relied upon insofar\\nas one trusts the available data to be representative of\\nthe complete set of possible realizations of the problem\\nunder study. Alternatively, under an algorithm deﬁcit, a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='as one trusts the available data to be representative of\\nthe complete set of possible realizations of the problem\\nunder study. Alternatively, under an algorithm deﬁcit, a\\nphysics-based model, if available, can be possibly used\\nto carry out computer simulations and obtain numerical\\nperformance guarantees.\\nIn Sec. IV and Sec. VI, we will provide some pointers\\nto speciﬁc applications to supervised and unsupervised\\nlearning, respectively.\\nIII. S UPERVISED LEARNING\\nAs introduced in Sec. I, supervised learning aims at\\ndiscovering patterns that relate inputs to outputs on the\\nbasis of a training set of input-output examples. We can\\ndistinguish two classes of supervised learning problems\\ndepending on whether the outputs are continuous or dis-\\ncrete variables. In the former case, we have a regression\\nproblem, while in the latter we have a classiﬁcation\\n0 0.2 0.4 0.6 0.8 1-1.5\\n-1\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n?\\nFig. 5. Illustration of the supervised learning problem of regression:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='problem, while in the latter we have a classiﬁcation\\n0 0.2 0.4 0.6 0.8 1-1.5\\n-1\\n-0.5\\n0\\n0.5\\n1\\n1.5\\n?\\nFig. 5. Illustration of the supervised learning problem of regression:\\nGiven input-output training examples (xn,tn), with n = 1,...,N ,\\nhow should we predict the output t for an unobserved value of the\\ninput x?\\nproblem. We discuss the respective goals of the two\\nproblems next. This is followed by a formal deﬁnition of\\nclassiﬁcation and regression, and by a discussion of the\\nmethodology and of the main steps involved in tackling\\nthe two classes of problems.\\nA. Goals\\nAs illustrated in Fig. 5, in a regression problem, we\\nare given a training set Dof N training points (xn,tn),\\nwith n= 1,...,N , where the variables xn are the inputs,\\nalso known as covariates, domain points, or explanatory\\nvariables; while the variables tn are the outputs, also\\nknown as dependent variables, labels, or responses. In\\nregression, the outputs are continuous variables. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='variables; while the variables tn are the outputs, also\\nknown as dependent variables, labels, or responses. In\\nregression, the outputs are continuous variables. The\\nproblem is to predict the output t for a new, that is,\\nas of yet unobserved, input x.\\nAs illustrated in Fig. 6, classiﬁcation is similarly\\ndeﬁned with the only caveat that the outputstare discrete\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='4 5 6 7 8 90.5\\n1\\n1.5\\n2\\n2.5\\n3\\n3.5\\n4\\n4.5\\n?\\nFig. 6. Illustration of the supervised learning problem of classi-\\nﬁcation: Given input-output training examples (xn,tn), with n =\\n1,...,N , how should we predict the output tfor an unobserved value\\nof the input x?\\nvariables that take a ﬁnite number of possible values. The\\nvalue of the output t for a given input x indicates the\\nclass to which x belongs. For instance, the label t is a\\nbinary variable as in Fig. 6 for a binary classiﬁcation\\nproblem. Based on the training set D, the goal is to\\npredict the label, or the class, t for a new, as of yet\\nunobserved, input x.\\nTo sum up, the goal of both regression and clas-\\nsiﬁcation is to derive from the training data set D a\\npredictor ˆt(x) that generalizes the input-output mapping\\nin Dto inputs x that are not present in D. As such,\\nlearning is markedly distinct from memorizing: while\\nmemorizing would require producing a value tn for some\\nrecorded input xn in the training set, learning is about'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='learning is markedly distinct from memorizing: while\\nmemorizing would require producing a value tn for some\\nrecorded input xn in the training set, learning is about\\ngeneralization from the data set to the rest of the relevant\\ninput space.\\nThe problem of extrapolating a predictor from the\\ntraining set is evidently impossible unless one is willing\\nto make some assumption about the underlying input-\\noutput mapping. In fact, the output t may well equal\\nany value for an unobserved xif nothing else is speciﬁed\\nabout the problem. This impossibility is formalized by\\nthe no free-lunch theorem: without making assumptions\\nabout the relationship between input and output, it is not\\npossible to generalize the available observations outside\\nthe training set [14]. The set of assumptions made in\\norder to enable learning are known as inductive bias .\\nAs an example, for the regression problem in Fig. 5,\\na possible inductive bias is to postulate that the input-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='order to enable learning are known as inductive bias .\\nAs an example, for the regression problem in Fig. 5,\\na possible inductive bias is to postulate that the input-\\noutput mapping is a polynomial function of some order.\\nB. Deﬁning Supervised Learning\\nHaving introduced the goal of supervised learning, we\\nnow provide a more formal deﬁnition of the problem.\\nThroughout, we use Roman font to denote random\\nvariables and the corresponding letter in regular font for\\nrealizations.\\nAs a starting point, we assume that the training set D\\nis generated as\\n(xn,tn) ∼\\ni.i.d.\\np(x,t), n= 1,...,N, (1)\\nthat is, each training sample pair (xn,tn) is generated\\nfrom the same true joint distribution p(x,t) and the sam-\\nple pairs are independent identically distributed (i.i.d.).\\nAs discussed, based on the training set D, we wish\\nto obtain a predictor ˆt(x) that performs well on any\\npossible relevant input x. This requirement is formalized\\nby imposing that the predictor is accurate for any test'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to obtain a predictor ˆt(x) that performs well on any\\npossible relevant input x. This requirement is formalized\\nby imposing that the predictor is accurate for any test\\npair (x,t) ∼p(x,t), which is generated independently\\nof all the pairs in the training set D.\\nThe quality of the prediction ˆt(x) for a test pair ( x,t)\\nis measured by a given loss function ℓ(t,ˆt) as ℓ(t,ˆt(x)).\\nTypical examples of loss functions include the quadratic\\nloss ℓ(t,ˆt) = (t−ˆt)2 for regression problems; and the\\nerror rate ℓ(t,ˆt) = 1(t ̸= ˆt), which equals 1 when the\\nprediction is incorrect, i.e., t ̸= ˆt, and 0 otherwise, for\\nclassiﬁcation problems.\\nThe formal goal of learning is that of minimizing the\\naverage loss on the test pair, which is referred to as the\\ngeneralization loss. For a given predictorˆt, this is deﬁned\\nas\\nLp(ˆt) =E(x,t)∼p(x,t)[ℓ(t,ˆt(x))]. (2)\\nThe generalization loss (2) is averaged over the distribu-\\ntion of the test pair ( x,t).\\nBefore moving on to the solution of the problem of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='as\\nLp(ˆt) =E(x,t)∼p(x,t)[ℓ(t,ˆt(x))]. (2)\\nThe generalization loss (2) is averaged over the distribu-\\ntion of the test pair ( x,t).\\nBefore moving on to the solution of the problem of\\nminimizing the generalization loss, we mention that the\\nformulation provided here is only one, albeit arguably\\nthe most popular, of a number of alternative formula-\\ntions of supervised learning. The frequentist framework\\ndescribed above is in fact complemented by other view-\\npoints, including Bayesian and Minimum Description\\nLength (MDL) (see [19] and references therein).\\nC. When The True Distribution p(x,t) is Known: Infer-\\nence\\nConsider ﬁrst the case in which the true joint dis-\\ntribution p(x,t) relating input and output is known.\\nThis scenario can be considered as an idealization of\\nthe situation resulting from the conventional engineering\\ndesign ﬂow when the available physics-based model is\\naccurate (see Sec. I). Under this assumption, the data set\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Dis not necessary, since the mapping between input and\\noutput is fully described by the distribution p(x,t).\\nIf the true distribution p(x,t) is known, the problem\\nof minimizing the generalization loss reduces to a stan-\\ndard inference problem, i.e., an estimation problem in a\\nregression set-up, in which the outputs are continuous\\nvariables, or a detection problem in a classiﬁcation set-\\nup, in which the outputs are ﬁnite discrete variables.\\nIn an inference problem, the optimal predictor ˆt can\\nbe directly computed from the posterior distribution\\np(t|x) =p(x,t)\\np(x) , (3)\\nwhere p(x) is the marginal distribution of the input x.\\nThe latter can be computed from the joint distribution\\np(x,t) by summing or integrating out all the values of t.\\nIn fact, given a loss function ℓ(t,ˆt), the optimal predictor\\nfor any input x is obtained as\\nˆt∗(x) =arg min\\nˆt\\nEt∼p(t|x)[ℓ(t,ˆt)|x]. (4)\\nIn words, the optimal predictor ˆt∗(x) is obtained by\\nidentifying the value (or values) of t that minimizes the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='for any input x is obtained as\\nˆt∗(x) =arg min\\nˆt\\nEt∼p(t|x)[ℓ(t,ˆt)|x]. (4)\\nIn words, the optimal predictor ˆt∗(x) is obtained by\\nidentifying the value (or values) of t that minimizes the\\naverage loss, where the average is taken with respect\\nto the posterior distribution p(t|x) of the output given\\nthe input. Given that the posterior p(t|x) yields the\\noptimal predictor, it is also known as the true predictive\\ndistribution.\\nThe optimal predictor (4) can be explicitly evaluated\\nfor given loss functions. For instance, for the quadratic\\nloss, which is typical for regression, the optimal predictor\\nis given by the mean of the predictive distribution, or the\\nposterior mean, i.e.,\\nˆt∗(x) =Et∼p(t|x)[t|x], (5)\\nwhile, with the error rate loss, which is typical for\\nclassiﬁcation, problems, the optimal predictor is given\\nby the maximum of the predictive distribution, or the\\nmaximum a posteriori (MAP) estimate, i.e.,\\nˆt∗(x) =arg max\\nt\\np(t|x). (6)\\nFor a numerical example, consider binary inputs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='by the maximum of the predictive distribution, or the\\nmaximum a posteriori (MAP) estimate, i.e.,\\nˆt∗(x) =arg max\\nt\\np(t|x). (6)\\nFor a numerical example, consider binary inputs\\nand outputs and the joint distribution p(x,t) such that\\np(0,0) = 0 .05, p(0,1) = 0 .45, p(1,0) = 0 .4 and\\np(1,1) = 0.1. The predictive distribution for input x= 0\\nis then given as p(t = 1|x = 0) = 0.9, and hence\\nwe have the optimal predictor given by the average\\nˆt∗(x = 0) = 0.9 ×1 + 0.1 ×0 = 0.9 for the quadratic\\nloss, and by the MAP solution ˆt∗(x = 0) = 1for the\\nerror rate loss.\\nD. When the True Distribution p(x,t) is Not Known:\\nMachine Learning\\nConsider now the case of interest in which domain\\nknowledge is not available and hence the true joint\\ndistribution is unknown. In such a scenario, we have a\\nlearning problem and we need to use the examples in the\\ntraining set Din order to obtain a meaningful predictor\\nthat approximately minimizes the generalization loss.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='learning problem and we need to use the examples in the\\ntraining set Din order to obtain a meaningful predictor\\nthat approximately minimizes the generalization loss.\\nAt a high level, the methodology applied by machine\\nlearning follows three main steps, which are described\\nnext.\\n1. Model selection (inductive bias) : As a ﬁrst step,\\none needs to commit to a speciﬁc class of hypotheses that\\nthe learning algorithm may choose from. The hypothesis\\nclass is also referred to as model. The selection of the hy-\\npothesis class characterizes the inductive bias mentioned\\nabove as a pre-requisite for learning. In a probabilistic\\nframework, the hypothesis class, or model, is deﬁned\\nby a family of probability distributions parameterized\\nby a vector θ. Speciﬁcally, there are two main ways\\nof specifying a parametric family of distributions as a\\nmodel for supervised learning:\\n• Generative model : Generative models specify a\\nfamily of joint distributions p(x,t|θ);'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of specifying a parametric family of distributions as a\\nmodel for supervised learning:\\n• Generative model : Generative models specify a\\nfamily of joint distributions p(x,t|θ);\\n• Discriminative model : Discriminative models pa-\\nrameterize directly the predictive distribution as\\np(t|x,θ).\\nBroadly speaking, discriminative models do not make\\nany assumptions about the distribution of the inputs\\nx and hence may be less prone to bias caused by a\\nmisspeciﬁcation of the hypothesis class. On the ﬂip side,\\ngenerative models may be able to capture more of the\\nstructure present in the data and consequently improve\\nthe performance of the predictor [29]. For both types of\\nmodels, the hypothesis class is typically selected from\\na common set of probability distributions that lead to\\nefﬁcient learning algorithms in Step 2. Furthermore, any\\navailable basic domain knowledge can be in principle\\nincorporated in the selection of the model (see also Sec.\\nVII).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='efﬁcient learning algorithms in Step 2. Furthermore, any\\navailable basic domain knowledge can be in principle\\nincorporated in the selection of the model (see also Sec.\\nVII).\\n2. Learning: Given data D, in the learning step, a\\nlearning criterion is optimized in order to obtain the\\nparameter vector θ and identify a distribution p(x,t|θ)\\nor p(t|x,θ), depending on whether a generative or dis-\\ncriminative model was selected at Step 1.\\n3. Inference: In the inference step, the learned model\\nis used to obtain the predictor ˆt(x) by using (4) with\\nthe learned model in lieu of the true distribution. Note\\nthat generative models require the calculation of the\\npredictive distribution p(t|x) via marginalization, while\\ndiscriminative models provide directly the predictive\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='distribution. As mentioned, the predictor should be eval-\\nuated on test data that is different from the training set\\nD. As we will discuss, the design cycle typically entails\\na loop between validation of the predictor at Step 3 and\\nmodel selection at Step 1.\\nThe next examples illustrate the three steps introduced\\nabove for a binary classiﬁcation problem.\\nExample 1 : Consider a binary classiﬁcation problem\\nin which the input is a generic D-dimensional vector\\nx = [x1,...,x D]T and the output is binary, i.e., t ∈\\n{0,1}. The superscript “ T” represents transposition. In\\nStep 1, we select a model, that is, a parameterized family\\nof distributions. A common choice is given by logistic\\nregression1, which is a discriminative model whereby\\nthe predictive distribution p(t|x,θ) is parameterized as\\nillustrated in Fig. 7. The model ﬁrst computes D′ ﬁxed\\nfeatures φ(x) = [φ1(x) ···φD′(x)]T of the input, where\\na feature is a function of the data. Then, it computes the\\npredictive probability as'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='illustrated in Fig. 7. The model ﬁrst computes D′ ﬁxed\\nfeatures φ(x) = [φ1(x) ···φD′(x)]T of the input, where\\na feature is a function of the data. Then, it computes the\\npredictive probability as\\np(t= 1|x,w) =σ(wTφ(x)), (7)\\nwhere w is the set of learnable weights – i.e., the pa-\\nrameter θ deﬁned above – and σ(a) = (1 + exp(−a))−1\\nis the sigmoid function.\\nUnder logistic regression, the probability that the label\\nis t= 1 increases as the linear combination of features\\nbecomes more positive, and we havep(t= 1|x,w) >0.5\\nfor wTφ(x) > 0. Conversely, the probability that the\\nlabel is t = 0 increases as the linear combination of\\nfeatures becomes more negative, with p(t = 0|x,w) >\\n0.5 for wTφ(x) < 0. As a speciﬁc instance of this\\nproblem, if we wish to classify emails between spam\\nand non-spam ones, possible useful features may count\\nthe number of times that certain suspicious words appear\\nin the text.\\nStep 2 amounts to the identiﬁcation of the weight'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='and non-spam ones, possible useful features may count\\nthe number of times that certain suspicious words appear\\nin the text.\\nStep 2 amounts to the identiﬁcation of the weight\\nvector w on the basis of the training set D with the\\nideal goal of minimizing the generalization loss (2). This\\nstep will be further discussed in the next subsection.\\nFinally, in Step 3, the optimal predictor is obtained\\nby assuming that the learned model p(t|x,w) is the\\ntrue predictive distribution. Assuming an error rate loss\\nfunction, following the discussion in Sec. III-C, the\\noptimal predictor is given by the MAP choice ˆt∗(x) = 1\\nif wTφ(x) >0 and ˆt∗(x) = 0otherwise. It is noted that\\nthe linear combination wTφ(x) is also known as logit\\nor log-likelihood ratio (LLR) . This rule can be seen to\\ncorrespond to a linear classiﬁer [19]. The performance\\n1The term ”regression” may be confusing, since the model applies\\nto classiﬁcation.\\nFig. 7. An illustration of the hypothesis class p(t|x,w) assumed by'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='1The term ”regression” may be confusing, since the model applies\\nto classiﬁcation.\\nFig. 7. An illustration of the hypothesis class p(t|x,w) assumed by\\nlogistic regression using a neural network representation: functions\\nφi, with i = 1,...,D ′, are ﬁxed and compute features of the input\\nvector x = [x1,...,x D]. The learnable parameter vector θ here\\ncorresponds to the weights w used to linearly combine the features\\nin (7).\\nof the predictor should be tested on new, test, input-\\noutput pairs, e.g., new emails in the spam classiﬁcation\\nexample. □\\nExample 2 : Logistic regression requires to specify a\\nsuitable vector of features φ(x). As seen in the email\\nspam classiﬁcation example, this entails the availability\\nof some domain knowledge to be able to ascertain which\\nfunctions of the input x may be more relevant for the\\nclassiﬁcation task at hand. As discussed in Sec. I, this\\nknowledge may not be available due to, e.g., cost or\\ntime constraints. Multi-layer neural networks provide an'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='classiﬁcation task at hand. As discussed in Sec. I, this\\nknowledge may not be available due to, e.g., cost or\\ntime constraints. Multi-layer neural networks provide an\\nalternative model choice at Step 1 that obviates the need\\nfor hand-crafted features. The model is illustrated in\\nFig. 8. Unlike linear regression, in a multi-layer neural\\nnetwork, the feature vector φ(x) used by the last layer to\\ncompute the logit, or LLR, that determines the predictive\\nprobability (7) is not ﬁxed a priori. Rather, the feature\\nvector is computed by the previous layers. To this end,\\neach neuron, represented as a circle in Fig. 8, computes\\na ﬁxed non-linear function, e.g., sigmoid, of a linear\\ncombination of the values obtained from the previous\\nlayer. The weights of these linear combinations are part\\nof the learnable parameters θ, along with the weights of\\nthe last layer. By allowing the weights at all layers of the\\nmodel to be trained simultaneously, multi-layer neural'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of the learnable parameters θ, along with the weights of\\nthe last layer. By allowing the weights at all layers of the\\nmodel to be trained simultaneously, multi-layer neural\\nnetworks enable the joint learning of the last-layer linear\\nclassiﬁer and of the features φ(x) the classiﬁer operates\\non. As a notable example, deep neural networks are\\ncharacterized by a large number of intermediate layers\\nthat tend to learn increasingly abstract features of the\\ninput [7]. □\\nIn the rest of this section, we ﬁrst provide some\\ntechnical details about Step 2, i.e., learning, and then we\\nreturn to Step 1, i.e., model selection. As it will be seen,\\nthis order is dictated by the fact that model selection\\nrequires some understanding of the learning process.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Fig. 8. An illustration of the hypothesis class p(t|x,w) assumed\\nby multi-layer neural networks. The learnable parameter vector θ\\nhere corresponds to the weights wL used at the last layer to linearly\\ncombine the features φ(x) and the weight matrices W1,...,W L−1\\nused at the preceding layers in order to compute the feature vector.\\nE. Learning\\nIdeally, a learning rule should obtain a predictor\\nthat minimizes the generalization error (2). However, as\\ndiscussed in Sec. III-C, this task is out of reach without\\nknowledge of the true joint distribution p(x,t). There-\\nfore, alternative learning criteria need to be considered\\nthat rely on the training set Drather than on the true\\ndistribution.\\nIn the context of probabilistic models, the most basic\\nlearning criterion is Maximum Likelihood (ML). ML\\nselects a value of θin the parameterized family of models\\np(x,t|θ) or p(t|x,θ) that is the most likely to have\\ngenerated the observed training set D. Mathematically,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='selects a value of θin the parameterized family of models\\np(x,t|θ) or p(t|x,θ) that is the most likely to have\\ngenerated the observed training set D. Mathematically,\\nML solves the problem of maximizing the log-likelihood\\nfunction\\nmaximize ln p(D|θ) (8)\\nover θ, where p(D|θ) is the probability of the data set\\nDfor a given value of θ. Given the assumption of i.i.d.\\ndata points in D(see Sec. III-B), the log-likelihood can\\nbe written as\\nln p(D|θ) =\\nN∑\\nn=1\\nln p(tn|xn,θ), (9)\\nwhere we have used as an example the case of discrim-\\ninative models. Note that most learning criteria used in\\npractice can be interpreted as ML problems, including\\nthe least squares criterion – ML for Gaussian models –\\nand cross-entropy – ML for categorical models.\\nThe ML problem (8) rarely has analytical solutions\\nand is typically addressed by Stochastic Gradient De-\\nscent (SGD). Accordingly, at each iteration, subsets of\\nexamples, also known as mini-batches, are selected from'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='and is typically addressed by Stochastic Gradient De-\\nscent (SGD). Accordingly, at each iteration, subsets of\\nexamples, also known as mini-batches, are selected from\\nthe training set, and the parameter vector is updated in\\nthe direction of gradient of the log-likelihood function\\nas evaluated on these examples. The resulting learning\\nrule can be written as\\nθnew ←θold + γ∇θln p(tn|xn,θ)|θ=θold , (10)\\nwhere we have deﬁned as γ >0 the learning rate, and,\\nfor simplicity of notation, we have considered a mini-\\nbatch given by a single example (xn,tn). It is noted\\nthat, with multi-layer neural networks, the computation\\nof the gradient ∇θln p(tn|xn,θ) yields the standard\\nbackpropagation algorithm [7], [19]. The learning rate is\\nan example of hyperparameters that deﬁne the learning\\nalgorithm. Many variations of SGD have been proposed\\nthat aim at improving convergence (see, e.g., [7], [19]).\\nML has evident drawbacks as an indirect means of\\nminimizing the generalization error. In fact, ML only'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='that aim at improving convergence (see, e.g., [7], [19]).\\nML has evident drawbacks as an indirect means of\\nminimizing the generalization error. In fact, ML only\\nconsiders the ﬁt of the probabilistic model on the training\\nset without any consideration for the performance on\\nunobserved input-output pairs. This weakness can be\\nsomewhat mitigated by regularization [7], [19] during\\nlearning and by a proper selection of the model via\\nvalidation, as discussed in the next subsection. Regu-\\nlarization adds a penalty term to the log-likelihood that\\ndepends on the model parameters θ. The goal is to\\nprevent the learned model parameters θto assume values\\nthat are a priori too unlikely and that are hence possible\\nsymptoms of overﬁtting. As an example, for logistic\\nregression, one can add a penalty that is proportional\\nto the norm ||w||2 of the weight vector w in order to\\nprevent the weights to assume excessively high values\\nwhen ﬁtting the data in the learning step.\\nF . Model Selection'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to the norm ||w||2 of the weight vector w in order to\\nprevent the weights to assume excessively high values\\nwhen ﬁtting the data in the learning step.\\nF . Model Selection\\nWe now discuss the ﬁrst, key, step of model selection,\\nwhich deﬁnes the inductive bias adopted in the learning\\nprocess. In order to illustrate the main ideas, here we\\nstudy a particular aspect of model selection, namely that\\nof model order selection . To this end, we consider a\\nhierarchical set of models of increasing complexity and\\nwe address the problem of selecting (in Step 1) the order,\\nor the complexity, of the speciﬁc model to be posited\\nfor learning (in Step 2). As an example of model order\\nselection, one may ﬁx a set of models including multi-\\nlayer networks of varying number of intermediate layers\\nand focus on determining the number of layers. It is\\nemphasized that the scope of model selection goes much\\nbeyond model order selection, including the possible\\nincorporation of domain knowledge and the tuning of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='emphasized that the scope of model selection goes much\\nbeyond model order selection, including the possible\\nincorporation of domain knowledge and the tuning of\\nthe hyperparameters of the learning algorithm.\\nFor concreteness, we focus on the regression problem\\nillustrated in Fig. 5 and assume a set of discriminative\\nmodels p(t|x,w) under which the output tis distributed\\nas\\nM∑\\nm=0\\nwmxm + N(0,1). (11)\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='0 0.2 0.4 0.6 0.8 1\\n-3\\n-2\\n-1\\n0\\n1\\n2\\n3\\n= 9M\\nM = 1\\nM = 3\\nFig. 9. Training set in Fig. 5, along with a predictor trained by\\nusing the discriminative model (11) and ML for different values of\\nthe model order M.\\nIn words, the output tis given by a polynomial function\\nof order M of the input xplus zero-mean Gaussian noise\\nof power equal to one. The learnable parameter vector\\nθ is given by the weights w = [w0,...,w M−1]T. Model\\nselection, to be carried out in Step 1, amounts to the\\nchoice of the model order M.\\nHaving chosen M in Step 1, the weights w can be\\nlearned in Step 2 using ML, and then the optimal pre-\\ndictor can be obtained for inference in Step 3. Assuming\\nthe quadratic loss, the optimal predictor is given by the\\nposterior mean ˆt(x) = ∑M\\nm=0 wmxm for the learned\\nparameters w. This predictor is plotted in Fig. 9 for\\ndifferent values of M, along with the training set of Fig.\\n5.\\nWith M = 1, the predictor ˆt(x) is seen to underﬁt\\nthe training data. This is in the sense that the model is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='different values of M, along with the training set of Fig.\\n5.\\nWith M = 1, the predictor ˆt(x) is seen to underﬁt\\nthe training data. This is in the sense that the model is\\nnot rich enough to capture the variations present in the\\ntraining data, and, as a result, we obtain a large training\\nloss\\nLD(w) = 1\\nN\\nN∑\\nn=1\\n(tn −ˆt(xn))2. (12)\\nThe training loss measures the quality of the predictor\\ndeﬁned by weights won the points in the training set. In\\ncontrast, with M = 9, the predictor ﬁts well the training\\ndata – so much so that it appears to overﬁt it. In other\\nwords, the model is too rich and, in order to account\\nfor the observations in the training set, it appears to\\nyield inaccurate predictions outside it. As a compromise\\nbetween underﬁtting and overﬁtting, the selection M = 3\\nseems to be preferable.\\nAs implied by the discussion above, underﬁtting can\\nbe detected by observing solely the training data Dvia\\nthe evaluation of the training loss (12). In contrast, over-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='seems to be preferable.\\nAs implied by the discussion above, underﬁtting can\\nbe detected by observing solely the training data Dvia\\nthe evaluation of the training loss (12). In contrast, over-\\nﬁtting cannot be ascertained on the basis of the training\\ndata as it refers to the performance of the predictor out-\\nside D. It follows that model selection cannot be carried\\nout by observing only the training set. Rather, some\\ninformation must be available about the generalization\\nperformance of the predictor. This is typically obtained\\nby means of validation. In its simplest instantiation,\\nvalidation partitions the available data into two sets, a\\ntraining set Dand a validation set . The training set is\\nused for learning as discussed in Sec. III-E, while the\\nvalidation set is used to estimate the generalization loss.\\nThis is done by computing the average in (12) only over\\nthe validation set. More sophisticated forms of validation\\nexist, including cross-validation [7].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='This is done by computing the average in (12) only over\\nthe validation set. More sophisticated forms of validation\\nexist, including cross-validation [7].\\nKeeping some data aside for validation, one can obtain\\na plot as in Fig. 10, where the training loss (12) is\\ncompared with the generalization loss (2) estimated\\nvia validation. The ﬁgure allows us to conclude that,\\nwhen M is large enough, the generalization loss starts\\nincreasing, indicating overﬁtting. Note, in contrast, that\\nunderﬁtting is detectable by observing the training loss.\\nA ﬁgure such as Fig. 10 can be used to choose a value\\nof M that approximately minimizes the generalization\\nloss.\\nMore generally, validation allows for model selection,\\nas well as for the selection of the parameters used\\nby learning the algorithm, such as the learning rate γ\\nin (10). To this end, one compares the generalization\\nloss, estimated via validation, for a number of models\\nand then chooses the one with the smallest estimated\\ngeneralization loss.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='in (10). To this end, one compares the generalization\\nloss, estimated via validation, for a number of models\\nand then chooses the one with the smallest estimated\\ngeneralization loss.\\nFinally, it is important to remark that the performance\\nof the model selected via validation should be estimated\\non the basis of a separate data set, typically called\\nthe test set . This is because the generalization loss\\nestimated using validation is a biased estimate of the\\ntrue generalization loss (2) due to the process of model\\nselection. In particular, the loss on the validation set will\\ntend to be small, since the model was selected during\\nvalidation with the aim of minimizing it. Importantly, the\\ntest set should never be used during the three steps that\\nmake up the machine learning methodology and should\\nideally only be used once to test the trained predictor.\\nIV. A PPLICATIONS OF SUPERVISED LEARNING TO\\nCOMMUNICATION SYSTEMS\\nIn this section, we provide some pointers to existing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='ideally only be used once to test the trained predictor.\\nIV. A PPLICATIONS OF SUPERVISED LEARNING TO\\nCOMMUNICATION SYSTEMS\\nIn this section, we provide some pointers to existing\\napplications of supervised learning to communication\\nnetworks. The discussion is organized by following the\\napproach described in Sec. II. Accordingly, we distin-\\nguish between tasks carried out at edge and cloud (see\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='1 2 3 4 5 6 7 8 9\\n0\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\n1.2\\n1.4\\n1.6root average squared loss\\ntraining\\ngeneralization \\n(via validation)\\noverfitting\\nunderfitting\\nFig. 10. Training loss and generalization loss, estimated via valida-\\ntion, as a function of the model order M for the example in Fig.\\n9.\\nFig. 4), as well as at different layers of the protocol\\nstack. We refer to Table I and Table II for examples of\\ndata types that may be available at the edge and cloud\\nsegments.\\nA. At the Edge\\nConsider ﬁrst tasks to be carried out at the edge, i.e.,\\nat the base stations or at the associated edge computing\\nplatform.\\n1) Physical Layer: For the physical layer, we focus\\nﬁrst on the receiver side and then on the transmitter.\\nAt the receiver, a central task that can potentially ben-\\neﬁt from machine learning is channel detection and\\ndecoding. This amounts to a multi-class classiﬁcation\\nproblem, in which the input x is given by the received\\nbaseband signal and the output is the label of the correct'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='decoding. This amounts to a multi-class classiﬁcation\\nproblem, in which the input x is given by the received\\nbaseband signal and the output is the label of the correct\\ntransmitted message (e.g., the transmitted bits) [13],\\n[30]. When can machine learning help? Recalling the\\ndiscussion in Sec. II, we should ﬁrst ask whether a\\nmodelling or algorithmic deﬁcit exists. A model deﬁcit\\nmay occur when operating over channels that do not\\nhave well-established mathematical models, such as\\nfor molecular communications [31]. Algorithm deﬁcit\\nis more common, given that optimal decoders over a\\nnumber of well-established channel models tend to be\\ncomputationally complex. This is the case for channels\\nwith strong non-linearities, as recognized as early as the\\nnineties in the context of satellite communication [2],\\n[32] and more recently for optical communications [33];\\nor for modulation schemes such as continuous phase\\nmodulation [34] – another work from the nineties – or\\nin multi–user networks [35].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[32] and more recently for optical communications [33];\\nor for modulation schemes such as continuous phase\\nmodulation [34] – another work from the nineties – or\\nin multi–user networks [35].\\nAssuming that the problem at hand is characterized by\\na modelling or algorithmic deﬁcit, then one should also\\ncheck the remaining criteria listed in Sec. II, particularly\\nthose regarding the rate of change of the phenomenon\\nunder study and the requirements in terms of perfor-\\nmance guarantees. For channel decoding, the presence\\nof fast-varying channels may make the ﬁrst criterion\\nhard to be satisﬁed in practice (unless channel estimation\\nis made part of the learning process); while stringent\\nreliability requirements may preclude the use of machine\\nlearning in the presence of a model deﬁcit.\\nAs mentioned, a generally beneﬁcial idea in the use\\nof data-aided methods is that of incorporating domain\\nknowledge in the deﬁnition of the hypothesis class . As'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='As mentioned, a generally beneﬁcial idea in the use\\nof data-aided methods is that of incorporating domain\\nknowledge in the deﬁnition of the hypothesis class . As\\nnotable examples related to channel decoding, in [36],\\n[37], knowledge of the near-optimality of message pass-\\ning methods for the decoding of sparse graphical codes\\nis used to set up a parameterized model that borrows the\\nmessage passing structure and that is trained to decode\\nmore general codes. A related approach is investigated\\nin [38] for polar codes.\\nAnother useful idea is that of directly integrating\\nalgorithms designed using the standard engineering ﬂow\\nwith trained machines. Instances of this idea include [39]\\nin which a conventional channel decoder is deployed in\\ntandem with a channel equalizer at its input that is trained\\nto compensate for hardware impairments. A related\\napproach is proposed in [40], whereby a conventional\\ndecoder is implemented within a turbo-like iterative loop'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to compensate for hardware impairments. A related\\napproach is proposed in [40], whereby a conventional\\ndecoder is implemented within a turbo-like iterative loop\\nwith a machine learning-based regressor that has the role\\nof estimating the channel noise.\\nOther tasks that can potentially beneﬁt from machine\\nlearning at the receiver’s side include modulation clas-\\nsiﬁcation, which is a classiﬁcation problem justiﬁed by\\nthe complexity of optimal solutions (algorithm deﬁcit)\\n[41]; localization, which is a regression problem, typ-\\nically motivated by the lack of tractable channels for\\ncomplex propagation environments (model deﬁcit) [42];\\nand channel state information-based authentication, a\\nclassiﬁcation problem made difﬁcult by the absence of\\nwell-established models relating channel features with\\ndevices’ identities (model deﬁcit) [43].\\nTurning to the transmitter side, most emerging ap-\\nplications tackle the algorithmic deﬁcit related to the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='devices’ identities (model deﬁcit) [43].\\nTurning to the transmitter side, most emerging ap-\\nplications tackle the algorithmic deﬁcit related to the\\ncomplexity of the non-convex programs that typically\\nunderlie power control and precoding optimization for\\nthe downlink. Notably, in [44], a training set is ob-\\ntained by running a non-convex solver to produce an\\noptimized output power vector for given input channels.\\nNote that the approach does not directly optimize the\\nperformance criterion of interest, such as the sum-rate.\\nRather, it relies on the assumption that similar inputs –\\nthe channel coefﬁcients – generally yield similar optimal\\nsolutions – the power allocation vector. if the analytical\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='model available based on domain knowledge is only a\\ncoarse approximation of the physical model, the resulting\\ntraining set can be used to augment the data in order to\\ncarry out a preliminary training of a machine learning\\nmodel [45]2.\\nFor an application at a full-duplex transceiver, we refer\\nto [47], which learns how to cancel self-interference in\\norder to overcome the lack of well-established models\\nfor the transmitter-receiver chain of non-linearities.\\n2) Link and Medium Access Control Layers: At the\\nmedium access control layer, we highlight some ap-\\nplications of machine learning that tackle the lack of\\nmathematical models for complex access protocols and\\ncommunication environments. In [48], a mechanism is\\nproposed to predict whether a channel decoder will suc-\\nceed on the basis of the outputs of the ﬁrst few iterations\\nof the iterative decoding process. This binary predictor\\nis useful in order to request an early retransmission at'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='ceed on the basis of the outputs of the ﬁrst few iterations\\nof the iterative decoding process. This binary predictor\\nis useful in order to request an early retransmission at\\nthe link layer using Automatic Retransmission Request\\n(ARQ) or Hybrid ARQ (HARQ) in order to reduce\\nlatency. At the medium access control layer, data-aided\\nmethods can instead be used to predict the availability\\nof spectrum in the presence of interfering incumbent\\ndevices with complex activation patterns for cognitive\\nradio applications [49] (see also [50]). An approach\\nthat leverages depth images to detect the availability of\\nmmwave channels is proposed in [51].\\n3) Network and Application Layers: A task that\\nis particularly well-suited for machine learning is the\\ncaching of popular contents for reduced latency and\\nnetwork congestion [52]. Caching may take place at the\\nedge and, more traditionally, within the core network\\nsegment. Caching at the edge has the advantage of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='network congestion [52]. Caching may take place at the\\nedge and, more traditionally, within the core network\\nsegment. Caching at the edge has the advantage of\\ncatering directly to the preference of the local population\\nof users, but it generally suffers from a reduced hit rate\\ndue to the smaller available storage capacity. Optimizing\\nthe selection of contents to be stored at the edge can be\\nformulated as a classiﬁcation problem that can beneﬁt\\nfrom a data-driven approach in order to adapt to the\\nspeciﬁc features of the local trafﬁc [52].\\nB. At the Cloud\\nWe now turn to some relevant tasks to be carried out\\nat the cloud at both network and application layers.\\n1) Network: The main task of the network layer is\\nrouting (see [53] for further discussion). Considering a\\nsoftware-deﬁned networking implementation, routing re-\\nquires the availability at a network controller of informa-\\ntion regarding the quality of individual communication'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='software-deﬁned networking implementation, routing re-\\nquires the availability at a network controller of informa-\\ntion regarding the quality of individual communication\\n2This can be thought of as an example of experience learning as\\npart of small-sample learning techniques [46].\\nlinks in the core network, as well as regarding the status\\nof the queues at the network routers. In the presence\\nof wireless or optical communications, the quality of a\\nlink may not be available at the network controller, but\\nit may be predicted using available historical data [33],\\n[54] in the absence of agreed-upon dynamic availability\\nmodels. In a similar manner, predicting congestion can\\nbe framed as a data-aided classiﬁcation problem [55].\\n2) Application: Finally, a relevant supervised learning\\ntask is that of trafﬁc classiﬁcation, whereby data streams\\nare classiﬁed on the basis of some extracted features,\\nsuch as packet sizes and inter-arrival times, in terms of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='task is that of trafﬁc classiﬁcation, whereby data streams\\nare classiﬁed on the basis of some extracted features,\\nsuch as packet sizes and inter-arrival times, in terms of\\ntheir applications, e.g., V oice over IP. [56]\\nV. U NSUPERVISED LEARNING\\nAs introduced in Sec. I, unlike supervised learning,\\nunsupervised learning tasks operate over unlabelled data\\nsets consisting solely of the inputs xn, with n= 1,...,N ,\\nand the general goal is that of discovering properties\\nof the data. We start this section by reviewing some\\nof the typical speciﬁc unsupervised learning tasks. We\\nthen cover methodology, models, and learning, includ-\\ning advanced methods such as Generative Adversarial\\nNetworks (GANs) [7].\\nA. Goals and Deﬁnitions\\nIn unsupervised learning, taking a frequentist formu-\\nlation (see Sec. III-A), we are given a training set D\\nconsisting of N i.i.d. samples xn ∼ p(x) with n =\\n1,...,N generated from an unknown true distribution\\np(x). The high-level goal is that of learning some useful'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='consisting of N i.i.d. samples xn ∼ p(x) with n =\\n1,...,N generated from an unknown true distribution\\np(x). The high-level goal is that of learning some useful\\nproperties of the distribution p(x). More speciﬁcally, we\\ncan identify the following tasks.\\n• Density estimation : Density estimation aims at es-\\ntimating directly the distribution p(x). This may be\\nuseful, for example, for use in plug-in estimators of\\ninformation-theoretic quantities, for the design of\\ncompression algorithms, or to detect outliers;\\n• Clustering: Clustering aims at partitioning all points\\nin the data set Din groups of similar objects, where\\nthe notion of similarity is domain-dependent;\\n• Dimensionality reduction , representation, and fea-\\nture extraction: These three related tasks represent\\neach data point xn in a different space, typically\\nof lower dimensionality, in order to highlight in-\\ndependent explanatory factors and/or to ease visu-\\nalization, interpretation, or the implementation of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='of lower dimensionality, in order to highlight in-\\ndependent explanatory factors and/or to ease visu-\\nalization, interpretation, or the implementation of\\nsuccessive tasks, e.g., classiﬁcation;\\n• Generation of new samples : Given the data set D,\\nwe wish to learn a machine that produces sam-\\nples that are approximately distributed according\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='to p(x). As an example, if the data set contains\\nimages of celebrities, the idea is to produce plausi-\\nble images of non-existent celebrities. This can be\\nuseful, e.g., to produce artiﬁcial scenes for video\\nparameterizes or ﬁlms.\\nAs suggested by the variety of tasks listed above,\\nunsupervised learning does not have a formal uniﬁed\\nformulation as supervised learning. Nevertheless, the\\ngeneral methodology follows three main steps in a\\nmanner similar to supervised learning (see Sec. III-D). In\\nStep 1 (model selection), a model, or a hypothesis class,\\nis selected, deﬁning the inductive bias of the learning\\nprocess. This is done by positing a family of probability\\ndistributions p(x|θ) parameterized by a vector θ. In\\nStep 2 (learning), the data D is used to optimize a\\nlearning criterion with the aim of choosing a value for the\\nparameter vector θ. Finally, in Step 3, the trained model\\nis leveraged in order to carry out the task of interest,\\ne.g., clustering or sample generation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='parameter vector θ. Finally, in Step 3, the trained model\\nis leveraged in order to carry out the task of interest,\\ne.g., clustering or sample generation.\\nIn the following, we discuss Step 1 (model selection)\\nand Step 2 (learning). For the formulation of speciﬁc\\ntasks to be carried out at Step 3, we refer to, e.g., [7],\\n[19], [57].\\nB. Models\\nUnsupervised learning models, selected at Step 1 of\\nthe machine learning process, typically involve a hidden\\nor latent (vector of) variables zn for each data point xn.\\nFor example, in a clustering problem, the latent variable\\nzn represents the cluster index of xn. Latent variables are\\nhidden or unobserved in the sense that they do not appear\\nfor any of the data points xn in D.3 The relationship\\nbetween latent variables zn and observable variables xn\\ncan be modelled in different ways, giving rise to a\\nnumber of different types of models for unsupervised\\nlearning. These are illustrated in Fig. 11 and discussed\\nnext.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='can be modelled in different ways, giving rise to a\\nnumber of different types of models for unsupervised\\nlearning. These are illustrated in Fig. 11 and discussed\\nnext.\\nBy way of a short round-up of types of models,\\nwith reference to Fig. 11, directed generative models ,\\nillustrated by Fig. 11(a), posit that there exist hidden\\ncauses z yielding the observation x. Undirected genera-\\ntive models, represented in Fig. 11(b) model the mutual\\ncorrelation between x and z. Discriminative models ,\\nillustrated by Fig. 11(c) model the extraction of the\\nlatent representation z from x. Finally, autoencoders,\\nrepresented in Fig. 11(d) assume that x is encoded into\\na latent representation z in such as way that x can then\\nbe approximately recovered from z. In the following, we\\nprovide some additional details about directed generative\\n3Problems in which some of the inputs in Dare labelled by a value\\nzn are ﬁled under the rubric of semi-supervised learning [29].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='provide some additional details about directed generative\\n3Problems in which some of the inputs in Dare labelled by a value\\nzn are ﬁled under the rubric of semi-supervised learning [29].\\nFig. 11. Illustration of typical unsupervised learning models: (a)\\ndirected generative models; (b) undirected generative models; (c)\\ndiscriminative models; and (d) autoencoders.\\nmodels and autoencoders, and we point to [19] and\\nreferences therein for a discussion about the remaining\\nmodels.\\nAs illustrated in Fig. 11(a), directed generative models\\nassume that each data point x is caused 4 by a hidden\\nvariable z. This is in the sense that the joint distribution\\np(x,z|θ) is parameterized as p(x,z|θ) =p(z|θ)p(x|z,θ),\\nwhere p(z|θ) is the distribution of the hidden cause and\\np(x|z,θ) is the conditional distribution of the data x\\ngiven the cause z. As a result, under a directed generative\\nmodel, the distribution of an observation x =x can be\\nwritten as\\np(x|θ) =\\n∑\\nz\\np(z|θ)p(x|z,θ) =Ez∼p(z|θ)[ln p(x|z,θ)],'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='given the cause z. As a result, under a directed generative\\nmodel, the distribution of an observation x =x can be\\nwritten as\\np(x|θ) =\\n∑\\nz\\np(z|θ)p(x|z,θ) =Ez∼p(z|θ)[ln p(x|z,θ)],\\n(13)\\nwhere the sum in the second term should be replaced by\\nan integration for continuous hidden variables, and the\\nlast equality expresses the marginalization over z as an\\nexpectation.\\nAs an example, for the problem of document clus-\\ntering, variable x represents a document in the training\\nset and z is interpreted as a latent topic that “causes”\\nthe generation of the document. Model selection requires\\nthe speciﬁcation of a parameterized distribution p(z|θ)\\nover the topics, e.g., a categorical distribution with\\nparameters equals to the probability of each possible\\nvalue, and the distribution p(x|z,θ) of the document\\ngiven a topic. Basic representatives of directed generative\\nmodels include mixture of Gaussians and likelihood-free\\nmodels [19], [58].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='value, and the distribution p(x|z,θ) of the document\\ngiven a topic. Basic representatives of directed generative\\nmodels include mixture of Gaussians and likelihood-free\\nmodels [19], [58].\\n4The use of the term “cause” is meant to be taken in an intuitive,\\nrather than formal, way. For a discussion on the study of causality,\\nwe refer to [8].\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='As represented in Fig. 11(d), autoencoders model\\nencoding from data x to hidden variables z, as well as de-\\ncoding from hidden variables back to data. Accordingly,\\nmodel selection for autoencoders requires the speciﬁca-\\ntion of a parameterized family of encoders p(z|x,θ) and\\ndecoders p(x|z,θ). As an example, autoencoders can be\\nused to learn how to compress an input signal x into a\\nrepresentation z in a smaller space so as to ensure that\\nx can be recovered from z within an admissible level of\\ndistortion. Representatives of autoencoders, which cor-\\nrespond to speciﬁc choices for the encoder and decoder\\nfamilies of distributions, include Principal Component\\nAnalysis (PCA), dictionary learning, and neural network-\\nbased autoencoders [19], [57], [58].\\nC. Learning\\nWe now discuss learning, to be carried out as Step 2.\\nFor brevity, we focus on directed generative models and\\nrefer to [19] and references therein for a treatment of\\nlearning for the other models in Fig. 11. In this regard,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='For brevity, we focus on directed generative models and\\nrefer to [19] and references therein for a treatment of\\nlearning for the other models in Fig. 11. In this regard,\\nwe note that the problem of training autoencoders is\\nakin to supervised learning in the sense that autoencoders\\nspecify the desired output for each input in the training\\nset.\\nAs for supervised learning, the most basic learning\\ncriterion for probabilistic models is ML. Following the\\ndiscussion in Sec. III-E, ML tackles the problem of\\nmaximizing the log-likelihood of the data, i.e.,\\nmaximize\\nθ\\nln p(x|θ) = lnEz∼p(z|θ)[ln p(x|z,θ)]. (14)\\nNote that problem (14) considers only one data point xin\\nthe data set for the purpose of simplifying the notation,\\nbut in practice the log-likelihood needs to be summed\\nover the N examples in D.\\nUnlike the corresponding problem for supervised\\nlearning (8), the likelihood in (14) requires an average\\nover the hidden variables. This is because the value'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='over the N examples in D.\\nUnlike the corresponding problem for supervised\\nlearning (8), the likelihood in (14) requires an average\\nover the hidden variables. This is because the value\\nof the hidden variables z is not known, and hence the\\nprobability of the observation x needs to account for\\nall possible values of z weighted by their probabilities\\np(z|θ). This creates a number of technical challenges.\\nFirst, the objective in (14) is generally more complex to\\noptimize, since the average over z destroys the typical\\nstructure of the model p(x|z,θ), whose logarithm is often\\nselected as a tractable function (see, e.g., logistic re-\\ngression). Second, the average in (14) cannot be directly\\napproximated using Monte Carlo methods if the goal is\\nto optimize over the model parameters θ, given that the\\ndistribution p(z|θ) generally depends on θ itself.\\nTo tackle these issues, a standard approach is based\\non the introduction of a variational distribution q(z)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='distribution p(z|θ) generally depends on θ itself.\\nTo tackle these issues, a standard approach is based\\non the introduction of a variational distribution q(z)\\nover the hidden variables and on the optimization of a\\ntractable lower bound on the log-likelihood known as\\nthe Evidence Lower BOund (ELBO) . To elaborate, for\\nany ﬁxed value xand any distribution q(z) on the latent\\nvariables z (possibly dependent on x), the ELBO L(q,θ)\\nis deﬁned as\\nL(q,θ) =Ez∼q(z)[ln p(x|z,θ)]−KL(q(z)||p(z|θ)), (15)\\nwhere KL(q||p) = Ez∼q(z)[ln(q(z)/p(z))] is the\\nKullback-Leibler (KL) divergence. The latter is a mea-\\nsure of the distance between the two distributions, as\\nwe will further discuss in Sec. V-D (see [59], [60]).\\nThe analytical advantages of the ELBO L(q,θ) over\\nthe original log-likelihood are that: ( i) it entails an\\nexpectation of the logarithm of the model p(x|z,θ),\\nwhich, as mentioned, is typically a tractable function;\\nand ( ii) the average is over a ﬁxed distribution q(z),'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='expectation of the logarithm of the model p(x|z,θ),\\nwhich, as mentioned, is typically a tractable function;\\nand ( ii) the average is over a ﬁxed distribution q(z),\\nwhich does not depend on the model parameter θ.\\nUsing Jensen’s inequality, it can be seen that the\\nELBO (15) is a global lower bound on the log-likelihood\\nfunction, that is,\\nln p(x|θ) ≥L(q,θ). (16)\\nAn illustration of the lower bounding property of the\\nELBO can be found in Fig. 12. An important feature\\nof this inequality is that the ELBO “touches” the log-\\nlikelihood function at values θ0, if any, for which the\\ndistribution q(z) satisﬁes the equality\\nq(z) =p(z|x,θ0). (17)\\nIn words, the ELBO is tight if the variational distribution\\nis selected to equal the posterior distribution of the\\nhidden variables given the observation xunder the model\\nparameter θ0. Stated less formally, in order to ensure\\nthat the ELBO is tight at a value θ0, one needs to solve\\nthe problem of inferring the distribution of the hidden'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='parameter θ0. Stated less formally, in order to ensure\\nthat the ELBO is tight at a value θ0, one needs to solve\\nthe problem of inferring the distribution of the hidden\\nvariables z given the observation x under the model\\nidentiﬁed by the value θ0.\\nThe property (16) leads to the natural idea of the\\nExpectation-Maximization (EM) algorithm as a means\\nto tackle the ML problem. As illustrated in Fig. 13,\\nEM maximizes the ELBO iteratively, where the ELBO\\nat each iteration is computed to be tight at the current\\niterate for θ. More formally, the EM algorithm can be\\nsummarized as follows 5. The model vector is initialized\\nto some value θold and then for each iteration the\\nfollowing two steps are performed.\\n5EM is an instance of the more general Majorization-Minimization\\nalgorithm [61].\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='-4 -3 -2 -1 0 1 2 3 4\\n-5\\n-4.5\\n-4\\n-3.5\\n-3\\n-2.5\\n-2\\n-1.5Log-likelihood\\nELBO ( 0=  3)\\nELBO ( 0 =  2)\\nLL\\nFig. 12. The ELBO (15) is a global lower bound on the log-likelihood\\nthat is tight at values of the model parameters θ0 for which equality\\n(17) holds.\\n• Expectation, or E, step: For ﬁxed parameter vector\\nθold, solve the problem\\nmaximize\\nq\\nL(q,θold). (18)\\nThe solution of this problem is given by qnew(z) =\\np(z|x,θold). In fact, as discussed, the tightest (i.e.,\\nlargest) value of the ELBO is obtained by choosing\\nthe variational distribution q(z) as the posterior\\nof the latent variables under the current model\\nθold. This step can be interpreted as estimating the\\nlatent variables z, via the predictive distribution\\np(z|x,θold), assuming that the current model θold\\nis correct.\\n• Maximization, or M, step: For ﬁxed variational\\ndistribution qnew(z), solve the problem\\nmaximize\\nθ\\nL(qnew,θ) =Ez∼qnew(z) [ln p(x,z|θ)] .\\n(19)\\nThis optimization is akin to that carried out in'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='• Maximization, or M, step: For ﬁxed variational\\ndistribution qnew(z), solve the problem\\nmaximize\\nθ\\nL(qnew,θ) =Ez∼qnew(z) [ln p(x,z|θ)] .\\n(19)\\nThis optimization is akin to that carried out in\\nthe corresponding supervised learning problem with\\nknown latent variables z with the difference that\\nthese are randomly selected from the ﬁxed varia-\\ntional distribution qnew(z) obtained in the E step.\\nGiven that the EM algorithm maximizes at each step\\na lower bound on the log-likelihood that is tight at the\\ncurrent iterate θold, EM guarantees decreasing objective\\nvalues along the iterations, which ensures convergence\\nto a local optimum of the original problem. We refer to\\n[57], [58] for detailed examples.\\nThe EM algorithm is generally impractical for large-\\nscale problems due to the complexity of computing the\\nposterior of the latent variables in the E step and of\\naveraging over such distribution in the M step. Many\\nstate-of-the-art solutions to the problem of unsupervised\\n...\\nLL\\nnewold'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='posterior of the latent variables in the E step and of\\naveraging over such distribution in the M step. Many\\nstate-of-the-art solutions to the problem of unsupervised\\n...\\nLL\\nnewold\\nFig. 13. Illustration of the EM algorithm: At each iteration, a tight\\nELBO is evaluated in the E step by solving the problem of estimating\\nthe latent variables (via the posterior distribution p(z|x,θ)), and then\\nthe ELBO is maximized in the M step by solving a problem akin to\\nsupervised learning with the estimated latent variables.\\nlearning with probabilistic models entail some approxi-\\nmation of the EM algorithm. Notably, the E step can be\\napproximated by parametrizing the variational distribu-\\ntion with some function q(z|ϕ), or q(z|x,ϕ) to include\\nthe dependence on x, and by maximizing ELBO over\\nthe variational parameters ϕ. This approach underlies\\nthe popular variational autoencoder technique [7]. In the\\nM step, instead, one can approximate the expectation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='the variational parameters ϕ. This approach underlies\\nthe popular variational autoencoder technique [7]. In the\\nM step, instead, one can approximate the expectation\\nin (19) using Monte Carlo stochastic approximation\\nbased on randomly sampled values of z from the current\\ndistribution q(z). Finally, gradient descent can be used\\nto carry out the mentioned optimizations for both E and\\nM steps (see, e.g., [62]).\\nD. Advanced Learning Methods\\nAs discussed in the previous section, ML is generally\\nprone to overﬁtting for supervised learning. For unsu-\\npervised learning, the performance of ML depends on\\nthe task of interest. For example, consider the tasks of\\ndensity estimation or of generation of new samples (see\\nSec. V-A). In order to illustrate some of the typical issues\\nencountered when applying the ML criterion, in Fig. 14\\nwe report a numerical result for a problem in which\\nthe true data distribution p(x) is multi-modal and the\\nmodel distribution p(x|θ) is assumed to be a mixture'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='we report a numerical result for a problem in which\\nthe true data distribution p(x) is multi-modal and the\\nmodel distribution p(x|θ) is assumed to be a mixture\\nof Gaussians, i.e., a directed generative model. The\\nML problem is tackled by using EM based on samples\\ngenerated from the true distribution (see [19] for details).\\nThe learned distribution is seen to be a rather“blurry”\\nestimate that misses the modes of p(x) in an attempt\\nof being inclusive of the full support of p(x). Being a\\npoor estimate of the true distribution, the learned model\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='-5 0 5\\n0\\n0.05\\n0.1\\n0.15\\n0.2\\n0.25\\n0.3\\n0.35\\nFig. 14. Illustration of the limitations of ML unsupervised learning,\\nhere obtained via the EM algorithm: The ML solution tends to be\\nblurry, missing the modes of the true distribution p(x).\\ncan clearly also be problematic for sample generation in\\nthe sense that samples generated from the model would\\ntend to be quite different from the data samples. In the\\nrest of this section, we brieﬂy review advanced learning\\nmethods that address this limitation of ML.\\nIn order to move beyond ML, we ﬁrst observe that\\nML can be proven to minimize the KL divergence\\nKL(pD(x)||p(x|θ)) =Ez∼pD(x)\\n[\\nln pD(x)\\np(x|θ)\\n]\\n(20)\\nbetween the empirical distribution, or histogram, of the\\ndata\\npD(x) =N[x]\\nN , (21)\\nwhere N[x] counts the number of occurrences of value\\nx in the data, and the parameterized model distribution\\np(x|θ). In other words, ML ﬁts the model to the his-\\ntogram of the data by using the KL divergence as a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='x in the data, and the parameterized model distribution\\np(x|θ). In other words, ML ﬁts the model to the his-\\ntogram of the data by using the KL divergence as a\\nmeasure of ﬁtness. Indeed, as mentioned in Sec. V-C, the\\nKL divergence is a quantitative measure of “difference”\\nbetween two distributions. More precisely, as per (20),\\nthe KL divergence KL (p||q) quantiﬁes the difference\\nbetween two distributions p(x) and q(x) by evaluating\\nthe average of the LLR ln(p(x)/q(x)) with respect to\\np(x).\\nConsider now the problem illustrated in Fig. 15, in\\nwhich a discriminator wishes to distinguish between two\\nhypotheses, namely the hypothesis that the data x is a\\nsample from distribution p(x) and the hypothesis that it\\nis instead generated from q(x). To ﬁx the ideas, one can\\nfocus as an example on the case where p(x) and q(x)\\nare two Gaussian distributions with different means. To\\nthis end, the discriminator computes a statistic, that is,\\na function, T(x) of the data x, and then decides for the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='are two Gaussian distributions with different means. To\\nthis end, the discriminator computes a statistic, that is,\\na function, T(x) of the data x, and then decides for the\\nformer hypothesis if T(x) is sufﬁciently large and for\\n𝑇(𝑥)\\n𝑥~𝑝(𝑥)\\n𝑥~𝑞(𝑥)\\n𝑝 𝑥 if𝑇 𝑥 large\\ndiscriminator\\n𝑞 𝑥 if𝑇 𝑥 small\\nFig. 15. Discriminator between the hypotheses x ∼p(x) and x ∼\\nq(x) based on the statistic T(x). The performance of the optimal\\ndiscriminator function T(x) under different design criteria yields a\\nmeasure of the difference between the two distributions.\\nthe latter hypothesis otherwise. Intuitively, one should\\nexpect that, the more distinct the two distributions p(x)\\nand q(x) are, the easier it is to design a discriminator\\nthat is able to choose the correct hypothesis with high\\nprobability.\\nThe connection between the hypothesis testing prob-\\nlem in Fig. 15 and the KL divergence becomes evident\\nif one recalls that the LLR ln(p(x)/q(x)) is known\\nto be the best statistic T(x) in the Neyman-Pearson'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='lem in Fig. 15 and the KL divergence becomes evident\\nif one recalls that the LLR ln(p(x)/q(x)) is known\\nto be the best statistic T(x) in the Neyman-Pearson\\nsense [63]. The KL divergence is hence associated to\\na particular way of evaluating the performance of the\\ndiscriminator between the two distributions. Considering\\na broader formulation of the problem of designing the\\ndiscriminator in Fig. 15, one can generalize the notion\\nof KL divergence to the class of f-divergences. These\\nare deﬁned as\\nDf(p||q) = max\\nT(x)\\nEx∼p(x)[T(x)] −Ex∼q(x)[g(T(x))],\\n(22)\\nfor some concave increasing function g(·). The expres-\\nsion above can be interpreted as measuring the perfor-\\nmance of the best discriminator T(x) when the design\\ncriterion is given by the right-hand side of (22), i.e.,\\nEx∼p(x)[T(x)] −Ex∼q(x)[g(T(x))], for a given function\\ng(·). Note that this criterion is indeed larger for a\\ndiscriminator that is able to output a large value of the\\nstatistic T(x) under p(x) and a small value under q(x).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='g(·). Note that this criterion is indeed larger for a\\ndiscriminator that is able to output a large value of the\\nstatistic T(x) under p(x) and a small value under q(x).\\nThe KL divergence corresponds to a speciﬁc choice of\\nsuch function (see [19] for details).\\nIn order to move beyond ML, one can then consider\\nﬁtting the model distribution to the data histogram by\\nusing a divergence measure that is tailored to the data and\\nthat captures the features of the empirical distribution\\nthat are most relevant for a given application. Such\\na divergence measure can be obtained by choosing a\\nsuitable function g(·) in (22) and by optimizing (22) over\\na parameterized (differentiable) discriminator function\\nTϕ(x). Integrating the evaluation of the divergence with\\nthe problem of learning the model parameters yields the\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='min-max problem\\nmin\\nθ\\nmax\\nϕ\\nEx∼pD(x)[Tϕ(x)] −Ex∼p(x|θ)[g(Tϕ(x))]. (23)\\nThis can be famously interpreted as a game between the\\nlearner, which optimizes the model parameters θ, and the\\ndiscriminator, which tries to ﬁnd the best function Tϕ(x)\\nto distinguish between data and generated samples. The\\nresulting method, known as GAN, has recently led to\\nimpressive improvements of ML for sample generation\\n[64].\\nVI. A PPLICATIONS OF UNSUPERVISED LEARNING TO\\nCOMMUNICATION SYSTEMS\\nIn this section, we highlight some applications of\\nunsupervised learning to communication networks.\\nA. At the Edge\\n1) Physical Layer: Let us ﬁrst consider some appli-\\ncations of autoencoders at the physical layer as imple-\\nmented by the network edge nodes. A fundamental idea\\nis to treat the chain of encoder, channel, and decoder in\\na communication link as an autoencoder, where, with\\nreference to Fig. 11(d), the input message is x, the\\ntransmitted codewords and received signals represent'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='a communication link as an autoencoder, where, with\\nreference to Fig. 11(d), the input message is x, the\\ntransmitted codewords and received signals represent\\nthe intermediate representation z, and the output of the\\ndecoder should match the input [30]. Note that, for this\\nparticular autoencoder, the mapping p(x|z) can only be\\npartially learned, as it includes not only the encoder but\\nalso the communication channel, while the conditional\\ndistribution p(x|z) deﬁning the decoder can be learned.\\nWe should now ask when this viewpoint can be beneﬁcial\\nin light of the criteria reviewed in Sec. I-C.\\nTo address this question, one should check whether\\na model or algorithm deﬁcit exists to justify the use of\\nmachine learning tools. Training an autoencoder requires\\nthe availability of a model for the channel, and hence\\na model deﬁcit would make this approach inapplicable\\nunless further mechanisms are put in place (see below).\\nExamples of algorithm deﬁcit include channels with'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='a model deﬁcit would make this approach inapplicable\\nunless further mechanisms are put in place (see below).\\nExamples of algorithm deﬁcit include channels with\\ncomplex non-linear dynamical models, such as optical\\nlinks [65]; Gaussian channels with feedback, for which\\noptimal practical encoding schemes are not known [66];\\nmultiple access channels with sparse transmission codes\\n[67]; and joint source-channel coding [68].\\nOther applications at the physical layer leverage the\\nuse of autoencoders as compressors (see Sec. V-B) or\\ndenoisers. For channels with a complex structure with\\nunavailable channel models or with unknown optimal\\ncompression algorithms, autoencoders can be used to\\ncompress channel state information for the purpose\\nof feedback on frequency-division duplex links [69].\\nAutoencoders can also be used for their capacity to\\ndenoise the input signal by means of ﬁltering through\\nthe lower dimensional representation z. This is done'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Autoencoders can also be used for their capacity to\\ndenoise the input signal by means of ﬁltering through\\nthe lower dimensional representation z. This is done\\nin [70] for the task of localization on the basis of the\\nreceived baseband signal. To this end, an autoencoder\\nis learned for every reference position in space with the\\nobjective of denoising signals received from the given\\nlocation. At test time, the location that corresponds to\\nthe autoencoder with the smallest reconstruction error is\\ntaken as an estimate of the unknown transmitting device.\\nWe now review some applications of the generative\\nmodels illustrated in Fig. 11(a). A natural idea is that\\nof using generative models to learn how to generate\\nsamples from a given channel [71], [72]. This approach\\nis sound for scenarios that lack tractable channel models.\\nAs a pertinent example, generative models can be used to\\nmimic and identify non-linear channels for satellite com-\\nmunications [2]. The early works on the subject carried'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='As a pertinent example, generative models can be used to\\nmimic and identify non-linear channels for satellite com-\\nmunications [2]. The early works on the subject carried\\nout in the nineties are also notable for the integration\\nof the domain knowledge into the deﬁnition of machine\\nlearning models (see Sec. IV). In fact, mindful of the\\nstrong linear components of the channels, these works\\nposit a learnable model that includes linear ﬁlters and\\nnon-linearities [2].\\nAnother approach that can be considered as unsu-\\npervised was proposed in [73] in order to solve the\\nchallenging problem of power control for interference\\nchannels. The approach tackles the resulting algorithm\\ndeﬁcit by means of a direct optimization of the sum-rate\\nwith the aim of obtaining the power allocation vector (as\\nfractions of the maximal available powers) at the output\\nof a neural network. Related supervised learning methods\\nwere discussed in Sec. IV. A similar approach – also'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='fractions of the maximal available powers) at the output\\nof a neural network. Related supervised learning methods\\nwere discussed in Sec. IV. A similar approach – also\\nbased on the idea of directly maximizing the criterion\\nof interest so as to obtain an approximate solution at the\\noutput of a neural network – was considered in [74] for\\nminimum mean squared error channel estimation with\\nnon-Gaussian channels, e.g., multi-path channels.\\n2) Medium Access Layer: At the medium access\\nlayer, generative models have been advocated in [75] as a\\nway to generate new examples so as to augment a data\\nset used to train a classiﬁer for spectrum sensing (see\\nSec. IV). An unsupervised learning task that has found\\nmany applications in communications is clustering. For\\nexample, in [76], clustering is used to support radio\\nresource allocation in a heterogeneous network.\\nB. At the Cloud\\n1) Network Layer: Another typical application of\\nclustering is to enable hierarchical clustering for routing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='resource allocation in a heterogeneous network.\\nB. At the Cloud\\n1) Network Layer: Another typical application of\\nclustering is to enable hierarchical clustering for routing\\nin self-organizing multi-hop networks. Thanks to cluster-\\ning, routing can be carried out more efﬁciently by routing\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='ﬁrst at the level of clusters, and then locally within\\neach cluster [77]. For an application of the unsupervised\\nlearning task of density estimation, consider the problem\\nof detecting anomalies in networks. For instance, by\\nlearning the typical distribution of the features of a\\nworking link, one can identify malfunctioning ones. This\\napproach may be applied, e.g., to optical networks [54].\\n2) Application Layer: Finally, we point to two in-\\nstances of unsupervised learning at the application layer\\nthat are usually carried out at data centers in the cloud.\\nThese tasks follow a conceptually different approach\\nas they are based on discovering structure in graphs.\\nThe ﬁrst problem is community detection in social\\nnetworks. This amounts to a clustering problem whereby\\none wishes to isolate communities of nodes in a social\\ngraph on the basis of the observation of a realization of\\nthe underlying true graph of relationships [78]. Another\\napplication is the ranking of webpages based on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='graph on the basis of the observation of a realization of\\nthe underlying true graph of relationships [78]. Another\\napplication is the ranking of webpages based on the\\ngraph of hyperlinks carried out by PageRank [19], [79].\\nVII. C ONCLUDING REMARKS\\nIn the presence of modelling or algorithmic deﬁcien-\\ncies in the conventional engineering ﬂow based on the\\nacquisition of domain knowledge, data-driven machine\\nlearning tools can speed up the design cycle, reduce\\nthe complexity and cost of implementation, and improve\\nover the performance of known algorithms. To this end,\\nmachine learning can leverage the availability of data\\nand computing resources in many engineering domains,\\nincluding modern communication systems. Supervised,\\nunsupervised, and reinforcement learning paradigms lend\\nthemselves to different tasks depending on the availabil-\\nity of examples of desired behaviour or of feedback.\\nThe applicability of learning methods hinges on speciﬁc'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='themselves to different tasks depending on the availabil-\\nity of examples of desired behaviour or of feedback.\\nThe applicability of learning methods hinges on speciﬁc\\nfeatures of the problem under study, including its time\\nvariability and its tolerance to errors. As such, a data-\\ndriven approach should not be considered as a universal\\nsolution, but rather as a useful tool whose suitability\\nshould be assessed on a case-by-case basis. Further-\\nmore, machine learning tools allow for the integration\\nof traditional model-based engineering techniques and\\nof existing domain knowledge in order to leverage the\\ncomplementarity and synergy of the two solutions (see\\nFig. 2).\\nAs a ﬁnal note, while this paper has focused on appli-\\ncations of machine learning to communication systems,\\ncommunication is conversely a key element of distributed\\nmachine learning platforms. In these systems, learning\\ntasks are carried out at distributed machines that need'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='communication is conversely a key element of distributed\\nmachine learning platforms. In these systems, learning\\ntasks are carried out at distributed machines that need\\nto coordinate via communication, e.g., by transferring\\nthe results of intermediate computations. A recent line\\nof work investigates the resulting interplay between\\ncomputation and communication [80].\\nREFERENCES\\n[1] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed,\\nN. Jaitly, A. Senior, V . Vanhoucke, P. Nguyen, T. N. Sainath\\net al., “Deep neural networks for acoustic modeling in speech\\nrecognition: The shared views of four research groups,” IEEE\\nSignal processing magazine , vol. 29, no. 6, pp. 82–97, 2012.\\n[2] M. Ibnkahla, “Applications of neural networks to digital\\ncommunications–a survey,” Signal processing , vol. 80, no. 7,\\npp. 1185–1215, 2000.\\n[3] H. J. Levesque, Common Sense, the Turing Test, and the Quest\\nfor Real AI: Reﬂections on Natural and Artiﬁcial Intelligence .\\nMIT Press, 2017.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='pp. 1185–1215, 2000.\\n[3] H. J. Levesque, Common Sense, the Turing Test, and the Quest\\nfor Real AI: Reﬂections on Natural and Artiﬁcial Intelligence .\\nMIT Press, 2017.\\n[4] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning\\ninternal representations by error propagation,” California Univ\\nSan Diego La Jolla Inst for Cognitive Science, Tech. Rep., 1985.\\n[5] A. P. Dempster, N. M. Laird, and D. B. Rubin, “Maximum\\nlikelihood from incomplete data via the em algorithm,” Journal\\nof the royal statistical society. Series B (methodological) , pp.\\n1–38, 1977.\\n[6] C. Watkins, “Learning form delayed rewards,” Ph. D. thesis,\\nKing’s College, University of Cambridge, 1989.\\n[7] I. Goodfellow, Y . Bengio, A. Courville, and Y . Bengio, Deep\\nlearning. MIT press Cambridge, 2016, vol. 1.\\n[8] J. Pearl and D. Mackenzie, The Book of Why: The New Science\\nof Cause and Effect . Basic Books, 2018.\\n[9] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Machine'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[8] J. Pearl and D. Mackenzie, The Book of Why: The New Science\\nof Cause and Effect . Basic Books, 2018.\\n[9] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Machine\\nlearning in wireless sensor networks: Algorithms, strategies,\\nand applications,” IEEE Communications Surveys & Tutorials ,\\nvol. 16, no. 4, pp. 1996–2018, 2014.\\n[10] C. Jiang, H. Zhang, Y . Ren, Z. Han, K.-C. Chen, and L. Hanzo,\\n“Machine learning paradigms for next-generation wireless net-\\nworks,” IEEE Wireless Communications, vol. 24, no. 2, pp. 98–\\n105, 2017.\\n[11] Z. Qin, H. Ye, G. Y . Li, and B.-H. F. Juang, “Deep Learning\\nin Physical Layer Communications,” ArXiv e-prints, Jul. 2018.\\n[12] S. Lin and D. J. Costello, Error control coding . Pearson\\nEducation India, 2001.\\n[13] T. Gruber, S. Cammerer, J. Hoydis, and S. ten Brink, “On deep\\nlearning-based channel decoding,” in CISS 2017, 2017, pp. 1–6.\\n[14] S. Shalev-Shwartz and S. Ben-David, Understanding machine\\nlearning: From theory to algorithms . Cambridge university'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='learning-based channel decoding,” in CISS 2017, 2017, pp. 1–6.\\n[14] S. Shalev-Shwartz and S. Ben-David, Understanding machine\\nlearning: From theory to algorithms . Cambridge university\\npress, 2014.\\n[15] D. Arpit, S. Jastrze ¸bski, N. Ballas, D. Krueger, E. Bengio, M. S.\\nKanwal, T. Maharaj, A. Fischer, A. Courville, Y . Bengio, and\\nS. Lacoste-Julien, “A Closer Look at Memorization in Deep\\nNetworks,” ArXiv e-prints, Jun. 2017.\\n[16] T. Hastie, R. Tibshirani, and J. Friedman, “Unsupervised learn-\\ning,” in The elements of statistical learning . Springer, 2009,\\npp. 485–585.\\n[17] R. S. Sutton, A. G. Barto et al. , Reinforcement learning: An\\nintroduction. MIT press, 2018.\\n[18] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van\\nDen Driessche, J. Schrittwieser, I. Antonoglou, V . Panneershel-\\nvam, M. Lanctot et al. , “Mastering the game of go with deep\\nneural networks and tree search,” Nature, vol. 529, no. 7587,\\np. 484, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='vam, M. Lanctot et al. , “Mastering the game of go with deep\\nneural networks and tree search,” Nature, vol. 529, no. 7587,\\np. 484, 2016.\\n[19] O. Simeone, “A brief introduction to machine learning for en-\\ngineers,” Foundations and Trends in Signal Processing, vol. 12,\\nno. 3-4, pp. 200–431, 2018.\\n[20] E. Brynjolfsson and T. Mitchell, “What can machine learning\\ndo? Workforce implications,” Science, vol. 358, no. 6370, pp.\\n1530–1534, 2017.\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[21] S. Kannan, H. Kim, and S. Oh, “Deep learning and information\\ntheory: An emerging interface,” IEEE ISIT 2018 Tutorial .\\n[22] M. Davies, N. Srinivasa, T.-H. Lin, G. Chinya, Y . Cao, S. H.\\nChoday, G. Dimou, P. Joshi, N. Imam, S. Jain et al. , “Loihi:\\nA neuromorphic manycore processor with on-chip learning,”\\nIEEE Micro, vol. 38, no. 1, pp. 82–99, 2018.\\n[23] A. Bagheri, O. Simeone, and B. Rajendran, “Training proba-\\nbilistic spiking neural networks with ﬁrst-to-spike decoding,”\\narXiv preprint arXiv:1710.10704 , 2017.\\n[24] J. Chen, L. Song, M. J. Wainwright, and M. I. Jordan, “Learn-\\ning to explain: An information-theoretic perspective on model\\ninterpretation,” arXiv preprint arXiv:1802.07814 , 2018.\\n[25] M. Polese, R. Jana, V . Kounev, K. Zhang, S. Deb, and M. Zorzi,\\n“Machine Learning at the Edge: A Data-Driven Architecture\\nwith Applications to 5G Cellular Networks,” ArXiv e-prints ,\\nAug. 2018.\\n[26] G. Paschos, E. Bastug, I. Land, G. Caire, and M. Debbah,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='“Machine Learning at the Edge: A Data-Driven Architecture\\nwith Applications to 5G Cellular Networks,” ArXiv e-prints ,\\nAug. 2018.\\n[26] G. Paschos, E. Bastug, I. Land, G. Caire, and M. Debbah,\\n“Wireless caching: Technical misconceptions and business bar-\\nriers,” IEEE Communications Magazine, vol. 54, no. 8, pp. 16–\\n22, 2016.\\n[27] M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah,\\n“Machine learning for wireless networks with artiﬁcial in-\\ntelligence: A tutorial on neural networks,” arXiv preprint\\narXiv:1710.02913, 2017.\\n[28] M. Angjelichinoski, K. F. Trillingsgaard, and P. Popovski,\\n“A statistical learning approach to ultra-reliable low latency\\ncommunication,” arXiv preprint arXiv:1809.05515 , 2018.\\n[29] M. Seeger, “A taxonomy for semi-supervised learning methods,”\\nMIT Press, Tech. Rep., 2006.\\n[30] T. J. O’Shea and J. Hoydis, “An introduction to machine\\nlearning communications systems,” arXiv preprint , vol. 1702,\\n2017.\\n[31] N. Farsad and A. Goldsmith, “Neural network detection of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[30] T. J. O’Shea and J. Hoydis, “An introduction to machine\\nlearning communications systems,” arXiv preprint , vol. 1702,\\n2017.\\n[31] N. Farsad and A. Goldsmith, “Neural network detection of\\ndata sequences in communication systems,” arXiv preprint\\narXiv:1802.02046, 2018.\\n[32] S. Bouchired, D. Roviras, and F. Castani ´e, “Equalisation of\\nsatellite mobile channels with neural network techniques,”\\nSpace Communications, vol. 15, no. 4, pp. 209–220, 1998.\\n[33] Y . Wang, M. Martonosi, and L.-S. Peh, “A supervised learning\\napproach for routing optimizations in wireless sensor networks,”\\nin Proc. Int. Workshop on Multi-hop ad hoc Networks . ACM,\\n2006, pp. 79–86.\\n[34] G. De Veciana and A. Zakhor, “Neural net-based continuous\\nphase modulation receivers,” IEEE Transactions on Communi-\\ncations, vol. 40, no. 8, pp. 1396–1408, 1992.\\n[35] X. Jin and H.-N. Kim, “Deep Learning Detection Networks in\\nMIMO Decode-Forward Relay Channels,” ArXiv e-prints , Jul.\\n2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='cations, vol. 40, no. 8, pp. 1396–1408, 1992.\\n[35] X. Jin and H.-N. Kim, “Deep Learning Detection Networks in\\nMIMO Decode-Forward Relay Channels,” ArXiv e-prints , Jul.\\n2018.\\n[36] E. Nachmani, E. Marciano, L. Lugosch, W. J. Gross, D. Bur-\\nshtein, and Y . Be’ery, “Deep learning methods for improved\\ndecoding of linear codes,” IEEE Journal of Selected Topics in\\nSignal Processing, vol. 12, no. 1, pp. 119–131, 2018.\\n[37] L. Lugosch and W. J. Gross, “Neural offset min-sum decoding,”\\nin IEEE int. Symp. Information Theory (ISIT 2017) . IEEE,\\n2017, pp. 1361–1365.\\n[38] S. Cammerer, T. Gruber, J. Hoydis, and S. ten Brink, “Scaling\\ndeep learning-based decoding of polar codes via partitioning,”\\nin IEEE GLOBECOM 2017 , 2017, pp. 1–6.\\n[39] S. Schibisch, S. Cammerer, S. D ¨orner, J. Hoydis, and S. t.\\nBrink, “Online label recovery for deep learning-based com-\\nmunication through error correcting codes,” arXiv preprint\\narXiv:1807.00747, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Brink, “Online label recovery for deep learning-based com-\\nmunication through error correcting codes,” arXiv preprint\\narXiv:1807.00747, 2018.\\n[40] F. Liang, C. Shen, and F. Wu, “An iterative bp-cnn architecture\\nfor channel decoding,” IEEE Journal of Selected Topics in\\nSignal Processing, vol. 12, no. 1, pp. 144–159, Feb 2018.\\n[41] H. Agirman-Tosun, Y . Liu, A. M. Haimovich, O. Simeone,\\nW. Su, J. Dabin, and E. Kanterakis, “Modulation classiﬁcation\\nof mimo-ofdm signals by independent component analysis and\\nsupport vector machines,” in Proc. ASILOMAR 2011, 2011, pp.\\n1903–1907.\\n[42] S.-H. Fang and T.-N. Lin, “Indoor location system based on\\ndiscriminant-adaptive neural network in ieee 802.11 environ-\\nments,” IEEE Transactions on Neural networks, vol. 19, no. 11,\\npp. 1973–1978, 2008.\\n[43] Q. Wang, H. Li, Z. Chen, D. Zhao, S. Ye, and J. Cai, “Su-\\npervised and Semi-Supervised Deep Neural Networks for CSI-\\nBased Authentication,” ArXiv e-prints, Jul. 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='pp. 1973–1978, 2008.\\n[43] Q. Wang, H. Li, Z. Chen, D. Zhao, S. Ye, and J. Cai, “Su-\\npervised and Semi-Supervised Deep Neural Networks for CSI-\\nBased Authentication,” ArXiv e-prints, Jul. 2018.\\n[44] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropou-\\nlos, “Learning to optimize: Training deep neural networks for\\nwireless resource management,” in IEEE Signal Processing\\nAdvances in Wireless Communications (SPAWC) 2017 , 2017,\\npp. 1–6.\\n[45] A. Zappone, M. Di Renzo, M. Debbah, T. T. Lam, and X. Qian,\\n“Model-Aided Wireless Artiﬁcial Intelligence: Embedding Ex-\\npert Knowledge in Deep Neural Networks Towards Wireless\\nSystems Optimization,” ArXiv e-prints, Aug. 2018.\\n[46] J. Shu, Z. Xu, and D. Meng, “Small Sample Learning in Big\\nData Era,” ArXiv e-prints, Aug. 2018.\\n[47] A. Balatsoukas-Stimming, “Non-linear digital self-interference\\ncancellation for in-band full-duplex radios using neural net-\\nworks,” arXiv preprint arXiv:1711.00379 , 2017.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[47] A. Balatsoukas-Stimming, “Non-linear digital self-interference\\ncancellation for in-band full-duplex radios using neural net-\\nworks,” arXiv preprint arXiv:1711.00379 , 2017.\\n[48] N. Strodthoff, B. G ¨oktepe, T. Schierl, C. Hellge, and W. Samek,\\n“Enhanced Machine Learning Techniques for Early HARQ\\nFeedback Prediction in 5G,” ArXiv e-prints, Jul. 2018.\\n[49] V . K. Tumuluru, P. Wang, and D. Niyato, “A neural net-\\nwork based spectrum prediction scheme for cognitive radio,”\\nin IEEE International Conference on Communications (ICC\\n2010), 2010, pp. 1–5.\\n[50] D. Del Testa, M. Danieletto, G. M. Di Nunzio, and M. Zorzi,\\n“Estimating the number of receiving nodes in 802.11 networks\\nvia machine learning techniques,” in IEEE Global Communica-\\ntions Conference (GLOBECOM) , 2016, pp. 1–7.\\n[51] H. Okamoto, T. Nishio, K. Nakashima, Y . Koda, K. Ya-\\nmamoto, M. Morikura, Y . Asai, and R. Miyatake, “Machine-\\nlearning-based future received signal strength prediction using'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[51] H. Okamoto, T. Nishio, K. Nakashima, Y . Koda, K. Ya-\\nmamoto, M. Morikura, Y . Asai, and R. Miyatake, “Machine-\\nlearning-based future received signal strength prediction using\\ndepth images for mmwave communications,” arXiv preprint\\narXiv:1803.09698, 2018.\\n[52] M. Chen, W. Saad, C. Yin, and M. Debbah, “Echo state\\nnetworks for proactive caching in cloud-based radio access\\nnetworks with mobile users,” IEEE Transactions on Wireless\\nCommunications, vol. 16, no. 6, pp. 3520–3535, 2017.\\n[53] M. Zorzi, A. Zanella, A. Testolin, M. D. F. De Grazia, and\\nM. Zorzi, “Cognition-based networks: A new perspective on\\nnetwork optimization using learning and distributed intelli-\\ngence,” IEEE Access, vol. 3, pp. 1512–1530, 2015.\\n[54] F. Musumeci, C. Rottondi, A. Nag, I. Macaluso, D. Zibar,\\nM. Rufﬁni, and M. Tornatore, “A survey on application of ma-\\nchine learning techniques in optical networks,” arXiv preprint\\narXiv:1803.07976, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='M. Rufﬁni, and M. Tornatore, “A survey on application of ma-\\nchine learning techniques in optical networks,” arXiv preprint\\narXiv:1803.07976, 2018.\\n[55] F. Tang, B. Mao, Z. M. Fadlullah, N. Kato, O. Akashi, T. Inoue,\\nand K. Mizutani, “On removing routing protocol from future\\nwireless networks: A real-time deep learning approach for intel-\\nligent trafﬁc control,” IEEE Wireless Communications, vol. 25,\\nno. 1, pp. 154–160, 2018.\\n[56] T. T. Nguyen and G. Armitage, “A survey of techniques for\\ninternet trafﬁc classiﬁcation using machine learning,” IEEE\\nCommunications Surveys & Tutorials, vol. 10, no. 4, pp. 56–76,\\n2008.\\n[57] C. M. Bishop, Pattern recognition and machine learning .\\nspringer, 2006.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[58] K. P. Murphy, Machine learning: a probabilistic perspective .\\nMIT press, 2012.\\n[59] T. M. Cover and J. A. Thomas, Elements of information theory.\\nJohn Wiley & Sons, 2012.\\n[60] O. Simeone, “Introducing information measures via inference\\n[lecture notes],” IEEE Signal Processing Magazine , vol. 35,\\nno. 1, pp. 167–171, 2018.\\n[61] Y . Sun, P. Babu, and D. P. Palomar, “Majorization-minimization\\nalgorithms in signal processing, communications, and machine\\nlearning,” IEEE Transactions on Signal Processing , vol. 65,\\nno. 3, pp. 794–816, 2017.\\n[62] A. Mnih and K. Gregor, “Neural variational inference and\\nlearning in belief networks,” arXiv preprint arXiv:1402.0030 ,\\n2014.\\n[63] H. V . Poor, An introduction to signal detection and estimation .\\nSpringer Science & Business Media, 2013.\\n[64] I. Goodfellow, “NIPS 2016 tutorial: Generative adversarial\\nnetworks,” arXiv preprint arXiv:1701.00160 , 2016.\\n[65] B. Karanov, M. Chagnon, F. Thouin, T. A. Eriksson, H. B ¨ulow,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[64] I. Goodfellow, “NIPS 2016 tutorial: Generative adversarial\\nnetworks,” arXiv preprint arXiv:1701.00160 , 2016.\\n[65] B. Karanov, M. Chagnon, F. Thouin, T. A. Eriksson, H. B ¨ulow,\\nD. Lavery, P. Bayvel, and L. Schmalen, “End-to-end deep\\nlearning of optical ﬁber communications,” arXiv preprint\\narXiv:1804.04097, 2018.\\n[66] H. Kim, Y . Jiang, S. Kannan, S. Oh, and P. Viswanath,\\n“Deepcode: Feedback codes via deep learning,” arXiv preprint\\narXiv:1807.00801, 2018.\\n[67] M. Kim, N. I. Kim, W. Lee, and D. H. Cho, “Deep learning-\\naided scma,” IEEE Communications Letters , vol. 22, no. 4, pp.\\n720–723, April 2018.\\n[68] E. Bourtsoulatze, D. Burth Kurka, and D. Gunduz, “Deep Joint\\nSource-Channel Coding for Wireless Image Transmission,”\\nArXiv e-prints, Sep. 2018.\\n[69] C.-K. Wen, W.-T. Shih, and S. Jin, “Deep learning for massive\\nmimo csi feedback,” IEEE Wireless Communications Letters ,\\n2018.\\n[70] C. Xiao, D. Yang, Z. Chen, and G. Tan, “3-d ble indoor'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[69] C.-K. Wen, W.-T. Shih, and S. Jin, “Deep learning for massive\\nmimo csi feedback,” IEEE Wireless Communications Letters ,\\n2018.\\n[70] C. Xiao, D. Yang, Z. Chen, and G. Tan, “3-d ble indoor\\nlocalization based on denoising autoencoder,” IEEE Access ,\\nvol. 5, pp. 12 751–12 760, 2017.\\n[71] T. J. O’Shea, T. Roy, and N. West, “Approximating the void:\\nLearning stochastic channel models from observation with\\nvariational generative adversarial networks,” arXiv preprint\\narXiv:1805.06350, 2018.\\n[72] H. Ye, G. Y . Li, B.-H. F. Juang, and K. Sivanesan, “Channel\\nagnostic end-to-end learning based communication systems\\nwith conditional gan,” arXiv preprint arXiv:1807.00447 , 2018.\\n[73] F. Liang, C. Shen, W. Yu, and F. Wu, “Towards Optimal Power\\nControl via Ensembling Deep Neural Networks,”ArXiv e-prints,\\nJul. 2018.\\n[74] D. Neumann, T. Wiese, and W. Utschick, “Learning the mmse\\nchannel estimator,” IEEE Transactions on Signal Processing ,\\n2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='Jul. 2018.\\n[74] D. Neumann, T. Wiese, and W. Utschick, “Learning the mmse\\nchannel estimator,” IEEE Transactions on Signal Processing ,\\n2018.\\n[75] K. Davaslioglu and Y . E. Sagduyu, “Generative ad-\\nversarial learning for spectrum sensing,” arXiv preprint\\narXiv:1804.00709, 2018.\\n[76] A. Abdelnasser, E. Hossain, and D. I. Kim, “Clustering and\\nresource allocation for dense femtocells in a two-tier cellular\\nofdma network,” IEEE Transactions on Wireless Communica-\\ntions, vol. 13, no. 3, pp. 1628–1641, 2014.\\n[77] A. A. Abbasi and M. Younis, “A survey on clustering algo-\\nrithms for wireless sensor networks,” Computer communica-\\ntions, vol. 30, no. 14-15, pp. 2826–2841, 2007.\\n[78] E. Abbe, A. S. Bandeira, and G. Hall, “Exact recovery in the\\nstochastic block model,” arXiv preprint arXiv:1405.3267, 2014.\\n[79] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank\\ncitation ranking: Bringing order to the web.” Stanford InfoLab,\\nTech. Rep., 1999.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-11-06T02:54:33+00:00', 'author': '', 'keywords': '', 'moddate': '2018-11-06T02:54:33+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ML intro.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20', 'source_file': 'ML intro.pdf', 'file_type': 'pdf'}, page_content='[79] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank\\ncitation ranking: Bringing order to the web.” Stanford InfoLab,\\nTech. Rep., 1999.\\n[80] C. Karakus, Y . Sun, S. Diggavi, and W. Yin, “Redundancy\\ntechniques for straggler mitigation in distributed optimization\\nand learning,” arXiv preprint arXiv:1803.05397 , 2018.\\n20')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2f1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert the text\n",
    "texts = [doc.page_content for doc in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaaae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 703 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22/22 [00:11<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (703, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Generate embedding \n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d018fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06859832, -0.0196328 ,  0.13569172, ...,  0.04772124,\n",
       "        -0.10425296,  0.04991322],\n",
       "       [ 0.01080389,  0.04381944, -0.02950113, ...,  0.09828102,\n",
       "         0.0225188 , -0.02271296],\n",
       "       [ 0.03615247, -0.05212416, -0.0576537 , ...,  0.02717868,\n",
       "        -0.04543386,  0.04596977],\n",
       "       ...,\n",
       "       [-0.05402548, -0.04097266,  0.04875919, ...,  0.09031661,\n",
       "        -0.14548384,  0.05893738],\n",
       "       [-0.06312645, -0.04029313,  0.00369945, ..., -0.02250622,\n",
       "        -0.11598643, -0.00098798],\n",
       "       [-0.08754771, -0.01736764, -0.07827104, ..., -0.04052905,\n",
       "        -0.03786953,  0.07347643]], shape=(703, 384), dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c79d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 703 documents to vector store...\n",
      "Successfully added 703 documents to vector store\n",
      "Total documents in collection: 703\n"
     ]
    }
   ],
   "source": [
    "vectorstore.add_documents(chunks,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90efcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
