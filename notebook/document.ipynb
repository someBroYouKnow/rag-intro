{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9f063d",
   "metadata": {},
   "source": [
    "### Data Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65de02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Document Structure \n",
    "\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8eb587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc  = Document(\n",
    "    page_content='this is the main text content I am using for RAG',\n",
    "    metadata= {\n",
    "        \"source\": \"example.txt\",\n",
    "        \"pages\": 1,\n",
    "        \"author\":\"Batman\",\n",
    "        \"date_created\": \"2025-01-01\"\n",
    "    }\n",
    ")\n",
    "## This is helpful in applying filters to search things by , talking of metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b779889",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a txt file \n",
    "import os \n",
    "os.makedirs(\"../data/text_files\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2ad537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"✅ Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fede8bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "### TextLoader \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader \n",
    "# This shenanigan is to use whatever is not deprecatedl. \n",
    "\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\", encoding= \"utf-8\")\n",
    "#\n",
    "#If a class does not define a special __str__ method, Python falls back to __repr__.\n",
    "\n",
    "# Many libraries (including langchain) don’t bother implementing both, so str(loader) and repr(loader) return the same string.\n",
    "###\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41200fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory loader \n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the dierctory \n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\", \n",
    "    glob= \"**/*.txt\",\n",
    "    loader_cls = TextLoader, ### loader class to use \n",
    "    loader_kwargs = {'encoding': \"utf-8\"}, \n",
    "    show_progress= False\n",
    ")\n",
    "\n",
    "dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ded1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "## load all pdfs \n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/pdf\", \n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyMuPDFLoader,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "pdf_documents = dir_loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508030a4",
   "metadata": {},
   "source": [
    "embedding and vector store db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4be52a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sentence_transformers import SentenceTransformer ### model for embedding \n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca1d41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager: \n",
    "    \"\"\"Handles document embedding generation using SentenceTranformer\"\"\"\\\n",
    "    \n",
    "    def __init__(self, model_name: str= \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialise the embedding manager \n",
    "\n",
    "        Atrgs: \n",
    "        model_name: HigghingFace model name for sentence embedding \n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None  ## we willl initialise this value later \n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension : {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts \n",
    "\n",
    "        Args: \n",
    "            texts: List of text strings to embed \n",
    "\n",
    "        Returns: \n",
    "            numpy array of embeddings with shape (len(texts), embeeding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded \")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts ... \")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings \n",
    "    \n",
    "    def get_embedding_dimension(self) -> int: \n",
    "        \"\"\"Get the embedding dimension of the model  \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        return self.model.get_sentence_embedding_dimension()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e261dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Learning\\AI\\rag-intro\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashis\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully. Embedding dimension : 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x145ff0ce900>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_manager= EmbeddingManager() ## initalise \n",
    "embedding_manager "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f1f65",
   "metadata": {},
   "source": [
    "### Vector Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bb6305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vector Store \n",
    "class VectorStore: \n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store \"\"\"\n",
    "\n",
    "    def __init__(self , collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Intialise the vector store \n",
    "\n",
    "        Args: \n",
    "            collection_name: Name of the ChromaDB colelction \n",
    "            persist_directory: Directory to persist the vector store \n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None \n",
    "        self.collection = None \n",
    "        self._initialise_store()\n",
    "\n",
    "\n",
    "    def _initialise_store(self):\n",
    "        \"\"\"Initialise ChromaDb client and collection \"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok = True)\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "\n",
    "            # Get or create collection \n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata= {\"description\":\"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialised. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error initialising vector store: {e}\")\n",
    "            raise     \n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings tot heri vector store \n",
    "\n",
    "        Args: \n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Correspoinding embeddings for the documents \n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings): \n",
    "            raise ValueError(\"Number of documents must match number of embeddings \")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        ids=[]\n",
    "        metadatas = []\n",
    "        documents_text=[]\n",
    "        embeddings_list= []\n",
    "\n",
    "        for i, (doc,embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # generate Unique ID \n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Prepare metadata \n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding content\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas= metadatas,\n",
    "                documents= documents_text\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store \")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e: \n",
    "            print(f\"Error adding documents to vector store : {e}\")\n",
    "            raise \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc6fce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialised. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x145d3119550>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = VectorStore()\n",
    "vectorstore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "908e7eba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### convert the text to embeddings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m texts= [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchunks\u001b[49m]\n\u001b[32m      3\u001b[39m texts\n",
      "\u001b[31mNameError\u001b[39m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "### convert the text to embeddings\n",
    "texts= [doc.page_content for doc in chunks]\n",
    "texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
